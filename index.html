<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>Yancy&#39;s blog</title>
	<link rel="stylesheet" href="/css/style.css" />
	
      <link rel="alternate" href="/atom.xml" title="Yancy&#39;s blog" type="application/atom+xml">
    
</head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/" class="header__link">Home</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/archives" class="header__link">ARCHIVES</a>
			
				<a href="/about/About" class="header__link">ABOUT</a>
			
				<a href="http://weibo.com/yangcvo" class="header__link">Weibo</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Yancy&#39;s blog</a></h1>
		<h2 class="header__subtitle">SIMPLICITY IS PREREQUISITE FOR  RELIABILITY</h2>
	</header>

	<main>
		



	<article>
	
		<h1><a href="/2017/10/11/Bigdata-hadoop/Kafka/KafKa从0.8.2.1升级到0.9.0.1变化方案与步骤/">KafKa从0.8.2.1升级到0.9.0.1变化方案与步骤</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-10-11</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<h2 id="KafKa从0-8-2-1升级到0-9-0-1变化方案与步骤"><a href="#KafKa从0-8-2-1升级到0-9-0-1变化方案与步骤" class="headerlink" title="KafKa从0.8.2.1升级到0.9.0.1变化方案与步骤"></a>KafKa从0.8.2.1升级到0.9.0.1变化方案与步骤</h2><p>🍊我这里是采用,群集升级,全部更新停止老版本zk和kafka更新服务。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">9.0.0有潜在的中断更改风险（在升级之前需要知道），并且与之前版本的broker之间的协议改变。这意味着此次升级可能和客户端旧版本不兼容。因此在升级客户端之前，先升级kafka集群。如果你使用MirrorMaker下游集群，则同样应首先升级。</div><div class="line"></div><div class="line"><span class="comment">### 滚动升级</span></div><div class="line"></div><div class="line">升级所有broker的server.properties,并在其中添加</div><div class="line">inter.broker.protocol.version = 0.8.2.X</div><div class="line">每次升级一个broker：关闭broker，替换新版本，然后重新启动。</div><div class="line"></div><div class="line"><span class="comment">### 群集升级</span></div><div class="line">一旦整个群集升级，通过编辑inter.broker.protocol.version并将其设置为0.9.0.0来转换所有协议。</div><div class="line">逐个重新启动broker，使新协议版本生效。</div><div class="line">注意 ：如果你可接受停机，你可以简单地将所有broker关闭，更新版本并重启启动，协议将默认从新版本开始。</div><div class="line">注意 ：变换协议版本和重启启动可以在broker升级完成后的任何时间去做，不必马上做。</div></pre></td></tr></table></figure>
		<p><a class="article__read-more-link" href="/2017/10/11/Bigdata-hadoop/Kafka/KafKa从0.8.2.1升级到0.9.0.1变化方案与步骤/">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/10/11/Bigdata-hadoop/Kafka/KafKa扩容群集(Topic.partitions迁移)/">KafKa扩容群集(Topic.partitions迁移)</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-10-11</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<h4 id="kafka的扩容难点："><a href="#kafka的扩容难点：" class="headerlink" title="kafka的扩容难点："></a>kafka的扩容难点：</h4><p>1）主要在于增加机器之后，数据需要rebalance到新增的空闲节点，即把partitions迁移到空闲机器上。<br>kafka提供<code>bin/kafka-reassign-partitions.sh</code>工具，完成parttition的迁移。</p>
<p>2）kafka的集群的数据量加大，数据rebalance的时间较长。解决办法是把<code>log.retention.hours=1</code>设置一小时（生产参数24小时）。<br>修改参数之后，重启kakfa节点，kafka会主动purge 1小时之前的log数据。<br>以下是kafka_0.8.1.1版本kafkka集群扩容操作记录，从3台物理机扩容到4台物理，partition数量由24个增加到28个。</p>
<p>参考：<a href="http://kafka.apache.org/081/documentation.html#basic_ops_modify_topic" target="_blank" rel="external">http://kafka.apache.org/081/documentation.html#basic_ops_modify_topic</a></p>
<p>将服务器添加到Kafka集群非常简单，只需为其分配唯一的代理ID，然后在新服务器上启动Kafka。但是，这些新的服务器不会自动分配任何数据分区，除非将分区移动到这些分区，否则直到创建新主题时才会执行任何工作。所以通常当你将机器添加到你的群集中时，你会想把一些现有的数据迁移到这些机器上。<br>数据迁移过程是手动启动的，但是完全自动化。下面介绍的是，Kafka会将新服务器添加为正在迁移的分区的跟随者，并允许其完全复制该分区中的现有数据。当新服务器完全复制了此分区的内容并加入了同步副本时，其中一个现有副本将删除其分区的数据。</p>
<p>分区重新分配工具可用于跨代理移动分区。理想的分区分布将确保所有代理的数据加载和分区大小。分区重新分配工具不具备自动研究Kafka集群中的数据分布并移动分区以实现均匀负载分配的功能。因此，管理员必须找出哪些主题或分区应该移动。</p>
<p>分区重新分配工具可以运行在3个互斥的模式中：</p>
<ul>
<li>生成：在此模式下，给定主题列表和经纪人列表，该工具会生成候选重新​​分配，以将指定主题的所有分区移至新经纪人。此选项仅提供了一种便捷的方式，可以根据主题和目标代理列表生成分区重新分配计划。<br>–execute：在此模式下，该工具根据用户提供的重新分配计划启动分区重新分配。（使用–reassignment-json-file选项）。这可以是由管理员制作的自定义重新分配计划，也可以是使用–generate选项提供的自定义重新分配计划<br>–verify：在此模式下，该工具会验证上次执行过程中列出的所有分区的重新分配状态。状态可以是成功完成，失败或正在进行</li>
</ul>
<p>自动将数据迁移到新机器</p>
<p>分区重新分配工具可用于将当前一组经纪人的一些主题移到新增的经纪人。这在扩展现有集群时通常很有用，因为将整个主题移动到新的代理集比移动一个分区更容易。用于这样做时，用户应该提供应该移动到新的经纪人集合和新的经纪人的目标列表的主题列表。然后，该工具在新的代理集合上均匀分配给定主题列表的所有分区。在此过程中，主题的复制因子保持不变。有效地，主题输入列表的所有分区副本都从旧的代理集合移动到新添加的代理。<br>例如，以下示例将把主题<code>countly_apppush，countly_event...</code>的所有分区移动到新的代理集4 。在本次移动结束时，主题<code>countly_apppush，countly_event...</code>的所有分区将仅存在于代理4上。</p>
<h5 id="1-kafka-扩容"><a href="#1-kafka-扩容" class="headerlink" title="1.kafka 扩容"></a>1.kafka 扩容</h5><p>首先按照搭建步骤，在其他机器上搭建集群，kafka的配置文件中 zkconnect 要保持与原kafka一致<br>kafka版本一致，配置跟之前kafka集群一致，只需要修改本地kafka的地址.</p>
<h5 id="2-验证kafka新节点是否加入集群成功，这个应该去zookeeper的zkCli-sh-去查看"><a href="#2-验证kafka新节点是否加入集群成功，这个应该去zookeeper的zkCli-sh-去查看" class="headerlink" title="2.验证kafka新节点是否加入集群成功，这个应该去zookeeper的zkCli.sh 去查看"></a>2.验证kafka新节点是否加入集群成功，这个应该去zookeeper的zkCli.sh 去查看</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@kafka1 bin]<span class="comment"># ./zkCli.sh -server  10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281</span></div><div class="line">[zk: 10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281(CONNECTED) 0] ls /brokers/ids/</div><div class="line">1,2,3,4</div></pre></td></tr></table></figure>
<h5 id="3-由于该工具接受主题的输入列表作为json文件，因此首先需要确定要移动的主题并创建json文件，如下所示："><a href="#3-由于该工具接受主题的输入列表作为json文件，因此首先需要确定要移动的主题并创建json文件，如下所示：" class="headerlink" title="3.由于该工具接受主题的输入列表作为json文件，因此首先需要确定要移动的主题并创建json文件，如下所示："></a>3.由于该工具接受主题的输入列表作为json文件，因此首先需要确定要移动的主题并创建json文件，如下所示：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"topics"</span>: [&#123;<span class="string">"topic"</span>: <span class="string">"countly_apppush"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"countly_event"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"countly_imp"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"countly_metrics"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"countly_pv"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"countly_session"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"mongotail_lz4"</span>&#125;,</div><div class="line">            &#123;<span class="string">"topic"</span>: <span class="string">"mongotail_lz4_imp"</span>&#125;</div><div class="line">            ],</div><div class="line"> <span class="string">"version"</span>:1</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="4-一旦json文件准备就绪，使用分区重新分配工具来生成候选分配："><a href="#4-一旦json文件准备就绪，使用分区重新分配工具来生成候选分配：" class="headerlink" title="4.一旦json文件准备就绪，使用分区重新分配工具来生成候选分配："></a>4.一旦json文件准备就绪，使用分区重新分配工具来生成候选分配：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">bin/kafka-reassign-partitions.sh --zookeeper 10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281 --topics-to-move-json-file topics-to-move.json --broker-list <span class="string">"1,2,3,4"</span> --generate</div><div class="line"></div><div class="line"></div><div class="line">[jollybi@kafka3 kafka_2.10-0.9.0.1]$ bin/kafka-reassign-partitions.sh --zookeeper 10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281 --topics-to-move-json-file topics-to-move.json --broker-list <span class="string">"1,2,3,4"</span> --generate</div><div class="line">Current partition replica assignment</div><div class="line"></div><div class="line">&#123;<span class="string">"version"</span>:1,<span class="string">"partitions"</span>:[&#123;<span class="string">"topic"</span>:<span class="string">"countly_metrics"</span>,<span class="string">"partition"</span>:7,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_event"</span>,<span class="string">"partition"</span>:6,<span class="string">"replicas"</span>:[1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[3,2,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:0,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:5,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_apppush"</span>,<span class="string">"partition"</span>:0,<span class="string">"replicas"</span>:[2,3,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_session"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:9,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_metrics"</span>,<span class="string">"partition"</span>:2,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_session"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[3,1,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[2,3,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_apppush"</span>,<span class="string">"partition"</span>:6,<span class="string">"replicas"</span>:[2,3,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:11,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:3,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_metrics"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_metrics"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:10,<span class="string">"replicas"</span>:[3,2,1]&#125;,</div><div class="line">.....</div><div class="line"></div><div class="line">Proposed partition reassignment configuration</div><div class="line"></div><div class="line">&#123;<span class="string">"version"</span>:1,<span class="string">"partitions"</span>:[&#123;<span class="string">"topic"</span>:<span class="string">"countly_event"</span>,<span class="string">"partition"</span>:6,<span class="string">"replicas"</span>:[3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_metrics"</span>,<span class="string">"partition"</span>:7,<span class="string">"replicas"</span>:[4,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:0,<span class="string">"replicas"</span>:[2,3,4]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:5,<span class="string">"replicas"</span>:[3,4,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[2,4,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_apppush"</span>,<span class="string">"partition"</span>:0,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:9,<span class="string">"replicas"</span>:[3,1,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_session"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_metrics"</span>,<span class="string">"partition"</span>:2,<span class="string">"replicas"</span>:[3,4,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_session"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[1,4,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[2,4,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_apppush"</span>,<span class="string">"partition"</span>:6,<span class="string">"replicas"</span>:[3,1,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_imp"</span>,<span class="string">"partition"</span>:11,<span class="string">"replicas"</span>:[1,3,4]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"countly_pv"</span>,<span class="string">"partition"</span>:3,<span class="string">"replicas"</span>:[1,2,3]&#125;</div><div class="line">......</div></pre></td></tr></table></figure>
<p>其中的<code>Current partition replica assignment</code>指的是迁移前的partition replica；Proposed partition reassignment configuration 指的就是迁移分配规则json。需要将该<code>[Proposed partition reassignment configuration]</code>json文件保存到json文件中(如expand-cluster-reassignment.json)</p>
<p>该工具会生成一个候选分配，将所有分区从主题<code>countly_apppush，countly_event...</code>移动到<code>brokers 1,2,3,4</code>但是，请注意，在这一点上，分区运动还没有开始，它只是告诉你当前的任务和建议的新任务。应该保存当前的分配，以防你想要回滚到它。新的任务应该保存在一个json文件中<code>（例如expand-cluster-reassignment.json）</code>，并用<code>--execute</code>选项输入到工具中，如下所示:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">./bin/kafka-reassign-partitions.sh --zookeeper 10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281  --reassignment-json-file expand-cluster-reassignment.json --execute</div><div class="line">Current partition replica assignment</div><div class="line"></div><div class="line">&#123;<span class="string">"version"</span>:1,<span class="string">"partitions"</span>:[&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:9,<span class="string">"replicas"</span>:[2,3,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:7,<span class="string">"replicas"</span>:[3,2,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:6,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:5,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:2,<span class="string">"replicas"</span>:[1,3,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:1,<span class="string">"replicas"</span>:[3,2,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[3,1,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:0,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:10,<span class="string">"replicas"</span>:[3,1,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:3,<span class="string">"replicas"</span>:[2,3,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:11,<span class="string">"replicas"</span>:[1,2,3]&#125;]&#125;</div><div class="line"></div><div class="line">Save this to use as the --reassignment-json-file option during rollback</div><div class="line">Successfully started reassignment of partitions &#123;<span class="string">"version"</span>:1,<span class="string">"partitions"</span>:[&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:3,<span class="string">"replicas"</span>:[3,4,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:8,<span class="string">"replicas"</span>:[4,3,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:0,<span class="string">"replicas"</span>:[4,1,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:6,<span class="string">"replicas"</span>:[2,4,1]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:11,<span class="string">"replicas"</span>:[3,2,4]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:1,<span class="string">"replicas"</span>:[1,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:10,<span class="string">"replicas"</span>:[2,1,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:4,<span class="string">"replicas"</span>:[4,2,3]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:9,<span class="string">"replicas"</span>:[1,4,2]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:2,<span class="string">"replicas"</span>:[2,3,4]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:5,<span class="string">"replicas"</span>:[1,3,4]&#125;,&#123;<span class="string">"topic"</span>:<span class="string">"mongotail_lz4_imp"</span>,<span class="string">"partition"</span>:7,<span class="string">"replicas"</span>:[3,1,2]&#125;]&#125;</div><div class="line">``` </div><div class="line"></div><div class="line"></div><div class="line">最后，可以使用`--verify`选项来检查分区重新分配的状态。</div><div class="line">请注意，相同的`expand-cluster-reassignment.json`（与`--execute`选项一起使用）应该与--verify选项一起使用</div><div class="line"></div><div class="line">```BASH</div><div class="line">/bin/kafka-reassign-partitions.sh --zookeeper 10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281  --reassignment-json-file expand-cluster-reassignment.json  --verify</div><div class="line"></div><div class="line">[jollybi@kafka4 kafka_2.10-0.9.0.1]$ ./bin/kafka-reassign-partitions.sh --zookeeper 10.155.90.153:2281,10.155.90.155:2281,10.155.90.138:2281  --reassignment-json-file expand-cluster-reassignment.json  --verify</div><div class="line">Status of partition reassignment:</div><div class="line">Reassignment of partition [countly_event,2] completed successfully</div><div class="line">Reassignment of partition [countly_session,7] completed successfully</div><div class="line">Reassignment of partition [countly_pv,5] completed successfully</div><div class="line">Reassignment of partition [countly_apppush,1] completed successfully</div><div class="line">Reassignment of partition [countly_event,0] completed successfully</div><div class="line">Reassignment of partition [countly_session,10] completed successfully</div><div class="line">Reassignment of partition [countly_apppush,4] completed successfully</div><div class="line">Reassignment of partition [countly_event,7] is still <span class="keyword">in</span> progress</div><div class="line">Reassignment of partition [countly_metrics,7] completed successfully</div><div class="line">Reassignment of partition [countly_imp,4] is still <span class="keyword">in</span> progress</div><div class="line">Reassignment of partition [countly_apppush,10] completed successfully</div><div class="line">Reassignment of partition [countly_imp,5] is still <span class="keyword">in</span> progress</div><div class="line">.....</div></pre></td></tr></table></figure>
<p>注意：在迁移过程中不能人为的结束或停止kafka服务，不然会有数据不一致的问题.</p>

	

	

</article>




	<article>
	
		<h1><a href="/2017/09/21/性能监控/Zabbix/ZABBIX monitoring Flume/">ZABBIX monitoring Flume</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-09-21</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/monitoring/">monitoring</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Zabbix-monitoring/">Zabbix monitoring</a>
			</span>
		
	</div>

	

	
		<h3 id="ZABBIX-monitoring-Flume"><a href="#ZABBIX-monitoring-Flume" class="headerlink" title="ZABBIX monitoring Flume"></a>ZABBIX monitoring Flume</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Flume本身提供了http, ganglia的监控服务，而我们目前主要使用zabbix做监控。因此，我们为Flume添加了zabbix监控模块，和sa的监控服务无缝融合。</div><div class="line">另一方面，净化Flume的metrics。只将我们需要的metrics发送给zabbix，避免 zabbix server造成压力。目前我们最为关心的是Flume能否及时把应用端发送过来的日志写到Hdfs上， 对应关注的metrics为：</div><div class="line">Source : 接收的event数和处理的event数</div><div class="line">Channel : Channel中拥堵的event数</div><div class="line">Sink : 已经处理的event数</div></pre></td></tr></table></figure>
		<p><a class="article__read-more-link" href="/2017/09/21/性能监控/Zabbix/ZABBIX monitoring Flume/">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/09/11/Bigdata-hadoop/Kafka/KafKa不懂就学就问就解答笔记/">KafKa不懂就学就问就解答笔记</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-09-11</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<h2 id="kafka不懂就学笔记"><a href="#kafka不懂就学笔记" class="headerlink" title="kafka不懂就学笔记"></a>kafka不懂就学笔记</h2><h5 id="1-部署生产环境，打算部署三个broker实例，但zookeeper部署一个可以吗"><a href="#1-部署生产环境，打算部署三个broker实例，但zookeeper部署一个可以吗" class="headerlink" title="1. 部署生产环境，打算部署三个broker实例，但zookeeper部署一个可以吗?"></a>1. 部署生产环境，打算部署三个broker实例，但zookeeper部署一个可以吗?</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">答案：可以是可以，但为了容错还是部署zookeeper集群比较好。broker和zookeeper的对应比例倒是没什么，都是独立集群。</div></pre></td></tr></table></figure>
<h5 id="2-kafka集群为什么需要zookeeper来配合？"><a href="#2-kafka集群为什么需要zookeeper来配合？" class="headerlink" title="2. kafka集群为什么需要zookeeper来配合？"></a>2. kafka集群为什么需要zookeeper来配合？</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">答案：zookeeper 是作为性能协调工具的角色存在。存储着你Kafka服务的一些些元数据（partitions、offset等等）。zookeeper集群的作用在于保证Zookeeper服务的高可用。因此你可以根据你的需要来选择是否构建zookeeper集群。</div></pre></td></tr></table></figure>
<h5 id="3-查看kafka-topic-消费记录报错WARN-Session-0x0-for-server-null-unexpected-error-closing-socket-connection-and-attempting-reconnect-org-apache-zookeeper-ClientCnxn"><a href="#3-查看kafka-topic-消费记录报错WARN-Session-0x0-for-server-null-unexpected-error-closing-socket-connection-and-attempting-reconnect-org-apache-zookeeper-ClientCnxn" class="headerlink" title="3. 查看kafka topic 消费记录报错WARN Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)"></a>3. 查看kafka topic 消费记录报错WARN Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)</h5><p>java.net.ConnectException: Connection timed out</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">问题：</div><div class="line">1.是kafka连不上zookeeper了。请检查 zk 集群是否正常能Telnet，kafka集群是否正常。</div><div class="line">2.检查server.properties 中zookeeper.connect是否配置正确，如果都没有问题，重新启动服务。</div></pre></td></tr></table></figure>
<h5 id="4-kafka-支持压缩传输吗？"><a href="#4-kafka-支持压缩传输吗？" class="headerlink" title="4. kafka 支持压缩传输吗？"></a>4. kafka 支持压缩传输吗？</h5><h5 id="5-Kafka-如何在开启数据压缩的情况下-consumer维护自己的offset"><a href="#5-Kafka-如何在开启数据压缩的情况下-consumer维护自己的offset" class="headerlink" title="5. Kafka 如何在开启数据压缩的情况下, consumer维护自己的offset?"></a>5. Kafka 如何在开启数据压缩的情况下, consumer维护自己的offset?</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">问题：</div><div class="line">kafka这边数据传输消费跨aws机房较慢。会有网络瓶颈,我们kafka在国外的一dalasi机房，消费端在dalasi。</div><div class="line"></div><div class="line">官网解答：</div><div class="line">Offset management on the consumer</div><div class="line"></div><div class="line">The data received by a consumer <span class="keyword">for</span> a topic might contain both compressed as well as uncompressed messages. The consumer iterator transparently decompresses compressed data and only returns an uncompressed message. The offset maintenance <span class="keyword">in</span> the consumer gets a little tricky. In the zookeeper consumer, the consumed offset is updated each time a message is returned. This consumed offset should be a valid fetch offset <span class="keyword">for</span> correct failure recovery. Since data is stored <span class="keyword">in</span> compressed format on the broker, valid fetch offsets are the compressed message boundaries. Hence, <span class="keyword">for</span> compressed data, the consumed offset will be advanced one compressed message at a time. This has the side effect of possible duplicates <span class="keyword">in</span> the event of a consumer failure. For uncompressed data, consumed offset will be advanced one message at a time.</div><div class="line"></div><div class="line">这段话不是很理解: producer将100条message压缩成1条发给broker后, broker是如何存储的，并且consumer是如何取出这压缩后的数据, 并维护offset的?</div><div class="line"></div><div class="line"><span class="comment">### 消息压缩（message compression）</span></div><div class="line"></div><div class="line">考虑到网络带宽的瓶颈，Kafka提供了消息组压缩特性。Kafka通过递归消息集来支持高效压缩。高效压缩需要多个消息同时压缩，而不是对每个消息单独压缩。一批消息压缩在一起发送给broker。压缩消息集降低了网络的负载，但是解压缩也带来了一些额外的开销。消息集的解压缩是由broker处理消息offset时完成的。</div><div class="line"></div><div class="line">每个消息可通过一个不可比较的、递增的逻辑offset访问，这个逻辑offset在每个分区内是唯一的。接收到压缩数据后，lead broker将消息集解压缩，为每个消息分配offset。offset分配完成后，leader再次将消息集压缩并写入磁盘。</div><div class="line"></div><div class="line">在Kafka中，数据的压缩由producer完成，可使用GZIP或Snappy压缩协议。同时需要在producer端配置相关的参数：</div><div class="line"></div><div class="line">compression.codec：指定压缩格式，默认为none，可选的值还有gzip和snappy。</div><div class="line">compressed.topics：设置对指定的topic开启压缩，默认为null。当compression.codec不为none时，对指定的topic开启压缩；如果compressed.topics为null则对所有topic开启压缩。</div><div class="line">消息集ByteBufferMessageSet可能既包含压缩数据也包含非压缩数据，为了区分开来，消息头中添加了压缩属性字节。在该字节中，最低位的两位表示压缩格式，如果都是0表示非压缩数据。</div></pre></td></tr></table></figure>

	

	

</article>




	<article>
	
		<h1><a href="/2017/08/27/Bigdata-hadoop/zookeeper/Bigdata-Zookeeper集群日志配置详解和清理自定义启动内存 /">Bigdata-Zookeeper集群日志配置详解和清理自定义启动内存</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-08-27</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata/">Bigdata</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/ZooKeeper/">ZooKeeper</a>
			</span>
		
	</div>

	

	
		<h4 id="Zookeeper集群日志配置详解和清理自定义启动内存"><a href="#Zookeeper集群日志配置详解和清理自定义启动内存" class="headerlink" title="Zookeeper集群日志配置详解和清理自定义启动内存"></a>Zookeeper集群日志配置详解和清理自定义启动内存</h4><h3 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h3><p>搭建zookeeper和kafka集群运行大数据处理数据消费，公司dubbo使用zookeeper做服务端的服务发现管理及配置中心，在使用时都出现过由于zk的日志大小过大塞满磁盘的情况 ，遇到了Zookeeper日志问题输出路径的问题, 发现zookeeper设置log4j.properties不能解决日志路径问题, 发现解决方案如下。</p>
<p><img src="http://7xrthw.com1.z0.glb.clouddn.com/zookeeper_cartoon.jpg" alt=""></p>
<h3 id="zookeeper日志说明"><a href="#zookeeper日志说明" class="headerlink" title="zookeeper日志说明"></a>zookeeper日志说明</h3><p>ZooKeeper使用<code>SLF4J(the Simple Logging Facade for Java)</code>作为日志的抽象层，默认使用<code>Log4J</code>来做实际的日志工作。使用2层日志抽象看起来真是够呛，这里简要的说明如何来配置<code>Log4J</code>。尽管Log4J非常灵活且强大，但它也有一些复杂，可以用一整本书来描述它，这里只是简要的介绍一下基本的用法。</p>
		<p><a class="article__read-more-link" href="/2017/08/27/Bigdata-hadoop/zookeeper/Bigdata-Zookeeper集群日志配置详解和清理自定义启动内存 /">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/08/04/Bigdata-hadoop/Kafka/Monitor Kafka with Prometheus +Grafana/">Monitor Kafka with Prometheus +Grafana</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-08-04</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Grafana/">Grafana</a> <a class="article__tag-link" href="/tags/Kafka/">Kafka</a> <a class="article__tag-link" href="/tags/Prometheus/">Prometheus</a>
			</span>
		
	</div>

	

	
		<h3 id="Monitoring-Kafka-with-Prometheus"><a href="#Monitoring-Kafka-with-Prometheus" class="headerlink" title="Monitoring Kafka with Prometheus"></a>Monitoring Kafka with Prometheus</h3><p>We’ve previously looked at how to monitor Cassandra with <a href="https://www.robustperception.io/monitoring-cassandra-with-prometheus/" target="_blank" rel="external">Prometheus</a>. Let’s see the process for getting metrics from another popular Java application, <a href="https://kafka.apache.org/" target="_blank" rel="external">Kafka.</a></p>
<p><img src="http://7xrthw.com1.z0.glb.clouddn.com/kafka-overview.png" alt=""></p>
		<p><a class="article__read-more-link" href="/2017/08/04/Bigdata-hadoop/Kafka/Monitor Kafka with Prometheus +Grafana/">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/08/01/Bigdata-hadoop/Kafka/Kafka-node模块实现调用js发送数据/">Bigdata-Kafka-node模块实现调用js发送数据</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-08-01</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/大数据/">大数据</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<p><img src="http://7xrthw.com1.z0.glb.clouddn.com/streams-interactive-queries-02.png" alt=""></p>
<p>mongodb写到kafka 指定topic消费。为了保证数据稳定可靠性。<br>配合大数据在countly 使用开源<code>Kafka-node</code>是一个Node.js客户端 写js程序让countly三台集群分别数据到kafka 做新的topic主题备份。</p>
		<p><a class="article__read-more-link" href="/2017/08/01/Bigdata-hadoop/Kafka/Kafka-node模块实现调用js发送数据/">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/07/29/Bigdata-hadoop/countly/Cloudera Manager5及CDH5安装指导/">Bigdata-Cloudera Manager5及CDH5安装指导</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-07-29</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Bigdata-Hadoop/">Bigdata Hadoop</a> <a class="article__tag-link" href="/tags/Countly/">Countly</a>
			</span>
		
	</div>

	

	
		<p><img src="http://7xrthw.com1.z0.glb.clouddn.com/Bigdata-Cloudera-Manager.png" alt=""></p>
<h3 id="问题导读："><a href="#问题导读：" class="headerlink" title="问题导读："></a>问题导读：</h3><p>1.什么是cloudera CM 、CDH?<br>2.CDH、CM有哪些版本？<br>3.CDH、CM有哪些安装方式？<br>4.CDH如何开发？</p>
		<p><a class="article__read-more-link" href="/2017/07/29/Bigdata-hadoop/countly/Cloudera Manager5及CDH5安装指导/">...read more</a></p>
	

	

</article>





	<span class="different-posts">📖 <a href="/page/2">more posts</a> 📖</span>



	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<h5>Hi there,</h5>
	<p style="text-align:justify;">my name is Yancy, they know me as Radiant🐑🐑. This blog is about Bi-data and my live.<br> I like 🌳🌳🌳</p>
</div>


	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2017 Yancy | Powered by <a href="http://blog.yancy.cc/">Yancy</a> | Theme <a href="https://github.com/yangcvo">Yancy_GitHub</a></span>
		</div>

	</div>


</footer>



</body>

</html>
