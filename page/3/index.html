<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>Yancy&#39;s blog</title>
	<link rel="stylesheet" href="/css/style.css" />
	
      <link rel="alternate" href="/atom.xml" title="Yancy&#39;s blog" type="application/atom+xml">
    
</head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/" class="header__link">Home</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/archives" class="header__link">ARCHIVES</a>
			
				<a href="/about/About" class="header__link">ABOUT</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Yancy&#39;s blog</a></h1>
		<h2 class="header__subtitle">SIMPLICITY IS PREREQUISITE FOR  RELIABILITY</h2>
	</header>

	<main>
		
	<span class="different-posts different-posts_earlier">📖 <a href="/page/2">earlier posts</a> 📖</span>




	<article>
	
		<h1><a href="/2017/04/05/运维笔记/【翻译】监控不只是为了处理故障/">【翻译】监控不只是为了处理故障</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-04-05</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/运维笔记/">运维笔记</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Performance-monitoring/">Performance monitoring</a>
			</span>
		
	</div>

	

	
		<h3 id="【翻译】监控不只是为了处理故障"><a href="#【翻译】监控不只是为了处理故障" class="headerlink" title="【翻译】监控不只是为了处理故障"></a>【翻译】监控不只是为了处理故障</h3><p>有一种普遍的想法认为监控只是在系统出错的时候能够发出报警，我们一直相信，监控系统的方方面面给予我们洞察业务内部机制的能力，并驱动我们做出决策。<br>不同的人有不同的监控方式，手动查看日志，接受报警或者24x7值守查看各种图表。不管你用那种方式，最重要的是及时收到报错和警告。<br>但是监控其实能做的更多。</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/Prometheus-Overview.png" alt=""></figure></p>
<p>监控不止用于故障时候发报警</p>
<p>监控系统不应该只是告诉你“这有一个问题”，它也要帮助你排查问题出现的原因,你不只是想在服务变慢的时候收到报警，你其实想知道过去几小时流量是否增加了，机器是不是宕机了，后端服务器是不是变慢了或者内部执行时间变长了。</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/Prometheus-Overview-1.png" alt=""></figure><br>在你的应用中集成监控模块</p>
<p>做为报警和排错重要手段，监控要在你的架构体系中拥有核心位置。要集成监控工具在你的所有代码逻辑中，而不仅仅是在边缘区域添加一点。跟踪每个请求提交api需要多少组件，以便你在设计新的存储系统是否能够知道要处理多少数据，跟踪内存的命中率，以便你能度量它们随着流量模式变化的规律，甚至分解到memcached中来节省内存和提高命中率。跟踪用户命中你的业务逻辑的”慢路径“，以便你知道它什么时候可以更快，并且当新的功能使用”慢路径“的时候，你已经准备好了让它”延迟命中“。<br>在你的代码内部，做这样大量的细节工作，可以让你前进的更快，技术和产品决策会受益良多，根本上提升了你的效率。这就是监控的意义所在，监控不只是为了处理故障。</p>
<blockquote>
<p>原文 <a href="https://www.robustperception.io/monitoring-not-just-for-outages/" target="_blank" rel="external">https://www.robustperception.io/monitoring-not-just-for-outages/</a></p>
</blockquote>
<h3 id="交流学习："><a href="#交流学习：" class="headerlink" title="交流学习："></a>交流学习：</h3><p>🐧  Linux shell_高级运维派: <code>459096184</code>    圈子 (系统运维-应用运维-自动化运维-虚拟化技术研究欢迎加入)<br>🐧  BigData-Exchange School : <code>521621407</code>  圈子（大数据运维)（Hadoop开发人员)（大数据研究爱好者) 欢迎加入</p>
<p>相应Bidata有内部微信交流群互相学习，加入QQ群有链接。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2017/03/30/日志分析平台/Elasticsearch/研究学习 Elasticsearch 5.0.0 功能提升哪些,ES如何弹性迁移日志数据，安装需要什么环境？/">研究学习 Elasticsearch 5.0.0 功能提升哪些,ES如何弹性迁移日志数据，安装需要什么环境？</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-03-30</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Log-Analysis-Platform/">Log Analysis Platform</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Elasticsearch/">Elasticsearch</a>
			</span>
		
	</div>

	

	
		<p><img src="http://img13.deviantart.net/1fb9/i/2013/051/6/1/ella_vs__elastic_yoko_by_gamepal-d5vmtjm.png" alt=""></p>
<p>ES 现在普遍大公司都已经在使用，有的用来做数据存储，也有做性能监控，也有做日志收集，跟大数据结合做日志分析。<br>今天在家无聊研究官网学习了下Elasticsearch5.0.0 功能新增哪些，个人觉得ES也是现在开源日志分析平台比较火的，从14年开始陆续使用频率不断提升。<br>之前也有了解过Graylog  现在比ES 做数据存储分析 不错的是Graylog 比ES性能好。<br>废话不多说了哈哈</p>
		<p><a class="article__read-more-link" href="/2017/03/30/日志分析平台/Elasticsearch/研究学习 Elasticsearch 5.0.0 功能提升哪些,ES如何弹性迁移日志数据，安装需要什么环境？/">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/03/30/Bigdata-hadoop/Kafka/Kafka日志存储解析与实践数据存储优化/">Kafka日志存储解析与实践数据存储优化</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-03-30</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<p><img src="https://cdn-images-1.medium.com/max/640/1*kV768OHeCILNIYVCNPUyuQ.jpeg" alt=""></p>
<h4 id="Kafka的名词解释"><a href="#Kafka的名词解释" class="headerlink" title="Kafka的名词解释"></a>Kafka的名词解释</h4><p>kafka是一款分布式消息发布和订阅的系统，具有高性能和高吞吐率。 </p>
<ul>
<li>1，<code>Broker</code>： 一个单独的kafka机器节点就称为一个broker，多个broker组成的集群，称为kafka集群</li>
<li>2，<code>Topic</code>：类似数据库中的一个表，我们将数据存储在Topic里面，当然这只是逻辑上的，在物理上，一个Topic 可能被多个Broker分区存储，这对用户是透明的，用户只需关注消息的产生于消费即可.</li>
<li>3，<code>Partition</code>：类似分区表，每个Topic可根据设置将数据存储在多个整体有序的Partition中，每个顺序化partition会生成2个文件，一个是index文件一个是log文件，index文件存储索引和偏移量，log文件存储具体的数据.</li>
<li>4，<code>Producer</code>：生产者，向Topic里面发送消息的角色 </li>
<li>5，<code>Consumer</code>：消费者，从Topic里面读取消息的角色 </li>
<li>6，<code>Consumer Group</code>：每个Consumer属于一个特定的消费者组，可为Consumer指定group name，如果不指定默认属于group </li>
</ul>
		<p><a class="article__read-more-link" href="/2017/03/30/Bigdata-hadoop/Kafka/Kafka日志存储解析与实践数据存储优化/">...read more</a></p>
	

	

</article>




	<article>
	
		<h1><a href="/2017/03/29/Bigdata-hadoop/countly/Bigdata-countly需要迁移/">Bigdata-countly需要迁移</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-03-29</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Bigdata-Hadoop/">Bigdata Hadoop</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Bigdata-Hadoop/">Bigdata Hadoop</a> <a class="article__tag-link" href="/tags/Countly/">Countly</a>
			</span>
		
	</div>

	

	
		<h4 id="官方安装文档：http-resources-count-ly-docs-installing-countly-server"><a href="#官方安装文档：http-resources-count-ly-docs-installing-countly-server" class="headerlink" title="官方安装文档：http://resources.count.ly/docs/installing-countly-server"></a>官方安装文档：<a href="http://resources.count.ly/docs/installing-countly-server" target="_blank" rel="external">http://resources.count.ly/docs/installing-countly-server</a></h4><p>目前<code>countly</code>需要迁移，所需<code>countly</code>版本于官方提供的安装方案有冲突，所以如下安装：</p>
<p>安装官方<code>countly</code>让其设置所需环境变量及其启动脚本，手动指定安装nojs版本，拷贝原countly文件，具体如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">1、<span class="built_in">cd</span> /data <span class="comment">#countly安装在data目录 我看了安装脚本，是当前在哪个目录，安装文件就在哪个目录</span></div><div class="line">wget -qO- http://c.ly/install | bash</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">2、rpm -qa | grep -i nodejs | xargs -I&#123;&#125;  yum remove &#123;&#125; -y</div><div class="line">卸载掉官网安装的最新nodejs 然后新建如下yum源，用于安装旧版所需nodejs，也可以到nodejs官网下载所需nodejs</div><div class="line">cat /etc/yum.repos.d/nodesource-el.repo </div><div class="line">[nodesource]</div><div class="line">name=Node.js Packages <span class="keyword">for</span> Enterprise Linux 7 - <span class="variable">$basearch</span></div><div class="line">baseurl=https://rpm.nodesource.com/pub_5.x/el/7/<span class="variable">$basearch</span></div><div class="line">failovermethod=priority</div><div class="line">enabled=1</div><div class="line">gpgcheck=1</div><div class="line">gpgkey=file:///etc/pki/rpm-gpg/NODESOURCE-GPG-SIGNING-KEY-EL</div><div class="line">[nodesource-source]</div><div class="line">name=Node.js <span class="keyword">for</span> Enterprise Linux 7 - <span class="variable">$basearch</span> - Source</div><div class="line">baseurl=https://rpm.nodesource.com/pub_5.x/el/7/SRPMS</div><div class="line">failovermethod=priority</div><div class="line">enabled=0</div><div class="line">gpgkey=file:///etc/pki/rpm-gpg/NODESOURCE-GPG-SIGNING-KEY-EL</div><div class="line">gpgcheck=1</div></pre></td></tr></table></figure>
<h3 id="安装老版本所需nodejs"><a href="#安装老版本所需nodejs" class="headerlink" title="安装老版本所需nodejs"></a>安装老版本所需nodejs</h3><figure class="highlight cmake"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum <span class="keyword">install</span> nodejs</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">3、拷贝源countly文件到/data/countly目录</div><div class="line">修改 /data/countly/api/config.js 和 /data/countly/frontend/express/config.js      </div><div class="line">3001端口和 6001端口监听地址换成 本地私有地址   <span class="comment">#源文件是监听的原来机器的内网地址，不修改的话，服务启动不了。</span></div></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="number">4</span><span class="string">、拷贝mongo数据目录到/data/mongo目录，修改mongo配置文件.</span></div><div class="line"></div><div class="line"><span class="string">cat</span> <span class="string">/etc/mongod.conf</span></div><div class="line"><span class="attr">systemLog:</span></div><div class="line"><span class="attr">       destination:</span> <span class="string">file</span></div><div class="line"><span class="attr">       logAppend:</span> <span class="literal">true</span></div><div class="line"><span class="attr">       path:</span> <span class="string">/data/mongodb/mongod.log</span></div><div class="line"><span class="attr">storage:</span></div><div class="line"><span class="attr">       dbPath:</span> <span class="string">/data/mongo</span></div><div class="line"><span class="attr">       journal:</span></div><div class="line"><span class="attr">             enabled:</span> <span class="literal">true</span></div><div class="line"><span class="attr">       engine:</span> <span class="string">mmapv1</span></div><div class="line"><span class="attr">processManagement:</span></div><div class="line"><span class="attr">       fork:</span> <span class="literal">true</span></div><div class="line"><span class="attr">       pidFilePath:</span> <span class="string">/data/mongodb/mongod.pid</span></div><div class="line"><span class="attr">net:</span></div><div class="line"><span class="attr">       port:</span> <span class="number">27017</span></div><div class="line"><span class="attr">       bindIp:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></div><div class="line"><span class="attr">security:</span></div><div class="line"><span class="attr">       authorization:</span> <span class="string">enabled</span></div><div class="line"><span class="attr">operationProfiling:</span></div><div class="line"><span class="attr">       slowOpThresholdMs:</span> <span class="number">40960</span></div></pre></td></tr></table></figure>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/Bigdatacountly01.jpeg" alt=""></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">5、修改硬盘block：</div><div class="line">     blockdev --setra 256 /dev/mapper/xvdc--vg-xvdc–lv    <span class="comment">##按照mongo提示操作</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">6、修改nginx配置文件  conf.d/default.conf</div><div class="line">      将127.0.0.1修改为本地私有地址</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">7、重启countly   mongodb  nginx</div><div class="line"></div><div class="line">countly restart</div><div class="line"></div><div class="line">/etc/init.d/mongod restart</div><div class="line"></div><div class="line">service nginx restart</div><div class="line">迁移完毕</div></pre></td></tr></table></figure>
<h3 id="交流学习："><a href="#交流学习：" class="headerlink" title="交流学习："></a>交流学习：</h3><p>🐧  Linux shell_高级运维派: <code>459096184</code>    圈子 (系统运维-应用运维-自动化运维-虚拟化技术研究欢迎加入)<br>🐧  BigData-Exchange School : <code>521621407</code>  圈子（大数据运维)（Hadoop开发人员)（大数据研究爱好者) 欢迎加入</p>
<p>相应Bidata有内部微信交流群互相学习，加入QQ群有链接。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2017/03/28/Bigdata-hadoop/Kafka/Bigdata-Kafka集群快速搭建与增删改查命令讲解/">Bigdata-Kafka集群快速搭建与命令讲解</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-03-28</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/大数据/">大数据</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Bigdata-Hadoop/">Bigdata Hadoop</a> <a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<h1 id="Bigdata-Kafka集群快速搭建与命令讲解"><a href="#Bigdata-Kafka集群快速搭建与命令讲解" class="headerlink" title="Bigdata-Kafka集群快速搭建与命令讲解"></a>Bigdata-Kafka集群快速搭建与命令讲解</h1><h3 id="kafka集群和zookeeper集群规范"><a href="#kafka集群和zookeeper集群规范" class="headerlink" title="kafka集群和zookeeper集群规范"></a>kafka集群和zookeeper集群规范</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">kafka集群和zookeeper集群规范</div><div class="line">kafka版本：kafka_2.10-0.8.2.1</div><div class="line">zookeeper版本：zookeeper-3.4.5</div><div class="line"></div><div class="line">启动用户：jollybi</div><div class="line">kafka安装目录：/data/tools/</div><div class="line">kafka新建消息目录：/data/tools/kafka_2.10-0.8.2.1/kafka-logs</div><div class="line"></div><div class="line">启动用户：jollybi</div><div class="line">zookeeper安装目录：/data/tools/</div><div class="line">zookeeper新建日志目录：/data/tools/zookeeper-3.4.5/tmp/logs</div><div class="line"></div><div class="line">统一配置hosts</div><div class="line"></div><div class="line"></div><div class="line">10.155.90.153 kafka1.jollychic.com kafka1</div><div class="line">10.155.90.155 kafka2.jollychic.com kafka2</div><div class="line">10.155.90.138 kafka3.jollychic.com kafka3</div></pre></td></tr></table></figure>
<p>本文使用了3台机器部署Kafka集群，IP和主机名对应关系如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">10.155.90.153 kafka1.jollychic.com kafka1</div><div class="line">10.155.90.155 kafka2.jollychic.com kafka2</div><div class="line">10.155.90.138 kafka3.jollychic.com kafka3</div></pre></td></tr></table></figure>
<h3 id="Step1-配置-etc-hosts-（3台一致）"><a href="#Step1-配置-etc-hosts-（3台一致）" class="headerlink" title="Step1: 配置/etc/hosts （3台一致）"></a>Step1: 配置/etc/hosts （3台一致）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">127.0.0.1 localhost.localdomain localhost</div><div class="line">10.155.90.153 kafka1.jollychic.com kafka1</div><div class="line">10.155.90.155 kafka2.jollychic.com kafka2</div><div class="line">10.155.90.138 kafka3.jollychic.com kafka3</div></pre></td></tr></table></figure>
<h3 id="Step2-环境KafKa集群环境"><a href="#Step2-环境KafKa集群环境" class="headerlink" title="Step2: 环境KafKa集群环境"></a>Step2: 环境KafKa集群环境</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">下载地址：http://mirrors.hust.edu.cn/apache/kafka/0.9.0.0/kafka_2.10-0.8.2.1.tgz</div><div class="line">[jollybi@kafka1 ]<span class="comment"># tar -xvf kafka_2.10-0.8.2.1.tgz -C /data/tools/</span></div><div class="line"><span class="built_in">cd</span> /data/tools/kafka_2.10-0.8.2.1/config</div></pre></td></tr></table></figure>
<h3 id="设置data目录，最好不要用默认的-tmp-kafka-logs"><a href="#设置data目录，最好不要用默认的-tmp-kafka-logs" class="headerlink" title="设置data目录，最好不要用默认的/tmp/kafka-logs"></a>设置data目录，最好不要用默认的/tmp/kafka-logs</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir -p /data/tools/kafka_2.10-0.8.2.1/kafka-logs/</div></pre></td></tr></table></figure>
<p><em>修改kafka配置文件</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[root@kafka_01 config]<span class="comment"># vim server.properties</span></div><div class="line"></div><div class="line"></div><div class="line"> 设置brokerid（从0开始，3个节点分别设为1,2,3，不能重复）在这里id=0跟zookeeper id设置一样就行。 集群机器：按顺序写1</div><div class="line">broker.id=1  </div><div class="line"></div><div class="line">auto.leader.rebalance.enable=<span class="literal">true</span> </div><div class="line"></div><div class="line"><span class="comment">#修改本地IP地址：</span></div><div class="line">listeners=PLAINTEXT://10.46.72.172:9092</div><div class="line">port=9292 //设置访问端口</div><div class="line">host.name=10.155.90.153   kafka本机IP</div><div class="line">log.dirs=/data/tools/kafka_2.10-0.8.2.1/kafka-logs</div><div class="line"></div><div class="line"><span class="comment">#设置注册地址（重要，默认会把本机的hostanme注册到zk中，客户端连接时需要解析该hostanme，所以这里直接注册本机的IP地址，避免hostname解析失败，报错java.nio.channels.UnresolvedAddressException或java.io.IOException: Can not resolve address）</span></div><div class="line"><span class="comment">#设置zookeeper地址</span></div><div class="line"><span class="comment">#zookeeper.connect=10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181</span></div><div class="line">zookeeper.connect=kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281</div><div class="line"></div><div class="line">//这里我设置hosts代替IP</div></pre></td></tr></table></figure>
<p><em>配置zookeeper地址</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">vim zookeeper.properties </div><div class="line">dataDir=/data/tools/zookeeper-3.4.5/tmp</div><div class="line"><span class="comment"># the port at which the clients will connect</span></div><div class="line">clientPort=2281</div><div class="line"><span class="comment"># disable the per-ip limit on the number of connections since this is a non-production config</span></div><div class="line">maxClientCnxns=0</div><div class="line">~</div></pre></td></tr></table></figure>
<p><em>配置kafka访问地址</em></p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">vim</span> producer.properties </div><div class="line">metadata.broker.list=<span class="number">169.44.62.139:9292</span>,<span class="number">169.44.59.138:9292</span>,<span class="number">169.44.62.137:9292</span>   </div><div class="line"><span class="comment"># name of the partitioner class for partitioning events; default partition spreads data randomly</span></div><div class="line"><span class="comment">#partitioner.class=</span></div><div class="line"></div><div class="line"><span class="comment"># specifies whether the messages are sent asynchronously (async) or synchronously (sync)</span></div><div class="line">producer.type=sync</div><div class="line"></div><div class="line"><span class="comment"># specify the compression codec for all data generated: none, gzip, snappy, lz4.</span></div><div class="line"><span class="comment"># the old config values work as well: 0, 1, 2, 3 for none, gzip, snappy, lz4, respectively</span></div><div class="line">compression.codec=<span class="literal">none</span></div><div class="line"></div><div class="line"><span class="comment"># message encoder</span></div><div class="line">serializer.class=kafka.serializer.DefaultEncoder</div></pre></td></tr></table></figure>
<h3 id="Step3-集群机器快速拷贝配置"><a href="#Step3-集群机器快速拷贝配置" class="headerlink" title="Step3: 集群机器快速拷贝配置:"></a>Step3: 集群机器快速拷贝配置:</h3><p>远程复制分发安装文件<br>最好是把文件打包scp过去<br>接下来将上面的安装文件拷贝到集群中的其他机器上对应的目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp -P58958 -r kafka_2.10-0.8.2.1 jollybi@169.44.62.137:/home/jollybi/tools/. </div><div class="line">scp -P58958 -r kafka_2.10-0.8.2.1 jollybi@169.44.62.138:/home/jollybi/tools/.</div></pre></td></tr></table></figure>
<p>统一修改分别其他两台kafka <code>server.properties</code></p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">broker.id=<span class="number">2</span>  </div><div class="line">host.name=<span class="number">169.44</span><span class="number">.62</span><span class="number">.137</span>   kafka2本机IP</div><div class="line"></div><div class="line">broker.id=<span class="number">3</span> </div><div class="line">host.name=<span class="number">169.44</span><span class="number">.62</span><span class="number">.138</span>   kafka3本机IP</div></pre></td></tr></table></figure>
<h3 id="Step4-启动-kafka集群"><a href="#Step4-启动-kafka集群" class="headerlink" title="Step4:启动 kafka集群"></a>Step4:启动 kafka集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">./kafka-server-start.sh -daemon ../config/server.properties</div><div class="line"></div><div class="line">[jollybi@kafka1 config]$ jps</div><div class="line">3443 QuorumPeerMain</div><div class="line">16280 Jps</div><div class="line">3628 Kafka</div><div class="line">Step5: Kafka常用命令(普及)</div></pre></td></tr></table></figure>
<h4 id="Step5-测试集群基本命令"><a href="#Step5-测试集群基本命令" class="headerlink" title="Step5:测试集群基本命令"></a>Step5:测试集群基本命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div></pre></td><td class="code"><pre><div class="line"><span class="comment">### 默认创建kafka Topic:  1个副本备份 1个分区消费</span></div><div class="line"></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 1 --partitions 1 --topic mongotail_lz4</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 1 --partitions 1 --topic mongotail_lz4_imp</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 大数据这边需要12个分区这里我删除Topic重新创建Topic：</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 删除kafka Topic:</span></div><div class="line"></div><div class="line"></div><div class="line">第一步：删除kafka topic</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --delete --topic  mongotail_lz4 </div><div class="line"></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --delete --topic  mongotail_lz4_imp</div><div class="line"></div><div class="line"><span class="comment">### 这是由于删除topic没删干净会报错：</span></div><div class="line"></div><div class="line">org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 删除线程执行删除操作的真正逻辑是：</span></div><div class="line">1. 它首先会给当前所有broker发送更新元数据信息的请求，告诉这些broker说这个topic要删除了，你们可以把它的信息从缓存中删掉了</div><div class="line">2. 开始删除这个topic的所有分区</div><div class="line">2.1 给所有broker发请求，告诉它们这些分区要被删除。broker收到后就不再接受任何在这些分区上的客户端请求了</div><div class="line">2.2 把每个分区下的所有副本都置于OfflineReplica状态，这样ISR就不断缩小，当leader副本最后也被置于OfflineReplica状态时leader信息将被更新为-1</div><div class="line">2.3 将所有副本置于ReplicaDeletionStarted状态</div><div class="line">2.4 副本状态机捕获状态变更，然后发起StopReplicaRequest给broker，broker接到请求后停止所有fetcher线程、移除缓存，然后删除底层<span class="built_in">log</span>文件</div><div class="line">2.5 关闭所有空闲的Fetcher线程</div><div class="line">    </div><div class="line"><span class="comment">### 第二步：删除zookeeper相关的路径：</span></div><div class="line">[jollybi@kafka1 zookeeper-3.4.5]$ ./bin/zkCli.sh -server 127.0.0.1:2281 </div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 1] rmr /brokers/topics/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 0] rmr /consumers/group_ml_general/offsets/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 1] rmr /consumers/group_ml_general/owners/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 3] rmr  /config/topics/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 4] rmr /admin/delete_topics/mongotail_lz4</div><div class="line"></div><div class="line"><span class="comment">### 删除topic上面消费组 </span></div><div class="line"></div><div class="line">删除 ZooKeeper 下面的 /consumers/[group_id] 路径就可以了。ZooKeeper 原生API只支持删除空的路径，所以建议你使用 curator framework 进行这个删除操作，ZkPaths.deleteChildren 会递归式地删除整个路径（包括子路径）。</div><div class="line"></div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 0] rmr /consumers/kafka-node1-imp-group</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 1] rmr /consumers/kafka-node1-group</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 2] rmr /consumers/console-consumer-59053</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 3] rmr /consumers/</div><div class="line"></div><div class="line"></div><div class="line">1、设置配置文件允许删除</div><div class="line">delete.topic.enable=<span class="literal">true</span> 配置添加到 config/server.properties</div><div class="line">2、执行删除命令</div><div class="line">./bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic <span class="built_in">test</span>-topic</div><div class="line"></div><div class="line">在zookeeper中确认：</div><div class="line"></div><div class="line"> 删除zookeeper下/brokers/topics/<span class="built_in">test</span>-topic节点</div><div class="line"> 删除zookeeper下/config/topics/<span class="built_in">test</span>-topic节点</div><div class="line"> 删除zookeeper下/admin/delete_topics/<span class="built_in">test</span>-topic节点</div><div class="line"> </div><div class="line">consumer 的话 删除groupid</div><div class="line"> </div><div class="line"></div><div class="line"><span class="comment">### 重启kafka集群</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 大数据kafka建topic，不能建一个分区，那样吞吐量上不去，不够用，我们以前建了12个分区的</span></div><div class="line"><span class="comment">### 创建新 kafka Topic: 3个副本，12个分区</span></div><div class="line"></div><div class="line"> ./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 3 --partitions 12  --topic mongotail_lz4</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 3 --partitions 12  --topic mongotail_lz4_imp</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 查看创建的Topic:</span></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh  --describe --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281  --topic mongotail_lz4</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh  --describe --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281  --topic mongotail_lz4_imp</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 查看集群情况：</span></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh  --describe --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281  --topic mongotail_lz4</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 模拟生产者（producer）kafka生产客户端生产数据命令：</span></div><div class="line"></div><div class="line">./bin/kafka-console-producer.sh --broker-list 75.126.39.124:9292,75.126.5.162:9292,75.126.5.178:9292 --topic mongotail_lz4_imp                      </div><div class="line">......</div><div class="line">my <span class="built_in">test</span> message 1</div><div class="line">my <span class="built_in">test</span> message 2</div><div class="line">^C</div><div class="line"><span class="comment">### 模拟消费者（consumer）kafka消费客户端数据命令 现在我们来看看消息：</span></div><div class="line"></div><div class="line"> ./bin/kafka-console-consumer.sh --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  --fm-beginning --topic mongotail_lz4_imp</div><div class="line">......</div><div class="line">my <span class="built_in">test</span> message 1</div><div class="line">my <span class="built_in">test</span> message 2</div><div class="line"></div><div class="line">^C</div></pre></td></tr></table></figure>
<h3 id="Kafka常用命令"><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h3><p>以下是kafka常用命令行总结：  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">1、 list topic 显示所有topic</div><div class="line">./bin/kafka-topics.sh --list --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281</div><div class="line"></div><div class="line">2、 查看topic的详细信息  </div><div class="line"> ./bin/kafka-topics.sh --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  -describe -topic mongotail_lz4_imp</div><div class="line"></div><div class="line">3、为topic增加partition分区 参数：--alter --partitions</div><div class="line">./bin/kafka-topics.sh  --alter --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  --partitions 20 --topic mongotail_lz4_imp</div><div class="line"></div><div class="line">4、kafka生产者客户端命令  </div><div class="line">./bin/kafka-console-producer.sh --broker-list 75.126.39.124:9292,75.126.5.162:9292,75.126.5.178:9292 --topic mongotail_lz4_imp                        </div><div class="line"></div><div class="line">5、kafka消费者客户端命令  </div><div class="line">./bin/kafka-console-consumer.sh --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  --fm-beginning --topic </div><div class="line"></div><div class="line">6、kafka服务启动  </div><div class="line">./kafka-server-start.sh -daemon ../config/server.properties   </div><div class="line"></div><div class="line">7、下线broker  </div><div class="line">./kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper 127.0.0.1:2181 --broker <span class="comment">#brokerId# --num.retries 3 --retry.interval.ms 60  </span></div><div class="line">shutdown broker  </div><div class="line"></div><div class="line">8、删除topic  </div><div class="line">./kafka-run-class.sh kafka.admin.DeleteTopicCommand --topic <span class="built_in">test</span>KJ1 --zookeeper 127.0.0.1:2181  </div><div class="line">./kafka-topics.sh --zookeeper localhost:2181 --delete --topic <span class="built_in">test</span>KJ1  </div><div class="line"></div><div class="line">9、查看consumer组内消费的offset  </div><div class="line">./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group <span class="built_in">test</span> --topic <span class="built_in">test</span>KJ1</div></pre></td></tr></table></figure>
<h4 id="Step6-Kafka存储"><a href="#Step6-Kafka存储" class="headerlink" title="Step6:Kafka存储"></a>Step6:Kafka存储</h4><p>每个replica一个目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[jollybi@kafka1 kafka_2.10-0.8.2.0]<span class="comment"># cd /data/tools/kafka_2.10-0.8.2.0/kafka-logs/</span></div><div class="line">[root@master kafka-logs]<span class="comment"># ls</span></div><div class="line">__consumer_offsets-0   __consumer_offsets-20  __consumer_offsets-32  __consumer_offsets-44   my-replicatedtopic1-0</div><div class="line">__consumer_offsets-1   __consumer_offsets-21  __consumer_offsets-33  __consumer_offsets-45   my-replicated-topic1-1</div></pre></td></tr></table></figure>
<p>二级结构</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[jollybi@kafka1 kafka-logs]<span class="comment"># cd my-replicated-topic1-0/</span></div><div class="line">[jollybi@kafka1  my-replicated-topic1-0]<span class="comment"># ls</span></div><div class="line">00000000000000000000.index  00000000000000000000.log</div></pre></td></tr></table></figure>
<p><figure class="figure"><img src="http://static.zybuluo.com/sasaki/f71rtngyz2y8n3m6uxq1z2ec/%E5%9B%BE%E7%89%871.png" alt=""></figure></p>
<h3 id="交流学习："><a href="#交流学习：" class="headerlink" title="交流学习："></a>交流学习：</h3><p>🐧  Linux shell_高级运维派: <code>459096184</code>    圈子 (系统运维-应用运维-自动化运维-虚拟化技术研究欢迎加入)<br>🐧  BigData-Exchange School : <code>521621407</code>  圈子（大数据运维)（Hadoop开发人员)（大数据研究爱好者) 欢迎加入</p>
<p>相应Bidata有内部微信交流群互相学习，加入QQ群有链接。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2017/03/15/运维笔记/APP自动化部署:开发部署-测试部署-灰度发布:蓝绿部署-生产环境等部署流程方案总结/">APP自动化部署:开发部署-测试部署-灰度发布/蓝绿部署-生产环境等部署流程方案总结</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-03-15</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/运维笔记/">运维笔记</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Automation-Deploy/">Automation Deploy</a>
			</span>
		
	</div>

	

	
		<h1 id="APP自动化部署：开发部署、测试部署、灰度发布等部署方案对比与总结"><a href="#APP自动化部署：开发部署、测试部署、灰度发布等部署方案对比与总结" class="headerlink" title="APP自动化部署：开发部署、测试部署、灰度发布等部署方案对比与总结"></a>APP自动化部署：开发部署、测试部署、灰度发布等部署方案对比与总结</h1><h4 id="前言："><a href="#前言：" class="headerlink" title="前言："></a>前言：</h4><p>个人现在在一个医疗行业公司：美年大这边负责体检APP的运维相关工作，今天主要是整理了下现在团队APP发布流程<br>方案：</p>
<p>因为在项目迭代的过程中，不可避免需要”上线”。上线对应着部署，或者重新部署；部署对应着修改；修改则意味着风险。<br>目前有很多用于部署的技术，有的简单，有的复杂；有的得停机，有的不需要停机即可完成部署。</p>
<p>个人整理下部署流程说明其实现在很多部署方法，现在我们用目前比较流行的几种部署方案，或者说策略方案对比总结简单讨论一下目前比较流行的几种部署方案，或者说策略。如有不足之处请指出，如有谬误，请指正^_^。</p>
<p>我们有自己开发环境和测试环境 ：</p>
<h4 id="开发环境部署："><a href="#开发环境部署：" class="headerlink" title="开发环境部署："></a>开发环境部署：</h4><ul>
<li>问题：</li>
</ul>
<p>开发人员每个人在自己电脑环境写代码自己电脑本机测试代码是否run成功，每个开发人员都在自己本地写完测试出现问题是各自环境不统一导致遇到坑阻碍到测试人员测试，基础的bug也会浪费太多时间。</p>
<ul>
<li>解决后：</li>
</ul>
<p>主要是解决了给予开发团队在写代码或者修改bug可以第一时间更新部署。大家统一一个开发环境这个是为了在开发阶段能立马呈现效果。</p>
<h4 id="测试环境部署："><a href="#测试环境部署：" class="headerlink" title="测试环境部署："></a>测试环境部署：</h4><ul>
<li>问题：</li>
</ul>
<p>一开始没有测试环境，直接开发环境当作测试环境去跑，发现很多问题，就是测试环境数据跟生产不一样，导致很多bug问题，测试发现测试的时候，开发在更新代码发布，耽误了测试人员的测试过程，环境不能独立都互相占用，刀子效率没有提高，bug每个星期都不断提升。</p>
<ul>
<li>解决后：</li>
</ul>
<p>主要解决了开发环境和测试环境独立，不会互相影响，测试人员有单独环境去测试生产能准确的数据对比。</p>
<h4 id="选择灰度环境部署方案："><a href="#选择灰度环境部署方案：" class="headerlink" title="选择灰度环境部署方案："></a>选择灰度环境部署方案：</h4><p>先贴个百度百科：</p>
<p>灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。</p>
<p>灰度环境部署:</p>
<p>个人理解灰度部署是增量发布的一种类型，它的执行方式是在原有软件生产版本可用的情况下，同时部署一个新的版本。同时运行同一个软件产品的多个版本需要软件针对配置和完美自动化部署进行特别设计。</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">(1)</span> 准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。</div><div class="line"><span class="comment">(2)</span> 从负载均衡列表中移除掉“部署灰度环境”服务器。</div><div class="line"><span class="comment">(3)</span> 升级“灰度部署”应用（排掉原有流量并进行部署）。</div><div class="line"><span class="comment">(4)</span> 对应用进行自动化测试。</div><div class="line"><span class="comment">(5)</span> 将“灰度环境”服务器重新添加到负载均衡列表中（连通性和健康检查）。</div><div class="line"><span class="comment">(6)</span> 如果“灰度环境”在线使用测试成功，升级剩余的其他服务器。（否则就回滚）</div><div class="line">灰度发布中，常常按照用户设置路由权重，例如<span class="number">90</span><span class="meta">%</span>的用户维持使用老版本，<span class="number">10</span><span class="meta">%</span>的用户尝鲜新版本。不同版本应用共存，经常与A/B测试一起使用，用于测试选择多种方案。灰度发布比较典型的例子</div></pre></td></tr></table></figure>
<p>第1步: 把绿色集群的状态改为’备用’. 从负载均衡的池里把这些地址去掉,这样,绿色的集群就不再回接收到来自用户的请求了.转而进入备用负载均衡的池里.</p>
<h3 id="选择蓝绿环境部署方案："><a href="#选择蓝绿环境部署方案：" class="headerlink" title="选择蓝绿环境部署方案："></a>选择蓝绿环境部署方案：</h3><h5 id="蓝绿发布的意义"><a href="#蓝绿发布的意义" class="headerlink" title="蓝绿发布的意义"></a>蓝绿发布的意义</h5><p>整个发布过程，用户没有感受到任何宕机或者服务重启。</p>
<h5 id="蓝绿发布的过程"><a href="#蓝绿发布的过程" class="headerlink" title="蓝绿发布的过程"></a>蓝绿发布的过程</h5><ul>
<li>第0步:部署以前的配置<br><figure class="figure"><img src="http://1.bp.blogspot.com/-K8gbbN7S_xo/UmbijDyvS4I/AAAAAAAAE5M/3DCOJRrrbIY/s1600/Blue+Green+Deployment+for+Zero+Downtime+(8" alt=""></figure>.png)</li>
<li>第1步: 把绿色集群的状态改为’备用’. 从负载均衡的池里把这些地址去掉,这样,绿色的集群就不再回接收到来自用户的请求了.转而进入备用负载均衡的池里.<br><figure class="figure"><img src="http://1.bp.blogspot.com/-nITj_nPp5IY/UmbiuMblJNI/AAAAAAAAE5U/ovn4sSMcFco/s1600/Blue+Green+Deployment+for+Zero+Downtime+(9" alt=""></figure>.png)</li>
<li>第2步:在绿色集群里部署新的代码,直到应用启动成功<br><figure class="figure"><img src="http://3.bp.blogspot.com/-2F2dB-vux4g/UmbheBwtcAI/AAAAAAAAE5E/1l9il1igplQ/s1600/Blue+Green+Deployment+for+Zero+Downtime+(4" alt=""></figure>.png)</li>
<li>第3步:使用备用负载均衡简单测试一下备用集群的部署情况.理想状态下是全自动的.</li>
<li>第4步:把绿色备用集群的状态改成存货,于是进入了存活负载均衡的池里<br><figure class="figure"><img src="http://3.bp.blogspot.com/-2F2dB-vux4g/UmbheBwtcAI/AAAAAAAAE5E/1l9il1igplQ/s1600/Blue+Green+Deployment+for+Zero+Downtime+(4" alt=""></figure>.png)<br>看到 蓝色运行v1版本,绿色运行v2版本,都连接的是相同的数据库.这意味着v2版本也要在老的数据模型上运行.如果数据库有变更,要等到所有的集群升级到新的代码上.</li>
<li><p>第5步: 对蓝色集群也进行同样的操作.<br><figure class="figure"><img src="http://4.bp.blogspot.com/-aTz1EdP6pb0/UmbjAx46vrI/AAAAAAAAE5c/qqxolMnae44/s640/Blue+Green+Deployment+for+Zero+Downtime+(5" alt=""></figure>.png)<br><figure class="figure"><img src="http://3.bp.blogspot.com/-95YNOBeYoUU/UmbjFq711dI/AAAAAAAAE5k/Q5Naa80xk64/s640/Blue+Green+Deployment+for+Zero+Downtime+(6" alt=""></figure>.png)</p>
</li>
<li><p>最终v2代码完成部署.<br><figure class="figure"><img src="http://2.bp.blogspot.com/-eh1gR1sBPNc/UmbjMkDCixI/AAAAAAAAE5s/vJOeYjV03vI/s640/Blue+Green+Deployment+for+Zero+Downtime+(7" alt=""></figure>.png)</p>
</li>
<li><p>第6步:根据情况.运行数据库迁移</p>
</li>
</ul>
<p>参考：tks   <a href="http://sunitspace.blogspot.jp/2013/10/blue-green-deployment.html" target="_blank" rel="external">green-deployment</a></p>
<h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>1) 蓝绿部署：不停止老版本，额外搞一套新版本，等测试发现新版本OK后，删除老版本。其实这里删除老版本也就是重新部署了老版本成为新版本一起放上去，等需要更新发布迁下期中一个版本环境部署：现在我们公司使用蓝绿部署方案。</p>
<p>3) 灰度发布：不停止老版本，额外搞一套新版本，常常按照用户设置路由权重，例如90%的用户维持使用老版本，10%的用户尝鲜新版本。不同版本应用共存，经常与A/B测试一起使用，用于测试选择多种方案。</p>
<h3 id="其实两种含义个人认为相差不是特别大，都特别适合现在发布部署流程方案。"><a href="#其实两种含义个人认为相差不是特别大，都特别适合现在发布部署流程方案。" class="headerlink" title="其实两种含义个人认为相差不是特别大，都特别适合现在发布部署流程方案。"></a>其实两种含义个人认为相差不是特别大，都特别适合现在发布部署流程方案。</h3><h3 id="交流学习："><a href="#交流学习：" class="headerlink" title="交流学习："></a>交流学习：</h3><p>🐧  Linux shell_高级运维派: <code>459096184</code>    圈子 (系统运维-应用运维-自动化运维-虚拟化技术研究欢迎加入)<br>🐧  BigData-Exchange School : <code>521621407</code>  圈子（大数据运维)（Hadoop开发人员)（大数据研究爱好者) 欢迎加入</p>
<p>相应Bidata有内部微信交流群互相学习，加入QQ群有链接。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2016/12/29/日志分析平台/Elasticsearch/搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台/">搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2016-12-29</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/Log-Analysis-Platform/">Log Analysis Platform</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Elasticsearch/">Elasticsearch</a>
			</span>
		
	</div>

	

	
		<h3 id="搭建-ElasticSearch-2-x-Logstash-2-x-Kibana-4-5-x-zookeeper3-4-6-Kafka为消息中心的ELK日志平台"><a href="#搭建-ElasticSearch-2-x-Logstash-2-x-Kibana-4-5-x-zookeeper3-4-6-Kafka为消息中心的ELK日志平台" class="headerlink" title="搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台"></a>搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台</h3><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>ELK是业界标准的日志采集,存储索引,展示分析系统解决方案</p>
<p>logstash提供了灵活多样的插件支持不同的input/output</p>
<p>主流使用redis/kafka作为日志/消息的中间环节</p>
<p>如果已有kafka的环境了,使用kafka比使用redis更佳</p>
<p>以下是一个最简化的配置做个笔记,elastic官网提供了非常丰富的文档</p>
<p>不要用搜索引擎去搜索,没多少结果的,请直接看官网文档</p>
<h3 id="版本及连接"><a href="#版本及连接" class="headerlink" title="版本及连接"></a>版本及连接</h3><p>elasticseearch版本: 2.4.3</p>
<h3 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h3><p>如果仅作测试用, 不需要两天机器, 可以将两个节点部署在同一台机器上, 对磁盘/cpu要求不高, 内存大于2g基本足够了</p>
<p>如果是正式环境, 需要根据日志量进行评估, 例如, 每天日志量占硬盘约约10G, 且保留30天日志, 则磁盘会占用约300g, es设定的阈值是磁盘空间占满85%则日志开始告警. 所以, 需要至少 300/0.85=354g.</p>
<p>准备4台机器, 在同一个局域网内(可ping通), 分别在每台机器上部署相应es节点, 搭建一套日志集群.</p>
<p>4台机器, 最少的资源了, 但是没法做到高可用, 所以, 还需要再加一台机器, 防止脑裂, 具体见最后(两台主力机器+一台稳定的机器就行)</p>
<p>集群节点: 最少4台机器<br>内存: 8G及以上<br>cpu: 4核及以上<br>硬盘: 800G及以上, 建议1T, 集群容量约10亿级(取决于对应日志大小)<br>操作系统: centos</p>
<h3 id="准备工作-应用-网络-环境"><a href="#准备工作-应用-网络-环境" class="headerlink" title="准备工作: 应用/网络 环境"></a>准备工作: 应用/网络 环境</h3><p>SLB： 阿里云做负载均衡&amp; 或者自己搭建nginx</p>
<blockquote>
<p>ELK服务端集群：</p>
</blockquote>
<p>系统centos 6.7  JDK1.8  版本：Elasticsearch-2.4.0</p>
<p>es_01 10.47.88.206<br>es_02 10.47.88.188</p>
<blockquote>
<p>Kibana服务端集群：</p>
</blockquote>
<p>系统centos 6.7  JDK1.8  版本：kibana-4.5.1</p>
<p>es_01 10.47.88.206<br>es_02 10.47.88.188</p>
<blockquote>
<p>KafKa集群</p>
</blockquote>
<p>系统centos 6.7  JDK1.8  版本：kafka_2.10-0.9</p>
<p>kafka_01 10.46.72.172<br>kafka_02 10.47.88.103<br>kafka_03 10.47.102.137</p>
<blockquote>
<p>zookeeper集群</p>
</blockquote>
<p>系统centos 6.7  JDK1.8  版本：zookeeper-3.4.6</p>
<p>kafka_01 10.46.72.172<br>kafka_02 10.47.88.103<br>kafka_03 10.47.102.137</p>
<blockquote>
<p>logstash-2.4</p>
</blockquote>
<p>客户端：系统centos 6.7  JDK1.8  版本： logstash-2.4</p>
<p>tomcat-account_01: 10.27.232.85</p>
<p>都要jdk1.8支持。</p>
<h3 id="整体说明"><a href="#整体说明" class="headerlink" title="整体说明"></a>整体说明</h3><h4 id="数据流向-gt-日志-消息整体流向"><a href="#数据流向-gt-日志-消息整体流向" class="headerlink" title="数据流向=&gt;日志/消息整体流向"></a>数据流向=&gt;日志/消息整体流向</h4><p>logstash =&gt; kafka =&gt; logstash =&gt; elasticsearch =&gt; kibana</p>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><h4 id="1-确认JDK版本及安装"><a href="#1-确认JDK版本及安装" class="headerlink" title="1. 确认JDK版本及安装"></a>1. 确认JDK版本及安装</h4><p>es依赖java的版本最小为1.7</p>
<p>如果系统中未安装JDK<br>则命令返回<code>bash: java: command not found,</code> 需要安装<code>JDK</code></p>
<p>如果系统中安装了JDK, 需确认版本是否大于java 1.7, 否则需要升级</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">java -version</div><div class="line">java version <span class="string">"1.7.0_51"</span> Java(TM) SE Runtime Environment (build 1.7.0_51-b13) Java HotSpot(TM) Server VM (build 24.51-b03, mixed mode)</div><div class="line"></div><div class="line">安装及升级java(注意根据系统不同运行对应安装命令)</div><div class="line"></div><div class="line"><span class="comment"># Redhat/Centos/Fedora</span></div><div class="line">sudo yum install java-1.7.0-openjdk</div><div class="line"></div><div class="line">或者到官网, 下载最新的jdk的rpm包, 然后安装</div><div class="line"></div><div class="line">wget http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.rpm</div><div class="line">rpm -Uvh jdk-8u91-linux-x64.rpm</div></pre></td></tr></table></figure>
<p>再次确认安装成功</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">java -version</div></pre></td></tr></table></figure>
<h4 id="基本配置设置FQDN："><a href="#基本配置设置FQDN：" class="headerlink" title="基本配置设置FQDN："></a>基本配置设置FQDN：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#修改hostname</span></div><div class="line">cat /etc/hostname</div><div class="line">es_01</div><div class="line"></div><div class="line"><span class="comment">#修改hosts</span></div><div class="line">cat /etc/hosts</div><div class="line">127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4</div><div class="line">::1 localhost localhost.localdomain localhost6 localhost6.localdomain6</div><div class="line">10.47.88.206 es.ihaozhuo.com es_01</div><div class="line"></div><div class="line"><span class="comment">#刷新环境</span></div><div class="line">hostname -F /etc/hostname</div><div class="line"></div><div class="line"><span class="comment">#复查结果</span></div><div class="line">hostname <span class="_">-f</span></div><div class="line">es.ihaozhuo.com</div><div class="line"></div><div class="line">hostname</div><div class="line">es_01</div></pre></td></tr></table></figure>
<h3 id="防火墙配置"><a href="#防火墙配置" class="headerlink" title="防火墙配置"></a>防火墙配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#service iptables stop</span></div><div class="line"><span class="comment">#setenforce 0</span></div><div class="line"></div><div class="line">不过这里我防火墙是开启的，后期添加出去端口即可。</div><div class="line">或者可以不关闭防火墙，但是要在iptables中打开相关的端口：</div><div class="line"></div><div class="line"><span class="comment"># vim /etc/sysconfig/iptables</span></div><div class="line">-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT</div><div class="line">-A INPUT -m state --state NEW -m tcp -p tcp --dport 9200 -j ACCEPT</div><div class="line">-A INPUT -m state --state NEW -m tcp -p tcp --dport 9292 -j ACCEPT</div><div class="line"><span class="comment"># service iptables restart</span></div></pre></td></tr></table></figure>
<h4 id="RPM快速安装"><a href="#RPM快速安装" class="headerlink" title="RPM快速安装"></a>RPM快速安装</h4><p>elk所有安装都可以使用rpm二进制包的方式,增加<code>elastic官网</code>的仓库repo就可以用yum安装了</p>
<p>elasticsearch看这里 —– <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-repositories.html" target="_blank" rel="external">elasticsearch-rpm官方文档</a></p>
<p>logstash看这里 —-<a href="https://www.elastic.co/guide/en/logstash/current/installing-logstash.html" target="_blank" rel="external">logstash-rpm官网文档</a></p>
<p>kibana看这里 —<a href="https://www.elastic.co/guide/en/kibana/current/setup.html" target="_blank" rel="external">kibana-rpm官网文档</a></p>
<h3 id="es-01服务端源码安装"><a href="#es-01服务端源码安装" class="headerlink" title="es_01服务端源码安装"></a>es_01服务端源码安装</h3><p>这里我是源码安装的<br>下载ElasticSearch ElasticSearch默认的对外服务的HTTP端口是9200，节点间交互的TCP端口是9300。</p>
<p>下载地址：<a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="external">Elasticsearch</a></p>
<p>2.4版本：<br><a href="https://www.elastic.co/downloads/past-releases/elasticsearch-2-4-3" target="_blank" rel="external">Elasticsearch2.4.3</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">解压源码包：</div><div class="line">[root@es_01 ~]<span class="comment"># tar -zxvf elasticsearch-2.4.3.tar.gz -C /usr/local/</span></div><div class="line">然后给目录做个软链接：</div><div class="line">[root@es_01 <span class="built_in">local</span>]<span class="comment"># ln -s  /usr/local/elasticsearch-2.4.3/ /usr/local/elasticsearch</span></div><div class="line"></div><div class="line">这里需要修改配置文件：</div><div class="line">配置前先创建几个目录文件</div><div class="line">新建目录, 假设/data/目录挂载的硬盘最大(500G以上)</div><div class="line">[root@es_01 srv]]<span class="comment"># mkdir /srv/data/es-data -p</span></div><div class="line">[root@es_01 srv]<span class="comment"># mkdir /srv/data/es-work </span></div><div class="line"></div><div class="line">[root@es_01 <span class="built_in">local</span>]<span class="comment"># mkdir /usr/local/elasticsearch/logs</span></div><div class="line">[root@es_01 <span class="built_in">local</span>]<span class="comment"># mkdir /usr/local/elasticsearch/config/plugins</span></div><div class="line"></div><div class="line">新建用户</div><div class="line">修改源码目录属性属组：</div><div class="line">[root@es_01 elasticsearch]<span class="comment"># useradd  -s /sbin/nologin elasticsearch</span></div><div class="line">[root@es_01 elasticsearch]<span class="comment"># chown -R elasticsearch:elasticsearch /usr/local/elasticsearch</span></div><div class="line">[root@es_01 elasticsearch]<span class="comment"># chown -R elasticsearch:elasticsearch /srv/data/</span></div><div class="line"></div><div class="line"></div><div class="line">切换用户</div><div class="line">切换到elasticsearch用户, 并进入elasticsearch目录</div><div class="line"></div><div class="line">su elasticsearch</div><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/elasticsearch/</div></pre></td></tr></table></figure>
<h3 id="配置Elasticsearch："><a href="#配置Elasticsearch：" class="headerlink" title="配置Elasticsearch："></a>配置Elasticsearch：</h3><p>以用户es的身份进行操作</p>
<p>文件路径: <code>config/elasticsearch.yml</code><br>修改该文件中配置项: (注意, 原始文件中都是被#号注释掉了, 需要去掉对应注释并修改配置值)</p>
<ul>
<li>集群名: cluster.name, 注意: 两台机器配置一致</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cluster.name: elk_cluster</div></pre></td></tr></table></figure>
<ul>
<li>节点名: node.name, 注意: 两台机器配置不同, 一台为01, 另一台为02</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"> <span class="comment"># 第一台机器</span></div><div class="line"> </div><div class="line">node.name: inner_es_node_01</div><div class="line"></div><div class="line"><span class="comment"># 第二台机器</span></div><div class="line">node.name: inner_es_node_02</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">[root@es_01 config]<span class="comment"># vim elasticsearch.yml</span></div><div class="line"></div><div class="line"><span class="comment"># Use a descriptive name for your cluster:</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment">#</span></div><div class="line">cluster.name: elk_cluster</div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># ------------------------------------ Node ------------------------------------</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Use a descriptive name for the node:</span></div><div class="line"><span class="comment">#</span></div><div class="line">node.name: es_01</div><div class="line"></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Add custom attributes to the node:</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># node.rack: r1</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># ----------------------------------- Paths ------------------------------------</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Path to directory where to store the data (separate multiple locations by comma):</span></div><div class="line"><span class="comment">#</span></div><div class="line">path.data: /srv/data/es-data</div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Path to log files:</span></div><div class="line"><span class="comment">#</span></div><div class="line">path.logs: /usr/<span class="built_in">local</span>/elasticsearch/logs</div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># ----------------------------------- Memory -----------------------------------</span></div><div class="line"><span class="comment">#</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Lock the memory on startup:</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># bootstrap.memory_lock: true</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory</span></div><div class="line"><span class="comment"># available on the system and that the owner of the process is allowed to use this limit.</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Elasticsearch performs poorly when the system is swapping the memory.</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># ---------------------------------- Network -----------------------------------</span></div><div class="line"><span class="comment">#</span></div><div class="line"><span class="comment"># Set the bind address to a specific IP (IPv4 or IPv6):</span></div><div class="line"><span class="comment">#</span></div><div class="line">network.host: 10.47.88.206</div></pre></td></tr></table></figure>
<p>切换到elasticsearch用户启动服务。</p>
<p>源码安装启动需要执行 ：<code>/usr/local/elasticsearch/bin/elasticsearch &amp;</code><br>才能启动；</p>
<h3 id="测试访问服务正常："><a href="#测试访问服务正常：" class="headerlink" title="测试访问服务正常："></a>测试访问服务正常：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[elasticsearch@es_01 elasticsearch]$  curl http://10.47.88.206:9200</div><div class="line">&#123;</div><div class="line">  <span class="string">"name"</span> : <span class="string">"es_01"</span>,</div><div class="line">  <span class="string">"cluster_name"</span> : <span class="string">"elk_cluster"</span>,</div><div class="line">  <span class="string">"cluster_uuid"</span> : <span class="string">"mspLZT5nTL-d124suNbBBQ"</span>,</div><div class="line">  <span class="string">"version"</span> : &#123;</div><div class="line">    <span class="string">"number"</span> : <span class="string">"2.4.3"</span>,</div><div class="line">    <span class="string">"build_hash"</span> : <span class="string">"d38a34e7b75af4e17ead16f156feffa432b22be3"</span>,</div><div class="line">    <span class="string">"build_timestamp"</span> : <span class="string">"2016-12-07T16:28:56Z"</span>,</div><div class="line">    <span class="string">"build_snapshot"</span> : <span class="literal">false</span>,</div><div class="line">    <span class="string">"lucene_version"</span> : <span class="string">"5.5.2"</span></div><div class="line">  &#125;,</div><div class="line">  <span class="string">"tagline"</span> : <span class="string">"You Know, for Search"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>下面是写开机启动脚本，不写的直接切换es用户到目录启动 -d后台启动。<br>这里需要/etc/init.d/创建启动脚本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[root@ELK ~]<span class="comment"># git clone https://github.com/elastic/elasticsearch-servicewrapper.git</span></div><div class="line">Initialized empty Git repository <span class="keyword">in</span> /root/elasticsearch-servicewrapper/.git/</div><div class="line">remote: Counting objects: 184, done.</div><div class="line">remote: Total 184 (delta 0), reused 0 (delta 0), pack-reused 184</div><div class="line">Receiving objects: 100% (184/184), 4.55 MiB | 511 KiB/s, done.</div><div class="line">Resolving deltas: 100% (53/53), done.</div><div class="line">[root@ELK elasticsearch-servicewrapper]<span class="comment"># mv service/ /usr/local/elasticsearch/bin/</span></div><div class="line">[root@ELK elasticsearch-servicewrapper]<span class="comment"># cd /usr/local/elasticsearch</span></div><div class="line">[root@ELK elasticsearch]<span class="comment"># /usr/local/elasticsearch/bin/service/elasticsearch install    这里是安装es</span></div><div class="line">Detected RHEL or Fedora:</div><div class="line">Installing the Elasticsearch daemon..</div><div class="line">[root@ELK elasticsearch]<span class="comment"># vim /etc/init.d/elasticsearch   查看安装es启动配置文件</span></div><div class="line">[root@ELK elasticsearch]<span class="comment"># service elastic search start  启动es </span></div><div class="line">Starting Elasticsearch...</div><div class="line">Waiting <span class="keyword">for</span> Elasticsearch......</div><div class="line">running: PID:31360   服务已启动了。</div><div class="line"></div><div class="line">启动相关服务</div><div class="line">service elasticsearch start</div><div class="line">service elasticsearch status</div><div class="line"></div><div class="line">配置 elasticsearch 服务随系统自动启动</div><div class="line"><span class="comment"># chkconfig --add elasticsearch</span></div><div class="line"></div><div class="line">测试ElasticSearch服务是否正常，预期返回200的状态码</div><div class="line"><span class="comment"># curl -X GET http://localhost:9200</span></div></pre></td></tr></table></figure>
<h3 id="es-02服务端节点："><a href="#es-02服务端节点：" class="headerlink" title="es_02服务端节点："></a>es_02服务端节点：</h3><p>第一步基础配置都是一样的，跟es_01节点一样。  其他只需要到es_01拷贝过来,然后创建下es用户，修改下配置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">/usr/<span class="built_in">local</span>/elasticsearch  目录拷贝到es_02机器。</div><div class="line">这里需要修改配置文件：</div><div class="line">配置前先创建几个目录文件</div><div class="line">[root@es_01 srv]]<span class="comment"># mkdir /srv/data/es-data -p</span></div><div class="line">[root@es_01 srv]<span class="comment"># mkdir /srv/data/es-work </span></div><div class="line">修改源码目录属性属组：</div><div class="line">[root@es_01 elasticsearch]<span class="comment"># useradd  -s /sbin/nologin elasticsearch</span></div><div class="line">[root@es_01 elasticsearch]<span class="comment"># chown -R elasticsearch:elasticsearch /usr/local/elasticsearch/*</span></div><div class="line">[root@es_01 elasticsearch]<span class="comment"># chown -R elasticsearch:elasticsearch /srv/data/</span></div><div class="line"></div><div class="line">修改配置文件</div><div class="line">vim elasticsearch.yml</div><div class="line">node.name: es_02</div><div class="line">network.host: 10.47.88.188</div><div class="line"></div><div class="line">其他不需要修改</div></pre></td></tr></table></figure>
<h3 id="集群节点es-02测试："><a href="#集群节点es-02测试：" class="headerlink" title="集群节点es_02测试："></a>集群节点es_02测试：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@es_02 home]<span class="comment"># curl http://10.47.88.188:9200</span></div><div class="line">&#123;</div><div class="line">  <span class="string">"name"</span> : <span class="string">"es_02"</span>,</div><div class="line">  <span class="string">"cluster_name"</span> : <span class="string">"elk_cluster"</span>,</div><div class="line">  <span class="string">"cluster_uuid"</span> : <span class="string">"-4Rqn4IzS1GfnsodqZD8Tg"</span>,</div><div class="line">  <span class="string">"version"</span> : &#123;</div><div class="line">    <span class="string">"number"</span> : <span class="string">"2.4.3"</span>,</div><div class="line">    <span class="string">"build_hash"</span> : <span class="string">"d38a34e7b75af4e17ead16f156feffa432b22be3"</span>,</div><div class="line">    <span class="string">"build_timestamp"</span> : <span class="string">"2016-12-07T16:28:56Z"</span>,</div><div class="line">    <span class="string">"build_snapshot"</span> : <span class="literal">false</span>,</div><div class="line">    <span class="string">"lucene_version"</span> : <span class="string">"5.5.2"</span></div><div class="line">  &#125;,</div><div class="line">  <span class="string">"tagline"</span> : <span class="string">"You Know, for Search"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>elk集群已安装配置完毕，我这里配置了nginx做下反向代理，走80端口出去。然后在nginx设置下内部公司访问不对外开放。</p>
<h3 id="安装-head、marvel、bigdesk插件"><a href="#安装-head、marvel、bigdesk插件" class="headerlink" title="安装 head、marvel、bigdesk插件:"></a>安装 head、marvel、bigdesk插件:</h3><p>es1.5插件安装是<code>./plugin -install xxx</code>,而es2.4插件安装没有减号<code>./plugin install xxx</code></p>
<p>1.5版本方法：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">* head插件</div><div class="line"></div><div class="line">插件安装方法1：</div><div class="line">/usr/<span class="built_in">local</span>/elasticsearch/bin/plugin -install mobz/elasticsearch-head</div><div class="line">重启es 即可。</div><div class="line">打开http://localhost:9200/_plugin/head/</div><div class="line"></div><div class="line">插件安装方法2：</div><div class="line">1.https://github.com/mobz/elasticsearch-head下载zip 解压</div><div class="line">2.建立/usr/<span class="built_in">local</span>/elasticsearch/plugins/head/文件</div><div class="line">3.将解压后的elasticsearch-head-master文件夹下的文件copy到/usr/<span class="built_in">local</span>/elasticsearch/plugins/head/</div><div class="line">重启es 即可。</div><div class="line"></div><div class="line">打开http://localhost:9200/_plugin/head/</div></pre></td></tr></table></figure>
<p>2.4版本以上安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">* head插件</div><div class="line"></div><div class="line">插件安装方法1：</div><div class="line">/usr/<span class="built_in">local</span>/elasticsearch/bin/plugin install mobz/elasticsearch-head</div><div class="line">重启es 即可。</div><div class="line">打开http://localhost:9200/_plugin/head/</div><div class="line"></div><div class="line">插件安装方法2：</div><div class="line">1.https://github.com/mobz/elasticsearch-head下载zip 解压</div><div class="line">2.建立elasticsearch-1.0.0\plugins\head\_site文件</div><div class="line">3.将解压后的elasticsearch-head-master文件夹下的文件copy到_site</div><div class="line">重启es 即可。</div><div class="line"></div><div class="line">打开http://localhost:9200/_plugin/head/</div></pre></td></tr></table></figure>
<p>为了保障搜索服务的稳定性，增加了一台机器，将Elasticsearch部署成了集群模式， 部署到生产环境时发现，新的节点并不能被发现，后台发现阿里云并不支持多播，最后只能改为单播的方式配置了，好在之后一切顺利。</p>
<p>下面附上测试环境配置示例：添加下下面监听集群IP和端口。</p>
<ul>
<li>es_01</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@es_01 config]<span class="comment"># vim elasticsearch.yml</span></div><div class="line"></div><div class="line">discovery.zen.ping.multicast.enabled: <span class="literal">false</span></div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"10.47.88.206:9300"</span>,<span class="string">"10.47.88.188:9300"</span>]</div></pre></td></tr></table></figure>
<ul>
<li>es_02</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@es_02 config]<span class="comment"># vim elasticsearch.yml</span></div><div class="line"></div><div class="line">discovery.zen.ping.multicast.enabled: <span class="literal">false</span></div><div class="line">discovery.zen.ping.unicast.hosts: [<span class="string">"10.47.88.206:9300"</span>,<span class="string">"10.47.88.188:9300"</span>]</div></pre></td></tr></table></figure>
<p>然后重启服务，查看集群节点。</p>
<h3 id="es-02安装Kibana"><a href="#es-02安装Kibana" class="headerlink" title="es_02安装Kibana:"></a>es_02安装Kibana:</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div></pre></td><td class="code"><pre><div class="line">到https://www.elastic.co/downloads/kibana  找合适的版本。</div><div class="line"></div><div class="line">wget https://download.elastic.co/kibana/kibana/kibana-4.5.1-linux-x64.tar.gz</div><div class="line"></div><div class="line"><span class="comment">#解压</span></div><div class="line"></div><div class="line">＃tar zxvf kibana-4.1.2-linux-x64.tar.gz -C /usr/<span class="built_in">local</span> </div><div class="line">＃<span class="built_in">cd</span>  /usr/<span class="built_in">local</span>/ &amp;&amp; mv kibana-4.1.2-linux-x64 kibana</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#创建kibana启动脚本服务</span></div><div class="line">vi /etc/rc.d/init.d/kibana</div><div class="line"></div><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"><span class="comment">### BEGIN INIT INFO</span></div><div class="line"><span class="comment"># Provides:          kibana</span></div><div class="line"><span class="comment"># Default-Start:     2 3 4 5</span></div><div class="line"><span class="comment"># Default-Stop:      0 1 6</span></div><div class="line"><span class="comment"># Short-Description: Runs kibana daemon</span></div><div class="line"><span class="comment"># Description: Runs the kibana daemon as a non-root user</span></div><div class="line"><span class="comment">### END INIT INFO</span></div><div class="line"></div><div class="line"><span class="comment"># Process name</span></div><div class="line">NAME=kibana</div><div class="line">DESC=<span class="string">"Kibana4"</span></div><div class="line">PROG=<span class="string">"/etc/init.d/kibana"</span></div><div class="line"></div><div class="line"><span class="comment"># Configure location of Kibana bin</span></div><div class="line">KIBANA_BIN=/usr/<span class="built_in">local</span>/kibana/bin</div><div class="line"></div><div class="line"><span class="comment"># PID Info</span></div><div class="line">PID_FOLDER=/var/run/kibana/</div><div class="line">PID_FILE=/var/run/kibana/<span class="variable">$NAME</span>.pid</div><div class="line">LOCK_FILE=/var/lock/subsys/<span class="variable">$NAME</span></div><div class="line">PATH=/bin:/usr/bin:/sbin:/usr/sbin:<span class="variable">$KIBANA_BIN</span></div><div class="line">DAEMON=<span class="variable">$KIBANA_BIN</span>/<span class="variable">$NAME</span></div><div class="line"></div><div class="line"><span class="comment"># Configure User to run daemon process</span></div><div class="line">DAEMON_USER=root</div><div class="line"><span class="comment"># Configure logging location</span></div><div class="line">KIBANA_LOG=/var/<span class="built_in">log</span>/kibana.log</div><div class="line"></div><div class="line"><span class="comment"># Begin Script</span></div><div class="line">RETVAL=0</div><div class="line"></div><div class="line"><span class="keyword">if</span> [ `id -u` <span class="_">-ne</span> 0 ]; <span class="keyword">then</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"You need root privileges to run this script"</span></div><div class="line">        <span class="built_in">exit</span> 1</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="comment"># Function library</span></div><div class="line">. /etc/init.d/<span class="built_in">functions</span></div><div class="line"> </div><div class="line"><span class="function"><span class="title">start</span></span>() &#123;</div><div class="line">        <span class="built_in">echo</span> -n <span class="string">"Starting <span class="variable">$DESC</span> : "</span></div><div class="line"></div><div class="line">pid=`pidofproc -p <span class="variable">$PID_FILE</span> kibana`</div><div class="line">        <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$pid</span>"</span> ] ; <span class="keyword">then</span></div><div class="line">                <span class="built_in">echo</span> <span class="string">"Already running."</span></div><div class="line">                <span class="built_in">exit</span> 0</div><div class="line">        <span class="keyword">else</span></div><div class="line">        <span class="comment"># Start Daemon</span></div><div class="line"><span class="keyword">if</span> [ ! <span class="_">-d</span> <span class="string">"<span class="variable">$PID_FOLDER</span>"</span> ] ; <span class="keyword">then</span></div><div class="line">                        mkdir <span class="variable">$PID_FOLDER</span></div><div class="line">                <span class="keyword">fi</span></div><div class="line">daemon --user=<span class="variable">$DAEMON_USER</span> --pidfile=<span class="variable">$PID_FILE</span> <span class="variable">$DAEMON</span> 1&gt;<span class="string">"<span class="variable">$KIBANA_LOG</span>"</span> 2&gt;&amp;1 &amp;</div><div class="line">                sleep 2</div><div class="line">                pidofproc node &gt; <span class="variable">$PID_FILE</span></div><div class="line">                RETVAL=$?</div><div class="line">                [[ $? <span class="_">-eq</span> 0 ]] &amp;&amp; success || failure</div><div class="line"><span class="built_in">echo</span></div><div class="line">                [ <span class="variable">$RETVAL</span> = 0 ] &amp;&amp; touch <span class="variable">$LOCK_FILE</span></div><div class="line">                <span class="built_in">return</span> <span class="variable">$RETVAL</span></div><div class="line">        <span class="keyword">fi</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">reload</span></span>()</div><div class="line">&#123;</div><div class="line">    <span class="built_in">echo</span> <span class="string">"Reload command is not implemented for this service."</span></div><div class="line">    <span class="built_in">return</span> <span class="variable">$RETVAL</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="title">stop</span></span>() &#123;</div><div class="line">        <span class="built_in">echo</span> -n <span class="string">"Stopping <span class="variable">$DESC</span> : "</span></div><div class="line">        killproc -p <span class="variable">$PID_FILE</span> <span class="variable">$DAEMON</span></div><div class="line">        RETVAL=$?</div><div class="line"><span class="built_in">echo</span></div><div class="line">        [ <span class="variable">$RETVAL</span> = 0 ] &amp;&amp; rm <span class="_">-f</span> <span class="variable">$PID_FILE</span> <span class="variable">$LOCK_FILE</span></div><div class="line">&#125;</div><div class="line"> </div><div class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></div><div class="line">  start)</div><div class="line">        start</div><div class="line">;;</div><div class="line">  stop)</div><div class="line">        stop</div><div class="line">        ;;</div><div class="line">  status)</div><div class="line">        status -p <span class="variable">$PID_FILE</span> <span class="variable">$DAEMON</span></div><div class="line">        RETVAL=$?</div><div class="line">        ;;</div><div class="line">  restart)</div><div class="line">        stop</div><div class="line">        start</div><div class="line">        ;;</div><div class="line">  reload)</div><div class="line">reload</div><div class="line">;;</div><div class="line">  *)</div><div class="line"><span class="comment"># Invalid Arguments, print the following message.</span></div><div class="line">        <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &#123;start|stop|status|restart&#125;"</span> &gt;&amp;2</div><div class="line"><span class="built_in">exit</span> 2</div><div class="line">        ;;</div><div class="line"><span class="keyword">esac</span></div><div class="line"></div><div class="line"></div><div class="line">修改启动权限</div><div class="line">chmod +x /etc/rc.d/init.d/kibana</div></pre></td></tr></table></figure>
<p>配置Kibana：</p>
<h3 id="编辑kibana-yaml-修改端口，设置host-可以设置本地服务器IP"><a href="#编辑kibana-yaml-修改端口，设置host-可以设置本地服务器IP" class="headerlink" title="编辑kibana.yaml  修改端口，设置host 可以设置本地服务器IP"></a>编辑kibana.yaml  修改端口，设置host 可以设置本地服务器IP</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line">vim /usr/<span class="built_in">local</span>/kibana/config/kibana.yml</div><div class="line"></div><div class="line"><span class="comment"># Kibana is served by a back end server. This controls which port to use.</span></div><div class="line">server.port: 5601</div><div class="line"></div><div class="line"><span class="comment"># The host to bind the server to.</span></div><div class="line">server.host: <span class="string">"10.47.88.188"</span></div><div class="line"></div><div class="line"><span class="comment"># If you are running kibana behind a proxy, and want to mount it at a path,</span></div><div class="line"><span class="comment"># specify that path here. The basePath can't end in a slash.</span></div><div class="line"><span class="comment"># server.basePath: ""</span></div><div class="line"></div><div class="line"><span class="comment"># The maximum payload size in bytes on incoming server requests.</span></div><div class="line"><span class="comment"># server.maxPayloadBytes: 1048576</span></div><div class="line"></div><div class="line"><span class="comment"># The Elasticsearch instance to use for all your queries.</span></div><div class="line">elasticsearch.url: <span class="string">"http://10.47.88.188:9200"</span></div><div class="line"></div><div class="line"><span class="comment"># preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false,</span></div><div class="line"><span class="comment"># then the host you use to connect to *this* Kibana instance will be sent.</span></div><div class="line"></div><div class="line">elasticsearch.preserveHost: <span class="literal">true</span></div><div class="line"></div><div class="line"><span class="comment"># Kibana uses an index in Elasticsearch to store saved searches, visualizations</span></div><div class="line"><span class="comment"># and dashboards. It will create a new index if it doesn't already exist.</span></div><div class="line"><span class="comment"># kibana.index: ".kibana"</span></div><div class="line"></div><div class="line"><span class="comment"># The default application to load.</span></div><div class="line">kibana.defaultAppId: <span class="string">"discover"</span></div><div class="line"></div><div class="line"><span class="comment"># If your Elasticsearch is protected with basic auth, these are the user credentials</span></div><div class="line"><span class="comment"># used by the Kibana server to perform maintenance on the kibana_index at startup. Your Kibana</span></div><div class="line"><span class="comment"># users will still need to authenticate with Elasticsearch (which is proxied through</span></div><div class="line"><span class="comment"># the Kibana server)</span></div><div class="line"></div><div class="line"><span class="comment"># elasticsearch.ssl.key: /path/to/your/client.key</span></div><div class="line"></div><div class="line"><span class="comment"># If you need to provide a CA certificate for your Elasticsearch instance, put</span></div><div class="line"><span class="comment"># the path of the pem file here.</span></div><div class="line"><span class="comment"># elasticsearch.ssl.ca: /path/to/your/CA.pem</span></div><div class="line"></div><div class="line"><span class="comment"># Set to false to have a complete disregard for the validity of the SSL</span></div><div class="line"><span class="comment"># certificate.</span></div><div class="line"><span class="comment"># elasticsearch.ssl.verify: true</span></div><div class="line"></div><div class="line"><span class="comment"># Time in milliseconds to wait for elasticsearch to respond to pings, defaults to</span></div><div class="line"><span class="comment"># request_timeout setting</span></div><div class="line"><span class="comment"># elasticsearch.pingTimeout: 1500</span></div><div class="line"></div><div class="line"><span class="comment"># Time in milliseconds to wait for responses from the back end or elasticsearch.</span></div><div class="line"><span class="comment"># This must be &gt; 0</span></div><div class="line"></div><div class="line">elasticsearch.requestTimeout: 30000</div><div class="line"></div><div class="line"><span class="comment"># Time in milliseconds for Elasticsearch to wait for responses from shards.</span></div><div class="line"><span class="comment"># Set to 0 to disable.</span></div><div class="line"><span class="comment"># elasticsearch.shardTimeout: 0</span></div></pre></td></tr></table></figure>
<h3 id="启动kibana服务"><a href="#启动kibana服务" class="headerlink" title="启动kibana服务"></a>启动kibana服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">service kibana start</div><div class="line">service kibana status</div></pre></td></tr></table></figure>
<h3 id="查看端口"><a href="#查看端口" class="headerlink" title="查看端口"></a>查看端口</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">netstat -nltp</div><div class="line">[root@es_02 config]<span class="comment"># netstat -nltp</span></div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name</div><div class="line">tcp        0      0 127.0.0.1:32000             0.0.0.0:*                   LISTEN      2517/java</div><div class="line">tcp        0      0 10.47.88.188:5601           0.0.0.0:*                   LISTEN      6474/node</div><div class="line">tcp        0      0 10.47.88.188:10050          0.0.0.0:*                   LISTEN      305/zabbix_agentd</div><div class="line">tcp        0      0 10.47.88.188:9200           0.0.0.0:*                   LISTEN      5198/java</div><div class="line">tcp        0      0 10.47.88.188:9300           0.0.0.0:*                   LISTEN      5198/java</div><div class="line">tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      25265/sshd</div></pre></td></tr></table></figure>
<p>到我Github上面下载kabana启动脚本。</p>
<p>es_01机器从es_02机器拷贝过去修改下配置就可以。 </p>
<h3 id="kibana安装插件参考："><a href="#kibana安装插件参考：" class="headerlink" title="kibana安装插件参考："></a>kibana安装插件参考：</h3><p><a href="https://www.elastic.co/guide/en/marvel/current/installing-marvel.html#installing-marvel" target="_blank" rel="external">Installing Marvel</a></p>
<p>这里kibana我做了nginx反向代理，集群代理。</p>
<h3 id="nginx配置kibana反向代理："><a href="#nginx配置kibana反向代理：" class="headerlink" title="nginx配置kibana反向代理："></a>nginx配置kibana反向代理：</h3><p>这里我只允许我公司IP访问：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">  upstream kibana.ihaozhuo.com &#123;</div><div class="line">        server 10.47.88.206:5601 weight=1;</div><div class="line">        server 10.47.88.188:5601 weight=1;</div><div class="line">&#125;</div><div class="line">  server &#123;</div><div class="line">        listen       80;</div><div class="line">        server_name  kibana.ihaozhuo.com;</div><div class="line">        location / &#123;</div><div class="line">             index        index.html index.php index.jsp index.htm;</div><div class="line">             allow 202.107.202.82/32;</div><div class="line">             deny all;</div><div class="line">             proxy_pass           http://kibana.ihaozhuo.com;</div><div class="line">             proxy_ignore_client_abort on;</div><div class="line">             proxy_redirect               off;</div><div class="line">             proxy_set_header     Host    <span class="variable">$host</span>;</div><div class="line">             proxy_set_header     X-Real-IP       <span class="variable">$remote_addr</span>;</div><div class="line">             proxy_set_header     X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</div><div class="line">             &#125;</div><div class="line">      &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="KafKa集群搭建"><a href="#KafKa集群搭建" class="headerlink" title="KafKa集群搭建"></a>KafKa集群搭建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">下载地址：http://mirrors.hust.edu.cn/apache/kafka/0.9.0.0/kafka_2.10-0.9.0.0.tgz</div><div class="line">[root@kafka_01 srv]<span class="comment"># tar -xvf kafka_2.10-0.9.0.0.tgz</span></div><div class="line">[root@kafka_01 srv]<span class="comment"># mv kafka_2.10-0.9.0.0 kafka</span></div></pre></td></tr></table></figure>
<p><em>修改kafka配置文件</em> </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@kafka_01 config]<span class="comment"># vim /srv/kafka/config/server.properties</span></div><div class="line"></div><div class="line"><span class="comment">#设置brokerid（从0开始，3个节点分别设为0,1,2，不能重复）在这里id=0跟zookeeper id设置一样就行。 集群机器：按顺序写1</span></div><div class="line">broker.id=0  </div><div class="line"></div><div class="line"><span class="comment">#设置data目录，最好不要用默认的/tmp/kafka-logs</span></div><div class="line">mkdir -p /srv/kafka/data/kafka-logs</div><div class="line"> </div><div class="line"></div><div class="line"><span class="comment">#修改本地IP地址：</span></div><div class="line">listeners=PLAINTEXT://10.46.72.172:9092</div><div class="line"> </div><div class="line">log.dirs=/srv/kafka/data/kafka-logs</div><div class="line"><span class="comment">#设置注册地址（重要，默认会把本机的hostanme注册到zk中，客户端连接时需要解析该hostanme，所以这里直接注册本机的IP地址，避免hostname解析失败，报错java.nio.channels.UnresolvedAddressException或java.io.IOException: Can not resolve address）</span></div><div class="line"><span class="comment">#设置zookeeper地址</span></div><div class="line">zookeeper.connect=10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181</div></pre></td></tr></table></figure>
<p><em>配置zookeeper地址</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">vim zookeeper.properties </div><div class="line">dataDir=/home/jollybi/tools/zookeeper-3.4.5/tmp</div><div class="line"><span class="comment"># the port at which the clients will connect</span></div><div class="line">clientPort=2281</div><div class="line"><span class="comment"># disable the per-ip limit on the number of connections since this is a non-production config</span></div><div class="line">maxClientCnxns=0</div><div class="line">~</div></pre></td></tr></table></figure>
<p><em>配置kafka访问地址</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">vim producer.properties </div><div class="line">metadata.broker.list=169.44.62.139:9292,169.44.59.138:9292,169.44.62.137:9292   </div><div class="line"><span class="comment"># name of the partitioner class for partitioning events; default partition spreads data randomly</span></div><div class="line"><span class="comment">#partitioner.class=</span></div><div class="line"></div><div class="line"><span class="comment"># specifies whether the messages are sent asynchronously (async) or synchronously (sync)</span></div><div class="line">producer.type=sync</div><div class="line"></div><div class="line"><span class="comment"># specify the compression codec for all data generated: none, gzip, snappy, lz4.</span></div><div class="line"><span class="comment"># the old config values work as well: 0, 1, 2, 3 for none, gzip, snappy, lz4, respectively</span></div><div class="line">compression.codec=none</div><div class="line"></div><div class="line"><span class="comment"># message encoder</span></div><div class="line">serializer.class=kafka.serializer.DefaultEncoder</div></pre></td></tr></table></figure>
<h3 id="Kafka常用命令-普及"><a href="#Kafka常用命令-普及" class="headerlink" title="Kafka常用命令(普及)"></a>Kafka常用命令(普及)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">Kafka常用命令</div><div class="line">以下是kafka常用命令行总结：  </div><div class="line">1.查看topic的详细信息  </div><div class="line">./kafka-topics.sh -zookeeper 127.0.0.1:2181 -describe -topic <span class="built_in">test</span>KJ1  </div><div class="line">2、为topic增加副本  </div><div class="line">./kafka-reassign-partitions.sh -zookeeper 127.0.0.1:2181 -reassignment-json-file json/partitions-to-move.json -execute  </div><div class="line">3、创建topic </div><div class="line">./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <span class="built_in">test</span>KJ1  </div><div class="line">4、为topic增加partition  </div><div class="line">./bin/kafka-topics.sh –zookeeper 127.0.0.1:2181 –alter –partitions 20 –topic <span class="built_in">test</span>KJ1  </div><div class="line">5、kafka生产者客户端命令  </div><div class="line">./kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="built_in">test</span>KJ1  </div><div class="line">6、kafka消费者客户端命令  </div><div class="line">./kafka-console-consumer.sh -zookeeper localhost:2181 --from-beginning --topic <span class="built_in">test</span>KJ1  </div><div class="line">7、kafka服务启动  </div><div class="line">./kafka-server-start.sh -daemon ../config/server.properties   </div><div class="line">8、下线broker  </div><div class="line">./kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper 127.0.0.1:2181 --broker <span class="comment">#brokerId# --num.retries 3 --retry.interval.ms 60  </span></div><div class="line">shutdown broker  </div><div class="line">9、删除topic  </div><div class="line">./kafka-run-class.sh kafka.admin.DeleteTopicCommand --topic <span class="built_in">test</span>KJ1 --zookeeper 127.0.0.1:2181  </div><div class="line">./kafka-topics.sh --zookeeper localhost:2181 --delete --topic <span class="built_in">test</span>KJ1  </div><div class="line">10、查看consumer组内消费的offset  </div><div class="line">./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group <span class="built_in">test</span> --topic <span class="built_in">test</span>KJ1</div></pre></td></tr></table></figure>
<h3 id="Kafka群集新建一个Topic"><a href="#Kafka群集新建一个Topic" class="headerlink" title="Kafka群集新建一个Topic"></a>Kafka群集新建一个Topic</h3><p>叫做logstash  Topic</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#查看tocpic列表（--zookeeper指定任意一个zk节点即可，用于获取集群信息）</span></div><div class="line">/usr/<span class="built_in">local</span>/kafka/bin/kafka-topics.sh --zookeeper zk1.yazuoyw.com:2181 --describe</div><div class="line"> </div><div class="line"><span class="comment">#创建topic（--replication-factor表示复制到多少个节点，--partitions表示分区数，一般都设置为2或与节点数相等，不能大于总节点数）</span></div><div class="line">/usr/<span class="built_in">local</span>/kafka/bin/kafka-topics.sh --zookeeper zk1.yazuoyw.com:2181 --create --topic topic1 --replication-factor 2 --partitions 2</div><div class="line"> </div><div class="line"><span class="comment">#发送消息（--topic 指定topic）</span></div><div class="line">/usr/<span class="built_in">local</span>/kafka/bin/kafka-console-producer.sh --broker-list kafka1.yazuoyw.com:9092,kafka2.yazuoyw.com:9092,kafka3.yazuoyw.com:9092 --topic topic1</div><div class="line">message1</div><div class="line">message2</div><div class="line"> </div><div class="line"><span class="comment">#消费消息</span></div><div class="line">/usr/<span class="built_in">local</span>/kafka/bin/kafka-console-consumer.sh --zookeeper zk1.yazuoyw.com:2181 --topic topic1</div><div class="line"></div><div class="line"><span class="comment">#replica检查</span></div><div class="line">/usr/<span class="built_in">local</span>/kafka/bin/kafka-replica-verification.sh --broker-list kafka1.yazuoyw.com:9092,kafka2.yazuoyw.com:9092,kafka3.yazuoyw.com:9092</div></pre></td></tr></table></figure>
<p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处）</p>
<p><code>ElasticSearch</code>机器<code>logstash</code>把数据从<code>kafka</code>存到<code>elasticsearch</code>的配置</p>
<p>其中选取kafka群集任意一个有zk的ip做连接使用</p>
<p><code>topic_id</code>就是kafka中设置的<code>topic logstash</code></p>
<p>在es上面安装logstash配置<br>/usr/local/logstash/config/kafka_to_es.conf</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"> input &#123;</div><div class="line">    kafka &#123;</div><div class="line">                zk_connect =&gt; <span class="string">"10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181/kafka"</span></div><div class="line">                group_id =&gt; <span class="string">"logstash"</span></div><div class="line">                topic_id =&gt; <span class="string">"logstash"</span></div><div class="line">                reset_beginning =&gt; <span class="literal">false</span> <span class="comment"># boolean (optional)， default: false</span></div><div class="line">                consumer_threads =&gt; 2  <span class="comment"># number (optional)， default: 1</span></div><div class="line">                decorate_events =&gt; <span class="literal">false</span> <span class="comment"># boolean (optional)， default: false</span></div><div class="line">        &#125;</div><div class="line">  &#125;</div><div class="line">  output &#123;</div><div class="line">    elasticsearch &#123;</div><div class="line">      hosts =&gt; [<span class="string">"10.47.88.206:9200"</span>,<span class="string">"10.47.88.188:9200"</span>]</div><div class="line">      index =&gt; <span class="string">"%&#123;host&#125;-%&#123;+YYYY.MM.dd&#125;"</span></div><div class="line">&#125;</div><div class="line">   <span class="comment"># stdout &#123; codec =&gt; rubydebug &#125;</span></div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>新建了个测试的，测试下发送是否成功：/usr/local/logstash/config/stdin_to_es.conf </p>
<figure class="highlight puppet"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">input</span> &#123;</div><div class="line"> stdin &#123;&#125;</div><div class="line">&#125;</div><div class="line">  <span class="keyword">output</span> &#123;</div><div class="line">    elasticsearch &#123;</div><div class="line">      <span class="attr">hosts</span> =&gt; <span class="string">"10.47.88.206"</span>&#125;</div><div class="line">    <span class="keyword">stdout</span> &#123;</div><div class="line">      <span class="attr">codec</span> =&gt; rubydebug &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h3 id="Step-2-启动服务"><a href="#Step-2-启动服务" class="headerlink" title="Step 2: 启动服务"></a>Step 2: 启动服务</h3><figure class="highlight dts"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">Kafka用到了Zookeeper，所有首先启动Zookper，下面简单的启用一个单实例的Zookkeeper服务。可以在命令的结尾加个&amp;符号，这样就可以启动后离开控制台。</div><div class="line"></div><div class="line"><span class="meta">#现在启动Kafka:</span></div><div class="line"></div><div class="line"><span class="meta-keyword">/srv/</span>kafka<span class="meta-keyword">/bin/</span>kafka-server-start.sh -daemon config/server.properties</div><div class="line"></div><div class="line"><span class="meta">#添加开机启动</span></div><div class="line">echo ‘</div><div class="line"><span class="meta"># start kafka</span></div><div class="line"><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/kafka/</span>bin/kafka-server-start.sh -daemon <span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/kafka/</span>config/server.properties</div><div class="line">‘ &gt;&gt; <span class="meta-keyword">/etc/</span>rc.local</div><div class="line"> </div><div class="line"><span class="meta">#关闭</span></div><div class="line"><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/kafka/</span>bin/kafka-server-stop.sh</div></pre></td></tr></table></figure>
<h3 id="kafka配置防火墙："><a href="#kafka配置防火墙：" class="headerlink" title="kafka配置防火墙："></a>kafka配置防火墙：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 4888 -j ACCEPT</div></pre></td></tr></table></figure>
<h3 id="zookeeper集群"><a href="#zookeeper集群" class="headerlink" title="zookeeper集群"></a>zookeeper集群</h3><p>查看我之前写的这篇文档 <a href="http://blog.yangcvo.me/2016/05/28/%E5%A4%A7%E6%95%B0%E6%8D%AEhadoop/zookeeper/ZooKeeper%E9%9B%86%E7%BE%A4%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BC%98%E5%8C%96/" target="_blank" rel="external">ZooKeeper的集群快速搭建与优化</a> </p>
<h3 id="走kafka查看是否所有节点都启动："><a href="#走kafka查看是否所有节点都启动：" class="headerlink" title="走kafka查看是否所有节点都启动："></a>走kafka查看是否所有节点都启动：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@kafka_03 bin]<span class="comment"># sh zkCli.sh</span></div><div class="line">Connecting to localhost:2181</div><div class="line">2017-01-04 19:20:24,849 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT</div><div class="line">2017-01-04 19:20:24,853 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=kafka_03</div><div class="line">2017-01-04 19:20:24,853 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.8.0_66</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/srv/jdk1.8.0_66/jre</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/srv/zookeeper-3.4.6/bin/../build/classes:/srv/zookeeper-3.4.6/bin/../build/lib/*.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/srv/zookeeper-3.4.6/bin/../lib/<span class="built_in">log</span>4j-1.2.16.jar:/srv/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/srv/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/srv/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/srv/zookeeper-3.4.6/bin/../conf:</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib</div><div class="line"></div><div class="line">[zk: localhost:2181(CONNECTED) 0] ls /</div><div class="line">[controller_epoch, brokers, zookeeper, kafka, dubbo, admin, isr_change_notification, consumers, config, sthp]</div><div class="line">[zk: localhost:2181(CONNECTED) 5] ls /kafka/brokers/ids</div><div class="line">[0, 1, 2]</div></pre></td></tr></table></figure>
<p>kafka 三台集群这里可以看到获取到ids。</p>
<h4 id="安全问题"><a href="#安全问题" class="headerlink" title="安全问题"></a>安全问题</h4><p>特别要注意elk所有软件的端口监听,切勿暴露监听到公网上去,另外即便是内网你也得注意配置内网的访问限制。</p>
<h3 id="logstash-客户端安装："><a href="#logstash-客户端安装：" class="headerlink" title="logstash 客户端安装："></a>logstash 客户端安装：</h3><h5 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">我这里源码包安装</div><div class="line"><span class="comment"># wget https://download.elasticsearch.org/logstash/logstash/logstash-2.4.0.tar.gz</span></div><div class="line"><span class="comment">#curl -O https://download.elastic.co/logstash/logstash/logstash-2.4.0.tar.gz</span></div><div class="line"><span class="comment">#tar -zxvf logstash-2.4.0.tar.gz</span></div><div class="line"><span class="comment">#mv logstash-2.4.0 /usr/local/</span></div><div class="line"><span class="comment">#ln -s /usr/local/logstash-2.4.0/ /usr/local/logstash</span></div><div class="line"></div><div class="line">下载启动脚本</div><div class="line">生产都是运行在后台的，我这里源码安装没有init脚本启动。 去Github下载  https://github.com/benet1006/ELK_config.git</div><div class="line"><span class="comment">#cp logstash.init /etc/init.d/logstash</span></div><div class="line"><span class="comment">#chmod +x /etc/init.d/logstash</span></div><div class="line">这个脚本我做过修改。</div><div class="line"></div><div class="line"><span class="comment">#启动logstash服务</span></div><div class="line">service logstash start</div><div class="line">service logstash status</div><div class="line"></div><div class="line"><span class="comment">#查看5000端口</span></div><div class="line">netstat -nltp</div><div class="line"></div><div class="line">Active Internet connections (only servers)</div><div class="line">Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name</div><div class="line">tcp 0 0 0.0.0.0:9200 0.0.0.0:* LISTEN 1765/java</div><div class="line">tcp 0 0 0.0.0.0:9300 0.0.0.0:* LISTEN 1765/java</div><div class="line">tcp 0 0 0.0.0.0:9301 0.0.0.0:* LISTEN 2309/java</div><div class="line">tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1509/sshd</div><div class="line">tcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 1876/node</div><div class="line">tcp 0 0 0.0.0.0:5000 0.0.0.0:* LISTEN 2309/java</div><div class="line">tcp 0 0 :::22 :::* LISTEN 1509/sshd</div><div class="line"></div><div class="line"></div><div class="line">修改启动脚本</div><div class="line">vim /etc/init.d/logstash </div><div class="line">指定的目录自己源码安装的路径。</div><div class="line"></div><div class="line">name=logstash</div><div class="line">pidfile=<span class="string">"/var/run/<span class="variable">$name</span>.pid"</span></div><div class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</div><div class="line">LS_USER=logstash</div><div class="line">LS_GROUP=logstash</div><div class="line">LS_HOME=/usr/<span class="built_in">local</span>/logstash 安装路径</div><div class="line">LS_HEAP_SIZE=<span class="string">"1000m"</span></div><div class="line">LS_JAVA_OPTS=<span class="string">"-Djava.io.tmpdir=<span class="variable">$&#123;LS_HOME&#125;</span>"</span></div><div class="line">LS_LOG_DIR=/usr/<span class="built_in">local</span>/logstash</div><div class="line">LS_LOG_FILE=<span class="string">"<span class="variable">$&#123;LS_LOG_DIR&#125;</span>/<span class="variable">$name</span>.log"</span></div><div class="line">LS_CONF_FILE=/etc/logstash.conf     收集日志的规则conf</div><div class="line">LS_OPEN_FILES=16384</div><div class="line">LS_NICE=19</div><div class="line">LS_OPTS=<span class="string">""</span></div><div class="line"></div><div class="line">https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html</div><div class="line">这个是<span class="built_in">log</span> stash的官方文档的配置说明。</div><div class="line">这个配置说明上面我先修改下我之前的配置文件。</div></pre></td></tr></table></figure>
<h4 id="logstash-agent配置："><a href="#logstash-agent配置：" class="headerlink" title="logstash agent配置："></a>logstash agent配置：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">配置<span class="built_in">log</span> stash－实现系统日志收集input</div><div class="line">file_to_kafka.conf 日志文件读出写入到kafka</div><div class="line">input &#123;</div><div class="line">file &#123;</div><div class="line">path =&gt; <span class="string">"/srv/tomcat/logs/account/logFile.*.log"</span></div><div class="line"><span class="built_in">type</span> =&gt; <span class="string">"tomcat"</span></div><div class="line">discover_interval =&gt; 15 <span class="comment">#logstash</span></div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">output &#123;</div><div class="line"><span class="comment">#stdout &#123; codec =&gt; rubydebug &#125;</span></div><div class="line">kafka&#123;</div><div class="line">bootstrap_servers =&gt; <span class="string">"10.46.72.172:9092,10.47.88.103:9092,10.47.102.137:9092"</span></div><div class="line"><span class="comment">#group_id =&gt; "logstash"</span></div><div class="line">topic_id =&gt; <span class="string">"logstash"</span></div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">2.2 logstash indexer 配置</div><div class="line">kafka_to_es.conf</div><div class="line">input &#123;</div><div class="line">kafka &#123;</div><div class="line">zk_connect =&gt; <span class="string">"10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181kafka"</span></div><div class="line">group_id =&gt; <span class="string">"logstash"</span></div><div class="line">topic_id =&gt; <span class="string">"logstash"</span></div><div class="line">reset_beginning =&gt; <span class="literal">false</span> <span class="comment"># boolean (optional)， default: false</span></div><div class="line">consumer_threads =&gt; 2 <span class="comment"># number (optional)， default: 1</span></div><div class="line">decorate_events =&gt; <span class="literal">false</span> <span class="comment"># boolean (optional)， default: false</span></div><div class="line">&#125;</div><div class="line">&#125;</div><div class="line">output &#123;</div><div class="line">elasticsearch &#123;</div><div class="line">hosts =&gt; [<span class="string">"10.47.88.206:9200"</span>,<span class="string">"10.47.88.188:9200"</span>]</div><div class="line">index =&gt; <span class="string">"%&#123;host&#125;-%&#123;+YYYY.MM.dd&#125;"</span></div><div class="line">&#125;</div><div class="line"><span class="comment"># stdout &#123; codec =&gt; rubydebug &#125;</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="es安装插件head查看下效果："><a href="#es安装插件head查看下效果：" class="headerlink" title="es安装插件head查看下效果："></a>es安装插件head查看下效果：</h4><p>然后打开网站：<a href="http://elk.ihaozhuo.com/_plugin/head/" target="_blank" rel="external">http://elk.ihaozhuo.com/_plugin/head/</a></p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/es_head.png" alt=""></figure></p>
<p>####kibana网站效果：</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/es_kibana.png" alt=""></figure></p>
<h3 id="交流学习："><a href="#交流学习：" class="headerlink" title="交流学习："></a>交流学习：</h3><p>🐧  Linux shell_高级运维派: <code>459096184</code>    圈子 (系统运维-应用运维-自动化运维-虚拟化技术研究欢迎加入)<br>🐧  BigData-Exchange School : <code>521621407</code>  圈子（大数据运维)（Hadoop开发人员)（大数据研究爱好者) 欢迎加入</p>
<p>相应Bidata有内部微信交流群互相学习，加入QQ群有链接。</p>

	

	

</article>





	<span class="different-posts">📖 <a href="/page/4">more posts</a> 📖</span>



	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<h5>Hi there,</h5>
	<p style="text-align:justify;">my name is Yancy, they know me as Radiant🐑🐑. This blog is about Bi-data and my live.<br> I like 🌳🌳🌳</p>
</div>


	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2017 Yancy | Powered by <a href="http://blog.yancy.cc/">Yancy</a> | Theme <a href="https://github.com/yangcvo">Yancy_GitHub</a></span>
		</div>

	</div>


</footer>



</body>

</html>
