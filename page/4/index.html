<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>Yancy&#39;s blog</title>
	<link rel="stylesheet" href="/css/style.css" />
	
      <link rel="alternate" href="/atom.xml" title="Yancy&#39;s blog" type="application/atom+xml">
    
</head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/" class="header__link">Home</a>
			
				<a href="/tags" class="header__link">Tags</a>
			
				<a href="/archives" class="header__link">ARCHIVES</a>
			
				<a href="/about/About" class="header__link">ABOUT</a>
			
				<a href="/atom.xml" class="header__link">RSS</a>
			
		</nav>
		<h1 class="header__title"><a href="/">Yancy&#39;s blog</a></h1>
		<h2 class="header__subtitle">SIMPLICITY IS PREREQUISITE FOR  RELIABILITY</h2>
	</header>

	<main>
		
	<span class="different-posts different-posts_earlier">📖 <a href="/page/3">earlier posts</a> 📖</span>




	<article>
	
		<h1><a href="/2017/05/28/Bigdata-hadoop/Kafka/Bigdata-Kafka集群快速搭建与增删改查命令讲解/">Bigdata-Kafka集群快速搭建与命令讲解</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-05-28</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/大数据/">大数据</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Big-data-Hadoop/">Big data Hadoop</a> <a class="article__tag-link" href="/tags/Kafka/">Kafka</a>
			</span>
		
	</div>

	

	
		<h1 id="Bigdata-Kafka集群快速搭建与命令讲解"><a href="#Bigdata-Kafka集群快速搭建与命令讲解" class="headerlink" title="Bigdata-Kafka集群快速搭建与命令讲解"></a>Bigdata-Kafka集群快速搭建与命令讲解</h1><h3 id="kafka集群和zookeeper集群规范"><a href="#kafka集群和zookeeper集群规范" class="headerlink" title="kafka集群和zookeeper集群规范"></a>kafka集群和zookeeper集群规范</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">kafka集群和zookeeper集群规范</div><div class="line">kafka版本：kafka_2.10-0.8.2.1</div><div class="line">zookeeper版本：zookeeper-3.4.5</div><div class="line"></div><div class="line">启动用户：jollybi</div><div class="line">kafka安装目录：/data/tools/</div><div class="line">kafka新建消息目录：/data/tools/kafka_2.10-0.8.2.1/kafka-logs</div><div class="line"></div><div class="line">启动用户：jollybi</div><div class="line">zookeeper安装目录：/data/tools/</div><div class="line">zookeeper新建日志目录：/data/tools/zookeeper-3.4.5/tmp/logs</div><div class="line"></div><div class="line">统一配置hosts</div><div class="line"></div><div class="line"></div><div class="line">10.155.90.153 kafka1.jollychic.com kafka1</div><div class="line">10.155.90.155 kafka2.jollychic.com kafka2</div><div class="line">10.155.90.138 kafka3.jollychic.com kafka3</div></pre></td></tr></table></figure>
<p>本文使用了3台机器部署Kafka集群，IP和主机名对应关系如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">10.155.90.153 kafka1.jollychic.com kafka1</div><div class="line">10.155.90.155 kafka2.jollychic.com kafka2</div><div class="line">10.155.90.138 kafka3.jollychic.com kafka3</div></pre></td></tr></table></figure>
<h3 id="Step1-配置-etc-hosts-（3台一致）"><a href="#Step1-配置-etc-hosts-（3台一致）" class="headerlink" title="Step1: 配置/etc/hosts （3台一致）"></a>Step1: 配置/etc/hosts （3台一致）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">127.0.0.1 localhost.localdomain localhost</div><div class="line">10.155.90.153 kafka1.jollychic.com kafka1</div><div class="line">10.155.90.155 kafka2.jollychic.com kafka2</div><div class="line">10.155.90.138 kafka3.jollychic.com kafka3</div></pre></td></tr></table></figure>
<h3 id="Step2-KafKa集群搭建"><a href="#Step2-KafKa集群搭建" class="headerlink" title="Step2: KafKa集群搭建"></a>Step2: KafKa集群搭建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">下载地址：http://mirrors.hust.edu.cn/apache/kafka/0.9.0.0/kafka_2.10-0.8.2.1.tgz</div><div class="line">[jollybi@kafka1 ]<span class="comment"># tar -xvf kafka_2.10-0.8.2.1.tgz -C /data/tools/</span></div><div class="line"><span class="built_in">cd</span> /data/tools/kafka_2.10-0.8.2.1/config</div></pre></td></tr></table></figure>
<h3 id="设置data目录，最好不要用默认的-tmp-kafka-logs"><a href="#设置data目录，最好不要用默认的-tmp-kafka-logs" class="headerlink" title="设置data目录，最好不要用默认的/tmp/kafka-logs"></a>设置data目录，最好不要用默认的/tmp/kafka-logs</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir -p /data/tools/kafka_2.10-0.8.2.1/kafka-logs/</div></pre></td></tr></table></figure>
<p><em>修改kafka配置文件</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[root@kafka_01 config]<span class="comment"># vim server.properties</span></div><div class="line"></div><div class="line"></div><div class="line"> 设置brokerid（从0开始，3个节点分别设为1,2,3，不能重复）在这里id=0跟zookeeper id设置一样就行。 集群机器：按顺序写1</div><div class="line">broker.id=1  </div><div class="line"></div><div class="line">auto.leader.rebalance.enable=<span class="literal">true</span> </div><div class="line"></div><div class="line"><span class="comment">#修改本地IP地址：</span></div><div class="line">listeners=PLAINTEXT://10.46.72.172:9092</div><div class="line">port=9292 //设置访问端口</div><div class="line">host.name=10.155.90.153   kafka本机IP</div><div class="line">log.dirs=/data/tools/kafka_2.10-0.8.2.1/kafka-logs</div><div class="line"></div><div class="line"><span class="comment">#设置注册地址（重要，默认会把本机的hostanme注册到zk中，客户端连接时需要解析该hostanme，所以这里直接注册本机的IP地址，避免hostname解析失败，报错java.nio.channels.UnresolvedAddressException或java.io.IOException: Can not resolve address）</span></div><div class="line"><span class="comment">#设置zookeeper地址</span></div><div class="line"><span class="comment">#zookeeper.connect=10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181</span></div><div class="line">zookeeper.connect=kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281</div><div class="line"></div><div class="line">//这里我设置hosts代替IP</div></pre></td></tr></table></figure>
<p><em>配置zookeeper地址</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">vim zookeeper.properties </div><div class="line">dataDir=/data/tools/zookeeper-3.4.5/tmp</div><div class="line"><span class="comment"># the port at which the clients will connect</span></div><div class="line">clientPort=2281</div><div class="line"><span class="comment"># disable the per-ip limit on the number of connections since this is a non-production config</span></div><div class="line">maxClientCnxns=0</div><div class="line">~</div></pre></td></tr></table></figure>
<p><em>配置kafka访问地址</em></p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="attribute">vim</span> producer.properties </div><div class="line">metadata.broker.list=<span class="number">169.44.62.139:9292</span>,<span class="number">169.44.59.138:9292</span>,<span class="number">169.44.62.137:9292</span>   </div><div class="line"><span class="comment"># name of the partitioner class for partitioning events; default partition spreads data randomly</span></div><div class="line"><span class="comment">#partitioner.class=</span></div><div class="line"></div><div class="line"><span class="comment"># specifies whether the messages are sent asynchronously (async) or synchronously (sync)</span></div><div class="line">producer.type=sync</div><div class="line"></div><div class="line"><span class="comment"># specify the compression codec for all data generated: none, gzip, snappy, lz4.</span></div><div class="line"><span class="comment"># the old config values work as well: 0, 1, 2, 3 for none, gzip, snappy, lz4, respectively</span></div><div class="line">compression.codec=<span class="literal">none</span></div><div class="line"></div><div class="line"><span class="comment"># message encoder</span></div><div class="line">serializer.class=kafka.serializer.DefaultEncoder</div></pre></td></tr></table></figure>
<h3 id="Step3-集群机器快速拷贝配置"><a href="#Step3-集群机器快速拷贝配置" class="headerlink" title="Step3: 集群机器快速拷贝配置:"></a>Step3: 集群机器快速拷贝配置:</h3><p>远程复制分发安装文件<br>最好是把文件打包scp过去<br>接下来将上面的安装文件拷贝到集群中的其他机器上对应的目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scp -P58958 -r kafka_2.10-0.8.2.1 jollybi@169.44.62.137:/home/jollybi/tools/. </div><div class="line">scp -P58958 -r kafka_2.10-0.8.2.1 jollybi@169.44.62.138:/home/jollybi/tools/.</div></pre></td></tr></table></figure>
<p>统一修改分别其他两台kafka <code>server.properties</code></p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">broker.id=<span class="number">2</span>  </div><div class="line">host.name=<span class="number">169.44</span><span class="number">.62</span><span class="number">.137</span>   kafka2本机IP</div><div class="line"></div><div class="line">broker.id=<span class="number">3</span> </div><div class="line">host.name=<span class="number">169.44</span><span class="number">.62</span><span class="number">.138</span>   kafka3本机IP</div></pre></td></tr></table></figure>
<h3 id="Step4-启动-kafka集群"><a href="#Step4-启动-kafka集群" class="headerlink" title="Step4:启动 kafka集群"></a>Step4:启动 kafka集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">./kafka-server-start.sh -daemon ../config/server.properties</div><div class="line"></div><div class="line">[jollybi@kafka1 config]$ jps</div><div class="line">3443 QuorumPeerMain</div><div class="line">16280 Jps</div><div class="line">3628 Kafka</div><div class="line">Step5: Kafka常用命令(普及)</div></pre></td></tr></table></figure>
<h4 id="Step5-测试集群"><a href="#Step5-测试集群" class="headerlink" title="Step5:测试集群"></a>Step5:测试集群</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div></pre></td><td class="code"><pre><div class="line"><span class="comment">### 默认创建kafka Topic:  1个副本备份 1个分区消费</span></div><div class="line"></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 1 --partitions 1 --topic mongotail_lz4</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 1 --partitions 1 --topic mongotail_lz4_imp</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 大数据这边需要12个分区这里我删除Topic重新创建Topic：</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 删除kafka Topic:</span></div><div class="line"></div><div class="line"></div><div class="line">第一步：删除kafka topic</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --delete --topic  mongotail_lz4 </div><div class="line"></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --delete --topic  mongotail_lz4_imp</div><div class="line"></div><div class="line"><span class="comment">### 这是由于删除topic没删干净会报错：</span></div><div class="line"></div><div class="line">org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 删除线程执行删除操作的真正逻辑是：</span></div><div class="line">1. 它首先会给当前所有broker发送更新元数据信息的请求，告诉这些broker说这个topic要删除了，你们可以把它的信息从缓存中删掉了</div><div class="line">2. 开始删除这个topic的所有分区</div><div class="line">2.1 给所有broker发请求，告诉它们这些分区要被删除。broker收到后就不再接受任何在这些分区上的客户端请求了</div><div class="line">2.2 把每个分区下的所有副本都置于OfflineReplica状态，这样ISR就不断缩小，当leader副本最后也被置于OfflineReplica状态时leader信息将被更新为-1</div><div class="line">2.3 将所有副本置于ReplicaDeletionStarted状态</div><div class="line">2.4 副本状态机捕获状态变更，然后发起StopReplicaRequest给broker，broker接到请求后停止所有fetcher线程、移除缓存，然后删除底层<span class="built_in">log</span>文件</div><div class="line">2.5 关闭所有空闲的Fetcher线程</div><div class="line">    </div><div class="line"><span class="comment">### 第二步：删除zookeeper相关的路径：</span></div><div class="line">[jollybi@kafka1 zookeeper-3.4.5]$ ./bin/zkCli.sh -server 127.0.0.1:2281 </div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 1] rmr /brokers/topics/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 0] rmr /consumers/group_ml_general/offsets/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 1] rmr /consumers/group_ml_general/owners/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 3] rmr  /config/topics/mongotail_lz4</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 4] rmr /admin/delete_topics/mongotail_lz4</div><div class="line"></div><div class="line"><span class="comment">### 删除topic上面消费组 </span></div><div class="line"></div><div class="line">删除 ZooKeeper 下面的 /consumers/[group_id] 路径就可以了。ZooKeeper 原生API只支持删除空的路径，所以建议你使用 curator framework 进行这个删除操作，ZkPaths.deleteChildren 会递归式地删除整个路径（包括子路径）。</div><div class="line"></div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 0] rmr /consumers/kafka-node1-imp-group</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 1] rmr /consumers/kafka-node1-group</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 2] rmr /consumers/console-consumer-59053</div><div class="line">[zk: 127.0.0.1:2281(CONNECTED) 3] rmr /consumers/</div><div class="line"></div><div class="line"></div><div class="line">1、设置配置文件允许删除</div><div class="line">delete.topic.enable=<span class="literal">true</span> 配置添加到 config/server.properties</div><div class="line">2、执行删除命令</div><div class="line">./bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic <span class="built_in">test</span>-topic</div><div class="line"></div><div class="line">在zookeeper中确认：</div><div class="line"></div><div class="line"> 删除zookeeper下/brokers/topics/<span class="built_in">test</span>-topic节点</div><div class="line"> 删除zookeeper下/config/topics/<span class="built_in">test</span>-topic节点</div><div class="line"> 删除zookeeper下/admin/delete_topics/<span class="built_in">test</span>-topic节点</div><div class="line"> </div><div class="line">consumer 的话 删除groupid</div><div class="line"> </div><div class="line"></div><div class="line"><span class="comment">### 重启kafka集群</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 大数据kafka建topic，不能建一个分区，那样吞吐量上不去，不够用，我们以前建了12个分区的</span></div><div class="line"><span class="comment">### 创建新 kafka Topic: 3个副本，12个分区</span></div><div class="line"></div><div class="line"> ./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 3 --partitions 12  --topic mongotail_lz4</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh --create --zookeeper  kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281 --replication-factor 3 --partitions 12  --topic mongotail_lz4_imp</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 查看创建的Topic:</span></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh  --describe --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281  --topic mongotail_lz4</div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh  --describe --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281  --topic mongotail_lz4_imp</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### 查看集群情况：</span></div><div class="line">./kafka_2.10-0.8.2.1/bin/kafka-topics.sh  --describe --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281  --topic mongotail_lz4</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">### kafka生产客户端生产数据命令：</span></div><div class="line"></div><div class="line">./bin/kafka-console-producer.sh --broker-list 75.126.39.124:9292,75.126.5.162:9292,75.126.5.178:9292 --topic mongotail_lz4_imp                      </div><div class="line">......</div><div class="line">my <span class="built_in">test</span> message 1</div><div class="line">my <span class="built_in">test</span> message 2</div><div class="line">^C</div><div class="line"><span class="comment">### kafka消费客户端数据命令 现在我们来看看消息：</span></div><div class="line"></div><div class="line"> ./bin/kafka-console-consumer.sh --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  --fm-beginning --topic mongotail_lz4_imp</div><div class="line">......</div><div class="line">my <span class="built_in">test</span> message 1</div><div class="line">my <span class="built_in">test</span> message 2</div><div class="line"></div><div class="line">^C</div></pre></td></tr></table></figure>
<h3 id="Kafka常用命令"><a href="#Kafka常用命令" class="headerlink" title="Kafka常用命令"></a>Kafka常用命令</h3><p>以下是kafka常用命令行总结：  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">1、 list topic 显示所有topic</div><div class="line">./bin/kafka-topics.sh --list --zookeeper kafka1.jollychic.com:2281,kafka2.jollychic.com:2281,kafka3.jollychic.com:2281</div><div class="line"></div><div class="line">2、 查看topic的详细信息  </div><div class="line"> ./bin/kafka-topics.sh --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  -describe -topic mongotail_lz4_imp</div><div class="line"></div><div class="line">3、为topic增加partition分区 参数：--alter --partitions</div><div class="line">./bin/kafka-topics.sh  --alter --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  --partitions 20 --topic mongotail_lz4_imp</div><div class="line"></div><div class="line">4、kafka生产者客户端命令  </div><div class="line">./bin/kafka-console-producer.sh --broker-list 75.126.39.124:9292,75.126.5.162:9292,75.126.5.178:9292 --topic mongotail_lz4_imp                        </div><div class="line"></div><div class="line">5、kafka消费者客户端命令  </div><div class="line">./bin/kafka-console-consumer.sh --zookeeper  75.126.39.124:2281,75.126.5.162:2281,75.126.5.178:2281  --fm-beginning --topic </div><div class="line"></div><div class="line">6、kafka服务启动  </div><div class="line">./kafka-server-start.sh -daemon ../config/server.properties   </div><div class="line"></div><div class="line">7、下线broker  </div><div class="line">./kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper 127.0.0.1:2181 --broker <span class="comment">#brokerId# --num.retries 3 --retry.interval.ms 60  </span></div><div class="line">shutdown broker  </div><div class="line"></div><div class="line">8、删除topic  </div><div class="line">./kafka-run-class.sh kafka.admin.DeleteTopicCommand --topic <span class="built_in">test</span>KJ1 --zookeeper 127.0.0.1:2181  </div><div class="line">./kafka-topics.sh --zookeeper localhost:2181 --delete --topic <span class="built_in">test</span>KJ1  </div><div class="line"></div><div class="line">9、查看consumer组内消费的offset  </div><div class="line">./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper localhost:2181 --group <span class="built_in">test</span> --topic <span class="built_in">test</span>KJ1</div></pre></td></tr></table></figure>

	

	

</article>




	<article>
	
		<h1><a href="/2017/05/27/Bigdata-hadoop/zookeeper/Bigdata-ZooKeeper的配置详解优化/">Bigdata-ZooKeeper的配置详解优化</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-05-27</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/大数据/">大数据</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/ZooKeeper/">ZooKeeper</a>
			</span>
		
	</div>

	

	
		<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p><code>ZooKeeper</code>的功能特性通过 <code>ZooKeeper</code> 配置文件来进行控制管理（ <code>zoo.cfg</code> 配置文件）。 ZooKeeper 这样的设计其实是有它自身的原因的。通过前面对 <code>ZooKeeper</code> 的配置可以看出，对 <code>ZooKeeper</code>集群进行配置的时候，它的配置文档是完全相同的（对于集群伪分布模式来说，只有很少的部分是不同的）。这样的配置方使得在部署 <code>ZooKeeper</code> 服务的时候非常地方便。另外，如果服务器使用不同的配置文件，必须要确保不同配置文件中的服务器列表相匹配。</p>
<p>在设置 <code>ZooKeeper</code> 配置文档的时候，某些参数是可选的，但是某些参数是必须的。这些必须的参数就构成了<code>ZooKeeper</code> 配置文档的最低配置要求。</p>
<h5 id="最近发现在用zookeeper出现经常出现连接超时，出现连接中断，数据丢失等原因。后面看了官网配置自己整理优化几点："><a href="#最近发现在用zookeeper出现经常出现连接超时，出现连接中断，数据丢失等原因。后面看了官网配置自己整理优化几点：" class="headerlink" title="最近发现在用zookeeper出现经常出现连接超时，出现连接中断，数据丢失等原因。后面看了官网配置自己整理优化几点："></a>最近发现在用zookeeper出现经常出现连接超时，出现连接中断，数据丢失等原因。后面看了官网配置自己整理优化几点：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">2.1错误日志：</div><div class="line"></div><div class="line">2016-04-11 15:00:58,981 [myid:] - WARN  [SyncThread:0:FileTxnLog@334] - fsync-ing the write ahead <span class="built_in">log</span> <span class="keyword">in</span> SyncThread:0 took 13973ms <span class="built_in">which</span> will adversely effect operation latency. See the ZooKeeper troubleshooting guide</div><div class="line"></div><div class="line"></div><div class="line">&gt;2.2，错误原因分析</div><div class="line"></div><div class="line">“FOLLOWER”在跟“LEADER”同步时，fsync操作时间过长，导致超时。</div><div class="line"></div><div class="line"></div><div class="line">第一步：分析服务器问题：</div><div class="line"></div><div class="line">我查看了服务器io和负载都不高。内存空间实际使用率不高。可是编辑文件出现了卡顿.</div><div class="line"></div><div class="line">可以发现：</div><div class="line"></div><div class="line">服务器并没有占用很多内存的进程；</div><div class="line">服务器也没有存在很多的进程；</div><div class="line">cat /var/<span class="built_in">log</span>/message查看系统日志并没有发现什么异常；</div><div class="line">另外ping服务器只有0.1ms多的延迟，因此不是网络问题。</div><div class="line"></div><div class="line">后面发现硬盘有故障重新更换了一块硬盘。或者更换服务器。</div><div class="line"></div><div class="line"></div><div class="line">&gt;2.3，错误解决</div><div class="line"></div><div class="line">增加“tickTime”或者“initLimit和syncLimit”的值，或者两者都增大。</div><div class="line"></div><div class="line"></div><div class="line">&gt;2.4，其他</div><div class="line"></div><div class="line">这个错误在上线“使用ZooKeeper获取地址方案”之前也存在，只不过过没有这么高频率，而上线了“ZooKeeper获取地址方案”之后，ZooKeeper Server之间的同步数据量增大，ZooKeeper Server的负载加重，因而最终导致高频率出现上述错误。</div></pre></td></tr></table></figure>
<h2 id="下面是在最低配置要求中必须配置的参数："><a href="#下面是在最低配置要求中必须配置的参数：" class="headerlink" title="下面是在最低配置要求中必须配置的参数："></a>下面是在最低配置要求中必须配置的参数：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">### 最小配置</span></div><div class="line"></div><div class="line">最小配置意味着所有的配置文件中必须要包含这些配置选项。</div><div class="line"></div><div class="line"><span class="comment">#### clientPort</span></div><div class="line"></div><div class="line">服务器监听客户端连接的端口, 亦即客户端尝试连接到服务器上的指定端口。</div><div class="line"></div><div class="line"><span class="comment">##### dataDir</span></div><div class="line"></div><div class="line">ZooKeeper 存储内存数据库快照文件的路径, 并且如果没有指定其它路径的话, 数据库更新的事务日志也将存储到该路径下。</div><div class="line"></div><div class="line">注意: 事务日志会影响 ZooKeeper 服务器的整体性能, 所以建议将事务日志放置到由 dataLogDir 参数指定的路径下。</div><div class="line"></div><div class="line"><span class="comment">##### tickTime</span></div><div class="line"></div><div class="line">单个 tick 的时间长度, 它是 ZooKeeper 中使用的基本时间单元, 以毫秒为单位。它用来调节心跳和超时时间。例如, 最小会话超时时间是 2 个 tick。</div></pre></td></tr></table></figure>
<p>生产环境例子：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">1.tickTime：CS通信心跳数</div><div class="line"></div><div class="line">Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。</div><div class="line"></div><div class="line">tickTime=2000  </div><div class="line"></div><div class="line">2.initLimit：LF初始通信时限</div><div class="line">集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。</div><div class="line"></div><div class="line">initLimit=5  </div><div class="line"></div><div class="line">3.syncLimit：LF同步通信时限</div><div class="line">集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。</div><div class="line"></div><div class="line">syncLimit=2  </div><div class="line"> </div><div class="line">4.dataDir：数据文件目录</div><div class="line">Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。</div><div class="line"></div><div class="line">dataDir=/home/michael/opt/zookeeper/data  </div><div class="line"></div><div class="line">5.dataLogDir：日志文件目录</div><div class="line">Zookeeper保存日志文件的目录。</div><div class="line"></div><div class="line">dataLogDir=/home/michael/opt/zookeeper/<span class="built_in">log</span>  </div><div class="line"></div><div class="line">6.clientPort：客户端连接端口</div><div class="line">客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。</div><div class="line"></div><div class="line">clientPort=2333  </div><div class="line"></div><div class="line">7.服务器名称与地址：集群信息（服务器编号，服务器地址，LF通信端口，选举端口）</div><div class="line">这个配置项的书写格式比较特殊，规则如下：</div><div class="line"></div><div class="line">server.N=YYY:A:B  </div><div class="line"></div><div class="line">其中N表示服务器编号，YYY表示服务器的IP地址，A为LF通信端口，表示该服务器与集群中的leader交换的信息的端口。B为选举端口，表示选举新leader时服务器间相互通信的端口（当leader挂掉时，其余服务器会相互通信，选择出新的leader）。一般来说，集群中每个服务器的A端口都是一样，每个服务器的B端口也是一样。但是当所采用的为伪集群时，IP地址都一样，只能时A端口和B端口不一样。</div><div class="line">下面是一个非伪集群的例子：</div><div class="line"></div><div class="line">server.0=233.34.9.144:2008:6008  </div><div class="line">server.1=233.34.9.145:2008:6008  </div><div class="line">server.2=233.34.9.146:2008:6008  </div><div class="line">server.3=233.34.9.147:2008:6008  </div><div class="line"></div><div class="line">下面是一个伪集群的例子：</div><div class="line"></div><div class="line">server.0=127.0.0.1:2008:6008  </div><div class="line">server.1=127.0.0.1:2007:6007  </div><div class="line">server.2=127.0.0.1:2006:6006  </div><div class="line">server.3=127.0.0.1:2005:6005</div></pre></td></tr></table></figure>
<h2 id="高级配置"><a href="#高级配置" class="headerlink" title="高级配置"></a>高级配置</h2><p>本节的配置选项是可选的。你可以使用它们进一步的优化 ZooKeeper 服务器的行为。有些可以使用 Java 系统属性来设置, 一般的格式是 “zookeeper.keyword”。如果有具体的系统属性, 会在配置选项下面标注出来。</p>
<h5 id="dataLogDir"><a href="#dataLogDir" class="headerlink" title="dataLogDir"></a>dataLogDir</h5><p>没有对应的 Java 系统属性。</p>
<p>该参数用于配置 ZooKeeper 服务器存储事务日志文件的路径, ZooKeeper 默认将事务日志文件和数据快照存储在同一个目录下, 应尽量将它们分开存储。</p>
<p>注意: 将事务日志文件存储到一个专门的日志设备上对于服务器的吞吐量和稳定的延迟有很大的影响。事务日志对磁盘性能要求比较高, 为了保证数据一致性, ZooKeeper 在响应客户端事务请求之前, 需要将请求的事务日志写到磁盘上, 所以事务日志的写入性能直接影响 ZooKeeper 服务器处理请求的吞吐。所以建议给事务日志的输出配置一个单独的磁盘或者挂载点。</p>
<h5 id="globalOutstandingLimit"><a href="#globalOutstandingLimit" class="headerlink" title="globalOutstandingLimit"></a>globalOutstandingLimit</h5><p>对应的 Java 系统属性: zookeeper.globalOutstandingLimit。</p>
<p>客户端提交请求的速度可能比 ZooKeeper 处理的速度快得多, 特别是当客户端的数量非常多的时候。为了防止 ZooKeeper 因为排队的请求而耗尽内存, ZooKeeper 将会对客户端进行限流, 即限制系统中未处理的请求数量不超过 globalOutstandingLimit 设置的值。默认的限制是 1,000。</p>
<h5 id="preAllocSize"><a href="#preAllocSize" class="headerlink" title="preAllocSize"></a>preAllocSize</h5><p>对应的 Java 系统属性: zookeeper.preAllocSize。</p>
<p>用于配置 ZooKeeper 事务日志文件预分配的磁盘空间大小。默认的块大小是 64M。改变块大小的其中一个原因是当数据快照文件生成比较频繁时可以适当减少块大小。比如 1000 次事务会新产生一个快照(参数为snapCount), 新产生快照后会用新的事务日志文件, 假设一个事务信息大小100b, 那么事务日志预分配的磁盘空间大小为100kb会比较好。</p>
<h5 id="snapCount"><a href="#snapCount" class="headerlink" title="snapCount"></a>snapCount</h5><p>对应的 Java 系统属性: zookeeper.snapCount。</p>
<p>ZooKeeper 将事务记录到事务日志中。当 snapCount 个事务被写到一个日志文件后, 启动一个快照并创建一个新的事务日志文件。snapCount 的默认值是 100,000。</p>
<h5 id="traceFile"><a href="#traceFile" class="headerlink" title="traceFile"></a>traceFile</h5><p>对应的 Java 系统属性: requestTraceFile。</p>
<p>如果定义了该选项, 那么请求将会记录到一个名为 traceFile.year.month.day 的跟踪文件中。使用该选项可以提供很有用的调试信息, 但是会影响性能。</p>
<p>注意: requestTraceFile 这个系统属性没有 zookeeper 前缀, 并且配置的变量名称和系统属性不一样。</p>
<h5 id="maxClientCnxns"><a href="#maxClientCnxns" class="headerlink" title="maxClientCnxns"></a>maxClientCnxns</h5><p>没有对应的 Java 系统属性</p>
<p>在 socket 级别限制单个客户端到 ZooKeeper 集群中单台服务器的并发连接数量, 可以通过 IP 地址来区分不同的客户端。它用来阻止某种类型的 DoS 攻击, 包括文件描述符资源耗尽。默认值是 60。将值设置为 0 将完全移除并发连接的限制。</p>
<h5 id="clientPortAddress"><a href="#clientPortAddress" class="headerlink" title="clientPortAddress"></a>clientPortAddress</h5><p>服务器监听客户端连接的地址 (ipv4, ipv6 或 主机名) , 亦即客户端尝试连接到服务器上的地址。该参数是可选的, 默认我们以这样一种方式绑定, 即对于服务器上任意 address/interface/nic, 任何连接到 clientPort 的请求将会被接受。</p>
<h5 id="minSessionTimeout"><a href="#minSessionTimeout" class="headerlink" title="minSessionTimeout"></a>minSessionTimeout</h5><p>没有对应的 Java 系统属性</p>
<p>服务器允许客户端会话的最小超时时间, 以毫秒为单位。默认值是 2 倍的 tickTime。</p>
<h5 id="maxSessionTimeout"><a href="#maxSessionTimeout" class="headerlink" title="maxSessionTimeout"></a>maxSessionTimeout</h5><p>没有对应的 Java 系统属性</p>
<p>服务器允许客户端会话的最大超时时间, 以毫秒为单位。默认值是 20 倍的 tickTime。</p>
<h5 id="fsync-warningthresholdms"><a href="#fsync-warningthresholdms" class="headerlink" title="fsync.warningthresholdms"></a>fsync.warningthresholdms</h5><p>对应的 Java 系统属性: fsync.warningthresholdms。</p>
<p>用于配置 ZooKeeper 进行事务日志 (WAL) fsync 操作消耗时间的报警阈值, 一旦超过这个阈值将会打印输出报警日志。该参数的默认值是 1000, 以毫秒为单位。参数值只能作为系统属性来设置。</p>
<h5 id="autopurge-snapRetainCount"><a href="#autopurge-snapRetainCount" class="headerlink" title="autopurge.snapRetainCount"></a>autopurge.snapRetainCount</h5><p>没有对应的 Java 系统属性。</p>
<p>当启用自动清理功能后, ZooKeeper 将只保留 autopurge.snapRetainCount 个最近的数据快照(dataDir)和对应的事务日志文件(dataLogDir), 其余的将会删除掉。默认值是 3。最小值也是 3。</p>
<h5 id="autopurge-purgeInterval"><a href="#autopurge-purgeInterval" class="headerlink" title="autopurge.purgeInterval"></a>autopurge.purgeInterval</h5><p>没有对应的 Java 系统属性。</p>
<p>用于配置触发清理任务的时间间隔, 以小时为单位。要启用自动清理, 可以将其值设置为一个正整数 (大于 1) 。默认值是 0。</p>
<h5 id="syncEnabled"><a href="#syncEnabled" class="headerlink" title="syncEnabled"></a>syncEnabled</h5><p>对应的 Java 系统属性: zookeeper.observer.syncEnabled。</p>
<p>和参与者一样, 观察者现在默认将事务日志以及数据快照写到磁盘上, 这将减少观察者在服务器重启时的恢复时间。将其值设置为 “false” 可以禁用该特性。默认值是 “true”。</p>
<p>集群配置选项</p>
<p>本节中的选项主要用于ZooKeeper集群。</p>
<h5 id="electionAlg"><a href="#electionAlg" class="headerlink" title="electionAlg"></a>electionAlg</h5><p>没有对应的 Java 系统属性。</p>
<p>用于选择使用的 leader 选举算法。”0” 对应于原始的基于 UDP 的版本, “1” 对应于快速 leader 选举基于UDP的无身份验证的版本, “2” 对应于快速 leader 选举有基于UDP的身份验证的版本, 而 “3” 对应于快速 leader 选举基于TCP的版本。目前默认值是算法 3。</p>
<p>注意: leader 选举 0, 1, 2 这三种实现已经废弃, 在接下来的版本中将会移除它们, 这样就只剩下 FastLeaderElection 算法。</p>
<h5 id="initLimit"><a href="#initLimit" class="headerlink" title="initLimit"></a>initLimit</h5><p>没有对应的 Java 系统属性。</p>
<p>默认值是 10, 即 tickTime 属性值的 10 倍。它用于配置允许 followers 连接并同步到 leader 的最大时间。如果 ZooKeeper 管理的数据量很大的话可以增加这个值。</p>
<h5 id="leaderServes"><a href="#leaderServes" class="headerlink" title="leaderServes"></a>leaderServes</h5><p>对应的 Java 系统属性: zookeeper.leaderServes。</p>
<p>用于配置 Leader 是否接受客户端连接, 默认值是 “yes”, 即 leader 将会接受客户端连接。在 ZooKeeper 中, leader 服务器主要协调事务更新请求。对于事务更新请求吞吐很高而读取请求吞吐很低的情况可以配置 leader 不接受客户端连接, 这样就可以专注于协调工作。</p>
<p>注意: 当 ZooKeeper 集群中服务器的数量超过 3 个时, 建议开启 leader 选举。</p>
<h5 id="server-x-hostname-nnnnn-nnnnn"><a href="#server-x-hostname-nnnnn-nnnnn" class="headerlink" title="server.x=[hostname]:nnnnn:nnnnn"></a>server.x=[hostname]:nnnnn:nnnnn</h5><p>没有对应的 Java 系统属性。</p>
<p>组成 ZooKeeper 集群的服务器。当服务器启动时, 可以通过查找数据目录中的 myid 文件来决定它是哪一台服务器。myid 文件包含服务器编号, 并且它要匹配 “server.x” 中的 x。</p>
<p>客户端用来组成 ZooKeeper 集群的服务器列表必须和每个 ZooKeeper 服务器中配置的 ZooKeeper 服务器列表相匹配。</p>
<p>有两个端口号 nnnnn, 第一个是 followers 用来连接到 leader, 第二个是用于 leader 选举。如果想在单台机器上测试多个服务, 则可以为每个服务配置不同的端口。</p>
<h5 id="syncLimit"><a href="#syncLimit" class="headerlink" title="syncLimit"></a>syncLimit</h5><p>没有对应的 Java 系统属性。</p>
<p>默认值是 5, 即 tickTime 属性值的 5 倍。它用于配置leader 和 followers 间进行心跳检测的最大延迟时间。如果在设置的时间内 followers 无法与 leader 进行通信, 那么 followers 将会被丢弃。</p>
<h5 id="group-x-nnnnn-nnnnn"><a href="#group-x-nnnnn-nnnnn" class="headerlink" title="group.x=nnnnn[:nnnnn]"></a>group.x=nnnnn[:nnnnn]</h5><p>没有对应的 Java 系统属性。</p>
<p>Enables a hierarchical quorum construction.”x” 是一个组的标识, 等号右边的数字对应于服务器的标识. 赋值操作右边是冒号分隔的服务器标识。注意: 组必须是不相交的, 并且所有组联合后必须是 ZooKeeper 集群。</p>
<h5 id="weight-x-nnnnn"><a href="#weight-x-nnnnn" class="headerlink" title="weight.x=nnnnn"></a>weight.x=nnnnn</h5><p>没有对应的 Java 系统属性。</p>
<p>和 “group” 一起使用, 当形成集群时它给每个服务器赋权重值。这个值对应于投票时服务器的权重。ZooKeeper 中只有少数部分需要投票, 比如 leader 选举以及原子的广播协议。服务器权重的默认值是 1。如果配置文件中定义了组, 但是没有权重, 那么所有服务器的权重将会赋值为 1。</p>
<h5 id="cnxTimeout"><a href="#cnxTimeout" class="headerlink" title="cnxTimeout"></a>cnxTimeout</h5><p>对应的 Java 系统属性: zookeeper.cnxTimeout。</p>
<p>用于配置 leader选举过程中，打开一次连接（选举的 server 互相通信建立连接）的超时时间。默认值是 5s。</p>
<h2 id="身份认证和授权选项"><a href="#身份认证和授权选项" class="headerlink" title="身份认证和授权选项"></a>身份认证和授权选项</h2><p>本节的选项允许通过身份认证和授权来控制服务执行。</p>
<p>zookeeper.DigestAuthenticationProvider.superDigest</p>
<p>对应的 Java 系统属性: zookeeper.DigestAuthenticationProvider.superDigest。</p>
<p>该功能默认是禁用的。</p>
<p>能够使 ZooKeeper 集群管理员可以作为一个 “super” 用户来访问 znode 层级结构。特别是对于一个已经认证为超级管理员的用户不需要 ACL 检查。</p>
<p>org.apache.zookeeper.server.auth.DigestAuthenticationProvider 可以用来生成 superDigest, 调用它带有 “super:<password>“ 参数的方法。当启动集群中的每台服务器时, 将生成的 “super:<data>“ 作为系统属性提供。</data></password></p>
<p>当 ZooKeeper 客户端向 ZooKeeper 服务器进行身份认证时, 会传递一个 “digest” 和 “super:<password>“ 的认证数据. 注意摘要式身份验证将认证数据以普通文本的形式传递给服务器, 在网络中需要谨慎使用该认证方法, 要么只在本机上或通过一个加密的连接。</password></p>
<h5 id="实验性选项-特性"><a href="#实验性选项-特性" class="headerlink" title="实验性选项/特性"></a>实验性选项/特性</h5><p>本节列举了一些目前还处于实验阶段的新特性。</p>
<h5 id="服务器只读模式"><a href="#服务器只读模式" class="headerlink" title="服务器只读模式"></a>服务器只读模式</h5><p>对应的 Java 系统属性: readonlymode.enabled。</p>
<p>将其设置为 true 将会启用服务器只读模式支持, 默认是禁用的。ROM 允许请求了 ROM 支持的客户端会话连接到服务器, 即使当服务器可能已经从集群中分隔出去。在该模式中, ROM 客户端仍然可以从 ZK 服务中读取值, 但是不能进行写操作以及看见其它客户端所做的一些变更。更多详细信息可以参见 ZOOKEEPER-784 获取更多详细信息。</p>
<h5 id="不安全的选项"><a href="#不安全的选项" class="headerlink" title="不安全的选项"></a>不安全的选项</h5><p>下面的选项会很有用, 但是使用的时候需要特别小心。</p>
<h5 id="forceSync"><a href="#forceSync" class="headerlink" title="forceSync"></a>forceSync</h5><p>对应的 Java 系统属性: zookeeper.forceSync。</p>
<p>用于配置是否需要在事务日志提交的时候调用 FileChannel.force 来保证数据完全同步到磁盘。默认值是 “yes”。如果该选项设置为 “no”, ZooKeeper 将不会强制同步事务更新日志到磁盘。</p>
<h5 id="jute-maxbuffer"><a href="#jute-maxbuffer" class="headerlink" title="jute.maxbuffer:"></a>jute.maxbuffer:</h5><p>对应的 Java 系统属性: jute.maxbuffer。没有 zookeeper 前缀。</p>
<p>用于指定一个 znode 中可以存储数据量的最大值, 默认值是 0xfffff, 或 1M 内。如果这个选项改变了, 那么该系统属性必须在所有的服务端和客户端进行设置, 否则会出现问题。ZooKeeper旨在存储大小为千字节数量的数据。</p>
<h5 id="skipACL"><a href="#skipACL" class="headerlink" title="skipACL"></a>skipACL</h5><p>对应的 Java 系统属性: zookeeper.skipACL。</p>
<p>用于配置 ZooKeeper 服务器跳过 ACL 权限检查。这将一定程度的提高服务器吞吐量, 但是也向所有客户端完全开放数据访问。</p>
<h5 id="quorumListenOnAllIPs"><a href="#quorumListenOnAllIPs" class="headerlink" title="quorumListenOnAllIPs"></a>quorumListenOnAllIPs</h5><p>当设置为 true 时, ZooKeeper 服务器将会在所有可用的 IP 地址上监听来自其对等点的连接请求, 而不仅是配置文件的服务器列表中配置的地址。它会影响处理 ZAB 协议和 Fast Leader Election 协议的连接。默认值是 false。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2017/05/26/Bigdata-hadoop/zookeeper/Bigdata-ZooKeeper集群快速搭建与优化/">Bigdata-ZooKeeper集群快速搭建与优化</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-05-26</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/大数据/">大数据</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Big-data-Hadoop/">Big data Hadoop</a>
			</span>
		
	</div>

	

	
		<h3 id="ZooKeeper集群快速搭建与优化"><a href="#ZooKeeper集群快速搭建与优化" class="headerlink" title="ZooKeeper集群快速搭建与优化"></a>ZooKeeper集群快速搭建与优化</h3><p>之前搞过了hadoop和spark，hue，现在在弄下zookeeper集群，文档就整理下。<br>本文是<code>ZooKeeper</code>的快速搭建,旨在帮助大家以最快的速度完成一个<code>ZK</code>集群的搭建,以便开展其它工作。</p>
<h2 id="集群："><a href="#集群：" class="headerlink" title="集群："></a>集群：</h2><p>本文使用了3台机器部署ZooKeeper集群，IP和主机名对应关系如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">IP            主机名</div><div class="line">10.46.72.172  namenode</div><div class="line">10.47.88.103  datenode1</div><div class="line">10.47.88.206  datenode2</div></pre></td></tr></table></figure>
<h3 id="安装说明"><a href="#安装说明" class="headerlink" title="安装说明"></a>安装说明</h3><p><code>Zookeeper</code>机器间不需要设置免密码登录，其它hadoop也可以不设置，只要不使用hadoop-daemons.sh来启动、停止进程，注意不是hadoop-daemon.sh，而是带“s”的那个，带“s”的会读取hadoop的salves文件，远程ssh启动DataNode和备NameNode等。</p>
<h3 id="配置-etc-hosts"><a href="#配置-etc-hosts" class="headerlink" title="配置/etc/hosts"></a>配置/etc/hosts</h3><p>将3台机器的IP和主机名映射关系，在3台机器上都配置一下，亦即在3台机器的/etc/hosts文件中，均增加以下内容（可以先配置好一台，然后通过scp等命令复制到其它机器上，注意主机名不能包含任何下划线）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">127.0.0.1 localhost  namenode</div><div class="line">::1        localhost localhost.localdomain localhost6 localhost6.localdomain6</div><div class="line">10.47.100.90 salt</div><div class="line">10.46.72.172  namenode</div><div class="line">10.47.88.103 datenode1</div><div class="line">10.47.88.206 datenode2</div><div class="line">10.47.102.137 datenode3</div></pre></td></tr></table></figure>
<h3 id="Step1"><a href="#Step1" class="headerlink" title="Step1:"></a>Step1:</h3><p>配置 JAVA 环境。检验方法:执行 <code>java –version</code> 和 <code>javac –version</code> 命令。</p>
<p>下载并解压 <code>zookeeper</code>。<a href="http://mirror.bjtu.edu.cn/apache/zookeeper/zookeeper-3.4.3/" target="_blank" rel="external">链接一</a> ，<a href="http://www-eu.apache.org/dist/zookeeper/" target="_blank" rel="external">链接二</a> (更多版本:<a href="http://dwz.cn/37HGI" target="_blank" rel="external">http://dwz.cn/37HGI</a>)</p>
<h3 id="Step2"><a href="#Step2" class="headerlink" title="Step2:"></a>Step2:</h3><p>2.zookeeper的环境变量的配置：<br>为了今后操作方便，我们需要对Zookeeper的环境变量进行配置，方法如下：<br>在/etc/profile文件中加入如下的内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#set zookeeper environment</span></div><div class="line"></div><div class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/srv/hadoop/zookeeper-3.3.6</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOOKEEPER_HOME</span>/bin:<span class="variable">$ZOOKEEPER_HOME</span>/conf</div></pre></td></tr></table></figure>
<h3 id="Step3"><a href="#Step3" class="headerlink" title="Step3:"></a>Step3:</h3><p>下载以后解压到我自己新建的：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[hadoop@namenode ~]$ tar -zxvf zookeeper-3.3.6.tar.gz -C /srv/hadoop/</div><div class="line">[hadoop@namenode ]$ <span class="built_in">cd</span> /srv/hadoop/zookeeper-3.3.6/conf/</div></pre></td></tr></table></figure>
<p>将<code>zoo_sample.cfg</code>拷贝一份命名为<code>zoo.cfg</code>,这里我拷贝一份命名为：<code>zoo.cfg</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[hadoop@namenode conf]$ cp -r zoo_sample.cfg zoo.cfg</div></pre></td></tr></table></figure>
<p>这里先创建/data和/logs 这两个目录。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p /srv/hadoop/zookeeper-3.3.6/zookeeper/data</div><div class="line">mkdir -p /srv/hadoop/zookeeper-3.3.6/zookeeper/logs</div></pre></td></tr></table></figure>
<p>注意上图的配置中master，slave1分别为主机名。</p>
<p>在上面的配置文件中<code>&quot;server.id=host:port:port&quot;</code>中的第一个port是从机器<code>（follower）</code>连接到主机器<code>（leader）</code>的端口号，第二个port是进行leadership选举的端口号。</p>
<p>修改配置：</p>
<p><code>vi zoo.cfg</code>，修改有的默认存在，添加红色的内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">tickTime=2000</div><div class="line"></div><div class="line">clientPort=2181</div><div class="line"></div><div class="line">initLimit=10</div><div class="line"></div><div class="line">syncLimit=5</div><div class="line">maxClientCnxns=0 这个是设置连接数0没有做限制</div><div class="line">dataDir=/haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data</div><div class="line">dataLogDir=/haozhuo/hadoop/zookeeper-3.3.6/zookeeper/logs</div><div class="line"></div><div class="line">server.0=namenode:2888:3888</div><div class="line">server.1=datanode1:2888:3888</div><div class="line">server.2=datanode2:2888:3888</div></pre></td></tr></table></figure>
<h3 id="创建maid"><a href="#创建maid" class="headerlink" title="创建maid:"></a>创建maid:</h3><p>这里所有节点都需要创建。<br>接下来在<code>dataDir</code>所指定的目录下创建一个文件名为<code>myid</code>的文件，文件中的内容只有一行，为本主机对应的id值，也就是上图中server.id中的id。例如：在服务器1中的myid的内容应该写入1。<br>创建myid：在<code>zoo.cfg</code>配置文件中的dataDir的目录下面创建<code>myid</code>，每个节点myid要求不一样：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /srv/hadoop/zookeeper-3.3.6/zookeeper/data</div><div class="line">touch myid</div></pre></td></tr></table></figure>
<h3 id="Step4"><a href="#Step4" class="headerlink" title="Step4:"></a>Step4:</h3><p>远程复制分发安装文件<br>最好是把文件打包scp过去<br>接下来将上面的安装文件拷贝到集群中的其他机器上对应的目录下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">haduser@master:~/zookeeper$ scp -r zookeeper-3.4.5/ slave1:/srv/hadoop/</div><div class="line"></div><div class="line">haduser@master:~/zookeeper$ scp -r zookeeper-3.4.5/ slave2:/srv/hadoop/</div></pre></td></tr></table></figure>
<p>拷贝完成后修改对应的机器上的myid。例如修改slave1中的myid如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">haduser@slave1:~/zookeeper/zookeeper-3.4.5$ <span class="built_in">echo</span> <span class="string">"2"</span> &gt; data/myid</div><div class="line">haduser@slave1:~/zookeeper/zookeeper-3.4.5$ cat data/myid</div><div class="line">[hadoop@namenode hadoop]$ <span class="built_in">echo</span> 0 &gt; /haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data/myid</div><div class="line">[hadoop@datanode1 hadoop]$ <span class="built_in">echo</span> 1 &gt; /haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data/myid</div><div class="line">[hadoop@datanode2 hadoop]$ <span class="built_in">echo</span> 2 &gt; /haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data/myid</div></pre></td></tr></table></figure>
<h3 id="Step5"><a href="#Step5" class="headerlink" title="Step5:"></a>Step5:</h3><p>启动 ZooKeeper集群<br>在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本，如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hadoop@namenode:~ /srv/hadoop/zookeeper-3.3.6/bin/zkServer.sh start</div><div class="line">hadoop@datanode1:~ /srv/hadoop/zookeeper-3.3.6/bin/zkServer.sh start</div><div class="line">haduser@datanode2:~ /srv/hadoop/zookeeper-3.3.6/bin/zkServer.sh start</div></pre></td></tr></table></figure>
<p>执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/haozhuo/hadoop/zookeeper-3.3.6/bin/zkServer.sh start</div></pre></td></tr></table></figure>
<h3 id="Step6"><a href="#Step6" class="headerlink" title="Step6:"></a>Step6:</h3><p>检测是否成功启动:执行 <code>jps</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">24933 QuorumPeerMain</div></pre></td></tr></table></figure>
<p>其中，QuorumPeerMain是zookeeper进程，启动正常。</p>
<p><code>./zkServer.sh status</code> 查看当前运行状态。</p>
<p>namenode1</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[hadoop@namenode zookeeper-3.3.6]<span class="comment"># ./zkServer.sh status</span></div><div class="line">JMX enabled by default</div><div class="line">Using config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfg</div><div class="line">Mode: follower</div><div class="line"></div><div class="line">[hadoop@datanode1 zookeeper-3.3.6]<span class="comment"># ./bin/zkServer.sh status</span></div><div class="line">JMX enabled by default</div><div class="line">Using config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfg</div><div class="line">Mode: leader</div><div class="line"></div><div class="line">[hadoop@datanode2 zookeeper-3.3.6]<span class="comment"># ./bin/zkServer.sh status</span></div><div class="line">JMX enabled by default</div><div class="line">Using config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfg</div><div class="line">Mode: leader</div></pre></td></tr></table></figure>
<h3 id="链接测试"><a href="#链接测试" class="headerlink" title="链接测试"></a>链接测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bin/zkCli.sh -server 127.0.0.1:2181</div><div class="line">bin/zkCli.sh -server 127.0.0.1:2181</div><div class="line">bin/zkCli.sh -server 127.0.0.1:2181</div></pre></td></tr></table></figure>
<h3 id="Step7"><a href="#Step7" class="headerlink" title="Step7:"></a>Step7:</h3><p>如果单台可以其他几台不行，看配置，如果没有问题。启动查看状态出现异常。</p>
<p>异常解决:<code>Error contacting service. It is probably not running.</code></p>
<p>而其他一个节点却是现实正常;</p>
<p>先<code>stop</code> 掉原<code>zk</code></p>
<p><code>./bin/zkServer.sh stop</code></p>
<p>然后以start-foreground方式启动，会看到启动日志</p>
<p><code>./bin/zkServer.sh start</code></p>
<p>当出现问题的时候，记得查看日志zookeeper.out，在你配置的dataDir（在conf/zoo.cfg中查看）目录下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">2015-12-29 11:09:38,034 [myid:1] - WARN  [WorkerSender[myid=1]:QuorumCnxManager@400] - Cannot open channel to 3 at election address Node2/10.0.0.102:38888</div><div class="line">java.net.ConnectException: 拒绝连接</div><div class="line">        at java.net.PlainSocketImpl.socketConnect(Native Method)</div><div class="line">        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)</div><div class="line">        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)</div><div class="line">        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)</div><div class="line">        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)</div><div class="line">        at java.net.Socket.connect(Socket.java:579)</div><div class="line">        at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:381)</div><div class="line">        at org.apache.zookeeper.server.quorum.QuorumCnxManager.toSend(QuorumCnxManager.java:354)</div><div class="line">        at org.apache.zookeeper.server.quorum.FastLeaderElection<span class="variable">$Messenger</span><span class="variable">$WorkerSender</span>.process(FastLeaderElection.java:452)</div><div class="line">        at org.apache.zookeeper.server.quorum.FastLeaderElection<span class="variable">$Messenger</span><span class="variable">$WorkerSender</span>.run(FastLeaderElection.java:433)</div><div class="line">        at java.lang.Thread.run(Thread.java:745)</div></pre></td></tr></table></figure>
<p>可以看到是连接到Node2的3888端口不通（我配置文件设置的节点端口，server.3=Node2:2888:3888），这样就找到问题了，所以当遇到问题的时候记得查看日志文件，这才是最有帮助的，而不是修改什么nc参数。</p>
<p>这里主要看下是否加入hosts</p>
<p>查看Node2节点发现，38888端口绑带到127.0.0.1上了，这让Master节点怎么连接呀，只需修改/etc/hosts文件即可，同理，修改Node1，然后重启zookeeper，发现问题解决。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">127.0.0.1 localhost  namenode</div><div class="line">::1        localhost localhost.localdomain localhost6 localhost6.localdomain6</div><div class="line">10.47.100.90 salt</div><div class="line">10.46.72.172  namenode</div><div class="line">10.47.88.103 datenode1</div><div class="line">10.47.88.206 datenode2</div><div class="line">10.47.102.137 datenode3</div></pre></td></tr></table></figure>
<p>这里我<code>127.0.0.1 localhost namenode</code> 就可以了。</p>
<h3 id="Step8-如何扩容zookeeper？"><a href="#Step8-如何扩容zookeeper？" class="headerlink" title="Step8: 如何扩容zookeeper？"></a>Step8: 如何扩容zookeeper？</h3><p>只需要将已有的zookeeper打包复制到新的机器上，然后修改myid文件并设置好，然后启动zookeeper即可。</p>
<hr>
<h3 id="设置开机自动启动"><a href="#设置开机自动启动" class="headerlink" title="设置开机自动启动"></a>设置开机自动启动</h3><p>1.写个启动脚本放到/etc/rc.d/init.d/zookeeper</p>
<p>这里touch zookeeper &amp;&amp; chmod +x zookeeper &amp;&amp; vim zookeeper</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">!/bin/bash</div><div class="line"><span class="comment">#chkconfig:2345 20 90</span></div><div class="line"><span class="comment">#description:zookeeper</span></div><div class="line"><span class="comment">#processname:zookeeper</span></div><div class="line"><span class="built_in">export</span> JAVA_HOME=/srv/jdk1.8.0_66</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></div><div class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></div><div class="line">    start) su root /srv/zookeeper-3.3.6/bin/zkServer.sh start;;</div><div class="line">    stop) su root /srv/zookeeper-3.3.6/bin/zkServer.sh stop;;</div><div class="line">    status) su root /srv/zookeeper-3.3.6/bin/zkServer.sh status;;</div><div class="line">    restart) su root /srv/zookeeper-3.3.6/bin/zkServer.shrestart;;</div><div class="line">    *)  <span class="built_in">echo</span> <span class="string">"requirestart|stop|status|restart"</span>;;</div><div class="line"><span class="keyword">esac</span></div></pre></td></tr></table></figure>
<p>2.设置开机启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chkconfig zookeeper on</div></pre></td></tr></table></figure>
<p>3.验证</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">chkconfig --add zookeeper</div><div class="line">chkconfig --list zookeeper</div></pre></td></tr></table></figure>
<p>这个时候我们就可以用service zookeeper start/stop来启动停止zookeeper服务了.<br>使用<code>chkconfig--add zookeeper</code>命令把<code>zookeeper</code>添加到开机启动里面<br>添加完成之后接这个使用<code>chkconfig--list</code>来看看我们添加的<code>zookeeper</code>是否在里面<br>如果上面的操作都正常的话；重启服务器测试就行。</p>
<div class="tip"><br><br>注意：zookeeper重启出现几种报错：<br><br>1. 启动服务报错找不到指定好的pid文件。<br>2. 关闭服务报错没有在/tmp/路径下面没有/srv/zookeeper-3.3.6/zookeeper/data/zookeeper_server.pid<br></div>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@zookeeper zookeeper-3.3.6]<span class="comment"># ./bin/zkServer.sh start</span></div><div class="line">JMX enabled by default</div><div class="line">Using config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfg</div><div class="line">Starting zookeeper ... ./bin/zkServer.sh: line 93: [: /tmp/zookeeper: binary operator expected</div><div class="line">./bin/zkServer.sh: line 103: /tmp/zookeeper</div><div class="line">/srv/zookeeper-3.3.6/zookeeper/data/zookeeper_server.pid: 没有那个文件或目录</div><div class="line">FAILED TO WRITE PID</div><div class="line">[root@zookeeper zookeeper-3.3.6]<span class="comment"># ./bin/zkServer.sh stop</span></div><div class="line">JMX enabled by default</div><div class="line">Using config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfg</div><div class="line">Stopping zookeeper ... no zookeeper to stop (could not find file /tmp/zookeeper</div><div class="line">/srv/zookeeper-3.3.6/zookeeper/data/zookeeper_server.pid)</div></pre></td></tr></table></figure>
<p>解决方法：网上很少有人讲这么详细，这里我就说下，就是你在修改zoo.cfg配置文件里面：</p>
<p>dataDir指定的路径是自定义的话等于的时候不要空格写。</p>
<p>如果重新另外写dataDir ,不要注释掉之前的，最好直接删除，重新指定这样就不会报错了，如果注释掉默认的<code>#dataDir = /tmp</code>这里需要空格。</p>
<h3 id="报错-占用端口："><a href="#报错-占用端口：" class="headerlink" title="报错 占用端口："></a>报错 占用端口：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">JMX enabled by default</div><div class="line">Using config: /opt/app/zookeeper/bin/../conf/zoo3.cfg</div><div class="line">Starting zookeeper ... STARTED</div></pre></td></tr></table></figure>
<p>查看状态：<br>用jps命令查看进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># jps</span></div><div class="line">24617 QuorumPeerMain （这个就是zookeeper进程）</div><div class="line"></div><div class="line">/opt/app/zookeeper/bin/zkServer.sh status zoo1.cfg</div><div class="line">JMX enabled by default</div><div class="line">Using config: /opt/app/zookeeper/bin/../conf/zoo1.cfg</div><div class="line">Error contacting service. It is probably not running.</div></pre></td></tr></table></figure>
<p>Ihaozhuo_b3314<br>说明有错误，查看日志文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># cd &lt;zookeeper_home&gt;</span></div><div class="line"><span class="comment"># less zookeeper.out</span></div><div class="line">java.net.BindException: 地址已在使用</div><div class="line">杀掉当前进程：</div><div class="line"><span class="comment"># kill -9 24617</span></div></pre></td></tr></table></figure>
<h3 id="报错-启动服务正常。"><a href="#报错-启动服务正常。" class="headerlink" title="报错: 启动服务正常。"></a>报错: 启动服务正常。</h3><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@api1 zookeeper<span class="number">-3.3</span><span class="number">.6</span>]<span class="comment"># ./bin/zkServer.sh start</span></div><div class="line">JMX enabled <span class="keyword">by</span> <span class="keyword">default</span></div><div class="line">Using config: <span class="regexp">/srv/zookeeper-3.3.6/bin/</span>../conf/zoo.cfg</div><div class="line">Starting zookeeper ... STARTED</div></pre></td></tr></table></figure>
<p>可是查询进程不存在，可是看pid是有的，然后关闭服务就说没有这个进程。</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">JMX enabled by <span class="keyword">default</span></div><div class="line">Using <span class="string">config:</span> <span class="regexp">/srv/</span>zookeeper<span class="number">-3.3</span><span class="number">.6</span><span class="regexp">/bin/</span>..<span class="regexp">/conf/</span>zoo.cfg</div><div class="line">Stopping zookeeper ... ./zkServer.<span class="string">sh:</span> line <span class="number">133</span>: <span class="string">kill:</span> (<span class="number">31415</span>) - 没有那个进程</div></pre></td></tr></table></figure>
<h3 id="走kafka查看是否所有节点都启动："><a href="#走kafka查看是否所有节点都启动：" class="headerlink" title="走kafka查看是否所有节点都启动："></a>走kafka查看是否所有节点都启动：</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@kafka_03 bin]<span class="comment"># sh zkCli.sh</span></div><div class="line">Connecting to localhost:2181</div><div class="line">2017-01-04 19:20:24,849 [myid:] - INFO  [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT</div><div class="line">2017-01-04 19:20:24,853 [myid:] - INFO  [main:Environment@100] - Client environment:host.name=kafka_03</div><div class="line">2017-01-04 19:20:24,853 [myid:] - INFO  [main:Environment@100] - Client environment:java.version=1.8.0_66</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.vendor=Oracle Corporation</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.home=/srv/jdk1.8.0_66/jre</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.class.path=/srv/zookeeper-3.4.6/bin/../build/classes:/srv/zookeeper-3.4.6/bin/../build/lib/*.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/srv/zookeeper-3.4.6/bin/../lib/<span class="built_in">log</span>4j-1.2.16.jar:/srv/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/srv/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/srv/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/srv/zookeeper-3.4.6/bin/../conf:</div><div class="line">2017-01-04 19:20:24,856 [myid:] - INFO  [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib</div><div class="line"></div><div class="line">[zk: localhost:2181(CONNECTED) 0] ls /</div><div class="line">[controller_epoch, brokers, zookeeper, kafka, dubbo, admin, isr_change_notification, consumers, config, sthp]</div><div class="line">[zk: localhost:2181(CONNECTED) 5] ls /kafka/brokers/ids</div><div class="line">[0, 1, 2]</div><div class="line"></div><div class="line">显示0 1 2 三台集群机器。</div></pre></td></tr></table></figure>
<p>kafka 三台集群这里可以看到获取到ids。</p>
<h3 id="Step9-相关文档"><a href="#Step9-相关文档" class="headerlink" title="Step9: 相关文档"></a>Step9: 相关文档</h3><p>《HBase-0.98.0分布式安装指南》</p>
<p>《Hive 0.12.0安装指南》</p>
<p>《ZooKeeper-3.4.6分布式安装指南》</p>
<p>《Hadoop 2.3.0源码反向工程》</p>
<p>《在Linux上编译Hadoop-2.4.0》</p>
<p>《Accumulo-1.5.1安装指南》</p>
<p>《Drill 1.0.0安装指南》</p>
<p>《Shark 0.9.1安装指南》</p>
<p>更多，敬请关注技术博客：<a href="http://blog.yancy.cc">http://blog.yancy.cc</a></p>
<h3 id="Step10-结束语"><a href="#Step10-结束语" class="headerlink" title="Step10:  结束语"></a>Step10:  结束语</h3><p>至此，ZooKeeper分布式安装大告成功！更多细节，请浏览<a href="http://zookeeper.apache.org/doc/trunk/zookeeperStarted.html" target="_blank" rel="external">官方文档</a></p>

	

	

</article>




	<article>
	
		<h1><a href="/2017/05/08/Bigdata-hadoop/HORTONW0RKS数据平台实现搭建Ambari配置和部署HDP集群监控Hadoop集群 /">HORTONW0RKS数据平台实现搭建Ambari配置和部署HDP集群监控Hadoop集群</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2017-05-08</span><br />
		
			<span class="article__category">
				<a class="article-category-link" href="/categories/大数据/">大数据</a>
			</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-link" href="/tags/Ambari/">Ambari</a> <a class="article__tag-link" href="/tags/Big-data-Hadoop/">Big data Hadoop</a>
			</span>
		
	</div>

	

	
		<h2 id="HORTONW0RKS数据平台搭建Ambari管理监控Hadoop集群"><a href="#HORTONW0RKS数据平台搭建Ambari管理监控Hadoop集群" class="headerlink" title="HORTONW0RKS数据平台搭建Ambari管理监控Hadoop集群"></a>HORTONW0RKS数据平台搭建Ambari管理监控Hadoop集群</h2><p><strong> 题外话 </strong></p>
<p>我现在在一家上市公司旗下控股子公司负责运维部门，负责IT网络安全办公：主要做的应用运维和网络运维，兼大数据运维。<br>最近跟新来的架构师聊了下Hadoop监控方面：HORTONW0RKS数据平台搭建Ambari监控Hadoop集群.</p>
<p><strong>HORTONW0RKS数据平台（HDP ®）</strong><br>HDP是业内唯一真正安全的企业级开源的<code>Apache的Hadoop™ ®</code>分配基于集中式架构。HDP解决了静态数据的完整需求，为实时客户应用提供支持，并提供可加速决策和创新的可靠分析。</p>
<p>使用Hortonworks Sandbox试用最新的HDP功能，或者为生产环境设置HDP，安装和配置群集。<br>查看官网文档：<a href="https://hortonworks.com/downloads/#data-platform" target="_blank" rel="external">HORTONWORKS CONNECTED DATA PLATFORMS DOWNLOADS</a></p>
<h3 id="1-将Ambari服务存储库文件下载到安装主机上的目录。"><a href="#1-将Ambari服务存储库文件下载到安装主机上的目录。" class="headerlink" title="1. 将Ambari服务存储库文件下载到安装主机上的目录。"></a>1. 将Ambari服务存储库文件下载到安装主机上的目录。</h3><ul>
<li>Centos6.5 </li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.4.2.0/ambari.repo -O /etc/yum.repos.d/ambari.repo</div></pre></td></tr></table></figure>
<p>⚠️警告：不要修改<code>ambari.repo</code>文件名。在代理注册期间，此文件应在Ambari服务器主机上可用。</p>
<ol>
<li>通过检查repo列表确认存储库已配置。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum repolist</div></pre></td></tr></table></figure>
<p>您应该在列表中看到类似于以下Ambari存储库的值。</p>
<p>版本值因安装而异。</p>
<ol>
<li>安装Ambari服务。这也安装了默认的PostgreSQL Ambari数据库。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install ambari-server</div></pre></td></tr></table></figure>
<p>输入<code>y</code>提示，以确认交易和依赖性检查时。</p>
<p>成功安装将显示类似于以下内容的输出：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">安装：postgresql-libs-8.4.20-3.el6_6.x86_64 1/4</div><div class="line">安装：postgresql-8.4.20-3.el6_6.x86_64 2/4</div><div class="line">安装：postgresql-server-8.4.20-3.el6_6.x86_64 3/4</div><div class="line">安装：ambari-server-2.4.2.0-1470.x86_64 4/4</div><div class="line">验证：ambari-server-2.4.2.0-1470.x86_64 1/4</div><div class="line">验证：postgresql-8.4.20-3.el6_6.x86_64 2/4</div><div class="line">验证：postgresql-server-8.4.20-3.el6_6.x86_64 3/4</div><div class="line">验证：postgresql-libs-8.4.20-3.el6_6.x86_64 4/4</div><div class="line"></div><div class="line">安装：</div><div class="line">  ambari-server.x86_64 0：2.4.2.0-1470  安装这里的时候会有点慢，因为是访问国外网站下载资源。</div><div class="line"></div><div class="line">已安装依赖关系：</div><div class="line"> postgresql.x86_64 0：8.4.20-3.el6_6           </div><div class="line"> postgresql-libs.x86_64 0：8.4.20-3.el6_6        </div><div class="line"> postgresql-server.x86_64 0：8.4.20-3.el6_6</div></pre></td></tr></table></figure>
<p>❗️❗️【注意】</p>
<p>接受有关信任<code>Hortonworks GPG</code>密钥的警告。该键将自动下载并用于验证Hortonworks的软​​件包。您将看到以下消息：</p>
<p>Importing GPG key 0x07513CAD: Userid: “Jenkins (HDP Builds) <a href="&#x6d;&#97;&#105;&#x6c;&#116;&#111;&#58;&#106;&#101;&#110;&#107;&#x69;&#x6e;&#x40;&#104;&#111;&#114;&#116;&#x6f;&#110;&#119;&#111;&#114;&#x6b;&#115;&#46;&#99;&#111;&#109;">&#106;&#101;&#110;&#107;&#x69;&#x6e;&#x40;&#104;&#111;&#114;&#116;&#x6f;&#110;&#119;&#111;&#114;&#x6b;&#115;&#46;&#99;&#111;&#109;</a>“ From :<code>http://s3.amazonaws.com/dev.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</code></p>
<p>❗️❗️【注意】</p>
<p>在具有有限Internet访问或没有Internet访问的群集上部署HDP时，应使用其他方法提供对位的访问。<br>有关设置本地存储库的详细信息，请参阅使用本地存储库。</p>
<p><code>Ambari</code>服务器默认使用嵌入式<code>PostgreSQL</code>数据库。当您安装<code>Ambari</code>服务器时，PostgreSQL软件包和依赖关系必须可用于安装。这些包通常作为操作系统存储库的一部分提供。请确认您具有适用于<code>postgresql-server</code>软件包的相应存储库。</p>
<h3 id="2-设置Ambari服务器"><a href="#2-设置Ambari服务器" class="headerlink" title="2.设置Ambari服务器"></a>2.设置Ambari服务器</h3><p>在启动<code>Ambari</code>服务器之前，必须设置Ambari服务器。安装程序将Ambari配置为与Ambari数据库通信，安装JDK并允许您自定义Ambari Server守护程序将作为运行的用户帐户。该 <code>ambari-server setup</code>命令管理设置过程。在Ambari服务器主机上运行以下命令以开始设置过程。您还可以将“ 设置选项”附加到命令。</p>
<ul>
<li>启动服务</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line">ambari-server setup</div><div class="line"></div><div class="line"><span class="comment">###这里由于下载jdk1.8太慢速度过慢。我提前把jdk下载下来放到了/srv/jdk1.8.0_66 目录</span></div><div class="line"></div><div class="line">[root@ambari-server_01 ~]<span class="comment"># ambari-server setup</span></div><div class="line">Using python  /usr/bin/python</div><div class="line">Setup ambari-server</div><div class="line">Checking SELinux...</div><div class="line">SELinux status is <span class="string">'enabled'</span></div><div class="line">SELinux mode is <span class="string">'permissive'</span></div><div class="line">WARNING: SELinux is <span class="built_in">set</span> to <span class="string">'permissive'</span> mode and temporarily disabled.</div><div class="line">OK to <span class="built_in">continue</span> [y/n] (y)? y</div><div class="line">Customize user account <span class="keyword">for</span> ambari-server daemon [y/n] (n)? y</div><div class="line">Enter user account <span class="keyword">for</span> ambari-server daemon (root):</div><div class="line">Adjusting ambari-server permissions and ownership...</div><div class="line">Checking firewall status...</div><div class="line">Checking JDK...</div><div class="line">[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8</div><div class="line">[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7</div><div class="line">[3] Custom JDK</div><div class="line">==============================================================================</div><div class="line">Enter choice (1): 3</div><div class="line">WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.</div><div class="line">WARNING: JCE Policy files are required <span class="keyword">for</span> configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.</div><div class="line">Path to JAVA_HOME: /srv/jdk1.8.0_66</div><div class="line">Validating JDK on Ambari Server...done.</div><div class="line">Completing setup...</div><div class="line">Configuring database...</div><div class="line">Enter advanced database configuration [y/n] (n)? y</div><div class="line">Configuring database...</div><div class="line">==============================================================================</div><div class="line">Choose one of the following options:</div><div class="line">[1] - PostgreSQL (Embedded)</div><div class="line">[2] - Oracle</div><div class="line">[3] - MySQL / MariaDB</div><div class="line">[4] - PostgreSQL</div><div class="line">[5] - Microsoft SQL Server (Tech Preview)</div><div class="line">[6] - SQL Anywhere</div><div class="line">[7] - BDB</div><div class="line">==============================================================================</div><div class="line">Enter choice (1):3</div><div class="line">Database name (ambari):</div><div class="line">Postgres schema (ambari):</div><div class="line">Username (ambari):</div><div class="line">Enter Database Password (bigdata):</div><div class="line">Default properties detected. Using built-in database.</div><div class="line">Configuring ambari database...</div><div class="line">Checking PostgreSQL...</div><div class="line">Running initdb: This may take up to a minute.</div><div class="line">正在初始化数据库：[确定]</div><div class="line"></div><div class="line">About to start PostgreSQL</div><div class="line">Configuring <span class="built_in">local</span> database...</div><div class="line">Connecting to <span class="built_in">local</span> database...done.</div><div class="line">Configuring PostgreSQL...</div><div class="line">Restarting PostgreSQL</div><div class="line">Extracting system views...</div><div class="line">ambari-admin-2.4.2.0.136.jar</div><div class="line">............</div><div class="line">Adjusting ambari-server permissions and ownership...</div><div class="line">Ambari Server <span class="string">'setup'</span> completed successfully.</div><div class="line">You have mail <span class="keyword">in</span> /var/spool/mail/root</div></pre></td></tr></table></figure>
<h5 id="2-1-响应安装提示："><a href="#2-1-响应安装提示：" class="headerlink" title="2.1 响应安装提示："></a>2.1 响应安装提示：</h5><p>如果您没有暂时禁用<code>SELinux</code>，您可能会收到警告。接受默认值<code>（y）</code>，然后继续。</p>
<p>默认情况下，Ambari服务器运行在<code>root</code>。在<code>Customize user account for ambari-server daemon</code>提示符处接受默认<code>（n）</code>，以继续root。</p>
<p>如果要创建其他用户以运行<code>Ambari</code>服务器或分配以前创建的用户，请<code>y</code>在 <code>Customize user account for ambari-server daemon</code>提示符处选择，然后提供用户名。<br>有关以非root用户身份运行Ambari服务器的更多信息，请参阅Hortonworks数据平台Apache Ambari参考&gt; <a href="http://docs.hortonworks.com/HDPDocuments/Ambari-2.4.2.0/bk_ambari-security/content/configuring_ambari_for_non-root.html" target="_blank" rel="external">为非根用户配置Ambari</a></p>
<p>如果您没有暂时停用<code>iptables</code>，可能会收到警告。输入<code>y</code>以继续。</p>
<p>JDK<br>选择要下载的<code>JDK</code>版本。输入<code>1</code>以下载<code>Oracle JDK 1.8</code>。或者，您可以选择输入<code>自定义JDK</code>。如果选择“<code>自定义JDK</code>”，则必须在所有主机上手动安装JDK并指定<code>Java Home</code>路径。</p>
<p>❗️❗️【注意】</p>
<p>JDK支持完全取决于您选择的<code>HDP Stack</code>版本。请参阅<a href="http://docs.hortonworks.com/HDPDocuments/Ambari-2.4.2.0/bk_ambari-reference/content/ch_changing_the_jdk_version_on_an_existing_cluster.html" target="_blank" rel="external">Hortonworks数据平台Apache Ambari</a>参考以查看要安装的HDP Stack版本支持的JDK版本。默认情况下，Ambari服务器设置下载并安装Oracle JDK 1.8和随附的Java密码术扩展（JCE）策略文件。如果计划使用其他版本的JDK，请参阅 设置选项以获取更多信息。</p>
<p>出现提示时接受<code>Oracle JDK</code>许可证。您必须接受此许可证才能从Oracle下载必需的JDK。JDK在部署阶段安装。</p>
<blockquote>
<p>数据库选择：</p>
</blockquote>
<p>选择<code>n</code>为，<code>Enter advanced database configuration</code>以便为<code>Ambari</code>使用默认的嵌入式<code>PostgreSQL</code>数据库。默认的PostgreSQL数据库名是ambari。默认用户名和密码为ambari/bigdata。否则，要使用现有的PostgreSQL，MySQL / MariaDB或Oracle数据库与Ambari，请选择y。</p>
<p>如果使用现有的PostgreSQL，MySQL / MariaDB或Oracle数据库实例，请使用以下提示之一：</p>
<p>❗️❗️[重要]<br>在运行安装程序和输入高级数据库配置之前，必须使用<code>“使用非默认数据库</code>- Ambari”中详述的步骤准备非默认数据库实例。</p>
<p>❗️❗️[重要]</p>
<p>不支持使用Microsoft SQL Server或SQL Anywhere数据库选项。</p>
<p>要使用现有的Oracle实例，并为该数据库选择自己的数据库名称，用户名和密码，请输入<code>2</code>。<br>选择要使用的数据库，并提供在提示中请求的任何信息，包括主机名，端口，服务名或SID，用户名和密码。<br>要使用现有的MySQL / MariaDB数据库，并为该数据库选择自己的数据库名称，用户名和密码，请输入3。<br>选择要使用的数据库，并提供在提示中请求的任何信息，包括主机名，端口，数据库名称，用户名和密码。<br>要使用现有的PostgreSQL数据库，并为该数据库选择自己的数据库名称，用户名和密码，请输入4。<br>选择要使用的数据库，并提供在提示中请求的任何信息，包括主机名，端口，数据库名称，用户名和密码。<br>继续配置远程数据库连接属性[y / n]选择<code>y</code>。</p>
<blockquote>
<p>这里数据库用户名和密码都是默认安装：</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Database name (ambari)</div><div class="line">Postgres schema (ambari)</div><div class="line">Username (ambari)</div><div class="line">Enter Database Password (bigdata)</div></pre></td></tr></table></figure>
<blockquote>
<p>这里我做了一层Nginx代理：将Ambari服务器配置为使用此代理服务器</p>
</blockquote>
<h3 id="3-启动Ambari服务器"><a href="#3-启动Ambari服务器" class="headerlink" title="3.启动Ambari服务器"></a>3.启动Ambari服务器</h3><p>在Ambari服务器主机上运行以下命令：</p>
<pre><code>ambari-server start
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@ambari-server ~]<span class="comment"># ambari-server start</span></div><div class="line">Using python  /usr/bin/python</div><div class="line">Starting ambari-server</div><div class="line">Ambari Server running with administrator privileges.</div><div class="line">Organizing resource files at /var/lib/ambari-server/resources...</div><div class="line">Ambari database consistency check started...</div><div class="line">No errors were found.</div><div class="line">Ambari database consistency check finished</div><div class="line">Server PID at: /var/run/ambari-server/ambari-server.pid</div><div class="line">Server out at: /var/<span class="built_in">log</span>/ambari-server/ambari-server.out</div><div class="line">Server <span class="built_in">log</span> at: /var/<span class="built_in">log</span>/ambari-server/ambari-server.log</div><div class="line">Waiting <span class="keyword">for</span> server start....................</div><div class="line">Ambari Server <span class="string">'start'</span> completed successfully.</div><div class="line">You have mail <span class="keyword">in</span> /var/spool/mail/root</div></pre></td></tr></table></figure>
<p>要检查Ambari服务器进程：</p>
<pre><code>ambari-server status
</code></pre><p>停止Ambari服务器：</p>
<pre><code>ambari-server stop
</code></pre><p>在Ambari服务器启动时，<code>Ambari</code>运行数据库一致性检查，查找问题。如果发现任何问题，Ambari服务器启动将中止，并且一条消息将打印到控制台“数据库配置一致性检查失败”。更多详细信息将写入以下日志文​​件：</p>
<pre><code>/var/log/ambari-server/ambari-server-check-database.log
</code></pre><p>您可以通过使用以下选项跳过此检查来强制Ambari服务器启动：</p>
<pre><code>ambari-server start --skip-database-check
</code></pre><p>如果存在数据库问题，请选择跳过此检查，在更正数据库一致性问题之前，不要对集群拓扑进行任何更改或执行集群升级。最好查看官网操作。</p>
<h2 id="第3章安装，配置和部署HDP集群"><a href="#第3章安装，配置和部署HDP集群" class="headerlink" title="第3章安装，配置和部署HDP集群"></a>第3章安装，配置和部署HDP集群</h2><h3 id="1-登录到Apache-Ambari"><a href="#1-登录到Apache-Ambari" class="headerlink" title="1.登录到Apache Ambari"></a>1.登录到Apache Ambari</h3><ul>
<li><p>将浏览器指向 <code>http://&lt;your.ambari.server&gt; :8080</code>，其中<code>&lt;your.ambari.server&gt;</code>是您的ambari服务器主机的名称。例如，默认Ambari服务器主机位于<code>http://c6401.ambari.apache.org:8080</code>。</p>
</li>
<li><p>使用默认用户名/密码登录Ambari服务器：<code>admin / admin</code>。您可以稍后更改这些凭据。</p>
</li>
</ul>
<h3 id="2-启动Ambari安装向导"><a href="#2-启动Ambari安装向导" class="headerlink" title="2.启动Ambari安装向导"></a>2.启动Ambari安装向导</h3><p>从<code>Ambari Welcome</code>页面，选择启动安装向导。</p>
<p>提供集群，管理谁可以访问群集，以及自定义视图为Ambari用户。</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/Ambariwelcome.png" alt=""></figure></p>
<p><figure class="figure"><img src="http://docs.hortonworks.com/HDPDocuments/Ambari-2.4.2.0/bk_ambari-installation/content/figures/2/figures/170AmbariWelcome.png" alt=""></figure></p>
<h3 id="3-命名您的群集"><a href="#3-命名您的群集" class="headerlink" title="3.命名您的群集"></a>3.命名您的群集</h3><p>在Name your cluster，键入要创建的集群的名称。名称中不要使用空格或特殊字符。</p>
<p>选择Next。</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_02.png" alt=""></figure></p>
<h3 id="4-选择版本"><a href="#4-选择版本" class="headerlink" title="4.选择版本"></a>4.选择版本</h3><p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_03.png" alt=""></figure></p>
<p>这里我选择<code>redhat6</code> 其他的都<code>remove</code>掉。</p>
<p>在此步骤中，您将选择群集的软件版本和交付方式。使用公共存储库需要Internet连接。使用本地存储库需要您在网络中可用的存储库中配置软件。</p>
<ul>
<li>选择堆栈</li>
</ul>
<p>可用的HDP版本显示在TAB中。当您选择TAB时，Ambari会尝试发现该HDP堆栈的特定版本可用。该列表显示在DROPDOWN中。对于该特定版本，将显示可用的服务，其中的版本显示在TABLE中。</p>
<ul>
<li>选择版本</li>
</ul>
<p>如果Ambari可以访问Internet，则特定版本将作为选项列在DROPDOWN中。如果您有未列出的版本的版本定义文件，您可以单击添加版本…并上载VDF文件。此外，如果您无法访问Internet或不确定要安装哪个特定版本，则 默认版本定义也包含在列表中。</p>
<ul>
<li>选择存储库</li>
</ul>
<p>Ambari允许您选择从公共存储库（如果您有Internet访问权限）或本地存储库安装软件。无论您的选择如何，您都可以编辑存储库的基本URL。将显示可用的操作系统，您可以从列表中添加/删除操作系统以适合您的环境</p>
<p>❗️❗️注意<br>UI显示基于操作系统系列（OS系列）的存储库基本URL。请确保基于正在运行的操作系统设置正确的操作系统系列。下表将OS系列映射到操作系统。</p>
<ul>
<li><p><strong>高级选项</strong></p>
</li>
<li><p><strong>有高级存储库选项可用。</strong></p>
</li>
</ul>
<p>跳过存储库基本URL验证（高级）： 当您单击下一步时，Ambari将尝试连接到存储库基本URL，并验证您已输入验证存储库。如果没有，将显示一个错误，您必须在继续之前纠正。</p>
<p>使用<code>RedHat Satellite/Spacewalk：</code>仅当计划使用本地存储库时，才会启用此选项。当您为软件存储库选择此选项时，您负责配置<code>Satellite/Spacewalk</code>中的存储库通道，并确认所选群集版本的存储库在群集中的主机上可用。</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_04.png" alt=""></figure></p>
<h3 id="5-安装选项"><a href="#5-安装选项" class="headerlink" title="5.安装选项"></a>5.安装选项</h3><p>为了构建集群，安装向导将提示您有关如何设置它的一般信息。您需要提供每个主机的FQDN。该向导还需要访问在设置无密码SSH中创建的私钥文件  。使用主机名和密钥文件信息，向导可以定位，访问和与群集中的所有主机安全交互。</p>
<p>使用Target Hosts文本框输入主机名列表，每行一个。您可以使用括号内的范围来表示较大的主机集。例如，对于host01.domain通过host10.domain使用 host[01-10].domain</p>
<p>⚠️ <strong>安装服务器集群机器一定要系统版本要一致不然安装会提示版本不兼容。</strong></p>
<p>❗️❗️    注意<br>如果要在EC2上部署，请使用内部专用<code>DNS主机名</code>。</p>
<p>在ambari服务器配置hosts</p>
<pre><code>vim /etc/hosts
</code></pre><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">192<span class="selector-class">.168</span><span class="selector-class">.1</span><span class="selector-class">.151</span>    <span class="selector-tag">datanode151</span></div><div class="line">192<span class="selector-class">.168</span><span class="selector-class">.1</span><span class="selector-class">.173</span>    <span class="selector-tag">datanode_173</span> <span class="selector-tag">datanode-173</span><span class="selector-class">.hadoop</span></div></pre></td></tr></table></figure>
<p>如果要让<code>Ambari</code>使用SSH在所有主机上自动安装Ambari代理，请选择<code>Provide your SSH Private Key</code>并使用部分中的 <code>Choose File</code>按钮<code>Host Registration Information</code>查找与先前在所有主机上安装的公钥相匹配的私钥文件，或者剪切并粘贴键手动插入文本框。</p>
<p>填写您选择的SSH密钥的用户名。如果不想使用root用户，则必须为可以在不输入密码的情况下执行sudo的帐户提供用户名。如果您的环境中的主机上的SSH配置为22以外的端口，您也可以更改它。</p>
<p>如果您不希望Ambari自动安装Ambari代理，请选择<code>Perform manual registration</code>。有关更多信息，请参阅手动安装Ambari代理。</p>
<p>选择<code>Register and Confirm</code>继续。</p>
<p>这里提示：The following hostnames are not valid FQDNs: datanode_173.hadoop</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_06.png" alt=""></figure></p>
<p>这里跳转到安装页面：发现报错提示datanode-173.hadoop主机访问Ambari机器不能访问。<br><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_07.png" alt=""></figure></p>
<h3 id="6-确认主机"><a href="#6-确认主机" class="headerlink" title="6.确认主机"></a>6.确认主机</h3><p><code>Confirm Hosts</code> 提示您确认<code>Ambari</code>已为您的集群找到正确的主机，并检查这些主机以确保它们具有继续安装所需的正确目录，软件包和进程。</p>
<p>如果选择了错误的主机，您可以通过选择相应的复选框并单击灰色<code>Remove Selected</code>按钮来删除它们。要删除单个主机，请单击Remove“操作”列中的小白色按钮。</p>
<p>在屏幕底部，您可能会注意到一个黄色框，表示在检查过程中遇到了一些警告。例如，您的主机可能已有<code>wget</code>或的副本 <code>curl</code>。选择<code>Click here to see the warnings</code> 查看检查内容和导致警告的原因的列表。警告页面还提供对python脚本的访问，可以帮助您清除可能遇到的任何问题，让您运行<code>Rerun Checks</code>。</p>
<p>在datanode_173服务器配置hosts</p>
<pre><code>vim /etc/hosts
</code></pre><figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">192<span class="selector-class">.168</span><span class="selector-class">.1</span><span class="selector-class">.151</span>    <span class="selector-tag">datanode151</span></div><div class="line">192<span class="selector-class">.168</span><span class="selector-class">.1</span><span class="selector-class">.173</span>    <span class="selector-tag">datanode_173</span> <span class="selector-tag">datanode-173</span><span class="selector-class">.hadoop</span></div></pre></td></tr></table></figure>
<p>每台节点里配置FQDN，如下以主节点为例</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">vi /etc/sysconfig/network</div><div class="line">NETWORKING=yes</div><div class="line">HOSTNAME=SY-001.hadoop</div></pre></td></tr></table></figure>
<p>配置上就可以了。 把datanode151也是ambari机器配置在hosts就可以了。</p>
<p><strong>最好设置root的无密码登录，因为我们配置的集群都是内网的，没什么安全性问题，使用root操作可以省去一些麻烦，非root用户可能在安装Hadoop组件时不能成功</strong></p>
<p>下面是我安装这里提示没有找到文件目录查看安装报错操作：</p>
<pre><code>mkdir /var/lib/ambari-agent/data
</code></pre><p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/Ambari_08.png" alt=""></figure><br><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_09.png" alt=""></figure><br><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_10.png" alt=""></figure></p>
<h3 id="7-选择服务"><a href="#7-选择服务" class="headerlink" title="7.选择服务"></a>7.选择服务</h3><p>将看到选择要安装到群集中的服务。HDP堆栈包括许多服务。您可以选择立即安装任何其他可用服务，或稍后添加服务。默认情况下，安装向导将选择所有可用的服务进行安装。</p>
<p>选择<code>none</code>清除所有选择，或选择 <code>all</code>选择所有列出的服务。</p>
<p>选择或清除单个复选框以定义一组要立即安装的服务。</p>
<p>选择要立即安装的服务后，选择Next。</p>
<p><figure class="figure"><img src="http://7xrthw.com1.z0.glb.clouddn.com/ambari_11.png" alt=""></figure></p>
<h3 id="8-分配主站"><a href="#8-分配主站" class="headerlink" title="8.分配主站"></a>8.分配主站</h3><p>Ambari安装向导会将所选服务的主组件分配给集群中的相应主机，并在Assign Masters中显示分配。左列显示服务和当前主机。右列显示主机的当前主组件分配，指示每个主机上安装的CPU内核数量和RAM数量。</p>
<p>要更改服务的主机分配，请从该服务的下拉菜单中选择主机名。</p>
<p>要删除ZooKeeper实例，请单击要删除的主机地址旁边的绿色减号图标。</p>
<p>当您对作业感到满意时，选择Next。</p>
<p><figure class="figure"><img src="" alt=""></figure></p>
<h3 id="9-分配从属和客户端"><a href="#9-分配从属和客户端" class="headerlink" title="9.分配从属和客户端"></a>9.分配从属和客户端</h3><p>Ambari安装向导将从属组件（DataNodes，NodeManager和RegionServers）分配给集群中的相应主机。它还会尝试选择主机以安装适当的客户端集。</p>
<p>使用<code>all</code>或<code>none</code>可分别选择列中的所有主机或不选择任何主机。</p>
<p>如果主机旁边有星号，则该主机也运行一个或多个主组件。将鼠标悬停在星号上，以查看该主机上的哪些主组件。</p>
<p>通过使用特定主机旁边的复选框来微调您的选择。</p>
<p>当你对你的作业感到满意时，选择<code>Next</code>。</p>
<h3 id="10-自定义服务"><a href="#10-自定义服务" class="headerlink" title="10.自定义服务"></a>10.自定义服务</h3><p>自定义服务步骤为您提供一组选项卡，您可以查看和修改HDP集群设置。向导会尝试为每个选项设置合理的默认值。你是强烈建议，以检查这些设置为您的要求可能略有不同。</p>
<p>浏览每个服务标签，然后将光标悬停在每个属性上，您可以看到属性做什么的简要说明。显示的服务选项卡数取决于您决定在群集中安装的服务。任何需要输入的选项卡都会显示一个红色徽章，其中包含需要注意的属性数。选择显示红色徽章编号的每个服务选项卡，然后输入相应的信息。</p>
<ul>
<li>目录</li>
</ul>
<p>HDP将存储信息的目录的选择是至关重要的。Ambari将尝试根据您环境中可用的安装点选择合理的默认值，但强烈建议您查看Ambari推荐的默认目录设置。特别是，确认目录，例如<code>/tmp和 /var</code>被不被用于下<code>HDFS的NameNode</code>目录和数据管理部目录HDFS标签。</p>
<ul>
<li>密码</li>
</ul>
<p>您必须为Hive和Oozie服务以及Knox的主密钥提供数据库密码。使用Hive作为示例，选择Hive选项卡并展开高级部分。在以红色标记的数据库密码字段中，提供密码，然后重新键入以确认。</p>
<p>安装各个服务，并且完成安装后会启动相关服务，安装过程比较长，如中中出现错误，根据具体提供或日志进行操作。 </p>
<p>这里我就不贴出来了，因为测试环境机器我做测试用机器配置不够所有后面结果经验写出来了。</p>
<p>安装的还是提示失败：<code>ImportError: No module named rpm</code></p>
<p>参考这篇文章重新安装解决了这个问题：<a href="http://stackoverflow.com/questions/17490921/no-module-named-rpm-when-i-call-yum-on-shell" target="_blank" rel="external">ImportError: No module named rpm</a></p>
<h3 id="11-安装，启动和测试"><a href="#11-安装，启动和测试" class="headerlink" title="11.安装，启动和测试"></a>11.安装，启动和测试</h3><p>安装的进度将显示在屏幕上。Ambari安装，启动，并对每个组件运行一个简单的测试。过程的总体状态显示在屏幕顶部的进度栏中，主机的主机状态显示在主要部分。在此过程中不要刷新浏览器。刷新浏览器可能会中断进度指示器。</p>
<p>要查看每个主机已完成的任务的具体信息，请单击Message相应主机列中的链接。在 Tasks弹出窗口中，单击单个任务以查看相关的日志文件。您可以使用Show下拉列表选择过滤条件。要查看更大版本的日志内容，请单击Open图标或将内容复制到剪贴板，使用Copy图标。</p>
<p><strong>安装完成效果图:</strong></p>
<p><figure class="figure"><img src="http://hortonassets.s3.amazonaws.com/ambari1_7/ambari002.png" alt=""></figure></p>
<blockquote>
<p>让我们从左侧栏或下拉菜单中选择Yarn进入YARN信息中心。</p>
</blockquote>
<p><figure class="figure"><img src="http://hortonassets.s3.amazonaws.com/ambari1_7/ambari004.png" alt=""></figure></p>
<blockquote>
<p>我们将开始更新线程容量调度策略的配置。</p>
</blockquote>
<p><figure class="figure"><img src="http://hortonassets.s3.amazonaws.com/ambari1_7/ambari005.png" alt=""></figure></p>
<p>向下滚动到<code>Scheduler</code>页面的部分。默认容量调度策略只有一个队列。</p>
<p><figure class="figure"><img src="http://hortonassets.s3.amazonaws.com/ambari1_7/ambari006.png" alt=""></figure></p>
<p>让我们看看调度策略。向上滚动到页面顶部，然后点击快速链接。然后从下拉列表中选择<code>ResourceManager UI</code>。</p>
<p><figure class="figure"><img src="http://hortonassets.s3.amazonaws.com/ambari1_7/ambari007.png" alt=""></figure></p>
<blockquote>
<p>正如你可以看到，我们只有默认策略。</p>
</blockquote>
<p><figure class="figure"><img src="http://hortonassets.s3.amazonaws.com/ambari1_7/ambari008.png" alt=""></figure></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>安装Ambari官网地址<a href="https://docs.hortonworks.com/HDPDocuments/Ambari-2.4.2.0/bk_ambari-installation/content/download_the_ambari_repo_lnx6.html" target="_blank" rel="external">install Ambari</a><br><a href="https://cwiki.apache.org/confluence/display/AMBARI/Installation+Guide+for+Ambari+2.4.2" target="_blank" rel="external">编译安装Ambari 2.4.2安装指南</a></p>

	

	

</article>





	<span class="different-posts">📖 <a href="/page/5">more posts</a> 📖</span>



	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>Hi there, <br />welcome to my Blog glad you found it. Have a look around, will you?</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2017 Yancy | Powered by <a href="http://blog.yancy.cc/">Yancy</a> | Theme <a href="https://github.com/yangcvo">Yancy_GitHub</a></span>
		</div>

	</div>


</footer>



</body>

</html>
